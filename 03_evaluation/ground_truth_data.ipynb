{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2289d66-c5e2-48e4-b77b-904849350fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c442131-4589-4cf9-beea-009d52379ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766e6ecc-f0f1-47be-9ad9-c69960bcd3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data-engineering-zoomcamp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]['course']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d94dba9c-d759-45fa-b4a9-b15aa3698cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data-engineering-zoomcamp-Course - What are the prerequisites for this course?-GitHub - D'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{documents[1]['course']}-{documents[1]['question']}-{documents[1]['text'][:10]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef92b834-2bd9-4429-b8ef-46f4eefedee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    # combined = f\"{doc['course']}-{doc['question']}\"\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7423bf-3aba-4c96-b521-3be3dbab00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc['id'] = generate_document_id(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a183741b-f5ea-4362-8d7a-495d57f402af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': '1f6520ca'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1307ae-68ac-468b-800a-40e4f76f1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6860bfb5-1079-4411-9426-3c0ddcb04657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947, 948)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes =  defaultdict(list)\n",
    "\n",
    "for doc in documents:\n",
    "    h = generate_document_id(doc)\n",
    "    doc['id'] = h\n",
    "    hashes[h].append(doc)\n",
    "\n",
    "len(hashes), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885483e8-4d24-4655-bb2f-6f5917a409af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': '1f6520ca'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e57975-c3ec-498c-ae8a-f122fa657cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593f7569\n"
     ]
    }
   ],
   "source": [
    "for k, values in hashes.items():\n",
    "    if len(values) > 1:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba14e92-1f4c-487b-a10b-08df68b60fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"They both do the same, it's just less typing from the script.\\nAsked by Andrew Katoch, Added by Edidiong Esu\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'},\n",
       " {'text': \"They both do the same, it's just less typing from the script.\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes['593f7569']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b7afb65-2372-4556-81ad-f1cd83694fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd256aa9-701c-4164-9757-2abc99d2df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('documents-with-ids.json', 'wt') as f_out:\n",
    "     json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddcefccd-ae44-4d6f-bc48-8f44227d5cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
      "    \"section\": \"General course-related questions\",\n",
      "    \"question\": \"Course - When will the course start?\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"id\": \"c02e79ef\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites\",\n"
     ]
    }
   ],
   "source": [
    "!head documents-with-ids.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e36abd06-57a8-40b7-8eb7-c6cd2d1b2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a student who's taking our course.\n",
    "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02349658-f763-4c9a-8ccc-096f33e7a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8374a6d-3543-4590-8ce7-867fdfcac9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[2]\n",
    "prompt = prompt_template.format(**doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c34f2e58-b54b-4a0b-9dc2-46a54599a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You emulate a student who's taking our course.\n",
      "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
      "should contain the answer to the questions, and the questions should be complete and not too short.\n",
      "If possible, use as fewer words as possible from the record. \n",
      "\n",
      "The record:\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "Provide the output in parsable JSON without using code blocks:\n",
      "\n",
      "[\"question1\", \"question2\", ..., \"question5\"]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebdbd4f-e917-4552-9a8b-4407f5d28182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9070fbd-dd24-420c-8b9b-a60e84755ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_questions = generate_questions(documents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c0adffb-be15-4f53-b86c-20fb86c7d523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is it possible to enroll in the course after it has already started?',\n",
       " 'What happens if I miss the registration deadline for the course?',\n",
       " 'Can I participate in homework submissions if I join late?',\n",
       " 'Are there any deadlines I need to consider for final projects?',\n",
       " 'Should I avoid procrastinating on my course assignments?']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39954682-4a88-4533-83ce-1ecc93c238ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a42b4c52-a67f-4fa7-b8e1-6660472fdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14d54ce6-c08e-4513-b0fd-f63378d9e977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 948/948 [39:40<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# for doc in tqdm(documents):\n",
    "#     doc_id = doc['id']\n",
    "#     if doc_id in results:\n",
    "#         continue\n",
    "#     questions = generate_questions(doc)\n",
    "#     results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc567d5-df65-4ab9-b284-3209c8eb370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcac481a-369d-47b2-b938-4b6a36b693f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8e47385-84f1-4129-ad0d-3e71d0a3e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# After your loop that fills results:\n",
    "with open('results.bin', 'wb') as f_out:\n",
    "    pickle.dump(results, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "78788bd4-2a88-4394-9f1c-03bf627135a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.bin', 'rb') as f_in:\n",
    "    results = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25580318-182b-4bcd-b97d-bb9dbf765146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c02e79ef': '[\\n    \"What is the specific date and time when the course is set to begin?\",\\n    \"How can I stay updated with course announcements and important dates?\",\\n    \"Is there a registration process required before the course starts?\",\\n    \"What platform should I use to access the course\\'s public calendar?\",\\n    \"Where can I find the link to register for the course?\"\\n]',\n",
       " '1f6520ca': '[\\n    \"What specific skills or knowledge do I need before enrolling in this course?\",\\n    \"Can you point me to where I can find the requirements for this course?\",\\n    \"Are there any prior courses or experiences necessary for joining this program?\",\\n    \"Is there a resource that outlines the prerequisites for this course?\",\\n    \"What should I have completed before I start this course?\"\\n]',\n",
       " '7842b56a': '[\\n    \"Is it possible to enroll in the course after it has begun?\",\\n    \"If I miss the registration, can I still participate in homework assignments?\",\\n    \"Are there any specific deadlines I should know about for the final project?\",\\n    \"What happens if I complete my final project after the deadline?\",\\n    \"Should I manage my time carefully to avoid last-minute submissions?\"\\n]',\n",
       " '0bbf41ec': '[\"When will I get a confirmation email after registering for the bootcamp?\", \"Is it necessary to wait for a confirmation email to start the course?\", \"Can I begin submitting my assignments without formal registration?\", \"What is the purpose of the registration for the Data Engineering Bootcamp?\", \"How does the registration process work for this course?\"]',\n",
       " '63394d91': '[\"What steps should I take to prepare for the course prior to its start?\", \"Are there any specific software or accounts I need to set up before the course begins?\", \"What prerequisites should I review to ensure I\\'m ready for the course?\", \"Is there a particular programming language I need to have installed before the course starts?\", \"What tools and technologies should I familiarize myself with ahead of the course?\"]',\n",
       " '2ed9b986': '[\\n    \"How many Zoom Camps are offered annually for this course?\",\\n    \"What are the specific time frames for each Zoom Camp throughout the year?\",\\n    \"Is there only one live cohort available for the Data-Engineering Zoom Camp each year?\",\\n    \"Can I participate in any Zoom Camp at my own pace if I don\\'t want a certificate?\",\\n    \"Are the schedules for each cohort consistent across different Zoom Camps?\"\\n]',\n",
       " '93e2c8ed': '[\\n  \"Will the 2024 cohort have different tools compared to the previous one?\",\\n  \"What AI tool will be used in the 2024 edition of the course?\",\\n  \"Are there any updated videos for the 2024 course cohort?\",\\n  \"What was used in the course for the 2023 edition instead of Airflow?\",\\n  \"How does the 2024 course differ from the one in 2023?\"\\n]',\n",
       " 'a482086d': '[\"Is it possible to access course materials after the course ends?\", \"Can I work on assignments after completion of the course?\", \"Will I be able to prepare for the next cohort after the course finishes?\", \"Can I start my capstone project after the course is over?\", \"How can I continue my learning journey after the course concludes?\"]',\n",
       " 'eb56ae98': '[\"Is there any support available for students in the self-paced course format?\", \"Where can I find answers to my questions about the course?\", \"How should I approach getting help if I encounter an issue while studying?\", \"Can I use the Slack channel for support while taking the course at my own pace?\", \"What should I do before asking a question in the Slack channel?\"]',\n",
       " '4292531b': '[\\n    \"Where can I find the main videos for our course on YouTube?\",\\n    \"Is there a specific GitHub repository that lists the video thumbnails linking to the playlist?\",\\n    \"Are there any additional playlists for this year available in the course materials?\",\\n    \"How do I access the year-specific playlist for office hours videos?\",\\n    \"Where is the main playlist for the DATA ENGINEERING course pinned in our communication tools?\"\\n]',\n",
       " 'ea739c65': '[\"What is the weekly time commitment for this course?\", \"How should I determine my expected hours per week?\", \"Is the required study time the same for everyone?\", \"Can I assess my own time investment for the course?\", \"What factors influence the number of hours needed weekly?\"]',\n",
       " 'cb257ee5': '[\"Is it possible to earn a certificate while taking the course at my own pace?\", \"What are the requirements for obtaining a certificate in this course?\", \"Why can\\'t I receive a certificate if I choose the self-paced option?\", \"Are peer-reviews necessary for earning the course certificate?\", \"When can I peer-review projects during the course?\"]',\n",
       " '04aa4897': '[\\n  \"Where can I find the video link for the Office Hour sessions?\",\\n  \"How do students submit questions during the workshop sessions?\",\\n  \"Is the Zoom link available to students for the Office Hours?\",\\n  \"When will the video URL for the sessions be announced?\",\\n  \"What platform should I use to watch the Office Hour sessions live?\"\\n]',\n",
       " '9681be3b': '[\"Will the Office Hours be recorded if I cannot make it to the live session?\", \"How soon after the Office Hours ends will the recording be available?\", \"Can I watch the recorded Office Hours at my convenience?\", \"Is there a way to access past Office Hours recordings?\", \"What happens if I miss the live workshop during Office Hours?\"]',\n",
       " 'a1daf537': '[\\n    \"What is the best way to keep track of my homework and project deadlines for this course?\",\\n    \"Where can I find the most current deadlines for assignments and projects?\",\\n    \"How should I stay updated on possible extensions or changes to deadlines?\",\\n    \"Is there a specific link to check for deadlines and updates throughout the course?\",\\n    \"What should I do if I believe a deadline has been changed or extended?\"\\n]',\n",
       " 'be5bfee4': '[\"Is it permitted to submit homework after the due date?\", \"What happens if I miss the deadline for homework submissions?\", \"Can I turn in my homework if the submission process is still open?\", \"How can I confirm my homework submission after it\\'s due?\", \"Are there any exceptions to the late submission policy for homework?\"]',\n",
       " '0e424a44': '[\\n    \"What specific URL do I need to provide for homework submissions?\",\\n    \"Where should I store my code for the homework assignments?\",\\n    \"Is it acceptable to use platforms other than GitHub for my homework?\",\\n    \"What criteria should my homework repository meet?\",\\n    \"How should I ensure my code is accessible for review?\"\\n]',\n",
       " '29865466': '[\\n    \"How is homework graded and how can I check my points for it?\",\\n    \"What does the leaderboard display in terms of my total points?\",\\n    \"Can you explain how points are earned from FAQ submissions?\",\\n    \"How many points can I earn from sharing my learning publicly?\",\\n    \"Where can I find the points I\\'ve accumulated for each homework task?\"\\n]',\n",
       " '016d46a1': '[\\n    \"How was my display name determined when I created my account for the course?\",\\n    \"Where can I find my current display name to check my leaderboard status?\",\\n    \"Is it possible to change my display name once I see it?\",\\n    \"What steps should I follow to view my display name in the course profile?\",\\n    \"Why am I not appearing on the leaderboard and how can I confirm my display name?\"\\n]',\n",
       " '47972cb1': '[\"Is Python 3.9 the preferred version for this course in 2024?\", \"Will using Python 3.10 or 3.11 cause issues with the course?\", \"Why is Python 3.9 recommended over other versions?\", \"Are there any advantages to using Python 3.9 in this course?\", \"What should I do if I have Python 3.10 or 3.11 installed?\"]',\n",
       " 'ddf6c1b3': '[\\n    \"What are the options for setting up my environment for this course?\",\\n    \"Are there any specific challenges for Windows users when working locally?\",\\n    \"What should I do if I want to start with Docker for my local setup?\",\\n    \"How can I use GitHub Codespaces for my virtual machine environment?\",\\n    \"Is it possible to work from different devices during the boot camp?\" \\n]',\n",
       " 'ac25d3af': '[\"Can I use GitHub Codespaces instead of CLI or Git Bash for data ingestion?\", \"What resources does GitHub Codespaces provide for my project?\", \"Does GitHub Codespaces come with pre-installed tools I might need?\", \"Is it possible to access GitHub repositories directly from a Codespace?\", \"How can GitHub Codespaces assist in creating a Docker file?\"]',\n",
       " '251218fc': '[\"Is GitHub Codespaces mandatory for this course?\", \"Can I use my own installed PostgreSQL and Docker for the assignments?\", \"Are there alternative environments besides GitHub Codespaces?\", \"Is it acceptable to complete the course using my personal laptop?\", \"Do I have to use the recommended platforms for the course?\"]',\n",
       " '3c0114ce': '[\"Do I have to use both GitHub Codespaces and GCP for the course?\", \"Which option should I choose for my final project development?\", \"Is it necessary to learn BigQuery during the course?\", \"Can I create a local environment instead of using the cloud platforms?\", \"What environment suits my project idea best?\"]',\n",
       " 'f43f5fe7': '[\\n    \"What steps should I follow to open the Run command window on my Windows machine?\",\\n    \"How can I access the Registry Editor to change registry values?\",\\n    \"What specific registry value do I need to modify to resolve the GCP VM connection issue?\",\\n    \"Is there an alternative way to address connection problems with a GCP VM besides changing registry values?\",\\n    \"Where can I find the known_hosts file on my Windows machine to delete the saved fingerprint?\"\\n]',\n",
       " 'd061525d': '[\\n  \"What are the main reasons for choosing GCP as the primary cloud provider for this course?\",\\n  \"Am I allowed to use other cloud platforms like AWS instead of GCP during the course?\",\\n  \"Is there any cost involved when signing up for a free GCP account?\",\\n  \"What benefits do new users receive when they start using GCP?\",\\n  \"Can you explain the relationship between BigQuery and GCP in the context of this course?\"\\n]',\n",
       " '1cd01b2c': '[\"Is it necessary to pay for cloud services during the course?\", \"What are the cloud service options available to us?\", \"How can I utilize GCP for free?\", \"Are there any costs associated with using cloud platforms in this course?\", \"Will using cloud services incur any fees while enrolled?\"]',\n",
       " 'e4a7c3b0': '[\\n    \"Is it feasible to complete the course without using cloud platforms like GCP?\",\\n    \"Are there local alternatives available for all the tools covered in the course?\",\\n    \"Can the course be entirely done using a home setup instead of cloud services?\",\\n    \"Will there be any materials provided for running elements of the course locally?\",\\n    \"Is BigQuery the only component of the course that requires cloud access?\"\\n]',\n",
       " '7cd1912e': '[\"Is it allowed to utilize AWS for the course assignments, and what should I keep in mind while doing so?\", \"What are the main tasks I need to focus on for the final capstone project?\", \"Will there be enough peers available for assistance if I choose AWS over GCP?\", \"How does my choice of AWS impact my collaboration with other students in the course?\", \"Are there any specific guidelines I need to follow when adapting the course content for AWS?\"]',\n",
       " '52393fb3': '[\"What additional live Zoom sessions might occur apart from the Office Hour?\",\"Will there be scheduled calls during the Capstone phase to address any inquiries?\",\"How will we be notified if there are extra Zoom calls during Capstone?\",\"Are live calls planned to assist with questions throughout the Capstone period?\",\"When can I expect announcements regarding potential Capstone Zoom sessions?\"]',\n",
       " '10515af5': '[\"Will we continue to use the NYC Trip data from January 2021 for our project?\", \"Is the project for this year the same as last year\\'s?\", \"Are we switching to the 2022 NYC Trip data for our assignments?\", \"Where can I access the NYC Trip data for January 2021?\", \"Is there a significant change in the project compared to last year?\"]',\n",
       " 'cdb86a97': '[\"Is the repository from 2022 still available?\", \"Where can I find the materials from 2022?\", \"Has the 2022 content been removed?\", \"What happened to the 2022 resources?\", \"Can I access the 2022 information somewhere?\"]',\n",
       " '3e0114ad': '[\"Is Airflow an acceptable tool for my final project?\", \"Am I allowed to choose any tool for my project?\", \"Can I select a different software for my final assignment?\", \"Are there restrictions on the tools I can use for my project?\", \"Is it mandatory to use a specific tool for the final project?\"]',\n",
       " 'b2799574': '[\\n    \"Can I utilize tools like Airflow or Prefect in place of the designated tool in the course?\",\\n    \"Is it acceptable to choose AWS or Snowflake instead of the prescribed GCP products for my projects?\",\\n    \"Am I permitted to use Tableau instead of Metabase or Google Data Studio in the course?\",\\n    \"What are the implications of selecting an alternative tool or stack for my capstone project?\",\\n    \"Will there be support available if I decide to go with a different data stack than what\\'s provided?\"\\n]',\n",
       " '2f19301f': '[\"What are some ways I can add value to this course?\", \"Is there a specific way to share the course with others?\", \"How can I suggest improvements or changes to the course materials?\", \"What should I do if I find something in the repository that needs better organization?\", \"Can you explain how to create a PR for the repository?\"]',\n",
       " '7c700adb': '[\"Is there a preferred operating system for this course?\", \"Can I use Windows for the course assignments?\", \"Are students in the course using different operating systems?\", \"Which operating system works best with the course material?\", \"Is Linux necessary for successful course completion?\"]',\n",
       " '44b14808': '[\"What issues might Windows users experience in the course when dealing with shell scripts in *.sh files?\", \"Why is it important to use WSL for the course modules involving shell scripts?\", \"How did past cohorts manage to overcome the challenges with shell scripts on Windows?\", \"Are there any alternatives for Windows users who do not want to use WSL when running the course materials?\", \"What specific modules will require the use of shell scripts that might pose problems for non-WSL Windows users?\"]',\n",
       " '76e4baf6': '[\\n    \"Are there any recommended books for this course?\",\\n    \"What additional resources should I check out?\",\\n    \"Is there a document that lists useful materials?\",\\n    \"Can you provide a link to the resources for data engineering?\",\\n    \"Do you suggest any particular readings for this curriculum?\"\\n]',\n",
       " '48b533a8': '[\"Can you explain what Project Attempt #1 and Project Attempt #2 are in detail?\", \"What happens if I\\'m late for the first project deadline?\", \"Is there a possibility to resubmit the project after a failed first attempt?\", \"How does the second attempt for the project work?\", \"What are the consequences of missing the first project submission?\"]',\n",
       " '954044d1': '[\\n    \"What are some effective strategies for troubleshooting technical issues on my own before seeking help?\",\\n    \"How can I find solutions to common errors I encounter while coding?\",\\n    \"What should I include in my question when seeking assistance from others on platforms like Stackoverflow?\",\\n    \"What is the recommended approach for using Slack to resolve technical problems with my peers?\",\\n    \"How can taking a break help me with solving coding issues, and what activities do you suggest for a mental reset?\"\\n]',\n",
       " 'a820b9b3': '[\"What should I include when I ask a question for help?\", \"When is it appropriate to seek assistance rather than relying on the troubleshooting guide?\", \"What specific details about my coding environment should I mention when asking for help?\", \"Why is it important to describe what I have already attempted when asking a question?\", \"What types of errors should I report, and how should I present them?\"]',\n",
       " 'f2945cd2': '[\\n    \"What steps should I follow after creating a GitHub account for this course?\",\\n    \"How can I ensure that my local Git repository is properly set up for accessing course materials?\",\\n    \"What should I do if I want to make modifications to the content of the course using Git?\",\\n    \"Are there any specific types of files that I need to ignore when creating my repositories?\",\\n    \"Where can I find helpful resources for learning how to manage my Git repositories effectively?\"\\n]',\n",
       " 'eb9d376f': '[\\n    \"What error message might I encounter if I use spaces instead of tabs in my Makefile?\",\\n    \"How can I resolve the issue of missing separators in a document?\",\\n    \"What should I replace spaces with in my Makefile to avoid errors?\",\\n    \"Is there a specific solution or guide I should follow for fixing tab issues in VS Code?\",\\n    \"What steps do I need to take if I see a \\'missing separator\\' error in my Makefile?\"\\n]',\n",
       " '72f25f6d': '[\"How can I open an HTML file using a Windows browser while working on Linux in WSL?\", \"What command do I need to use to view an HTML file from WSL?\", \"Is it possible to choose a specific browser for viewing HTML files in WSL?\", \"What should I do if I want to use Firefox to open an HTML file from Linux?\", \"Do I need to install any additional tools to open HTML files in a Windows browser from WSL?\"]',\n",
       " 'a1e59afc': '[\\n    \"How do I set up Chrome Remote Desktop on a Debian Linux virtual machine in Compute Engine?\",\\n    \"What should I do if I encounter an ERROR 403: Forbidden when trying to download the 2021 Yellow Taxi Trip Records?\",\\n    \"Where can I find a backup of the 2021 Yellow Taxi Trip Records data if the original link fails?\",\\n    \"What command should I use to properly unzip a gzipped file that I downloaded?\",\\n    \"Can I use the standard \\'unzip\\' command to extract contents from a .gz file?\"\\n]',\n",
       " '71c10610': '[\\n    \"What is the correct naming convention for taxi data files when handling them in our project?\",\\n    \"What alternative approach can I take to name the data file if it is downloaded with a csv.gz extension?\",\\n    \"How can I extract the file name from the URL provided for the yellow taxi data?\",\\n    \"Can you explain how to adjust the csv_name variable in the context of the video?\",\\n    \"What function can I use to read taxi data files that have the csv.gz extension in Python?\"\\n]',\n",
       " '17a5aea1': '[\"What is the data dictionary for Yellow Taxi trips in New York?\", \"Can you provide the link for the Green Taxi data dictionary?\", \"Where can I find the Yellow Trips data dictionary for NYC?\", \"Is there an online resource for Green Taxi trip records?\", \"How do I access the data dictionary for Yellow and Green Taxi trips?\"]',\n",
       " '5a275db7': '[\\n    \"How can I unzip a downloaded parquet file using the command line?\",\\n    \"What command should I use to extract the parquet file into a CSV format?\",\\n    \"Can you explain how to read a parquet file directly in a Python script?\",\\n    \"What do I need to include in the main function to handle parquet files?\",\\n    \"How can I convert a parquet file to CSV after downloading it?\"\\n]',\n",
       " '7ec0f9b0': '[\\n  \"What are the steps to install wget on an Ubuntu system if I encounter the error \\'wget is not recognized as an internal or external command\\'?\",\\n  \"Can you explain how to install wget on MacOS using Brew if the command is not recognized?\",\\n  \"What options do I have for installing wget on a Windows machine when the command is unrecognized?\",\\n  \"If I prefer using Python to download files, how can I utilize the wget library instead of the command line tool?\",\\n  \"Is there a way to bypass using wget entirely when attempting to download a file, and if so, what is the method?\"\\n]',\n",
       " 'bb1ba786': '[\\n  \"What should I do if I encounter a certificate verification error while using wget on MacOS?\",\\n  \"Can you explain the importance of adding \\'!\\' before wget when using it in a Jupyter Notebook?\",\\n  \"What are the two methods I can use to bypass the certificate verification for wget?\",\\n  \"How do I utilize the Python library wget as a potential solution for my issue on MacOS?\",\\n  \"What is the correct command format to run wget while ignoring certificate verification?\"\\n]',\n",
       " '2f83dbe7': '[\"How can I set the backslash as an escape character in Git Bash for Windows?\", \"What command do I need to use in the terminal for setting the escape character?\", \"Do I need to include the escape character setting in my .bashrc file?\", \"Is the escape character setting in Git Bash specific to any user or can anyone use it?\", \"What specific environment is mentioned for using the backslash as an escape character?\"]',\n",
       " '543ff080': '[\"What steps do I need to follow to securely store secrets in GitHub Codespaces?\", \"Is there a guide for managing account-specific secrets in GitHub Codespaces?\", \"Where can I find instructions for storing secrets in GitHub Codespaces?\", \"Can you explain how to handle my secrets while using GitHub Codespaces?\", \"What documentation is available for secret management in GitHub Codespaces?\"]',\n",
       " 'd407d65b': '[\"What should I do if I encounter an error about not being able to connect to the Docker daemon?\", \"How can I verify if the Docker daemon is running properly?\", \"Is there a specific command to update WSL in PowerShell?\", \"What steps should I follow to troubleshoot Docker connection issues?\", \"Can you explain how to start the Docker daemon if it\\'s not running?\"]',\n",
       " 'c9375c56': '[\"What are the requirements for running Docker on Windows Pro versions?\", \"How can Windows Home users run Docker if Hyper-V is not available?\", \"What should I do if I encounter an error related to WSL2 installation?\", \"Is it necessary to enable Hyper-V before using Docker on Windows 10 Pro?\", \"Where can I find instructions to install WSL2 on Windows 11?\"]',\n",
       " 'e866156b': '[\\n  \"What steps should I take to download an image from a public repository using Docker, and do I need to log in?\",\\n  \"If I get an error saying \\'access denied\\' when pulling an image, what could be causing this issue?\",\\n  \"What should I do if I face a permission denied error while creating a PostgreSQL container on macOS M1?\",\\n  \"Why is it necessary to install Docker Desktop instead of using Rancher Desktop for running PostgreSQL containers?\",\\n  \"Can you explain the potential reasons for a \\'repository does not exist\\' error when pulling a Docker image?\"\\n]',\n",
       " '16370470': '[\\n    \"Why is it impossible for me to delete a local folder that is mounted to a Docker volume?\",\\n    \"What ownership and permissions might prevent me from deleting a folder created by a Docker container?\",\\n    \"How do I resolve access errors in Obsidian that result from Docker volume permissions?\",\\n    \"What command should I use to forcefully delete a folder created during a Docker process?\",\\n    \"Can you explain the meaning of the options used in the command to remove the Docker test folder?\"\\n]',\n",
       " '316df755': '[\\n  \"What should I do if Docker on my Windows 10/11 is not starting or appears to be stuck in the settings?\",\\n  \"How can I check if I am using the latest version of Docker for Windows?\",\\n  \"Is there a way to switch between containers if Docker is stuck on starting?\",\\n  \"Do I need to enable Hyper-V on Windows 10/11 to run Docker smoothly?\",\\n  \"What are the steps to enable WSL2 for Docker on Windows?\"  \\n]',\n",
       " 'f3aa9252': '[\\n  \"Is it better to execute Docker commands from the Windows file system or a Linux distribution file system in WSL?\",\\n  \"What should I do if Docker does not work even after setting up WSL2 or Hyper-V correctly?\",\\n  \"Can I use Docker on Windows 10 Home Edition with the help of WSL2, and how?\",\\n  \"What steps should I take if my Docker installation remains stuck after setup?\",\\n  \"Is there a way to reset Docker to resolve issues after installation on Windows?\"\\n]',\n",
       " 'a4abe7a5': '[\\n    \"What is the recommended way to store code for optimal file system performance in Docker?\",\\n    \"Where can I find more information about Docker best practices?\",\\n    \"Which backend does Docker run on by default for Windows 10 Home users?\",\\n    \"What does the default setup for Windows 11 Home users imply for Docker usage?\",\\n    \"How does WSL2 affect Docker performance on my machine?\"\\n]',\n",
       " 'fb930700': '[\\n    \"What error might I encounter when running a Docker command in Windows?\",\\n    \"How can I resolve the \\'input device is not a TTY\\' error when using Docker?\",\\n    \"Is there a command I should use before my Docker command if I am using mintty?\",\\n    \"Can I create an alias to avoid typing \\'winpty\\' before Docker commands every time?\",\\n    \"Where should I add the alias command to make it permanent for Docker on my system?\"\\n]',\n",
       " 'aa187680': '[\"What could be causing the error when I try to pip install in a Docker container on Windows?\", \"Is there a specific error message I should look for when having issues with pip install on Docker?\", \"What DNS settings should I try if I\\'m experiencing temporary name resolution failures in Docker?\", \"Can you provide a command that might resolve issues with pip install in a Windows Docker container?\", \"Which version of Python is suggested for use in the Docker command to troubleshoot pip install issues?\"]',\n",
       " 'b000e899': '[\\n    \"What should I do if the ny_taxi_postgres_data folder remains empty after running the Docker script?\",\\n    \"Can you provide the specific command to run for populating the ny_taxi_postgres_data on a Windows machine?\",\\n    \"What are the environment variable settings needed for the Docker command to work correctly?\",\\n    \"Why is it important to specify the absolute path in the -v parameter of the Docker command?\",\\n    \"How can I verify that all the files are present in the ny_taxi folder within VS Code after running the command?\"\\n]',\n",
       " '9c66759f': '[\"What should I refer to for guidance on installing Docker on a Mac?\", \"Are there any known issues with the previous method for setting up Docker on macOS?\", \"What alternative method did you find effective for installing Docker?\", \"Has Docker\\'s licensing model impacted installation procedures on macOS?\", \"Where can I find the latest instructions for downloading Docker on a Mac?\"]',\n",
       " 'e3106e07': '[\"What is the solution if I encounter a permission error when trying to change the directory permissions for \\'/var/lib/postgresql/data\\' in Docker?\", \"How can I create a local Docker volume and utilize it for the PostgreSQL data directory?\", \"What are the necessary environment variables to set when running the PostgreSQL container?\", \"What should I do if I see an error stating that the directory \\'/var/lib/postgresql/data\\' exists but is not empty?\", \"How can I verify that my Docker volume has been created and is listed in Docker Desktop?\"]',\n",
       " '72229da5': '[\\n    \"What should I do if my Docker volume mapping is not working on Windows?\",\\n    \"Can you suggest some folder names that are compatible for data mapping in Docker on Windows?\",\\n    \"What options are available for specifying volume paths in Docker commands on Windows?\",\\n    \"How can I check and correct volume mapping issues if Docker creates an unexpected folder on Windows?\",\\n    \"Is it possible to use a volume name instead of a path for Docker on Windows, and how would I do that?\"\\n]',\n",
       " '58c9f99f': '[\"What should I do if I get an error related to the daemon when using Docker?\", \"How can I resolve the invalid mode error when working with PostgreSQL in Docker?\", \"Is there a specific format for mounting paths in Docker that I need to follow?\", \"Are there alternative mounting paths I can use instead of the one provided?\", \"What does adding a leading slash before \\'c:\\' achieve in the mounting path for Docker?\"]',\n",
       " 'bc42139a': '[\"What causes the specific Docker error related to creating a build mount source path?\", \"Is there a way to fix the error when running the Docker command a second time?\", \"What command can I use on subsequent runs of the Docker container to avoid the error?\", \"Which environment variables do I need to set for the PostgreSQL Docker container?\", \"What port should I use for PostgreSQL when running it in Docker?\"]',\n",
       " 'a146e3ee': '[\\n  \"What error occurs when running the command docker build -t taxi_ingest:v001?\",\\n  \"Why did the user encounter a permission issue with the ny_taxi_postgres_data directory?\",\\n  \"What files do I need present to avoid the build error when using Docker?\",\\n  \"How can I resolve the permission issue on an Ubuntu system?\",\\n  \"Where can I find more details about the Docker build error related to checking context?\"\\n]',\n",
       " '593a85ba': '[\"What should I do if I encounter an error waiting for a container in Docker?\", \"How can I check the status of my Docker installation if I used snap to install it?\", \"What steps should I take if I receive an unknown command error while checking Docker with snap?\", \"What might cause a failure when binding to the port 5432 in Docker?\", \"Is there a recommended method for installing Docker if I need to uninstall it first?\"]',\n",
       " '50bd1a71': '[\\n  \"What could be the reason for the build error in Docker related to my project folder?\",\\n  \"How can I resolve the issue of not having the proper authorization rights to my host folder in PopOS?\",\\n  \"Why does the folder appear empty when I encounter the Docker build error?\",\\n  \"What command should I use to change permissions for the folder causing the build error?\",\\n  \"Can you provide an example of how to set folder permissions for Docker in my case?\"\\n]',\n",
       " 'f409f751': '[\\n  \"What causes the permission denied error when trying to build a Docker container on Ubuntu/Linux?\",\\n  \"What command can I use to build the Docker container for the taxi ingest project?\",\\n  \"What folder is created when I run the Docker build command for this project?\",\\n  \"How can I resolve the permission issues when rebuilding the pipeline or creating a new one?\",\\n  \"What does the chmod command do when applied to the ny_taxi_postgres_data folder?\"\\n]',\n",
       " '7d217da3': '[\"How can I find the name of the Docker network?\", \"What command should I use to list Docker networks?\", \"Is there a specific way to retrieve the network name in Docker?\", \"What steps do I follow to obtain the Docker network name?\", \"Can you tell me how to view the available Docker networks?\"]',\n",
       " '09081824': '[\\n    \"What should I do if I encounter a conflict error stating that the container name \\'pg-database\\' is already in use?\",\\n    \"Can you explain how to resolve the issue when I\\'m trying to restart a Docker image and face a container name conflict?\",\\n    \"What command do I need to run to stop a running container before I can remove it?\",\\n    \"How can I restart a Docker image without removing the container that has the same name?\",\\n    \"Is there an alternative command to using \\'docker run\\' if I want to restart the Docker image safely?\"\\n]',\n",
       " '4df80c55': '[\"What could be the cause of receiving a name translation error when using docker-compose for ingestion?\", \"How can I determine the correct network to use in my ingestion script when running docker-compose?\", \"What is the significance of the error message from SQLAlchemy regarding operational issues with the database?\", \"Can you explain how to identify the correct database name when encountering host name translation issues?\", \"What are the specific naming conventions for networks and databases I should be aware of when using Docker and Terraform?\"]',\n",
       " '3aee7261': '[\\n    \"What should I do if I cannot install Docker on my MacOS or Windows 11 VM running on Linux?\",\\n    \"Is there a command I need to run to enable nested virtualization for Docker installation?\",\\n    \"What are the specific commands to run on an Intel CPU before starting my VM?\",\\n    \"Are there any different commands for enabling nested virtualization on an AMD CPU?\",\\n    \"What happens if nested virtualization is not enabled when using Docker in this environment?\"\\n]',\n",
       " '6497b659': '[\"How can I manage Docker containers and images using VS Code?\", \"What do I need to do to connect VS Code with my Docker setup?\", \"Is it possible to use VS Code with Docker running on WSL2?\", \"What command should I use to stop a Docker container?\", \"Where can I find the official VS Code extension for Docker management?\"]',\n",
       " 'a02f2039': '[\"What does it mean when the logs indicate that the PostgreSQL database directory contains a database but the system is shut down?\", \"Why is my PostgreSQL container not accepting requests?\", \"What error am I likely to encounter if my PostgreSQL server terminates abnormally?\", \"What should I do if I see a connection failure from my PostgreSQL container?\", \"How can I resolve the issue with the PostgreSQL database shutting down unexpectedly?\"]',\n",
       " 'c6db65aa': '[\"How can I install Docker if I\\'m using an unsupported version of Ubuntu?\", \"What is the command to install Docker using snap on Ubuntu?\", \"Is there a specific command I need to use for Docker installation on Ubuntu?\", \"Can I use snap to install Docker on my Ubuntu version?\", \"Are there alternatives to install Docker if snap isn\\'t available on my Ubuntu?\"]',\n",
       " 'f476a606': '[\"What should I do if I encounter a mounting error related to directory permissions when using Docker-Compose?\", \"How can I specify a named volume in my Docker-Compose file if I\\'ve set up a local Docker volume earlier?\", \"What command can I use to inspect the location of my named volume in Docker?\", \"Why did my composed service create a mounting directory with a different name than the one I expected?\", \"What steps did the author take to resolve the naming issue with the Docker volume in their setup?\"]',\n",
       " 'e41b100c': '[\\n  \"What steps should I follow if I encounter an error related to translating a host name to an address while working with Docker Compose?\",\\n  \"How can I ensure that my PostgreSQL database is running when using Docker Compose?\",\\n  \"What command do I need to use to start my Docker containers in detached mode?\",\\n  \"What should I do if the output of \\'docker ps\\' does not show my PostgreSQL database container as running?\",\\n  \"How can I check the logs of a specific Docker container to troubleshoot issues?\",\\n]',\n",
       " 'cd0f9300': '[\\n  \"What should I do if I encounter an error indicating that Docker can\\'t translate the host name \\'pg-database\\' after running \\'docker-compose up\\'?\",\\n  \"How can I retrieve the default network name created by Docker Compose to update my Ingestion script?\",\\n  \"What actions should I take if I lose database data after executing \\'docker-compose up\\'?\",\\n  \"In case of persistent issues with pgcli, what alternative tools can I use to connect to my database?\",\\n  \"Where can I find the logs for Docker Compose execution to check the network name?\"\\n]',\n",
       " '7f845a1c': '[\\n  \"What error do I get if the hostname does not resolve in Docker-Compose?\",\\n  \"What command can I use to view all stopped and running containers?\",\\n  \"How can I resolve an issue where the server cannot connect on localhost:8080?\",\\n  \"What is a recommended format for a hostname to avoid resolution issues?\",\\n  \"In the docker-compose.yml file, how should I configure networks for multiple containers?\"\\n]',\n",
       " '36e54439': '[\\n    \"What is the common issue when running docker-compose on Google Cloud Platform regarding Postgres data persistence?\",\\n    \"How can I ensure that PGAdmin data persists when using Docker on GCP?\",\\n    \"What is the recommended way to modify the volume configuration for PGAdmin in a docker-compose file?\",\\n    \"What should I change in the docker-compose file to make PGAdmin use Docker Volume for data persistence?\",\\n    \"Can you explain the difference between using a local path and Docker Volume for PGAdmin\\'s data storage?\"\\n]',\n",
       " '32e8450c': '[\\n    \"What should I do if my Docker engine keeps crashing?\",\\n    \"How can I check if I have the latest version of Docker installed?\",\\n    \"What steps should I take if updating Docker does not resolve my issue?\",\\n    \"Is it necessary to reinstall Docker if the problem continues?\",\\n    \"Will I lose any important data if I need to fetch images again after reinstalling Docker?\"\\n]',\n",
       " '96606db2': '[\\n    \"How can I ensure that my pgAdmin configuration is saved across container restarts?\",\\n    \"What specific YAML configuration should I use to set up pgAdmin with persistent storage?\",\\n    \"Before executing the docker-compose command, what permission changes must I make to the pgAdmin_data folder?\",\\n    \"What are the default environment variables required for setting up pgAdmin in Docker?\",\\n    \"Which user and group does the pgAdmin container run as, and how does that relate to folder permissions?\"\\n]',\n",
       " '0882bfac': '[\\n  \"What should I do if I encounter a permission denied error when using Docker-Compose?\",\\n  \"How can I ensure my user has the necessary permissions for Docker?\",\\n  \"What steps should I follow to create a volume for pgAdmin to retain previous connections?\",\\n  \"Can you explain how to modify the docker-compose.yaml file for pgAdmin?\",\\n  \"What do I need to do after adding my user to the docker group?\"\\n]',\n",
       " '7d067f5c': '[\"What should I do if docker-compose does not seem to work after I modified my .bashrc file?\", \"Why did my docker-compose file from GitHub get named docker-compose-linux-x86_64 instead of docker-compose?\", \"Is there a specific reason why using the command docker-compose is more convenient than the file I downloaded?\", \"What steps should I take to rename the downloaded docker-compose file for it to function correctly?\", \"Can you explain why the naming of the docker-compose file might affect its usability in my Google Cloud VM?\"]',\n",
       " 'ff352621': '[\"What should I do if I encounter an error related to credentials when using docker-compose up?\", \"How can I resolve the issue of getting credentials errors in Docker-Compose?\", \"Is there a specific solution for the Docker-Compose credentials error?\", \"Where can I find more information regarding the credentials error in Docker-Compose?\", \"What command is recommended to fix the Docker-Compose error related to getting credentials?\"]',\n",
       " '2d653208': '[\"What steps should I follow if I encounter errors with the docker-compose.yml file and pgadmin setup while using Docker-Compose?\", \"What adjustments do I need to make to my docker-compose.yml file to resolve issues with PostgreSQL data retrieval?\", \"How should I handle low_memory settings when importing a CSV file during the data ingestion process?\", \"What is the correct order of operations to ensure successful execution of my Docker setup for PostgreSQL and pgAdmin?\", \"How can I ensure that my pgAdmin server configuration matches the settings in my docker-compose.yml file?\"]',\n",
       " 'f09ea61e': '[\"How can I resolve the Docker Compose up -d error related to credentials in my environment?\", \"What should I do if I encounter an executable file not found error with docker-credential-desktop?\", \"Where can I find the config.json file for Docker on my system?\", \"What changes do I need to make to the credsStore in the config.json file?\", \"What steps should I follow after modifying the config.json file to address the error?\"]',\n",
       " 'fbd3d2bb': '[\\n  \"What steps should I follow to determine the correct docker-compose binary for my WSL setup?\",\\n  \"Where can I find the docker-compose releases for download?\",\\n  \"What commands can I use to check my system prior to downloading docker-compose?\",\\n  \"Is there a specific command I can run to download the appropriate version of docker-compose directly?\",\\n  \"What will the commands uname -s and uname -m return when executed?\"\\n]',\n",
       " '0b014d0c': '[\\n    \"What should I do if I see an error about an undefined volume in my Docker-Compose setup on Windows/WSL?\",\\n    \"Can you explain how to resolve the issue of a service referring to an undefined volume in my docker-compose.yaml file?\",\\n    \"What specific changes do I need to make in my docker-compose.yaml file to fix volume errors?\",\\n    \"How should I structure the volumes section in my docker-compose file to avoid errors?\",\\n    \"Is there a specific format I need to follow when adding volumes to the docker-compose file for my project?\"\\n]',\n",
       " 'd21bff1d': '[\\n  \"What causes the permission errors when using Docker with WSL?\",\\n  \"How can I resolve permission conflicts between WSL and Windows when using Docker?\",\\n  \"Why should I prefer using Docker volumes instead of local drives?\",\\n  \"What are the benefits of utilizing Docker volumes for data storage?\",\\n  \"Is it necessary to specify the \\'user:\\' option when using Docker volumes?\"\\n]',\n",
       " '6afb7b55': '[\"What should I do if pgadmin is malfunctioning when querying in Postgres?\", \"Why does pgadmin have issues when run on Git Bash or a VM in Windows?\", \"What are the required libraries for pgadmin to work correctly with Postgres?\", \"Can you suggest an alternative to pgadmin for executing queries in Postgres?\", \"How do I install the necessary libraries for using Postgres with Python?\"]',\n",
       " 'b51c3b82': '[\\n    \"What might cause the error message stating \\'Insufficient system resources exist to complete the requested service\\' when using WSL?\",\\n    \"How can I check if there are any pending updates for Windows Terminal and WSL?\",\\n    \"What steps should I follow to update the Windows Terminal app on my system?\",\\n    \"Is there a specific section of Windows updates where I can find pending security updates?\",\\n    \"What should I do after updating my apps and security updates to ensure changes take effect?\"\\n]',\n",
       " '326af690': '[\\n    \"What should I do if my WSL integration with Ubuntu stops unexpectedly with exit code 1?\",\\n    \"Can you provide a solution for a potential DNS issue related to WSL on Windows?\",\\n    \"What steps can I follow to resolve the Docker icon issue where I need to switch to Linux containers?\",\\n    \"Why am I receiving an error about an uninitialized database and missing superuser password?\",\\n    \"Is there a specific registry command I need to run to fix the DNS service for WSL?\"\\n]',\n",
       " 'c2ec9047': '[\\n    \"What might be the reason for the error when trying to run the GPC VM through SSH in WSL2?\",\\n    \"How can I resolve the permission issue with my SSH private key file in WSL2?\",\\n    \"What command can I use to create a .ssh directory in the home directory of WSL2?\",\\n    \"Is there a way to ensure that WSL2 uses the correct .ssh keys for SSH connections?\",\\n    \"What steps should I take to copy my Windows .ssh folder contents to the new .ssh folder in WSL2?\"\\n]',\n",
       " '3b711e73': '[\"What should I do if I encounter a host name resolution issue in WSL2?\", \"How do I create a .ssh/config file in WSL2?\", \"What commands do I need to run to set up the .ssh directory in WSL2?\", \"Where should I place the configuration details for my GPC VM in WSL2?\", \"What steps should I follow to ensure WSL2 references the correct .ssh/config path?\"]',\n",
       " 'cfe07c9d': '[\"What should I do if I encounter a PGCLI connection error indicating a failure to receive data from the server?\", \"How can I resolve the issue of the connection being refused when trying to connect to port 5432?\", \"What command do I need to use to connect to the database if I get an SSL negotiation packet error?\", \"Is there a specific host that I should use when attempting to connect via PGCLI in this course?\", \"Can you provide the correct connection string for accessing the ny_taxi database using PGCLI?\"]',\n",
       " 'acf42bb8': '[\"What should I do if I encounter a PGCLI --help error during the course?\", \"Is there a way to resolve a potential installation error related to PGCLI?\", \"How can I troubleshoot the PGCLI --help error we discussed in Module 1?\", \"Where can I find additional resources if I experience installation issues with PGCLI?\", \"What steps should I take to verify my installation if PGCLI is not functioning correctly?\"]',\n",
       " '176ce516': '[\"Is it necessary to run pgcli within a separate Docker container?\", \"What port do we need to map for pgsql in this module?\", \"Can pgcli be accessed directly from my local computer?\", \"What is the role of port 5432 in this section?\", \"Should pgcli be run locally or within another container?\"]',\n",
       " '3e5d1e9b': '[\\n    \"What should I do if I encounter a fatal password authentication error for user \\'root\\' when using PGCLI?\",\\n    \"How can I resolve conflicts with my local Postgres installation when running a Docker container?\",\\n    \"What port should I use to connect to my Postgres Docker container to avoid authentication issues?\",\\n    \"Is there a specific command I can use to check for applications using a port on my MacOS?\",\\n    \"What steps do I need to take to unload and start the PostgreSQL service on MacOS to free up a port?\"\\n]',\n",
       " '78833f32': '[\\n    \"What should I do if I encounter a PermissionError when running pgcli?\",\\n    \"How can I resolve the error related to creating the config directory for pgcli?\",\\n    \"What is the recommended method for installing pgcli without encountering permission issues?\",\\n    \"What should I do if conda install gets stuck at the \\'Solving environment\\' step?\",\\n    \"Can using sudo for installing pgcli lead to permission errors, and what is the alternative?\"   \\n]',\n",
       " '63823f21': '[\\n    \"What specific error does the PGCLI report when there is no valid pq wrapper available?\",\\n    \"What is the minimum Python version required to properly install psycopg2-binary?\",\\n    \"What command should I use to create a new conda environment with Python 3.9?\",\\n    \"What is the recommended method to install pgcli after ensuring the correct Python version?\",\\n    \"What alternative command can I run to install psycopg with binary and pool options?\"\\n]',\n",
       " 'b36ea564': '[\\n    \"What should I do if my Bash terminal is stuck at the password prompt for pgcli when trying to connect to PostgreSQL?\",\\n    \"Can you suggest any alternative terminals to use if I encounter issues with pgcli on my current setup?\",\\n    \"What steps should I take if I receive the error message stating \\'password authentication failed for user \\\\\"root\\\\\"\\' despite entering the correct password?\",\\n    \"What are the potential solutions if the PostgreSQL service is causing connection issues on my Windows machine?\",\\n    \"Why do I need to keep my database connection active while following the tutorial, especially after running a PostgreSQL container?\"\\n]',\n",
       " 'e2a46ce5': '[\\n    \"What should I do if my system shows the \\'command not found\\' error for pgcli after installation?\",\\n    \"How can I confirm the installation location of pgcli on my Windows system?\",\\n    \"What steps do I need to take to add Python Scripts to my Windows PATH variable?\",\\n    \"Is there a possibility that my Python installation might be under a different directory than the one provided?\",\\n    \"Where can I find more information or a reference regarding the pgcli command error?\"\\n]',\n",
       " '27bdbc3f': '[\\n  \"Is there a way to use pgcli without installing it on my local machine?\",\\n  \"What Docker command should I run to execute pgcli in a container?\",\\n  \"Can you tell me the Docker network name used in the course videos for pgcli?\",\\n  \"What are the PostgreSQL connection details necessary to use pgcli in Docker?\",\\n  \"What is the version of pgcli being used in this course\\'s Docker example?\"\\n]',\n",
       " 'f7c5d8da': '[\"Why is PULocationID not recognized in queries?\", \"How should I format column names with capital letters in PGCLI?\", \"What happens if I do not use quotations around capitalized columns?\", \"Can you explain the case sensitivity issue with local identifiers?\", \"Where can I find more information about case sensitivity in PGCLI?\"]',\n",
       " 'c91ad8f2': '[\\n    \"What error might I encounter when executing the command \\'\\\\\\\\d <database name>\\' in PGCLI?\",\\n    \"What steps should I take if I face the error \\'column c.relhasoids does not exist\\'?\",\\n    \"How can I resolve the issue of the database \\'ny_taxi\\' not being found?\",\\n    \"What should I do if I experience problems with PGCLI?\",\\n    \"Is restarting my computer necessary after reinstalling PGCLI?\"\\n]',\n",
       " '88bf31a0': '[\\n    \"What should I do if I encounter an OperationalError related to password authentication while trying to connect to Postgres in Jupyter Notebook?\",\\n    \"Why am I experiencing a connection issue with my Postgres database on localhost when using Docker?\",\\n    \"What steps can I take to resolve the problem if I get a connection error at port 5432 while working with my database?\",\\n    \"Is there a specific port I need to use when accessing my Postgres database through Docker, and how can I find that?\",\\n    \"How can I check if there is another Postgres service running on my Windows machine that might be causing connection issues?\"\\n]',\n",
       " '23524e6d': '[\\n  \"What could be the reason for receiving an OperationalError related to the role \\'root\\' when connecting to Postgres?\",\\n  \"How can I check if a \\'root\\' user exists with login capabilities in my Postgres setup?\",\\n  \"What steps should I take to change the default port if it conflicts with an existing Postgres installation?\",\\n  \"What alternative user settings can be applied in the Docker setup to resolve connection issues with Postgres?\",\\n  \"What actions should I perform to reset my Docker Postgres setup if I experience persistent connection errors?\"\\n]',\n",
       " '9211bbd6': '[\\n    \"What does the OperationalError related to psycopg2 indicate about the database connection to localhost?\",\\n    \"How can I verify if the Postgres server is running on my machine?\",\\n    \"What should I do if I encounter a connection error stating that the database \\'ny_taxi\\' does not exist?\",\\n    \"Is there a recommended port to use for Postgres if port 5432 is unavailable on my system?\",\\n    \"Where can I find the psycopg2 code referenced in the error message regarding the database connection?\"\\n]',\n",
       " '5db86809': '[\\n    \"What should I do if I encounter a ModuleNotFoundError related to psycopg2 when working with Postgres in Module 1?\",\\n    \"Can you explain the steps I should take if the initial installation of psycopg2-binary does not resolve the error?\",\\n    \"Is there a specific command I should use to update conda or pip before reinstalling psycopg2?\",\\n    \"What actions should I take if I still have issues with psycopg2 indicating that pg_config is not found?\",\\n    \"How do I install PostgreSQL on a Mac if required for resolving psycopg2 installation problems?\"\\n]',\n",
       " '20c604dd': '[\\n    \"What might cause a \\'column does not exist\\' error when using Postgres on a MacBook Pro M2?\",\\n    \"How should I properly reference column names in join queries to avoid SQL errors?\",\\n    \"What specific quoting method should I use for column names to prevent errors in Pyscopg2?\",\\n    \"Is there a difference between using single quotes and double quotes for column names in PostgreSQL?\",\\n    \"What error message indicates an issue with column names when executing queries in Postgres?\"\\n]',\n",
       " 'b11b8c15': '[\"Why doesn\\'t the Create server dialog appear in pgAdmin?\", \"What should I do if pgAdmin\\'s Create server dialog is missing?\", \"Is there a reason the Create server dialog is not showing in the latest version of pgAdmin?\", \"How can I create a server in pgAdmin if the dialog doesn\\'t show?\", \"What alternative action can I take to create a server in pgAdmin?\"]',\n",
       " 'a6475348': '[\\n    \"What could cause a blank or white screen when logging into pgAdmin in a browser?\",\\n    \"What error message was displayed in the terminal of the pgAdmin container when I encountered the login issue?\",\\n    \"What environment variable needs to be set to avoid the CSRF error when running pgAdmin in Docker?\",\\n    \"What modifications are needed in the \\'docker run\\' command to resolve the issue with pgAdmin?\",\\n    \"How can using VSCode locally help prevent the blank screen issue when working with GitHub Codespaces?\"\\n]',\n",
       " '1ea7680e': '[\"What should I do if I cannot access the pgAdmin interface through my web browser after starting the container?\", \"How did you modify the \\'docker run\\' command to successfully access pgAdmin?\", \"What changes did you make to the docker-compose.yaml to allow pgAdmin access?\", \"I encountered a ModuleNotFoundError for \\'pysqlite2\\'; how did you resolve this issue?\", \"Where can I find the missing sqlite3.dll file to fix the DLL load error I am experiencing?\"]',\n",
       " '10acd478': '[\\n    \"What should I do if I am missing 100000 records while ingesting data using the Jupyter notebook?\",\\n    \"Can you explain why I only see about 1.2 million rows instead of the expected 1.3 million when running the script again?\",\\n    \"Is there a recommended video that I should watch to understand how to properly ingest the NY Taxi Data?\",\\n    \"Why does running the entire script in the Jupyter notebook result in skipping the first chunk of records?\",\\n    \"What specific change do I need to make in the notebook to ensure I ingest all the records correctly?\"\\n]',\n",
       " '752e8452': '[\"How can I read a CSV file properly in Python without encountering errors?\", \"What is the advantage of using a compressed CSV file?\", \"What command do I need to run to install gunzip on an Ubuntu machine?\", \"Is there a way to preview uncompressed CSV files easily?\", \"What specific warning should I be aware of when executing my Python script?\"]',\n",
       " 'aa6f52b8': '[\\n    \"How can I configure Pandas to automatically handle date conversion when reading a CSV file?\",\\n    \"What parameter do I need to use with pd.read_csv to specify which columns should be parsed as dates?\",\\n    \"Can you provide an example of using parse_dates with the pd.read_csv function?\",\\n    \"What will be the data types of the columns after using parse_dates with my CSV data?\",\\n    \"Is it necessary to convert date strings to datetime types after importing data with Pandas if I use the appropriate parameter?\"\\n]',\n",
       " '3dacbb98': '[\"How can I download data using curl in my Python script?\", \"What command should I use to retrieve a CSV file from a GitHub link?\", \"Is there a specific format for the curl command in Python?\", \"What function allows me to execute system commands like curl?\", \"Can you provide a Python example for using curl to get data from a URL?\"]',\n",
       " '8b71a398': '[\\n    \"How can I read a Gzip compressed CSV file in Pandas?\",\\n    \"What file extension is used for a Gzip compressed CSV file?\",\\n    \"Which function in Pandas do I use to read CSV files?\",\\n    \"What parameters can the read_csv() function accept?\",\\n    \"Can you give an example of reading a Gzip compressed CSV file with Pandas?\"\\n]',\n",
       " 'aa244fa0': '[\"What is the recommended method for processing parquet files in Python?\", \"How does the process of ingesting parquet files differ from using pandas\\' read_csv method?\", \"Can you provide an example of how to clear an existing SQL table before ingesting new data?\", \"What library do we need to use to handle parquet files effectively in Python?\", \"What steps are involved in iterating through a parquet file and inserting its data into a PostgreSQL database?\"]',\n",
       " 'eac816d7': '[\"What error might occur when executing a Jupyter notebook cell that imports SQLAlchemy?\", \"How can I resolve an ImportError related to \\'TypeAliasType\\' in Python?\", \"Is there a specific version requirement for the \\'typing_extensions\\' module to avoid the error?\", \"What are the methods I can use to update the \\'typing_extensions\\' module in my environment?\", \"What is the import statement that triggers the error in the SQLAlchemy library?\"]',\n",
       " 'd44d1c77': '[\\n    \"What connection string should I use to avoid the \\'TypeError: module object is not callable\\' when working with SQLAlchemy?\",\\n    \"How can I correctly create an engine for a PostgreSQL database using SQLAlchemy?\",\\n    \"What is the appropriate format for the connection string for connecting to a local PostgreSQL database?\",\\n    \"Why do I receive a TypeError when attempting to use create_engine with my original connection string?\",\\n    \"Can you provide a corrected example for creating a connection with SQLAlchemy and PostgreSQL?\"\\n]',\n",
       " 'ed34766a': '[\"What error might occur when executing a cell in Jupyter Notebook related to SQLAlchemy?\", \"How can I resolve the ModuleNotFoundError for \\'psycopg2\\'?\", \"Which Python module needs to be installed for PostgreSQL connectivity?\", \"What commands can I use to install the missing \\'psycopg2\\' module?\", \"Under what circumstances would I see the error related to the PostgreSQL engine connection?\"]',\n",
       " 'fd714677': '[\\n    \"What should I do if I receive an error about adding Google Cloud SDK to the PATH on Windows?\",\\n    \"Are there steps I need to follow to set up Git Bash correctly on my Windows system?\",\\n    \"How can I ensure that Conda is added to the PATH when installing Anaconda Navigator?\",\\n    \"What options should I select during the Git Bash installation process?\",\\n    \"Is there a way to make Git Bash my default terminal in Windows?\"\\n]',\n",
       " '9de2c3e9': '[\\n  \"What should I do if I encounter a project creation failure due to the error message stating that the requested entity already exists?\",\\n  \"Why does the FAQ suggest that I might not need this information regarding project creation failures?\",\\n  \"Where should I go to create a project instead of relying on command-line instructions?\",\\n  \"What are the implications of using a common project ID like \\'testproject\\' when creating a new project in GCP?\",\\n  \"Can you explain what the status code 409 signifies in the response I receive during project creation attempts?\"\\n]',\n",
       " '827dd4af': '[\\n    \"What should I do if I encounter a \\'403: absent billing account\\' error on GCP?\",\\n    \"How can I find my unique project ID on the GCP Dashboard?\",\\n    \"What might prevent my billing account from linking to my current project?\",\\n    \"Where can I locate the project ID that I need to enter?\",\\n    \"Why is it important to enter my specific project ID in the GCP setup?\"\\n]',\n",
       " 'a42a7e8c': '[\"What should I do if my credit card is not accepted by Google for my GCP account?\", \"Is there a particular bank that has been successful for making payments in GCP?\", \"What other payment options do you recommend if my card is refused?\", \"How likely is it that Google support will assist with account issues?\", \"Are there any alternative payment methods that are known to work with Google Cloud?\"]',\n",
       " '4eefdd01': '[\\n  \"Could you please explain how I can locate the ny-rides.json file in Google Cloud Platform?\",\\n  \"What are the specific steps I need to follow to access my private file in GCP?\",\\n  \"In GCP, how do I navigate to the Service Accounts Keys tab to find the ny-rides.json file?\",\\n  \"Can you clarify where I should click in GCP after selecting my project to create a JSON key?\",\\n  \"What should I do after clicking the email in the Service Accounts Keys tab to find the \\'KEYS\\' option?\"\\n]',\n",
       " '0282578d': '[\"Is it necessary to remove my instance in Google Cloud after watching the lecture?\", \"What happens if I delete my instance in Google Cloud?\", \"Will I need to delete instances more than once if I don\\'t follow instructions?\", \"Could you clarify if deleting the instance is required in this course?\", \"What advice do you have regarding instances on Google Cloud during this module?\"]',\n",
       " 'bd3e60fd': '[\\n  \"What commands can I use to monitor the system resources on my virtual machine?\",\\n  \"Which command will show me the disk usage of a specific directory?\",\\n  \"How can I check the currently active network connections on my virtual machine?\",\\n  \"What command should I use to view the hardware configuration of my system?\",\\n  \"How can I find out who is currently logged into my system along with their activities?\"\\n]',\n",
       " 'c4e9bc60': '[\\n  \"What should I do if I receive an error message stating that billing has not been enabled for my project, even though I believe I have already set it up?\",\\n  \"Can you give me a solution if I\\'ve confirmed my billing account is enabled but still see the billing error?\",\\n  \"What is the specific error message I might encounter related to billing when working on my dataset?\",\\n  \"Is there a recommended action to take if I\\'m facing a billing-related error with my project on Google Cloud?\",\\n  \"How can I resolve the issue if I get a 403 error indicating that billing is not enabled for my project\\'s dataset?\"\\n]',\n",
       " 'f10b49be': '[\"What should I do if I encounter an error related to Application Default Credentials when installing the Google Cloud SDK on Windows?\", \"How can I resolve the issue of not being able to find a quota project while using the Google Cloud SDK?\", \"What steps did you take after reinstalling the Google Cloud SDK to ensure it was functioning correctly?\", \"How do I create a new Virtual Machine instance from an image if my original VM cannot start due to resource issues?\", \"What adjustments do I need to make on the settings page when creating a new VM instance from an image in GCP?\"]',\n",
       " '3184bd8b': '[\\n  \"Is it really necessary to use a GCP VM for this course?\",\\n  \"What issues did students face that led to the creation of the GCP VM video?\",\\n  \"Can I work with my own environment instead of using the GCP VM?\",\\n  \"What are the benefits of using my own environment while working on the course material?\",\\n  \"Why can\\'t I commit changes directly from the repo cloned in the GCP VM?\"\\n]',\n",
       " '8bea4d53': '[\"What should I do if I encounter a \\'Permission denied\\' error while trying to create the \\'.ssh\\' directory?\",\"Where is the correct location to create the directory for SSH?\",\"Why does the command fail when executed in the root folder instead of my home directory?\",\"Is there a tutorial or resource that can help me understand this issue better?\",\"Can I create the \\'.ssh\\' directory in any other location besides my home directory?\"]',\n",
       " '86d11cc0': '[\\n  \"What should I do if I encounter a permissions error when saving files in a GCP VM using VS Code?\",\\n  \"How can I change the ownership of files that I need to edit in my GCP VM?\",\\n  \"What command do I use to fix the \\'permission denied\\' error when attempting to save files in my VM?\",\\n  \"Is there a specific command I can run to resolve saving issues in VS Code related to file permissions?\",\\n  \"What steps should I take to ensure I have access to edit files located in my GCP VM directory?\"\\n]',\n",
       " '2cb48591': '[\"How can I troubleshoot a timeout issue when connecting to my GCP VM via SSH?\", \"What steps should I take if my VM was accessible last week but is timing out this week?\", \"What should I do to ensure my VM is running before trying to connect?\", \"How do I locate and edit the config file within my ~/.ssh folder?\", \"What is the process for retrieving the External IP of my VM?\"]',\n",
       " '9523c813': '[\"How can I fix the issue of not being able to connect to my GCP VM on port 22?\", \"What steps do I need to take to edit my VM settings in GCP?\", \"Where do I find the Automation section to add a startup script in my VM?\", \"What specific command should I include in the startup script to allow SSH connections?\", \"Do I need to stop and restart my VM after adding the startup script?\"]',\n",
       " '4f8d9174': '[\"How can I forward the ports for pgAdmin, postgres, and Jupyter Notebook from GCP without relying on VS Code?\", \"What command do I need to execute on my local machine to establish the SSH connection for port forwarding?\", \"After running the Jupyter Notebook command, where can I find the access token if I encounter credential issues?\", \"What specific ports do I need to use for accessing pgAdmin and Jupyter Notebook from my local browser?\", \"Is there a combined SSH command for forwarding both pgAdmin and postgres at the same time, and if so, what is it?\"]',\n",
       " '29f84a82': '[\\n  \"What should I do if gcloud authentication hangs while using MS VS Code in WSL2?\",\\n  \"Why do I see an error message when attempting to login to GCP via the gcloud CLI?\",\\n  \"How can I successfully open the login page after clicking the prompt in gcloud auth?\",\\n  \"What steps should I follow to configure Trusted Domains for gcloud auth?\",\\n  \"How can I ensure that gcloud auth works seamlessly next time I try to log in?\"\\n]',\n",
       " '20a01fd0': '[\\n    \"What could cause the error when Terraform fails to query available provider packages?\",\\n    \"How can I resolve the issue of Terraform not accessing the online registry?\",\\n    \"What steps should I take if I encounter a request failure for the provider hashicorp/google?\",\\n    \"Could my VPN or Firewall settings be affecting Terraform\\'s ability to connect to the registry?\",\\n    \"What actions might I take to fix the error after checking my network settings?\"\\n]',\n",
       " '5a712a20': '[\\n    \"What might cause the network error related to Terraform when trying to access Google\\'s storage service?\",\\n    \"How does using a VPN affect the connectivity issues I may face with Terraform?\",\\n    \"What steps did you take to resolve the Terraform error you encountered?\",\\n    \"Why does the terminal program not automatically use the system proxy when running Terraform commands?\",\\n    \"What should I do if I continue to have connectivity issues while using Terraform and a VPN?\"\\n]',\n",
       " '06021091': '[\"How can I install Terraform specifically for WSL on my system?\", \"Is there a guide available for configuring Terraform on Windows 10\\'s Linux Subsystem?\", \"Where can I find detailed instructions for setting up Terraform in a WSL environment?\", \"Are there any steps outlined for installing Terraform on Windows 10 with WSL?\", \"Can you recommend a resource for configuring Terraform using the Windows 10 Linux Subsystem?\"]',\n",
       " 'df8ea7e8': '[\\n  \"What should I do if I encounter a state lock error while using Terraform?\",\\n  \"Is there a specific GitHub issue I can refer to regarding state lock errors in Terraform?\",\\n  \"Where can I find more information on resolving state lock issues in Terraform?\",\\n  \"Can you guide me on troubleshooting the state lock error in Terraform?\",\\n  \"Where is the link to the GitHub discussion about Terraform\\'s state lock error?\"\\n]',\n",
       " '1093daf5': '[\\n    \"What error message might I encounter when executing terraform apply on WSL2?\",\\n    \"What causes the invalid JWT token error when using Terraform on WSL2?\",\\n    \"How can I resolve the 400 Bad Request error related to OAuth2 when running Terraform?\",\\n    \"What command can I use to synchronize my system time and potentially fix the JWT issue?\",\\n    \"What should I check in the JWT claim if I receive an invalid grant error during Terraform operations?\"\\n]',\n",
       " '947213b1': '[\"What does the Error 403 message indicate when using Terraform?\", \"How can I resolve the Access Denied issue with Google Cloud?\", \"Where should the GOOGLE_APPLICATION_CREDENTIALS point to?\", \"What command should I run to activate the service account?\", \"What is the format of the file referenced in GOOGLE_APPLICATION_CREDENTIALS?\"]',\n",
       " '002d4943': '[\"Is it necessary to create a separate service account for Terraform during the course?\", \"How many service accounts do I need for the services in this course?\", \"What should I do after obtaining the JSON file with my credentials?\", \"Will one service account cover all resources I use in the course?\", \"What is the importance of setting my environment variable after getting my credentials?\"]',\n",
       " '8dc77677': '[\"Where is the download link for Terraform 1.1.3 for Linux AMD 64?\", \"Can you provide me with the location of Terraform version 1.1.3 for Linux using AMD 64 architecture?\", \"Where can I access the download for Terraform 1.1.3 specifically for Linux AMD 64?\", \"Is there a direct link available for downloading Terraform 1.1.3 for Linux with AMD 64?\", \"What is the URL for obtaining Terraform version 1.1.3 for Linux AMD 64?\"]',\n",
       " '29d3d343': '[\"What does the error message regarding Terraform initialization mean?\", \"How should I properly set up my working directory for Terraform?\", \"What command do I need to run after navigating to my working directory?\", \"Why is it incorrect to run terraform init outside the working directory?\", \"What files do I need to create before starting to work with Terraform?\"]',\n",
       " 'e2095203': '[\"What does the error message regarding insufficient authentication scopes indicate?\", \"How can I solve the error related to creating a dataset in Terraform?\", \"What command should I run to check the status of GOOGLE_APPLICATION_CREDENTIALS?\", \"What does the command echo $? do in the context of this error?\", \"Where can I find instructions on setting GOOGLE_APPLICATION_CREDENTIALS correctly?\"]',\n",
       " '22a2b9f2': '[\"What does the error message \\'Error: googleapi: Error 403\\' indicate when using Terraform?\", \"How can I resolve the issue of being denied permission to create a bucket in Google Cloud?\", \"What specific permission is lacking if I encounter \\'storage.buckets.create access\\' error in Terraform?\", \"Is it necessary to use the Project ID instead of the Project name to avoid this error?\", \"Where can I find the correct Project ID for my Google Cloud project?\"]',\n",
       " '5d7588f0': '[\"How do I manage the GCP credentials securely within my Docker container?\", \"What is the format for specifying the Google provider in Terraform?\", \"Can I avoid hardcoding the credentials directly into my Terraform files?\", \"Which variables are necessary for configuring the Google provider in Terraform?\", \"Is there a specific method to input sensitive information like credentials in Terraform?\"]',\n",
       " '5276a695': '[\\n    \"What is the correct SQL query to retrieve data from the zones_taxi table for the Astoria Zone?\",\\n    \"Why does the error indicate that the column \\'Zone\\' doesn\\'t exist in the database?\",\\n    \"How do I properly reference columns that start with uppercase letters in SQL queries?\",\\n    \"Can you clarify if \\'Astoria Zone\\' actually exists in the dataset or if it\\'s listed as \\'Astoria\\'?\",\\n    \"What steps can I take to avoid similar issues with column names in my future SQL queries?\"\\n]',\n",
       " '70c159df': '[\"What should I do if I get an error stating that the Zone column doesn\\'t exist when running SQL on taxi zones?\", \"How can I avoid using quotation marks repeatedly in my SQL queries?\", \"Is there a preferred format for the data when putting it into the database?\", \"What steps should I take after loading the CSV file in Pandas to align column names?\", \"How can I ensure that my column names are consistently formatted in lowercase?\"]',\n",
       " 'f55efcf0': '[\"What steps should I follow to resolve the host issue when using CURL?\", \"Can you provide a solution for the CURL error related to output.csv?\", \"What command should Mac users use to solve the CURL error?\", \"How can I download a file using CURL if I encounter a host resolution problem?\", \"Is there a specific command format for CURL that Mac users need to follow?\"]',\n",
       " '2b7a8512': '[\\n  \"What should I check if I encounter an SSH error related to hostname resolution?\",\\n  \"Where should I verify the location of my SSH config file?\",\\n  \"What steps can I take to fix the error indicating \\'Name or service not known\\'?\",\\n  \"In case of SSH issues, how can I ensure proper configuration?\",\\n  \"What is the correct directory path for the SSH config file on Windows?\"\\n]',\n",
       " '1cd746c4': '[\\n    \"What steps do I need to follow to add Anaconda\\'s Python to the PATH on a Linux or MacOS system?\",\\n    \"How can I check if Python and pip are installed in the correct locations when using Git Bash on Windows?\",\\n    \"What command should I use to permanently add Anaconda to my PATH on a Linux system?\",\\n    \"What should I do if I\\'m using Windows without Git Bash to add Anaconda to the PATH?\",\\n    \"How can I refresh my environment after making changes to the PATH variable?\"\\n]',\n",
       " '6d367222': '[\\n    \"What should I do if I encounter the error stating that the address is already in use when starting the userland proxy?\",\\n    \"How can I resolve the permission denied error when attempting to stop a Docker container?\",\\n    \"What command do I need to run in Linux to fix the issue of not being able to import the psycopg2 module?\",\\n    \"What could be causing the Docker build error related to file context, and how can I resolve it?\",\\n    \"If Docker requires permission to access a file during a build, what steps can I take to address this issue?\"\\n]',\n",
       " '84e601e1': '[\\n    \"How can I create a requirements.txt file that is compatible with pip from Anaconda?\",\\n    \"What command should I run to install pip using Anaconda?\",\\n    \"Why doesn\\'t conda list -d > requirements.txt work for creating a requirements file?\",\\n    \"What is the correct way to export a pip-friendly requirements.txt file from Anaconda?\",\\n    \"Will using pip freeze > requirements.txt provide accurate paths for my dependencies?\"\\n]',\n",
       " '4cf83cc2': '[\\n    \"Can you provide the links to the FAQ documents for Prefect and Airflow from previous cohorts?\",\\n    \"Where can I find the FAQ questions pertaining to the orchestration module for past classes?\",\\n    \"Is there a specific document that contains the previous cohort questions for the orchestration module?\",\\n    \"Are there separate documents for Prefect and Airflow containing FAQ questions from earlier cohorts?\",\\n    \"What URLs should I visit to access the FAQ records related to the orchestration module?\"\\n]',\n",
       " '5adc5188': '[\\n    \"What should I do if my Docker containers exit with code 132 when I run docker compose up?\",\\n    \"Is the issue with Docker containers due to my computer\\'s architecture or hardware?\",\\n    \"What alternative solution can I try if purchasing a new computer is not an option?\",\\n    \"What version of Ubuntu and Docker is mentioned in the issue recorded about Mage?\",\\n    \"Why is it inconclusive to determine the cause of the Docker containers exiting without knowing the VirtualBox configuration?\"\\n]',\n",
       " '3ef0bb96': '[\\n  \"What is the primary reason behind unexpected kernel restarts in WSL 2 when using Docker?\",\\n  \"How can I check if my .wslconfig file exists in my Bash environment?\",\\n  \"What should I do if I notice WSL 2 not allocating enough CPU cores to Docker?\",\\n  \"How can I modify my .wslconfig file to improve Docker performance in WSL 2?\",\\n  \"What steps should I take after editing my .wslconfig file to ensure changes are applied?\"\\n]',\n",
       " 'a41ce360': '[\\n    \"What is the link to find the issue and solution for configuring Postgres in Module 2?\",\\n    \"Where can I access the discussion about Postgres configuration problems?\",\\n    \"Is there a specific Slack channel for questions related to Postgres setup?\",\\n    \"Can you share the resource for troubleshooting Postgres mentioned in the course?\",\\n    \"What do I do if I encounter issues while configuring Postgres?\"\\n]',\n",
       " 'b1cf59e5': '[\\n  \"What should I do if I encounter an OperationalError while trying to connect to my PostgreSQL database?\",\\n  \"How can I resolve the issue if the connection to the server at localhost fails?\",\\n  \"What is the correct port to set for the POSTGRES_PORT variable in the io_config.yml file?\",\\n  \"Is it necessary to change the POSTGRES_PORT to match a conflicting PostgreSQL installation on my host machine?\",\\n  \"Where can I find the POSTGRES_PORT variable that needs to be configured for the mage container?\"\\n]',\n",
       " 'f9d6f8bd': '[\"What could cause a KeyError when executing SELECT 1 in module 2?\", \"How do I avoid the KeyError when using PostgreSQL in MAGE?\", \"What should I check if I encounter a KeyError while working on workflow orchestration?\", \"Which profile do I need to select to successfully execute queries?\", \"Where can I find the dropdown menu to select the \\'dev\\' profile?\"]',\n",
       " 'f3adb937': '[\\n  \"What steps should I take if I encounter the ConnectionError with a timeout during my workflow orchestration?\",\\n  \"How can I resolve the 404 Not Found error when testing the BigQuery connection for my dataset?\",\\n  \"What specific timeout value should I set in the mage io_config.yaml file to fix the connection issue?\",\\n  \"Is there a specific setting I need to check if my service account has all the necessary roles but still returns a Not Found error?\",\\n  \"What should I do after I update the timeout value in my configuration file to ensure the changes take effect?\"\\n]',\n",
       " 'eb3d6d36': '[\"What should I do if I encounter a RefreshError related to invalid JWT while working with workflow orchestration?\", \"Can you guide me on how to resolve a problem where the error states my JWT must be short-lived?\", \"Where can I find more information on fixing the invalid grant issue related to JWT tokens?\", \"What does the error message about checking \\'iat\\' and \\'exp\\' values in the JWT claim mean?\", \"Is there a reliable source or link for troubleshooting the invalid JWT token issue?\"]',\n",
       " 'a76e1f4d': '[\\n    \"What causes the IndexError: list index out of range in the Mage workflow?\",\\n    \"How can I find the original solution for the IndexError in Mage version 0.9.61?\",\\n    \"What steps should I take to resolve the error that arises after addressing the issue in 2.2.4?\",\\n    \"Is there a newer version of Mage that I should consider using to avoid this error?\",\\n    \"What changes need to be made in the docker-compose.yaml file to fix this problem?\"\\n]',\n",
       " '934facf8': '[\\n    \"What should I do if I encounter an OSError indicating that I cannot save a file into a non-existent directory in Module 2?\",\\n    \"How can I ensure that the directory for saving a file exists before attempting to save it?\",\\n    \"What specific code should I add to handle the situation where the directory does not exist?\",\\n    \"Is there a way to convert a file path to a posix format in this module?\",\\n    \"Where can I find more information or discussion related to saving files and handling directories in this course?\"\\n]',\n",
       " 'a2c7b59f': '[\"What specific steps do I need to follow for deploying Mage to GCP using Terraform?\", \"Is there any information available about enabling the Cloud Filestore API in Google Cloud?\", \"During the deployment process, what does Terraform prompt me to enter?\", \"Can you explain what I need to do after the \\'terraform apply\\' command is executed?\", \"Where can I find the video that has the details about deploying Mage to GCP?\"]',\n",
       " '997d4aaa': '[\\n    \"What steps should I follow to run multiple Docker containers from different directories without issues?\",\\n    \"How can I customize the host port in my Docker setup for Mage on my local machine?\",\\n    \"What should I do if I encounter an insufficient authentication scopes error while terraforming resources in a GCP VM?\",\\n    \"What specific permission changes are necessary in the GCP console to resolve the insufficient permission error?\",\\n    \"How can I ensure that my GCP virtual machine has the correct access scopes for Google APIs?\" \\n]',\n",
       " 'bc269b95': '[\"What issues might I encounter when deploying infrastructures using Terraform on a free trial account in GCP?\", \"Is the Load Balancer service available for users on GCP\\'s free trial?\", \"What steps should I take if I face a Security Policies quota problem while using Terraform?\", \"Can you explain how to modify the main.tf file to resolve the load balancer issue?\", \"What command should I run after deleting the load_balancer.tf file to clean up the created infrastructure?\"]',\n",
       " '10ea342e': '[\"What should I do if I encounter an error when executing terraform apply for the GCP module?\", \"How can I ensure that my project-id, region, and zones are set correctly in the GCP workflow?\", \"What steps should I take if the MAGE Terraform files are taking longer than expected to deploy?\", \"Why might some GCP resources not be destroyed after running terraform destroy, and how can I find them?\", \"How can I check my GCP billing account to monitor charges related to the MAGE Terraform IaC?\"]',\n",
       " '4bd23594': '[\"What does the error message indicate regarding the permission \\'vpcaccess.connectors.create\\'?\", \"How can I resolve the \\'Permission denied\\' error when creating a Connector?\", \"What role should I assign to the Service Account to fix the error?\", \"What is the specific resource mentioned in the error details for the denied permission?\", \"In which part of the Terraform configuration does the error occur related to the Connector?\"]',\n",
       " 'b0d48cd7': '[\\n    \"Why is it that I cannot save a file in a folder that does not exist within my project?\",\\n    \"What should I do if Git fails to push my empty directory to GitHub?\",\\n    \"Can you explain how to create a directory in my code if it is not already present?\",\\n    \"Why might my local relative path not function properly when using GitHub storage?\",\\n    \"What are the recommended practices for handling file paths when uploading to GCS buckets?\"\\n]',\n",
       " '70a37f2c': '[\"What are the names of the pickup datetime columns in the green and yellow datasets?\", \"How should I adjust my scripts based on the dataset I am using?\", \"Is there a difference between lpep_pickup_datetime and tpep_pickup_datetime?\", \"Can I use the same script for both datasets?\", \"Which dataset contains lpep_pickup_datetime?\"]',\n",
       " '8ab78bee': '[\"What should I use to download the VSC utilizing Pandas?\", \"How do I handle large datasets in Pandas when reading from a URL?\", \"What method is recommended for appending data to a parquet file?\", \"Which compression technique should I use when saving to parquet format?\", \"What engine should be specified when appending data to parquet files?\"]',\n",
       " '54c6db2f': '[\\n    \"What does it mean when I encounter a push to Docker image failure?\",\\n    \"What should I do if I see a \\'requested access to the resource is denied\\' error?\",\\n    \"How can I ensure that I am properly logged into Docker Desktop before pushing an image?\",\\n    \"Is it important to use the correct username when pushing Docker images, and why?\",\\n    \"What commands do I need to run for building and pushing a Docker image with my username?\"\\n]',\n",
       " 'c5b998f3': '[\\n    \"What does it mean when my flow script fails and displays a \\'killed\\' message?\",\\n    \"How can I determine if memory issues are causing my flow script failures?\",\\n    \"What is the recommended RAM for a VM to prevent flow script termination?\",\\n    \"If my VM has 8GB of RAM, how much should I upgrade it to if I\\'m experiencing issues?\",\\n    \"Are there any specific indicators that confirm my flow script is failing due to memory shortage?\"\\n]',\n",
       " 'eec29536': '[\\n    \"What should I do if I encounter a situation where my GCP VM disk space is full?\",\\n    \"How can I check which directories are consuming the most disk space on my VM?\",\\n    \"Where are cached flows stored that might be taking up too much space?\",\\n    \"What steps should I take to delete older flows from my VM and prevent errors when running new ones?\",\\n    \"How can I resolve the SSL certificate verification error I received while trying to run flows on my MAC?\"\\n]',\n",
       " '727e5a69': '[\"What does it indicate when my Docker container crashes with a status code of 137?\", \"Why does my container use so much RAM when executing tasks in the homework?\", \"What steps can I take if restarting my computer does not resolve the issue with the container?\", \"Can you suggest ways to allocate more resources to Docker on my workstation?\", \"Is there a free online compute environment I can use if my local machine struggles with container memory requirements?\"]',\n",
       " 'da899638': '[\\n    \"What was the issue that caused the timeout during the task running the ETL script in Q3?\",\\n    \"Can you explain the process involved in uploading data from the web to GCS as described in the record?\",\\n    \"What kind of errors might occur due to slow internet connections, as mentioned in the FAQ?\",\\n    \"What is the recommended method for handling large data uploads to GCS when experiencing timeout issues?\",\\n    \"How should I adjust the timeout setting when uploading parquet files to accommodate larger datasets?\"\\n]',\n",
       " 'dde58c8f': '[\"What does the UndefinedColumn error mean when exporting green_taxi data to PostgreSQL?\", \"How can I resolve the issue of missing columns during the export process?\", \"What steps should I take if I encounter a re-run problem with the export block?\", \"Is there a specific SQL command to drop the table in Mage for the green_taxi data?\", \"Will re-running the block work after dropping the table in PostgreSQL?\"]',\n",
       " '207be93b': '[\"What is the cause of the SettingWithCopyWarning error in pandas?\", \"How can I avoid encountering the SettingWithCopyWarning in my homework?\", \"What syntax should I use to set values in a DataFrame without triggering a warning?\", \"Is there a recommended method for assigning new columns in a DataFrame?\", \"What does the error indicate about the DataFrame I am working with?\"]',\n",
       " 'f0617e65': '[\\n  \"What are the advantages of using the Pyspark kernel in Mage over the Python kernel when working with large CSV files?\",\\n  \"Is there any specific documentation available for utilizing the Pyspark kernel in Mage?\",\\n  \"How does the performance of Pyspark compare to Pandas when handling large datasets?\",\\n  \"Can you provide guidance on switching from the Python kernel to the Pyspark kernel in Mage?\",\\n  \"Are there any limitations or challenges I should be aware of when using Pyspark for large CSV files?\"\\n]',\n",
       " '6290a1a6': '[\\n  \"What steps should I follow to delete a block from a pipeline without encountering errors?\",\\n  \"Is it necessary to delete connections before removing a block in a pipeline?\",\\n  \"Can you explain the process of removing a connection between blocks in a pipeline?\",\\n  \"What should I do if I face an error while trying to delete a block in my pipeline?\",\\n  \"Are there any prerequisites to consider before deleting a block in my workflow orchestration?\"\\n]',\n",
       " '5a06248c': '[\"What should I do if I encounter a permission denied error while trying to edit the Pipeline name in Mage UI?\", \"Is there a workaround for editing the Pipeline name if the UI does not allow it?\", \"Can I save my work and edit the Pipeline name later if I face an error?\", \"What steps should I take if I cannot change the Pipeline name in Mage UI?\", \"Why does Mage UI throw a permission denied error when I attempt to rename the Pipeline?\"]',\n",
       " 'c46a2e9e': '[\\n    \"What are the steps to load all partitioned files I created into BigQuery using Mage?\",\\n    \"Can you explain how to load specific date ranges from partitioned files into BigQuery with Mage?\",\\n    \"What should I do if I encounter an \\'undefined column\\' error while connecting to the green_taxi table?\",\\n    \"Is there a way to delete the green_taxi table if it already exists before loading new data?\",\\n    \"How can I adjust the Data Extractor\\'s settings for loading data from the dataframe in Mage?\"\\n]',\n",
       " '0513ab8a': '[\\n    \"Where can I find the necessary mage files for Homework 2 on my local machine?\",\\n    \"What specific folders should I look for in my mage directory to complete the homework submission?\",\\n    \"How do I download the entire pipeline and what additional files will I receive?\",\\n    \"What types of files do I need to download from the mage folders for the blocks in my pipeline?\",\\n    \"Once I have downloaded the required files, what should I do with them before submitting on GitHub?\"\\n]',\n",
       " 'a9385356': '[\\n  \"What steps do I need to follow to integrate files from the Mage repository into my personal Data Engineering Zoomcamp repository?\",\\n  \"Why do I need to move the contents of the .gitignore file to include the Mage repo files in my Zoomcamp repo?\",\\n  \"What commands should I run in the terminal after accessing the Mage folder to prepare it for inclusion in my main repo?\",\\n  \"How does GitHub treat the Mage repo and my Data Engineering Zoomcamp repo when I try to include their files?\",\\n  \"What does the command \\'git remote remove origin\\' accomplish when working with the Mage repository?\"\\n]',\n",
       " 'c30468c0': '[\\n    \"What error did I encounter when adding multiple assertions in Module 2?\",\\n    \"What should I do if I receive a ValueError about the truth value of a Series?\",\\n    \"How can I correctly filter data based on multiple conditions in my code?\",\\n    \"Which operator should I use instead of \\'and\\' for combining conditions in a DataFrame?\",\\n    \"Where can I find more discussions or solutions related to this ValueError issue?\"\\n]',\n",
       " '305aead7': '[\\n  \"What should I do if I notice that my Mage AI files are missing after starting my PC and running docker compose up?\",\\n  \"Is there a specific command I need to use to properly shut down the Mage Docker before restarting it?\",\\n  \"How can I ensure that I am in the correct directory before executing the docker compose up command?\",\\n  \"What steps should I take if I continue encountering issues with disappearing files while using Mage?\",\\n  \"Where can I find additional discussions or solutions regarding issues with Mage AI files in the course community?\"\\n]',\n",
       " '77410975': '[\"What kind of errors can occur in the io.config.yaml file in relation to the Mage section?\", \"How should I fix errors that are caused by incorrect quotes in the io.config.yaml file?\", \"What specific modifications are necessary for fixing trailing side errors in the io.config.yaml file?\", \"Who can I refer to for help with issues related to the io.config.yaml file in Module 2?\", \"Are there particular characters that should be avoided in the io.config.yaml file to prevent errors?\"]',\n",
       " '0952abde': '[\"What error occurs when exporting data from Mage to a GCS bucket using pyarrow?\", \"What does the ArrowException indicate about permissions when accessing the GCP credentials file?\", \"How do I resolve the issue of Mage being unable to open the credentials file?\", \"What steps should I follow to create the necessary credentials folder for Mage?\", \"Where do I update the code to specify the path to my GCP service account credentials?\"]',\n",
       " '7c4326eb': '[\\n    \"What does the OSError related to Google Cloud indicate when working with Mage?\",\\n    \"Why might I encounter a retry policy exhaustion error while trying to get bucket metadata?\",\\n    \"What is required to successfully complete a request for Google Cloud resources?\",\\n    \"Where can I find more information about Google Cloud authentication?\",\\n    \"What does the underlying error message suggest about the issue with performing the work?\"\\n]',\n",
       " 'a1fc1a14': '[\\n  \"What issue arises when I try to export data from Mage to a Google Cloud Storage bucket?\",\\n  \"What does the error message indicate regarding the service account\\'s permissions?\",\\n  \"How can I resolve the PermissionError related to Google Cloud Storage access?\",\\n  \"What steps do I need to follow to add the necessary role to my service account?\",\\n  \"What role should I assign to the service account for it to gain access to the storage bucket?\"\\n]',\n",
       " '6d67fba9': '[\"What preparations do I need to make for my pyspark script before sending it to the Dataproc cluster?\", \"How do I create a Dataproc Cluster in the GCP Console?\", \"What changes must be made to the service account in order to add the Dataproc Editor role?\", \"Where should I place my python script in the GCS bucket and how do I access it?\", \"Is there a specific requirement for installing the gcloud CLI to allow Mage to access Dataproc?\"]',\n",
       " '06876291': '[\\n    \"What is a potential solution for the long installation time of zip and unzip packages in Docker-compose?\",\\n    \"How can I automate the installation of additional packages when using apt-get?\",\\n    \"Is there an alternative method for unpacking datasets besides using zip and unzip?\",\\n    \"Why might Docker-compose take a long time to install required packages for datasets on Linux?\",\\n    \"Is the Python ZipFile package available in all current Python environments?\"\\n]',\n",
       " '690ba010': '[\"What should I do if I encounter an error when writing data from the web to GCS?\", \"Are there specific data types I should use to avoid errors with GCS Buckets?\", \"Can you provide guidance on the types of data I should consider using for GCS?\", \"Is there a recommendation for handling Nullable data types when writing to a GCS Bucket?\", \"What data types are suggested to prevent errors in Module 3: Data Warehousing?\"]',\n",
       " 'b6fdd91d': '[\"What is the importance of having a consistent schema in BigQuery while ingesting data?\", \"Can you explain why all files in a directory must have the same schema for successful ingestion into BigQuery?\", \"How does the schema definition work when importing multiple parquet files into BigQuery?\", \"What steps should I take to prevent errors related to data type mismatches when uploading to BigQuery?\", \"What are the data types used in the FHV Datasets from 2019, and how do they affect schema consistency?\"]',\n",
       " '155aa868': '[\\n  \"What should I do if I get a gzip error while importing FHV data to GCS?\",\\n  \"How can I resolve the \\'Not a gzipped file\\' error when working with FHV dataset?\",\\n  \"What is the correct URL format for the FHV dataset in GCS?\",\\n  \"Can you clarify the specific part of the URL I need to emphasize for importing FHV data?\",\\n  \"Why does specifying the wrong URL lead to a gzip error when importing data?\"\\n]',\n",
       " 'e78cf960': '[\\n    \"Who should I contact regarding loading data from a URL list to a GCP bucket in Module 3?\",\\n    \"Is there a specific individual responsible for assistance with the GCS bucket tasks?\",\\n    \"In the context of Module 3, who can help with data loading into GCP?\",\\n    \"If I have questions about GCS buckets, who can provide guidance?\",\\n    \"For issues related to loading data from URLs to GCP, whom should I reach out to?\"\\n]',\n",
       " '9afa1f74': '[\"What should I do if I encounter a Bad character (ASCII 0) error while querying my dataset in the GCS Bucket?\", \"Is there a specific aspect of the data that I need to check when facing a Bad character error?\", \"How can I ensure that my CSV.GZ files are correctly formatted for upload?\", \"Are there any alternative methods to upload my CSV.GZ files aside from using pandas?\", \"Where can I find helpful tips regarding this issue discussed among peers?\"]',\n",
       " 'fac138a7': '[\"How can I verify if the BigQuery Command Line Tool is installed on my system?\", \"What command should I use to troubleshoot the \\'bq: command not found\\' error?\", \"Is there an alternative way to run the BigQuery command if \\'bq\\' is not recognized?\", \"What steps should I follow to check the installation status of Cloud components?\", \"Can I use a different command in place of \\'bq\\' to execute BigQuery functions?\"]',\n",
       " '0174dde5': '[\"What precautions should I take when using BigQuery within GCP?\", \"Why did I receive an $80 bill for using BigQuery on my project?\", \"How can I prevent unexpected charges while using BigQuery?\", \"What is the recommendation regarding managing datasets in BigQuery?\", \"Is there a specific action I should take regarding billing while using BigQuery?\"]',\n",
       " '1023ee65': '[\\n  \"What happens if my GCP resources are in different regions when attempting to load data into BigQuery?\",\\n  \"How can I successfully load data from a GCS bucket to BigQuery if they are in separate regions?\",\\n  \"Is it possible to keep my existing datasets and still load data from a GCS bucket in a different region?\",\\n  \"What should I do if I forgot to align the regions for my GCS bucket and BigQuery dataset during creation?\",\\n  \"Can I create a new BigQuery dataset in the same region as my GCS bucket to resolve the region issue?\"\\n]',\n",
       " 'effd2bfa': '[\"What should I do if I cannot read and write in different locations in GCP BQ?\", \"How can I ensure my BigQuery dataset is compatible with my GCS Bucket?\", \"Is it necessary for the BigQuery dataset and GCS Bucket to be in the same region?\", \"Can I create a BigQuery dataset in a different location from my GCS Bucket?\", \"What is an example of how to set the same location for both GCS Bucket and BigQuery dataset?\"]',\n",
       " '5b55273c': '[\"What should I do to prevent losing my work in BigQuery SQL Editor?\", \"Is there a specific button I need to click to save my queries in BigQuery?\", \"What happened to someone\\'s SQL script when their Chrome Tab froze?\", \"Can I save my queries in a different format outside of BigQuery?\", \"Which editors can I use to save my SQL scripts with color formatting?\"]',\n",
       " '1835bfe0': '[\"Is BigQuery suitable for real-time analytics in this project?\", \"Does BigQuery support real-time data streaming?\", \"Can I integrate real-time analytics using BigQuery later?\", \"Is real-time analytics a feature of BigQuery for this course?\", \"What capabilities does BigQuery offer for real-time analytics?\"]',\n",
       " '04656af5': '[\\n  \"What should I do if I encounter a timestamp parsing issue when loading data into a materialized table in BigQuery?\",\\n  \"How can I identify invalid timestamp data when importing to a materialized table in BigQuery?\",\\n  \"What is the cause of the invalid timestamp error related to the \\'pickup_datetime\\' field?\",\\n  \"Is there a way to filter out invalid rows during the loading process into a materialized table?\",\\n  \"What datatype should I use when defining the schema from the external table to avoid timestamp errors?\"\\n]',\n",
       " '2d6536d3': '[\\n    \"What error message do I encounter in BigQuery related to timestamps?\",\\n    \"How can I resolve the issue with timestamps being recognized as integers in BigQuery?\",\\n    \"What function do I need to modify in order to handle deprecated INT96 timestamps correctly?\",\\n    \"Where can I find resources to understand compatibility issues between Parquet files created with PyArrow and Pyspark?\",\\n    \"What parameter should I include in the pq.write_to_dataset function to fix timestamp formatting errors?\"\\n]',\n",
       " '0516ccbe': '[\"What is the issue with datetime columns in Parquet files created from Pandas when using BigQuery?\", \"What should I do if I am using Mage and facing problems with datetime columns in my data?\", \"How can I ensure that datetime columns are loaded correctly into BigQuery from Parquet files?\", \"Is there a way to use explicit schema in PyArrow when writing Parquet files for Google Cloud Storage?\", \"What specific logical type should I use for datetime columns in my PyArrow schema to avoid conversion issues in BigQuery?\"]',\n",
       " '6052513d': '[\\n    \"What is the process for creating an external table in BigQuery using Python?\",\\n    \"Which external source format should I specify when creating the external table?\",\\n    \"How do I point to my data in Google Cloud when setting up source URIs?\",\\n    \"What is the purpose of the ExternalConfig object in this context?\",\\n    \"How do I confirm that the external table has been successfully created?\"\\n]',\n",
       " '7a71fa2c': '[\"How can I verify if a table exists in BigQuery using Python?\", \"What is the method to delete an existing table in BigQuery?\", \"Is there a specific function to check for the existence of a table before creating it?\", \"Where can I find additional resources on handling BigQuery tables programmatically?\", \"What should I do if an error occurs while checking for a table\\'s existence in BigQuery?\"]',\n",
       " 'f83d9435': '[\"How can I resolve the error related to a missing close double quote in GCP BQ?\", \"What command should I use to upload data from Google Cloud Storage to BigQuery?\", \"Is there a way to avoid issues with quoted newlines when loading data into BigQuery?\", \"Where can I find the data files to upload to my BigQuery table?\", \"What is the recommended source format for loading CSV files into BigQuery?\"]',\n",
       " 'dbf65e11': '[\"What should I do if I\\'m unable to read and write data in different locations in GCP BigQuery?\", \"How can I check the region of my Google Cloud Storage bucket?\", \"What steps should I take to create a dataset in BigQuery with the correct region?\", \"Why does the error occur when my GCS and BigQuery are set up in different regions?\", \"Which icon do I need to click on to create a new dataset in BigQuery?\"]',\n",
       " 'c489266b': '[\"What are the advantages of using Cloud Functions for automating tasks in Google Cloud?\", \"How do I modify the provided Cloud Function script to use my own project, dataset, and table IDs?\", \"Can you explain how the LoadJobConfig schema is defined in the script?\", \"What happens when I run the script for loading data from the first month versus subsequent months?\", \"What steps should I take to ensure successful data loading into BigQuery in the specified location?\"]',\n",
       " 'ebd63566': '[\"What should I do in query settings to avoid caching when analyzing two tables?\", \"How can I ensure that my query results for external and materialized tables are accurate?\", \"Is there a specific option I need to change in the query settings when using GCP BQ?\", \"Why do I get the same count when querying different types of tables in BigQuery?\", \"What action can I take to differentiate the query outputs of external and materialized tables?\"]',\n",
       " 'f7252f17': '[\\n    \"What specific issue can arise when inserting data into GCS with Pandas related to DOlocationID and PUlocationID?\",\\n    \"How does the default behavior of Pandas affect the data type consistency between parquet files and BigQuery schema?\",\\n    \"What solution is recommended to resolve data type discrepancies before loading data into GCS?\",\\n    \"Which method should be used to cast the data types of DOlocationID and PUlocationID to avoid errors in BigQuery?\",\\n    \"Why is it important to define the data type of all columns in the Transformation section of the ETL pipeline?\"\\n]',\n",
       " '47a43bb0': '[\\n  \"What does the error message regarding the Parquet column \\'DOlocationID\\' indicate about data type mismatches?\",\\n  \"How can I resolve the issue related to invalid project IDs in GCP BQ?\",\\n  \"What should I check for if I encounter an error while reading a table in BigQuery?\",\\n  \"Are there any specific formatting requirements for project IDs in GCP BQ?\",\\n  \"What common mistakes can lead to errors when writing SQL queries in BigQuery?\"\\n]',\n",
       " 'f3f13def': '[\"What kind of error occurs when reading the trips_data_all.external_fhv_tripdata table?\", \"What is the data type mismatch situation with the DOlocationID column?\", \"Can you explain if BigQuery allows multiple columns for partitioning?\", \"What does the documentation say about partitioning in BigQuery?\", \"Is it possible to have more than one column partitioned in BigQuery?\"]',\n",
       " '4fd37712': '[\\n  \"What does the error message regarding \\'DOlocationID\\' indicate about the data type mismatch in BigQuery?\",\\n  \"What is the specified requirement for the PARTITION BY expression in BigQuery when encountering a DATE() error?\",\\n  \"Can you clarify the types of columns that can be used in a PARTITION BY expression in BigQuery?\",\\n  \"What steps should I follow to resolve the issue related to the DATETIME columns in my DataFrame?\",\\n  \"How do I convert my pickup and dropoff datetime columns to the correct format before using them in BigQuery?\"\\n]',\n",
       " '8abeca36': '[\\n    \"What is the primary difference between native tables and external tables in BigQuery?\",\\n    \"How does data storage differ between native and external tables in BigQuery?\",\\n    \"Can you explain what happens to metadata in external tables within BigQuery?\",\\n    \"Where is the data stored when using external tables in BigQuery?\",\\n    \"What resources can I consult for more information on BigQuery tables?\"\\n]',\n",
       " '16c16ff9': '[\\n  \"Why am I receiving an error about the Parquet column \\'DOlocationID\\' when trying to read my table?\",\\n  \"What should I do if my ML model export command is failing due to a dataset not found error in BigQuery?\",\\n  \"How can I ensure that my dataset and GCS bucket are properly configured to avoid location errors?\",\\n  \"What is the correct command syntax for exporting an ML model from BigQuery to Google Cloud Storage?\",\\n  \"Can you explain why my project ID and GCS bucket folder address might be causing an issue during the export process?\"\\n]',\n",
       " 'c65d8fd9': '[\"What error do I encounter when trying to read the trips_data_all.external_fhv_tripdata table?\", \"How can I address the issue with the DOlocationID type mismatch when running my queries?\", \"What specific configuration change do I need to make to the dim_zones table to resolve the dataset not found error?\", \"In which location should I specify the parameter when creating the dim_zones table?\", \"What steps do I need to follow after updating the dim_zones table configuration to ensure my fact_trips.sql runs successfully?\"]',\n",
       " 'c1a95536': '[\\n  \"What error might I encounter when reading the trips_data_all.external_fhv_tripdata table in GCP BQ ML?\",\\n  \"Can you explain the solution for running an ML model export on a MacBook with an Apple M1 chip?\",\\n  \"What command should I use to pull the Docker image for TensorFlow serving on an Apple M1 Mac?\",\\n  \"How do I set up the serving directory on my computer according to the extract_model.md file?\",\\n  \"What should I do after running the Docker command to get predictions for my model?\"\\n]',\n",
       " 'bba0da04': '[\\n    \"What steps should I take if I find that my virtual machine is running low on storage space?\",\\n    \"Are there any specific types of files I should focus on when trying to free up space in my VM?\",\\n    \"What actions should I take regarding processes if I delete files in my virtual machine?\",\\n    \"Is there a recommended tool I can use to identify large files on my virtual machine?\",\\n    \"What should I remember to do with my flow code if I delete files related to Prefect?\"\\n]',\n",
       " 'a2120335': '[\\n    \"What should I do if I encounter an error related to the trips_data_all.external_fhv_tripdata table?\",\\n    \"Can you clarify what the instruction means regarding stopping the loading of files into a bucket?\",\\n    \"Is it necessary to clean the data before creating the external table after loading it into the bucket?\",\\n    \"What should be the format of the files after loading them into the bucket for the external table creation?\",\\n    \"Are there specific file types we are allowed to load into the bucket for our project?\"\\n]',\n",
       " 'a4ba2478': '[\"What specific error might occur when trying to read parquet files directly from nyc.gov into pandas?\", \"Can you explain the cause of the out of bounds error when reading timestamp data from the dataset?\", \"What is the recommended method to read parquet files from nyc.gov to avoid the out of bounds error?\", \"How can I handle errant records in datetime columns when loading data with pandas?\", \"Is there a way to filter out offending rows that cause errors in datetime columns when working with parquet files?\"]',\n",
       " '74c361fe': '[\"What should I do if I encounter an error related to the Parquet column type while reading a table?\", \"Is it necessary to download each month\\'s green taxi parquet file separately for 2022?\", \"How can I refer to all 12 parquet files in a single string when creating an external table in BigQuery?\", \"Do I need to upload the parquet files to a specific location in my GCS bucket?\", \"Can I use a wildcard to access the green taxi data files for 2022 efficiently?\"]',\n",
       " 'b9b3ef9f': '[\"What should I do if I encounter an error while reading the trips_data_all.external_fhv_tripdata table?\", \"How can I avoid schema issues when completing the homework?\", \"What is the recommended method for uploading files to GCS?\", \"Is it possible to upload multiple files at the same time to GCS?\", \"Can I upload an entire folder to GCS instead of individual files?\"]',\n",
       " '009ac612': '[\\n    \"What should I do if my partitioned table is not providing the expected prediction?\",\\n    \"Could you clarify what steps I need to take regarding the date format for Homework Qn 5?\",\\n    \"Is it possible that the issue with my predictions relates to how dates are formatted in the dataset?\",\\n    \"What is the connection between date formats and the accuracy of predictions in our assignments?\",\\n    \"Can you explain why the table error I encountered might affect the results of my homework?\"\\n]',\n",
       " '68815ec2': '[\"What is the error that occurs when reading the table \\'trips_data_all.external_fhv_tripdata\\'?\", \"What type mismatch is causing the error related to \\'DOlocationID\\' in the Parquet column?\", \"Did anyone achieve an exact answer for the options in Module 3 homework question 6?\", \"How are students faring in terms of matching their answers for Homework Q6?\", \"What should students do if their answers are not exact according to Alexey\\'s guidance?\"]',\n",
       " 'c8ad08b3': '[\\n    \"What should I do if I encounter a Parquet column type mismatch error when reading the trips data?\",\\n    \"How can I resolve a UnicodeDecodeError related to invalid start bytes when working with data in Python?\",\\n    \"What encoding should I specify when reading a CSV file from the web into a pandas dataframe?\",\\n    \"How do I write a pandas dataframe to Google Cloud Storage as a CSV file while ensuring the correct encoding?\",\\n    \"Is there an alternative method for reading data from a URL instead of using the standard CSV approach in pandas?\"\\n]',\n",
       " 'd68b433f': '[\\n    \"What is a generator in Python and how does it differ from other iterables like lists or tuples?\",\\n    \"Can you explain the role of the yield keyword in creating a generator function?\",\\n    \"How do generators help with memory efficiency when working with large datasets?\",\\n    \"What does it mean for a generator to generate values on-the-fly?\",\\n    \"Could you provide examples of situations where using a generator would be more advantageous than using a list?\"\\n]',\n",
       " 'e265ee5a': '[\\n  \"What is the error message related to the Parquet column \\'DOlocationID\\' in the trips_data_all dataset?\",\\n  \"How does the read_parquet function handle multiple files?\",\\n  \"Can I merge multiple files into one table using read_parquet?\",\\n  \"What type does the column \\'DOlocationID\\' have in the dataset, and how does it affect reading it?\",\\n  \"Is it possible to pass a list of files to the read_parquet function for processing?\"\\n]',\n",
       " '0e7dfddc': '[\"What type must the \\'DOlocationID\\' column be when working with the trips_data_all table?\", \"What error can occur if the data type is not correctly set for \\'DOlocationID\\'?\", \"How should I correctly convert the \\'DOlocationID\\' column to avoid errors?\", \"What is the alternative way to convert \\'DOlocationID\\' if I encounter type mismatches?\", \"Is it acceptable to use astype(int) for the \\'DOlocationID\\' column?\"]',\n",
       " '0a059700': '[\\n    \"What should I do if I encounter an error while trying to read the Parquet column \\'DOlocationID\\' in my data?\",\\n    \"How can I resolve the ValueError regarding the missing path when running my Prefect flow?\",\\n    \"Is there a specific parameter I need to remove from my function to successfully run the flow again?\",\\n    \"What is the purpose of the cache key in my Prefect flow, and how does it affect execution?\",\\n    \"Can using the cache key in my initial run lead to any issues when I try to rerun my code?\"\\n]',\n",
       " 'feca7402': '[\"What is the purpose of the @task decorator in the code snippet provided?\", \"Can you explain how the download_file function works in detail?\", \"What type of file is being downloaded using the provided code sample?\", \"How is the flow function extract_from_web related to the downloading process?\", \"Is there a specific library that needs to be imported to use the requests.get method in this context?\"]',\n",
       " '1f519b1a': '[\\n    \"What should I do if I encounter an error stating that the prod dataset is not available in the correct location during production deployment?\",\\n    \"How can I resolve the issue of my DBT models creating a dataset in the US location instead of the EU location on DBT Cloud?\",\\n    \"Is there a specific configuration I need to adjust in the dbt_project.yaml file to fix seed column type errors?\",\\n    \"What steps did you take to successfully run your DBT job in production after encountering location errors?\",\\n    \"Why does everything work fine in development mode but fail in production when using DBT Cloud?\"\\n]',\n",
       " '43c454c7': '[\\n    \"What should I do if I encounter an error regarding a missing development environment?\",\\n    \"How can I configure my development credentials for dbt IDE?\",\\n    \"Where can I find the guide to resolve the development environment issue?\",\\n    \"Which video contains information about setting up the development environment?\",\\n    \"Is there a specific Slack chat where I can ask about the development environment error?\"\\n]',\n",
       " 'd7ad69da': '[\\n  \"What is the reason for the Runtime Error when connecting dbt Cloud with BigQuery?\",\\n  \"How can I resolve the \\'Access Denied\\' error for my dbt service account?\",\\n  \"What permissions does my service account need to create BigQuery jobs?\",\\n  \"What steps should I follow in Google Cloud to grant my service account the necessary access?\",\\n  \"What additional roles should I assign to prevent permission issues during the course?\"\\n]',\n",
       " '03fdb780': '[\\n    \"What causes a dbt Cloud run to be cancelled?\",\\n    \"How can I check if my dbt project is set up correctly?\",\\n    \"What file should be present for a valid dbt project?\",\\n    \"What should I do if my dbt project is in a subdirectory?\",\\n    \"Where can I specify the location of my dbt project in dbt Cloud?\"\\n]',\n",
       " '9c85f3aa': '[\\n    \"What should I do if I encounter an error stating that the repository failed to clone?\",\\n    \"How can I resolve the permission denied error when trying to clone the GitHub repository?\",\\n    \"What are the steps to clone the repository with my GitHub username?\",\\n    \"Is there an alternative way to set up a fresh repository for my dbt lessons?\",\\n    \"What is the recommended method for cloning the repository if I want to avoid permission issues?\"\\n]',\n",
       " '63026349': '[\\n  \"What should I do if the option to create a Continuous Integration job in dbt Cloud is disabled when I try to set it up?\",\\n  \"Is it possible to set up a CI Job in dbt Cloud while on the Developer Plan?\",\\n  \"What are the prerequisites for creating a Continuous Integration job in dbt Cloud?\",\\n  \"If I am currently in the Team Plan trial, but the CI job option is disabled, what can I do?\",\\n  \"What plan do I need to upgrade to in order to utilize CI Jobs in dbt Cloud?\"\\n]',\n",
       " '6ba02f77': '[\\n    \"What should I do if the DBT cloud IDE fails to start and shows an error?\",\\n    \"Where can I find instructions for setting up my DBT cloud environment?\",\\n    \"How can I resolve the issue of the DBT cloud IDE loading indefinitely?\",\\n    \"What steps are necessary to import a repository into my DBT project?\",\\n    \"How do I create an SSH key for my DBT cloud setup?\"\\n]',\n",
       " '8b14286c': '[\\n  \"What should I do if I encounter datatype problems with columns while using DBT and BigQuery?\",\\n  \"How can I define the schema when converting from CSV to Parquet to avoid datatype issues?\",\\n  \"What steps can I take to fix a task failure in DBT due to mismatched data types in Parquet columns?\",\\n  \"Is there a way to specify data types while importing a CSV file to a pandas DataFrame to prevent errors?\",\\n  \"What are the potential solutions for handling the \\'ehail_fee\\' column if it causes errors during DBT runs?\"\\n]',\n",
       " '14a876ea': '[\"What should I do if the quick script for loading trip data into GCS returns an Access Denied error from the S3 bucket?\", \"Is there an alternative way to download the trip data if the provided URL does not work?\", \"How can I use the GitHub CLI to obtain the trip data required for my project?\", \"What commands do I need to execute with the GitHub CLI to download the yellow and green trip data?\", \"After downloading the trip data using the GitHub CLI, how can I upload the files to a GCS bucket?\"]',\n",
       " '1cf5be74': '[\"What is the specific error encountered when converting the fhv_tripdata_2020-01.csv file using Airflow?\", \"What is the cause of the error thrown by the format_to_parquet_task during the ingestion process?\", \"How can I fix the issue related to the random line breaks in the fhv_tripdata_2020-01.csv file?\", \"What command should I manually run in the bash of the container to solve the conversion error?\", \"What should I do in Airflow after fixing the CSV file to ensure it re-executes properly?\"]',\n",
       " '315ac3cc': '[\\n  \"What approach did you initially use to load yellow and green trip data for 2019 and 2020?\",\\n  \"What issue did you encounter when trying to load the yellow trip data using the initial method?\",\\n  \"What alternative method worked for you when handling the parquet files and loading them to GCS?\",\\n  \"Who shared the hack that helped resolve the schema inconsistency when creating the BigQuery table?\",\\n  \"Is there a recommended resource to watch regarding schema changes needed for loading data to BigQuery?\"\\n]',\n",
       " 'c5c3beba': '[\\n    \"What is the format of the files I need to move from the Google Cloud Storage bucket to BigQuery?\",\\n    \"How do I specify multiple files when transferring data to BigQuery?\",\\n    \"Is there a specific syntax I should use to include all files in a folder?\",\\n    \"What path do I need to use for referencing the files in Google Cloud Storage?\",\\n    \"Do I need to state the file extension when moving files from Google Cloud Storage to BigQuery?\"\\n]',\n",
       " 'f19be91b': '[\\n    \"What might cause SSH to stop working on my GCP VM after a restart?\",\\n    \"How can I resolve SSH issues related to my GCP VM?\",\\n    \"What should I check in the \\'.prefect/storage\\' folder if I encounter problems?\",\\n    \"Is there a way to prevent SSH issues from occurring after running prefect?\",\\n    \"How often should I delete logs in the \\'.prefect/storage\\' folder to avoid problems?\"\\n]',\n",
       " '33db7dc7': '[\\n  \"What should I do if I can\\'t access my GCP VM due to insufficient space?\",\\n  \"How can I regain SSH access to my machine after a space issue?\",\\n  \"What steps can I take if I receive a permission denied error when trying to SSH?\",\\n  \"Is there a way to recover access to a GCP VM that I cannot connect to?\",\\n  \"What causes the \\'permission denied (publickey)\\' error when accessing my VM?\"\\n]',\n",
       " '67ef8f87': '[\"What should I do if I encounter a \\'404 Not Found\\' error regarding a dataset in BigQuery?\", \"How can I check the location of the source dataset and the schema I am writing to in BigQuery?\", \"What steps should I take to resolve issues related to dataset locations in BigQuery when using dbt?\", \"Is there a way to specify a single-region location for my datasets instead of using a multi-regional location in dbt?\", \"What are the steps to update the location settings in dbt Cloud for my BigQuery project?\"]',\n",
       " '6acf2e77': '[\\n    \"What should I do if I receive a warning after running dbt with the latest version of dbt-utils?\",\\n    \"How can I fix the error related to dbt_utils.surrogate_key when running a dbt command?\",\\n    \"What steps should I take if I encounter an \\'Access Denied\\' error in BigQuery after creating fact_trips.sql?\",\\n    \"Which role do I need to add to the service account to resolve the permission issue in BigQuery?\",\\n    \"Are there any additional permissions required for the service account in Google Cloud Storage related to dbt?\"\\n]',\n",
       " '18430f10': '[\"What should I do if I encounter an error stating that dbt_utils is not found?\", \"How can I add the necessary packages to my dbt project?\", \"Is it required to create a packages.yml file in the main project directory?\", \"What version of dbt_utils should I specify in the packages.yml?\", \"What steps should I follow after creating the packages.yml file?\"]',\n",
       " 'afb7a40a': '[\"What should I do if the lineage feature is not accessible in my project?\", \"How can I confirm that my yml file is formatted correctly?\", \"Where can I find the build logs to verify the success of my run?\", \"What steps can I take to view error messages or warnings in my command history console?\", \"Who should I contact if the lineage issue continues after checking for compilation errors?\"]',\n",
       " 'd6a5b80e': '[\"What command should I use to ensure my Fact_trips includes all available data?\", \"Is there a specific variable I need to set to get complete data in my Fact_trips?\", \"What should I do if my Fact_trips is missing data for certain days?\", \"Are there any formatting issues I need to be aware of when typing commands?\", \"What alternative syntax can I use if the standard command doesn\\'t work for my data build?\"]',\n",
       " 'de426d2f': '[\"What should I check if my fact_trips show data for only one month?\", \"How do the if_exists settings affect my data uploads to BigQuery?\", \"What happens if I use if_exists=\\'replace\\' while running my automated flow?\", \"How can I ensure that I include data from all months when uploading to BigQuery?\", \"What is the difference between if_exists=\\'replace\\' and if_exists=\\'append\\' in terms of data retention?\"]',\n",
       " '354f0e10': '[\\n    \"What change should I make in the dm_monthly_zone_revenue.sql model after the second SELECT statement?\",\\n    \"How should I format the month argument in the date_trunc function for BigQuery?\",\\n    \"What error might I encounter when running the dm_monthly_zone_revenue.sql model?\",\\n    \"What should I avoid when writing the month parameter in date_trunc for my SQL model?\",\\n    \"Can you clarify the correct way to use date_trunc for truncating dates by month in BigQuery?\"\\n]',\n",
       " '98fae8d0': '[\\n    \"What is the correct syntax for generating a surrogate key in dbt?\",\\n    \"How can I replace the old surrogate key function in my project?\",\\n    \"What function should I use to create surrogate keys for multiple fields?\",\\n    \"Is there a new method for surrogate key generation in dbt?\",\\n    \"What change should I make to the surrogate key definition in Module 4?\"\\n]',\n",
       " 'cb678fde': '[\\n    \"What should I do if my dbt run fails after changing the dataset location?\",\\n    \"How can I resolve the error I\\'m encountering in dbt run after altering the location?\",\\n    \"Is there a way to fix the issue with dbt run if I\\'ve modified the dataset\\'s location?\",\\n    \"What steps do I need to take to correct errors in dbt after changing its location?\",\\n    \"If I encounter errors after changing a location in dbt, how can I correct them?\"\\n]',\n",
       " '39bfb043': '[\\n    \"What should I do if running dbt run with a specified variable value does not change the number of rows in my table?\",\\n    \"Why is a new dataset created in BigQuery after I run my CI/CD job?\",\\n    \"How can I ensure that my development models are merged into production models when using dbt?\",\\n    \"What happens if I select \\'defer to another environment\\' in my CI/CD job setup?\",\\n    \"Is it necessary to remove the existing dataset before rerunning dbt to see the updated row count?\"\\n]',\n",
       " '351a078a': '[\\n    \"What role does the Staging dataset play in the analytics process?\",\\n    \"Can you explain why the Staging dataset is materialized as views instead of tables?\",\\n    \"In the context of the project, how did Vic utilize the production dataset?\",\\n    \"What alternative datasets did Vic create during the course videos?\",\\n    \"Does the Staging dataset have to be used when working with the dbt framework?\"\\n]',\n",
       " '61da1919': '[\\n    \"What should I do if I see a message indicating that DBT Docs are served but I can\\'t access them in my browser?\",\\n    \"Is there a specific line I need to delete from docker-compose to fix the access issue with DBT Docs?\",\\n    \"What changes should I make to my docker-compose file if the DBT Docs are not accessible?\",\\n    \"How can I troubleshoot the problem of DBT Docs being served but not shown in the browser?\",\\n    \"What configuration in docker-compose might be preventing me from accessing DBT Docs through my web browser?\"\\n]',\n",
       " '6528c6ae': '[\"How can I resolve the 404 error related to my BigQuery dataset not being found in the specified location?\", \"What steps should I follow to check and adjust the location settings for my BigQuery connection?\", \"Is there a specific procedure for re-uploading my GCP key after adjusting the location?\", \"What should I do if my dataset is still not found after rebuilding the project with dbt?\", \"Do I need to delete my dataset in GBQ before rebuilding the project with dbt?\"]',\n",
       " 'c0d3a2e8': '[\"How can I make changes to the main branch in dbt?\", \"What should I do if I want to edit files in dbt?\", \"Is the main branch in dbt editable?\", \"Where can I find more information about branching in dbt?\", \"What steps should I take to modify the main branch using git?\"]',\n",
       " '859a97c5': '[\"How can I make changes to files in dbt when I\\'m in read-only mode?\", \"What steps should I take to create a new branch for development in dbt?\", \"After creating a new branch, how do I merge my changes back to the main branch?\", \"What does it mean to commit and push changes in the context of dbt?\", \"Can you explain the process of switching branches when working with dbt and git?\"]',\n",
       " '32469a2d': '[\"What error occurs when trying to create CI checks for deployment to Production in dbt?\", \"What triggers the error related to pull requests in dbt deploy with Git CI?\", \"Which repository connections are required for the CI checks feature in dbt?\", \"What solution should I follow instead of using the Git Clone option when deploying?\", \"Where can I find the step-by-step guide for unlinking Git Clone and linking with Github?\"]',\n",
       " 'c599b3a0': '[\"How can I resolve the issue of not seeing the Run on Pull Requests option when setting up Continuous Integration with Github?\", \"What steps should I follow to reconnect my Github account with my dbt project?\", \"Where do I find the option to disconnect my current Github configuration within the dbt settings?\", \"What should I do after disconnecting the current Github configuration in order to set it up again properly?\", \"After reconnecting Github, how do I configure the job to ensure I see the Run on Pull Requests option?\"]',\n",
       " '179df18d': '[\"What should I do if I encounter a Compilation Error related to a missing source in my DBT project?\", \"How can I fix the issue with the Lineage graph not displaying during the tutorial in Module 4?\", \"Is there a specific moment in the DE Zoomcamp video where I should pay attention to avoid issues?\", \"What file do I need to save to resolve the Compilation Error mentioned in the FAQ?\", \"After saving the schema.yml file, will I be able to view the Lineage graph without problems?\"]',\n",
       " '1ce1a275': '[\\n    \"What does the error \\'NoneType\\' object is not iterable imply in the context of a macro?\",\\n    \"Which macro is associated with the error related to \\'NoneType\\' being not iterable?\",\\n    \"What is the significance of the vars section in the dbt_project.yml file?\",\\n    \"What values should I include for payment_type_values in the dbt_project.yml?\",\\n    \"Where can I find the definition of the macro test_accepted_values that caused the error?\"\\n]',\n",
       " 'b529b0bc': '[\"What specific issue might arise if I directly copy the dbt macro for get_payment_type_description from the data-engineering-zoomcamp repository?\", \"Why am I receiving a BadRequest error related to the CASE operator while using the get_payment_type_description macro?\", \"What changes do I need to make to the payment_type data type for the macro to function correctly?\", \"Can you explain the process required to convert numeric values to text within the dbt macro?\", \"What does the dbt macro get_payment_type_description return when given different payment_type input values?\"]',\n",
       " '2e51a111': '[\\n    \"How can I access the error log in dbt to troubleshoot issues?\",\\n    \"What happens when I click the link in the dbt error log?\",\\n    \"Will I be able to see the exact line causing the error in my query?\",\\n    \"Is there a specific module that covers troubleshooting in dbt?\",\\n    \"Where can I find resources for analytics engineering with dbt?\"\\n]',\n",
       " '6e1a0834': '[\\n  \"What is the reason behind dbt creating a schema named \\'dbt_marts\\' when I set the target schema to \\'marts\\'?\",\\n  \"Can you explain how to change the default behavior of schema naming in dbt?\",\\n  \"What steps do I need to follow to create a macro for overriding the default schema name in dbt?\",\\n  \"Is there a specific file where I need to adjust the custom schema settings in dbt?\",\\n  \"What syntax should I use for the macro to successfully modify the schema name in dbt?\"\\n]',\n",
       " 'a8657e65': '[\"What steps should I follow to designate a subdirectory of my GitHub repository as the root for my dbt project?\", \"Is there a specific setting in dbt Cloud that lets me configure the project subdirectory?\", \"How can I adjust settings in dbt Cloud to point to a subdirectory for my project?\", \"Can I set a specific folder within my GitHub repo to be the main dbt project folder?\", \"What do I need to do in dbt Cloud to change the root project directory for my dbt project?\"]',\n",
       " '2678d8c2': '[\\n    \"What should I do if I encounter a compilation error indicating a model depends on a source that cannot be found?\",\\n    \"How can I ensure that my SQL models in dbt reference the correct table names within BigQuery or Postgres?\",\\n    \"Is there a specific way to write SQL queries in dbt to pull data from existing tables?\",\\n    \"What example should I follow to correctly reference a table in my dbt models?\",\\n    \"Are there any specific practices I should follow to avoid model compilation errors related to missing sources?\"\\n]',\n",
       " 'aa85c6ae': '[\"What steps should I take if I encounter a Compilation Error related to a missing node in my model?\", \"How can I ensure that my seed file is correctly referenced in the Production Environment?\", \"Is there a specific branch I need to create a pull request from before checking for the seed file?\", \"What should I verify in my .gitignore file to avoid issues with my seed file?\", \"Can you clarify where I should look for the seed file if I run into a Compilation Error?\"]',\n",
       " 'de06929d': '[\\n    \"What should I do if I encounter an \\'Access Denied\\' message during dbt run with fhv_tripdata?\",\\n    \"How can I resolve permission issues while executing dbt run with external tables?\",\\n    \"What roles need to be added to fix the \\'Permission denied\\' error in BigQuery?\",\\n    \"Where can I find my dbt cloud service account to manage permissions?\",\\n    \"Is there a specific role that should be added alongside BigQuery Admin for dbt functionality?\"\\n]',\n",
       " 'b087fa95': '[\\n    \"What problem might arise when injecting data to BigQuery due to pandas handling of columns with missing values?\",\\n    \"How can I address the issue of pandas parsing integer columns with missing values as floats?\",\\n    \"What is one method for specifying the data type of integer columns during data transformation?\",\\n    \"Is there a simpler way to ensure pandas infers the correct data type for my dataframe\\'s integer columns?\",\\n    \"What steps should I follow to prepare my dataframe for data injection to avoid type errors?\"\\n]',\n",
       " '3c41892d': '[\\n  \"What should I do if I get an exception saying ‘taxi_zone_lookup’ is not found while loading my GitHub repository?\",\\n  \"Why is it necessary to rename the directory from ‘data’ to ‘seed’ for loading seed files?\",\\n  \"In Module 4, what specific directory name must I use to ensure seed files are recognized?\",\\n  \"Can you explain why the directory structure is important for loading seed files in dbt?\",\\n  \"Is there a specific naming convention for directories when working with seed files in this course?\"\\n]',\n",
       " '4842f3e8': '[\\n    \"What should I verify in the .gitignore file if I encounter the \\'taxi_zone_lookup\\' not found error?\",\\n    \"If I receive a 404 error for my dbt job, what should I check regarding the location of my datasets?\",\\n    \"How can I ensure that the region for my datasets is set correctly in dbt to avoid errors?\",\\n    \"Where can I adjust the location settings in dbt to ensure they match the required region for my project?\",\\n    \"What is the specific error message I might encounter if a table is not found in the specified location?\"\\n]',\n",
       " '5eaf61fe': '[\"What is the best way to prevent data type errors during ingestion when working with parquet files?\", \"Can you explain how to create an external table using .csv.gz files?\", \"What file format should I use to avoid data type problems in week 4?\", \"Is there a specific command to replace the table when ingesting data?\", \"Where can I find the .csv.gz files for the fhv_tripdata?\"]',\n",
       " '8ed36cea': '[\\n    \"What is causing the varying number of rows when I rerun the fact_trips model in Module 4?\",\\n    \"How can I ensure that the number of rows in the fact_trips table remains consistent across multiple runs?\",\\n    \"Why does the current deduplication method result in different first row selections during each execution?\",\\n    \"What specific changes need to be made in the staging files to resolve this issue with row consistency?\",\\n    \"Can you explain why the presence of an unknown borough affects the number of rows discarded in the fact_trips model?\"\\n]',\n",
       " '46aebc79': '[\"What should I do if I face a data type error while executing the fact table in Module 4?\", \"How can a nan value cause issues in the trip_type column?\", \"Is the trip_type column error related to BigQuery\\'s handling of null values?\", \"What data type should I use to resolve the data type error on trip_type?\", \"Can I use NUMERIC to fix the issue with the trip_type column in my fact table?\"]',\n",
       " 'e2d2bc58': '[\\n    \"What could be the reason for encountering an error regarding duplicate column names in the CREATE TABLE statement?\",\\n    \"How can I avoid the issue of duplicate column names when performing joins in my SQL query?\",\\n    \"What specific SQL query structure could lead to the error related to duplicated \\'locationid\\' columns?\",\\n    \"Can you explain how modifying my SELECT statement helps to resolve the issue of column name duplication?\",\\n    \"What is the recommended SQL syntax for selecting from multiple tables to prevent naming conflicts?\"\\n]',\n",
       " '137aab88': '[\\n    \"What does the error \\'Bad int64 value: 0.0\\' indicate in relation to ehail fees?\",\\n    \"How can I resolve the issue of null ehail fees causing casting errors in my dbt project?\",\\n    \"What is the purpose of using safe_cast in dbt, particularly for handling integer conversions?\",\\n    \"Can you provide an example of how to implement safe_cast for ehail_fee in Jinja code?\",\\n    \"Is it possible to use safe_cast without the dbt_utils function, and if so, how would that look?\"\\n]',\n",
       " 'a260e651': '[\\n  \"What specific error might I face when building the fact_trips.sql model?\",\\n  \"How can I resolve the issue with the payment_type_description field causing the bad int64 value error?\",\\n  \"What is the recommended method to handle decimal values before casting them to integer?\",\\n  \"Which columns in the Green_tripdata table are known to cause bad int64 value errors?\",\\n  \"Can you share the queries to properly cast ratecodeid and trip_type to avoid errors?\"\\n]',\n",
       " 'da8d9fcc': '[\\n    \"What error message might I encounter when building the fact_trips.sql file in DBT?\",\\n    \"What type mismatch issue is mentioned regarding the \\'ehail_fee\\' column in the Parquet file?\",\\n    \"Which file path is referenced in the error related to the double type of \\'ehail_fee\\'?\",\\n    \"What solution did you use in stg_green_trips.sql to resolve the error with \\'ehail_fee\\'?\",\\n    \"How can I cast the \\'ehail_fee\\' column to match the expected type in DBT?\"\\n]',\n",
       " '2314e3c4': '[\"What format should the - vars argument be in for dbt?\", \"How can I ensure my YAML dictionary is correctly interpreted?\", \"What does the error about the - vars argument indicate?\", \"Can you clarify the correct way to structure the dbt run command with variables?\", \"What should I check if my variable and value seem to be incorrectly formatted?\"]',\n",
       " 'e7bdbba6': '[\"Why is the Environment Type option greyed out for me?\", \"Can I change the Environment Type while following the course?\", \"What should I do if I can\\'t access the Environment Type settings?\", \"Is it necessary to modify the Environment Type during the course?\", \"What does it mean to create a Production Deployment in this context?\"]',\n",
       " '52cccade': '[\\n  \"What might cause the \\'Access Denied\\' error when querying the yellow_tripdata table in dbt?\",\\n  \"How can I change the branch I\\'m working on in dbt Cloud to avoid database permission issues?\",\\n  \"If I encounter an error stating \\'Could not parse the dbt project,\\' what should I check in my repository?\",\\n  \"What should I do if the dbt job continues to fail after changing the branch settings?\",\\n  \"How can I ensure that my dbt environment runs on the correct custom branch instead of the master branch?\"\\n]',\n",
       " '11a814ea': '[\"What should I do if my job still uses the old file after I committed changes to my modelling files?\", \"How can I ensure that my recent modifications in the development branch are reflected in the job run?\", \"Is there a specific process to follow when I want to merge my changes to the main branch?\", \"After making changes in my development branch, what are the steps to rerun my job successfully?\", \"Where do I need to go to approve the merging of my changes after creating a pull request?\"]',\n",
       " '0d1e02d5': '[\\n  \"What steps are needed to see my developments in the Develop tab after setting up Github and Bigquery?\",\\n  \"Is there a specific environment I need to create before working on my models in dbt?\",\\n  \"After developing a model in dbt, what environment do I need to set up next?\",\\n  \"Could you explain the parameters that need to be configured in the development environment?\",\\n  \"What is the process for running jobs once my model development is complete?\"\\n]',\n",
       " '0a0cc4c3': '[\\n  \"What should I do if my Prefect Agent encounters an httpx.LocalProtocolError when retrieving runs?\",\\n  \"How can I address the ProtocolError indicating invalid input in the context of my Prefect Agent?\",\\n  \"Is there a solution available for when the Prefect Agent fails due to ConnectionState issues?\",\\n  \"What steps can I take if the run retrieval process from the queue fails intermittently?\",\\n  \"How long should I wait before attempting to rerun the Prefect Agent if it encounters an error?\"\\n]',\n",
       " 'cb912983': '[\\n    \"What should I do if I encounter an error when running \\'dbt run\\' in BigQuery?\",\\n    \"Can you explain why I\\'m seeing a type mismatch error related to the \\'passenger_count\\' column during my dbt run?\",\\n    \"What transformations did you apply to resolve the error with column types in your parquet data?\",\\n    \"Where can I find additional discussions or solutions for common errors related to dbt in BigQuery?\",\\n    \"Has anyone else experienced similar issues with column formats in their parquet files when using dbt?\"\\n]',\n",
       " '2d4e434f': '[\"What command should I use instead of dbt run --models stg_green_tripdata --var \\'is_test_run: false\\' if it doesn\\'t return results?\", \"How can I modify the dbt run command for the stg_green_tripdata model?\", \"What is the correct syntax for running dbt with the is_test_run variable set to false?\", \"If I encounter issues with the tutorial\\'s code, what alternative command can I try?\", \"Can you provide the appropriate command to execute dbt for stg_green_tripdata without getting empty results?\"]',\n",
       " 'bb6655b9': '[\"What should I do if I encounter a \\'No module named pytz\\' error when setting up dbt with Docker?\", \"Can you explain the steps to resolve the \\'ModuleNotFoundError\\' for pytz while initializing dbt?\", \"Where exactly should I add the command to install pytz in the Dockerfile?\", \"What is the command needed to install the pytz module in the Dockerfile for dbt?\", \"Is the version of Python being used in the Dockerfile relevant to the pytz installation issue?\"]',\n",
       " 'fc2eb036': '[\\n  \"What should I do if I encounter a permission denied error when trying to edit dbt_project.yml after initializing with Docker?\",\\n  \"How can I change the profile from \\'taxi_rides_ny\\' to \\'bq-dbt-workshop\\' if I have run into issues?\",\\n  \"What command do I need to run to resolve file permission issues in my dbt project directory?\",\\n  \"What should I do if I see an internal error stating that the profile should not be None after loading is completed?\",\\n  \"When using dbt debug, how can I ensure I am in the correct directory to execute the command successfully?\"\\n]',\n",
       " '25daead9': '[\\n  \"What should I do if I receive a \\'table is not on the specified location\\' error when querying on BigQuery?\",\\n  \"How can I make sure my BigQuery bucket, datasets, and tables are in the same location?\",\\n  \"Where can I find the option to change the location settings for my BigQuery query?\",\\n  \"How can I verify if the paths in my BigQuery query are correct?\",\\n  \"What steps can I take to troubleshoot location-related issues in BigQuery?\"\\n]',\n",
       " '2221d75e': '[\\n  \"What should I do if I encounter an error message stating that a valid dbt project was not found during a dbt Cloud run?\",\\n  \"Could the cancellation of my dbt Cloud run be a result of moving the dbt project to a different directory?\",\\n  \"What steps do I need to follow to ensure the project settings in dbt Cloud match my local file explorer path?\",\\n  \"How do I set up the PROD environment to check in the appropriate branch if it\\'s not the default main branch?\",\\n  \"Is it necessary to manually merge and close the PR after triggering the CI check job in dbt Cloud?\"\\n]',\n",
       " '94524a9d': '[\"What issue may arise if my dataset on BigQuery is located in the \\'EU\\' region during a pull request with dbt?\", \"How does dbt determine the schema location when creating a pull request for BigQuery?\", \"What default location does dbt use when creating a new schema in BigQuery?\", \"How can I change the location setting for my BigQuery connection in dbt?\", \"Where in the dbt project settings can I find the option to set the location for BigQuery?\"]',\n",
       " '1f1ecbb7': '[\\n    \"What steps should I take if I encounter an error while deploying my dbt project on production?\",\\n    \"How can I ensure that my changes are reflected in the latest version of the repository before running the dbt project?\",\\n    \"What should I do if the dbt_project.yml file is not accessible to my project?\",\\n    \"Where can I find a solution if I see a message indicating that my dbt Cloud run was cancelled due to a missing dbt project?\",\\n    \"How do I verify that the dataset name in BigQuery matches the one I configured for the production environment on dbt Cloud?\"\\n]',\n",
       " 'c5af32ab': '[\\n    \"What error message did you receive after building from stg_green_tripdata.sql in the video?\",\\n    \"What is the default location for dbt Bigquery when a location is not specified?\",\\n    \"How can I fix the \\'404 Not Found\\' error related to the dataset location in my dbt project?\",\\n    \"What steps should I follow to specify the location as EU for my Bigquery connection?\",\\n    \"Where can I find the option to edit the location details for my dbt connection settings?\"\\n]',\n",
       " '1e6b7da1': '[\\n    \"What steps should I take if I encounter issues while loading the FHV_20?? data into GCS and BQ?\",\\n    \"Can you clarify how to correctly format the URL Template link for accessing FHV_20?? data?\",\\n    \"What value should I use for URL_PREFIX when working with the FHV_20?? data?\",\\n    \"Why is it important to ensure the link contains the word \\'blob\\' instead of \\'tree\\' when accessing the FHV_20?? data?\",\\n    \"Is there anything else I need to do besides updating the URL Template and URL_PREFIX to load the FHV_20?? data successfully?\"\\n]',\n",
       " '259481c4': '[\\n    \"What is the recommended method for uploading datasets from GitHub for our homework?\",\\n    \"Can you tell me about the script that simplifies the dataset upload process?\",\\n    \"Is there a specific script I should use for the NYC TLC data ingestion task?\",\\n    \"Who provided a script that is similar to git_csv_to_gcs.py?\",\\n    \"Where can I find the script referenced in relation to web_to_gcs.py?\"\\n]',\n",
       " 'edbae698': '[\\n    \"What is the recommended method for securely storing project credentials before pushing to a git repository?\",\\n    \"Which two environment variables should be set for the scripts web_to_gcs.py or git_csv_to_gcs.py?\",\\n    \"How can you install the dotenv package to manage environment variables in a project?\",\\n    \"What code is needed to access environment variables after loading them from a .env file?\",\\n    \"How can you reference the GCP_GCS_BUCKET environment variable after loading it using dotenv?\"\\n]',\n",
       " '67217f4c': '[\"What should I do if I encounter invalid date types after uploading FHV data through CSV files?\", \"How can I define the pickup_datetime and dropoff_datetime columns when creating an external table in BigQuery?\", \"What SQL command do I need to use to ensure the pickup_datetime and dropoff_datetime are correctly parsed as timestamps in dbt?\", \"Is there a specific format I need to specify for uploading CSV files in BigQuery?\", \"What should I do if my FHV data has a borough marked as \\'Unknown\\'?\"]',\n",
       " '2aadd232': '[\"What specific errors might I encounter when ingesting FHV data via parquet files?\", \"What is the recommended approach to avoid data type issues when creating an external table for the FHV 2019 data?\", \"How should I define the schema for the external table to ensure a successful load of the FHV data?\", \"Is there a way to upload multiple months of FHV data in one go, and if so, how?\", \"What are the essential columns to include in the schema definition for the external table of FHV trips?\"]',\n",
       " 'adcd914a': '[\"How can I access Looker Studio after my trial ends?\", \"What happens if I encounter subscription prompts in Looker Studio?\", \"Where should I go to access the free version of Looker Studio?\", \"What errors might I see when trying to use Looker Studio after the trial?\", \"Is there a way to avoid the Pro version subscription for Looker Studio?\"]',\n",
       " 'bbf094b3': '[\\n    \"What mechanism does dbt use to manage dependencies between models during execution?\",\\n    \"What should I do if loading FHV Data into Mage results in issues?\",\\n    \"How can I load data into a pandas dataframe for manipulation before uploading to GCP?\",\\n    \"What region setting should I use in dbt when working with datasets copied from BigQuery\\'s public datasets?\",\\n    \"How can I change the location of my dbt profile when working with BigQuery?\"\\n]',\n",
       " '2fdc5057': '[\"How can I quickly upload taxi data to dbt-postgres?\", \"What feature should I use for uploading CSV files to dbt-postgres?\", \"Is there a specific command I need to use for the COPY function?\", \"Can I specify columns when using the COPY FROM feature?\", \"Are there options available when uploading data with COPY FROM?\"]',\n",
       " '95e302f7': '[\\n  \"What should I do if I encounter an error regarding \\'invalid: \\'5432\\' in my profiles.yml for dbt-postgres?\",\\n  \"Can you tell me how to resolve the issue related to environment variables in my Jinja templates?\",\\n  \"What does the error message regarding \\'type integer\\' indicate in my dbt-postgres profile configuration?\",\\n  \"Is there a specific format I need to follow when updating the line in profiles.yml?\",\\n  \"What steps should I take to fix the credentials issue shown in the error for profile \\'PROFILE_NAME\\'?\"\\n]',\n",
       " '1ac2c13c': '[\"What is the process to install SDKMAN on a Linux system?\", \"How can I install Java 11 using SDKMAN?\", \"What command do I use to install Spark 3.3.2 through SDKMAN?\", \"After installing, how can I refresh the environment variables in the same terminal?\", \"What commands should I run to verify the installations of Java and Spark?\"]',\n",
       " '5cc0e4d9': '[\\n    \"What should I do if I am having difficulties with the local setup for Spark?\",\\n    \"Is there a specific guide available for running Spark in Google Colab?\",\\n    \"Where can I find a starter notebook for using Spark in Google Colab?\",\\n    \"Why is it recommended to set up Spark locally before using Google Colab?\",\\n    \"What does the local setup mean in the context of this course?\"\\n]',\n",
       " '17090545': '[\\n    \"What should I do if I encounter an error when running spark-shell at CMD on Windows?\",\\n    \"Is there a specific version of Java that Spark requires for proper functionality?\",\\n    \"What error message indicates a problem related to native-hadoop library loading?\",\\n    \"Which versions of Java are incompatible with Spark 3.x?\",\\n    \"Where can I find the instructions to install the correct version of Java for Spark?\"\\n]',\n",
       " 'd17e30c6': '[\\n    \"What error message did you encounter when trying to execute the user defined function in Spark?\",\\n    \"Can you explain the issues related to the PYSPARK_PYTHON environment variable while using conda?\",\\n    \"What specific command should I run on the command line to resolve the PySpark installation problem?\",\\n    \"What do I need to add at the top of my script to properly initialize findspark?\",\\n    \"How does the conda environment affect the Python paths when using PySpark on Windows?\"\\n]',\n",
       " '1520b5bc': '[\\n    \"What is the reason for the TypeError when I try to import PySpark on Windows with Spark 3.0.3 and Python 3.11?\",\\n    \"How can I resolve the TypeError that mentions \\'code() argument 13 must be str, not int\\' in my PySpark installation?\",\\n    \"Is using Python 3.11 with Spark 3.0.3 compatible, or should I consider downgrading my Python version?\",\\n    \"What versions of Python are recommended for use with older Spark to avoid compatibility issues?\",\\n    \"Can installing a newer version of PySpark help with compatibility problems I am experiencing with Python 3.11?\"\\n]',\n",
       " 'e86ca928': '[\\n    \"What steps should I follow to set up a conda environment for PySpark on MacOS while ensuring all Python dependencies are managed?\",\\n    \"Can you explain what to do if I encounter a Py4JJavaError related to connection issues while using Spark?\",\\n    \"Which versions of JDK and Python are compatible with the current version of Spark, and how do I ensure I use them correctly?\",\\n    \"Is it necessary to install findspark or similar packages when setting up PySpark, and why?\",\\n    \"What actions should I take if I face errors while writing a DataFrame to a file, specifically regarding the required environment configurations?\"\\n]',\n",
       " '3b5b4eb3': '[\\n    \"What can I do if I encounter a RuntimeError related to the Java gateway process when running my PySpark script in Jupyter Notebook?\",\\n    \"Is there a specific command I need to run to resolve the issue of the Java gateway process exiting unexpectedly?\",\\n    \"How can I verify if PySpark is configured to point to the correct location on my system?\",\\n    \"What steps should I take to permanently set the environment variables for Spark on my computer?\",\\n    \"If the error persists after following the initial troubleshooting steps, what additional resources can I refer to for help with setting up PySpark?\"\\n]',\n",
       " '489c366f': '[\\n    \"What should I do if I encounter a Module Not Found Error while using Jupyter Notebook after installing pyspark on my VM?\",\\n    \"Can you outline the steps needed to set up findspark in my Jupyter Notebook to resolve the pyspark import issue?\",\\n    \"Is there a specific command I need to use in Jupyter Notebook to install pyspark if the regular pip install command does not work?\",\\n    \"How can I filter data based on multiple conditions across different columns using PySpark?\",\\n    \"What is the import statement required for using the \\'col\\' function in PySpark when filtering DataFrames?\"\\n]',\n",
       " '59381b15': '[\\n    \"What should I do if I encounter a \\'ModuleNotFoundError\\' when trying to import pyspark?\",\\n    \"How can I determine the correct version of the Py4J file for my setup?\",\\n    \"What specific command do I need to run to check the contents of the python/lib directory in Spark?\",\\n    \"If I find a mismatch between the Py4J filename and my export command, how should I modify it?\",\\n    \"What additional step can I take if updating the PYTHONPATH does not resolve the issue with py4j?\"\\n]',\n",
       " '220b1cf3': '[\\n  \"What should I do if I encounter a Py4J Error related to ModuleNotFoundError and can\\'t find the \\'py4j\\' module?\",\\n  \"Can you explain how to resolve the issue with py4j not being recognized in my PySpark installation?\",\\n  \"What steps must I take to ensure that I have the latest version of py4j installed through conda?\",\\n  \"How do I add the necessary exports to my .bashrc file to fix the py4j error in PySpark?\",\\n  \"Is there a specific way to check for the latest version of py4j to ensure proper installation?\"\\n]',\n",
       " 'd970a0da': '[\\n  \"What should I do if I encounter an exception stating \\'Jupyter command jupyter-notebook not found\\' even after setting the paths correctly?\",\\n  \"Can you provide a brief overview of the steps needed to set up a virtual environment for Jupyter Notebook?\",\\n  \"What are the necessary commands to install Python and ensure Jupyter Notebook functions correctly on my machine?\",\\n  \"If I need to create a new Python virtual environment for Jupyter, what are the commands I should use?\",\\n  \"Where can I find more detailed instructions regarding Jupyter Notebook installation and setup?\"\\n]',\n",
       " '5fa98bd0': '[\\n    \"What error might occur when executing a PySpark script that attempts to read and write Parquet files?\",\\n    \"What is the reason for encountering a java.io.FileNotFoundException when using the \\'overwrite\\' mode in PySpark?\",\\n    \"How does Spark\\'s lazy transformation feature contribute to the FileNotFoundException error?\",\\n    \"What is the recommended solution to avoid the FileNotFoundException when writing Parquet files in PySpark?\",\\n    \"Where should I write the Parquet files to prevent overwriting existing data during a Spark job?\"\\n]',\n",
       " 'ce508f3c': '[\"What do I do if I encounter a FileNotFoundException related to Hadoop\\'s bin directory on Windows?\", \"How can I resolve the issue of Hadoop not being able to find its bin directory when trying to write?\", \"Is there a specific directory I need to create for Hadoop installation on Windows?\", \"Where should I place the downloaded Hadoop files for proper installation on Windows?\", \"Will the Windows installation automatically configure the Hadoop bin directory for me?\"]',\n",
       " 'b7b9487d': '[\\n    \"What is the primary type of SQL that is utilized in Spark?\",\\n    \"How does Spark SQL differ from SQL used in databases like Postgres or MySQL?\",\\n    \"Can you explain the general structure of a SQL query in Spark?\",\\n    \"What are some examples of how built-in functions vary across different SQL providers?\",\\n    \"Where can I find more information about Spark SQL and its functionality?\"\\n]',\n",
       " 'a74de125': '[\"Why was the spark viewer on localhost:4040 not displaying my current run?\", \"What should I do if the port I need is in use by another notebook?\", \"How can I find out which port my Spark notebook is using?\", \"What is the correct way to clean up after my Spark sessions?\", \"Is it normal for Spark to use a port other than 4040 if one is already in use?\"]',\n",
       " 'e5270303': '[\\n  \"What steps can I take to resolve the java.lang.NoSuchMethodError related to DirectBuffer when calling repartition in a conda pyspark installation?\",\\n  \"Is there a specific version of the Java Developer Kit that I should use for compatibility with my pyspark setup?\",\\n  \"What should I do if I encounter a RuntimeError stating that the Java gateway process exited before sending its port number?\",\\n  \"How can I check if the JAVA_HOME environment variable is correctly set in my notebook setup?\",\\n  \"Where can I find additional resources or discussions related to the Java gateway process issue in pyspark?\"\\n]',\n",
       " 'cabe8a5b': '[\"What specific version of the gcs-connector should I use to resolve Spark issues with BigQuery?\",\"How can I authenticate with Google Cloud Storage when using Spark?\",\"Can you provide the code snippet for creating the SparkSession with BigQuery configurations?\",\"What memory settings should I configure for Spark when reading from BigQuery?\",\"Where can I download the necessary authentication files for Google Cloud Platform?\"]',\n",
       " 'e3c0f777': '[\"What is the process for configuring the Spark BigQuery connector automatically?\", \"How do I create a SparkSession with the necessary BigQuery dependencies?\", \"Is there a specific version of the Spark BigQuery connector that I should use?\", \"Will the automatic configuration manage dependencies for me?\", \"Where can I find more information about the Spark BigQuery connector configuration?\"]',\n",
       " '50c009ef': '[\"What is the first step I need to take to connect PySpark with GCP Cloud Storage?\", \"Where should I move the .jar file after downloading the Cloud Storage connector?\", \"Can you outline the necessary classes I need to import in my Python script for PySpark?\", \"What configurations must I set up before building my SparkSession with PySpark?\", \"How can I read files directly from Google Cloud Storage once my SparkSession is set up?\"]',\n",
       " '3fe85b16': '[\\n    \"What library can I use to read a parquet file in PySpark for a limited number of rows?\",\\n    \"Is there an alternative method to read a small number of rows from a parquet file without using PyArrow?\",\\n    \"How do I convert a table into a Pandas dataframe after reading from a parquet file?\",\\n    \"What is the purpose of the \\'limit\\' function when working with a DataFrame in PySpark?\",\\n    \"Can you provide an example of how to obtain a manageable size Pandas dataframe from a parquet file?\"\\n]',\n",
       " '0fe0c76a': '[\\n  \"What could cause a DataType error when I create a Spark DataFrame using a specific schema?\",\\n  \"Which video should I refer to if I encounter issues while creating a Spark DataFrame?\",\\n  \"What is the issue with the PULocation and DOLocationID being defined as IntegerType?\",\\n  \"What error message will I get if my schema mismatches with the Parquet file format?\",\\n  \"How can I resolve the DataType error when using a parquet file for my DataFrame schema?\"\\n]',\n",
       " '18c5bafe': '[\"How can I eliminate spaces in the names of columns using Pyspark?\", \"What is the method to remove whitespace from column names in my dataframe?\", \"Can you show me how to use aliases to clean up column names in Pyspark?\", \"Is there a way to modify column names in PySpark by removing spaces?\", \"What code snippet should I use to adjust column names in a Pyspark dataframe?\"]',\n",
       " '59e86b40': '[\\n    \"What does the AttributeError related to \\'DataFrame\\' mean when using PySpark?\",\\n    \"Why does this error occur specifically in Spark video 5.3.1?\",\\n    \"How can I resolve the compatibility issue with pandas version 2.0.0 and Spark 3.3.2?\",\\n    \"Is there an alternative method to fixing the AttributeError without downgrading pandas?\",\\n    \"When was this problem with the DataFrame object fixed in Spark versions?\"\\n]',\n",
       " '1ac3ea8f': '[\"What should I do if I encounter an AttributeError related to \\'DataFrame\\' in PySpark?\", \"Is there a recommended version of pandas that works well with PySpark 3.5.1?\", \"How can I set up the environment variables for Spark on my system?\", \"What specific installation version of pandas is mentioned as compatible with PySpark?\", \"Where can I find instructions on configuring my environment for using Spark?\"]',\n",
       " 'e04529ac': '[\\n    \"What steps should I follow to start Spark in standalone mode on Windows?\",\\n    \"How can I access the Spark UI after setting up the master and worker nodes?\",\\n    \"Where can I find the correct homework file for Module 5 instead of the one in the code directory?\",\\n    \"What command do I need to use to start a master node in Spark on Windows?\",\\n    \"Is it possible to run the worker node on a different machine, and how would I do that?\"\\n]',\n",
       " 'a602a7f8': '[\\n    \"How can I make the PYTHONPATH environment variable persistent across sessions?\",\\n    \"What should I do if I want to avoid typing the export command every time?\",\\n    \"Is there a way to set the PYTHONPATH for my Jupyter notebooks?\",\\n    \"What file do I need to modify to add the export command permanently?\",\\n    \"Can you suggest a command to run at the start of my homework to set up findspark?\"\\n]',\n",
       " '9336ce2c': '[\\n    \"What should I do if I encounter a compressed file that stops before reaching the end-of-stream marker?\",\\n    \"How did you manage to fix the problem related to the compressed file not completing?\",\\n    \"Can you explain the steps to take before generating head.csv for a compressed file?\",\\n    \"Is there a specific command I need to use to unzip the file correctly?\",\\n    \"What should I do with the file after unzipping it to prevent issues when creating head.csv?\"\\n]',\n",
       " 'bac4e0f7': '[\"What should I do if I encounter gibberish output after using the zcat command on downloaded files?\", \"Why does the output appear compressed even after using zcat on certain files?\", \"How should I handle the CSV files from the course repo to avoid compression errors?\", \"What is the correct way to download the data files for Module 5 without encountering gzipping issues?\", \"Can you explain why we should not gzip the files downloaded from the course repo?\"]',\n",
       " '13dad632': '[\\n    \"What does the PicklingError indicate when running the spark.createDataFrame command?\",\\n    \"Why does the error occur specifically when I use python version 3.11?\",\\n    \"How can I create a new conda environment with a supported Python version for PySpark?\",\\n    \"After creating a new environment, what command do I need to run to start using Python 3.10?\",\\n    \"What should I do if I want to switch back to my previous environment after activating the new one?\"\\n]',\n",
       " 'ddc3c75b': '[\"How can I resolve the issue where my local Spark is unable to find my Google credentials?\", \"What should I check if Spark fails to locate my GCP credentials as demonstrated in the tutorial?\", \"Where exactly must I place my Google Cloud Platform credentials for Spark to recognize them?\", \"Is there a specific directory where my GCP credentials need to be stored in the VM?\", \"What steps do I need to follow to ensure my Spark setup can access my Google credentials?\"]',\n",
       " '095b667f': '[\"What are the initial steps to set up a Spark environment using Docker?\", \"How do I modify the Dockerfile for the Bitnami Spark container?\", \"What command should I use to build the Docker image for Spark?\", \"Could you provide the contents of the docker-compose.yml file required to run Spark?\", \"What command do I need to execute to start the Docker Compose deployment for Spark?\"]',\n",
       " '56a67c23': '[\"What is the first step to read data from GCS into pandas on my local machine?\", \"After installing gcsfs, what should I do to access my data?\", \"Could you explain how to utilize a URI path to read a file in pandas?\", \"Is there a specific command to read a CSV file from GCS using pandas?\", \"What command would I use in pandas to read data from a file stored in Google Cloud Storage?\"]',\n",
       " '7fed7813': '[\\n  \"What kind of error may occur when using the spark.createDataFrame function on a pandas DataFrame?\",\\n  \"What is the reason behind the TypeError related to the Affiliated_base_number when converting a pandas DataFrame to a PySpark DataFrame?\",\\n  \"How can I ensure the Affiliated_base_number column is correctly interpreted when reading a CSV file into Spark?\",\\n  \"What should I do if my pandas DataFrame contains null values in the Affiliated_base_number column?\",\\n  \"How can I filter out rows with null values in the Affiliated_base_number column before converting my pandas DataFrame to PySpark?\"\\n]',\n",
       " 'a0e7e259': '[\\n  \"What does the error MemoryManager indicate regarding heap memory usage?\",\\n  \"What is the default memory allocation for the executor in this course?\",\\n  \"Under what circumstances does the memory allocation error occur?\",\\n  \"How can I resolve the memory allocation issue while using Spark?\",\\n  \"What should I do to ensure that my changes to executor memory settings take effect?\"\\n]',\n",
       " '4ca14331': '[\"What steps should I follow to change the working directory to the Spark directory on Windows?\", \"How do I start the Spark Master in a standalone cluster setup?\", \"What command is used to create a local Spark cluster on Windows?\", \"How can I start up a cluster using the Spark Worker command?\", \"What do I need to set up before running Spark on Windows OS?\"]',\n",
       " '6fdd09eb': '[\"Why are the environment variables in ~/.bashrc not recognized in Jupyter when using VS Code?\", \"What steps do I need to take after modifying the ~/.bashrc file for changes to take effect?\", \"Is there an alternative method to set environment variables instead of using ~/.bashrc?\", \"What specific environment variables should I set for working with PySpark?\", \"How can I use PySpark in a Jupyter notebook if it\\'s not being recognized in VS Code?\"]',\n",
       " '64bfb2c3': '[\"What is the method to start port forwarding if I am not utilizing Visual Studio Code?\", \"Can you explain the command structure for SSH port forwarding?\", \"What values should I substitute for \\'user\\' and \\'IP\\' in the SSH command?\", \"Is there a specific port number that needs to be used for local and remote in the port forwarding process?\", \"How do I connect to the GCP VM using SSH for port forwarding?\"]',\n",
       " '33dd4516': '[\\n    \"Why does the output of wc -l differ when using the gzip file?\",\\n    \"What should I do to get the correct line count from the compressed file?\",\\n    \"Is it necessary to unzip the gzip file before running wc -l on it?\",\\n    \"What command should I use to obtain the accurate line count after unzipping?\",\\n    \"Can I run wc -l directly on the compressed file for the right results?\"\\n]',\n",
       " '504b8570': '[\\n    \"What should I do if I encounter a `WARN Utils: Your hostname resolves to a loopback address` error when using spark-submit?\",\\n    \"What might cause the error message stating that \\'Master must either be yarn or start with spark, mesos, k8s, or local\\'?\",\\n    \"How can I modify the spark-submit command to resolve issues with the master URL format?\",\\n    \"What error will I see if I use the wrong syntax for the --master option in spark version 3.4.2?\",\\n    \"What change is recommended to fix the failure regarding the unrecognized option for --master in spark version 3.4.2?\"\\n]',\n",
       " '42e933c5': '[\"What should I do if I encounter a java.lang.UnsatisfiedLinkError related to Hadoop when writing to parquet?\", \"How can I fix the error about NativeIO access0 in Hadoop on Windows?\", \"What specific environment variable needs to be set to resolve the UnsatisfiedLinkError in Hadoop?\", \"Can you tell me how to configure the PATH variable for Hadoop on a Windows machine?\", \"Where can I find additional support or information regarding the Hadoop error I am facing?\"]',\n",
       " 'fe9240b0': '[\\n    \"What can I do if I encounter a Java.io.IOException related to running winutils.exe?\",\\n    \"Which version of Hadoop should I switch to in order to resolve a compatibility issue with Windows?\",\\n    \"Where can I find the files I need to replace in the local Hadoop bin folder?\",\\n    \"What should I do if changing the Hadoop version to 3.0.1 does not resolve my issue?\",\\n    \"Is there a source for more detailed information about the compatibility problem I am facing?\"\\n]',\n",
       " 'c0a46e5d': '[\\n  \"What should I do if I encounter the error that the required property \\'project\\' is not currently set while submitting a Pyspark job with Dataproc?\",\\n  \"How can I specify my project ID when running a command to submit a Pyspark job using gcloud?\",\\n  \"Where can I find my project ID to include it in the gcloud command for submitting a Dataproc job?\",\\n  \"Can you provide an example of how to properly set the project flag when submitting a Pyspark job to Dataproc?\",\\n  \"What is the command structure for submitting a Pyspark job to Dataproc that includes specifying the project ID?\"\\n]',\n",
       " '943c2466': '[\\n  \"What steps must I follow to initiate a local Spark cluster on Windows 10 using CMD?\",\\n  \"How do I execute the master command for Spark in Windows 10 from the command line?\",\\n  \"What command do I need to run the worker in Spark after starting the master?\",\\n  \"How can I create a new Jupyter notebook to connect to my Spark application?\",\\n  \"Where can I find the Spark UI to monitor the status of the master, worker, and application?\"\\n]',\n",
       " 'f41ef231': '[\\n    \"What steps should I take if I encounter a 401 Anonymous caller error when accessing Google Cloud Storage?\",\\n    \"How do I resolve the permission issue related to storage.objects.list access in my Google Cloud Storage bucket?\",\\n    \"What command do I need to execute to log into my Google Cloud account for accessing storage objects?\",\\n    \"Can you explain how to set my project ID in the Google Cloud configuration using the terminal?\",\\n    \"What is the correct command to upload a directory to a Google Cloud Storage Bucket after resolving authentication issues?\"\\n]',\n",
       " '6b26d73c': '[\"What should I do if I encounter a py4j.protocol.Py4JJavaError when submitting a job in GCP?\", \"Can you explain the process of changing the cluster versioning control in Dataproc?\", \"Why did you choose Ubuntu 20.02 for the cluster instead of Debian-Hadoop-Spark?\", \"Is it necessary to delete the existing cluster before creating a new one with a different version?\", \"Did you find any documentation to support your choice of using Ubuntu for the cluster versioning?\"]',\n",
       " '830e2936': '[\\n  \"How can I reduce the number of partitions in my DataFrame to 6 instead of 8?\",\\n  \"What method should I use to ensure that my DataFrame has exactly 6 partitions?\",\\n  \"Can you explain how to effectively repartition a DataFrame with PySpark?\",\\n  \"What are the steps to write a DataFrame with 6 partitions to parquet format?\",\\n  \"Is it necessary to use both repartition and coalesce when setting the number of partitions?\"\\n]',\n",
       " '02007b7c': '[\\n  \"What should I do if my Jupyter Notebook or SparkUI won\\'t load after trying to forward a port from VS Code?\",\\n  \"How can I properly forward a port using the command line instead of using VS Code?\",\\n  \"What are the specific SSH commands I need to use to access localhost ports from a GCP VM?\",\\n  \"Is there a way to ensure that all necessary ports are automatically forwarded when accessing a GCP VM?\",\\n  \"What happens to my port connection if I log out of the SSH session on the GCP VM?\"\\n]',\n",
       " '1ebb9a47': '[\"How can I verify the available Java SDK versions in my codespace?\", \"What command should I use to install Java 11 in my environment?\", \"What should I do if prompted regarding the default Java version during installation?\", \"After installing Java, how can I confirm that it\\'s working correctly?\", \"What steps should I follow if Java isn\\'t functioning as expected after installation?\"]',\n",
       " '80125745': '[\\n    \"What does the error message regarding \\'SSD_TOTAL_GB\\' quota mean when creating a dataproc cluster?\",\\n    \"What should I do if I encounter an insufficient quota error while working on GCP?\",\\n    \"Why might there be insufficient resources available in a specific region for my cluster setup?\",\\n    \"How can changing the boot-disk type in terraform help resolve a quota error?\",\\n    \"Is it common for resources to become available again shortly after encountering a quota issue?\"\\n]',\n",
       " 'f01df45b': '[\\n  \"What method does Pyspark use to calculate the difference between two TimestampType values?\",\\n  \"How can I express the total duration between timestamps in hours using Pyspark?\",\\n  \"Can you explain how to use the datediff SQL function for calculating time difference?\",\\n  \"What parameters do I need to provide when using the datediff function in Pyspark?\",\\n  \"How do I convert the days result from datediff into hours?\"\\n]',\n",
       " '06014eec': '[\\n    \"What version combinations of PySpark and Pandas should I use to avoid the PicklingError?\",\\n    \"What could be causing the IndexError related to tuple index out of range in my PySpark project?\",\\n    \"What should I do if I continue to experience errors after using the recommended version combination?\",\\n    \"Can you specify the exact versions of PySpark and Pandas that resolved the PicklingError?\",\\n    \"Is there a specific module in PySpark where this PicklingError commonly occurs?\"\\n]',\n",
       " '54653ca9': '[\"What does the error message Py4JJavaError indicate regarding a task failure in Spark?\", \"How can I resolve the issue of the Python worker failing to connect back in PySpark?\", \"What environment variables should I set before starting my SparkSession to avoid connection issues?\", \"In which module do I find the instructions for addressing the PySpark connection error?\", \"What action should I take to prevent the Spark job from being aborted due to stage failure?\"]',\n",
       " 'f95304db': '[\"What error might occur if the Python versions in the worker and the driver don\\'t match?\", \"How can I resolve a RuntimeError related to different Python versions in PySpark?\", \"What environment variables should I check to ensure compatibility between the driver and worker in PySpark?\", \"Can you provide a Python code snippet to set the correct Python environment variables for PySpark?\", \"Where can I find pricing information related to Dataproc on GKE?\"]',\n",
       " '591df4e6': '[\"Is it possible to run Dataproc jobs without a virtual machine on GCP?\", \"What is the first step to submit a Dataproc job from my local machine?\", \"Which command should I use to submit a pyspark job to Dataproc from my computer?\", \"Where can I find the installation guide for gsutil?\", \"What are the parameters needed for the gcloud dataproc jobs submit command?\"]',\n",
       " '5cb7f597': '[\"What is the reason behind the error when executing spark.createDataFrame(df_pandas).show()?\", \"How can I resolve the AttributeError related to the \\'DataFrame\\' object in PySpark?\", \"What are the machine type and memory specifications for setting up a Dataproc cluster?\", \"I received an insufficient quota error while creating a cluster; what should I do?\", \"What is the maximum memory allocation allowed for worker nodes in the Dataproc cluster configuration?\"]',\n",
       " 'c5de1f96': '[\\n  \"What are the steps to configure JAVA_HOME on an Apple Silicon Mac using Homebrew?\",\\n  \"Is the provided setup instruction for setting JAVA_HOME applicable to Intel-based Macs only?\",\\n  \"How can I verify if the JAVA_HOME path has been set correctly on my system?\",\\n  \"Where should I add the JAVA_HOME environment variable for an Apple Silicon Mac?\",\\n  \"What output should I expect when I run the command to check the Java installation path?\"\\n]',\n",
       " '70ac8e80': '[\\n    \"What should I verify in the docker-compose.yaml file to successfully start the control-center service?\",\\n    \"Are there any specific configurations that need to be checked for the control-center service to launch properly?\",\\n    \"What steps can I take if I encounter issues starting the Kafka control center on my system?\",\\n    \"How did the user resolve the problem of starting the Kafka control center if it was not appearing in the docker ps command?\",\\n    \"What actions did the user take in Docker Desktop to troubleshoot the starting issue of the control center?\"\\n]',\n",
       " 'f6551ffb': '[\\n    \"What should I do if I encounter an error indicating that the module \\'kafka\\' cannot be found when executing producer.py?\",\\n    \"Can you explain the steps I need to follow to set up a virtual environment for running the requirements.txt file?\",\\n    \"What command do I need to run to activate the virtual environment after I have created it?\",\\n    \"Is there a specific command to deactivate the virtual environment when I no longer need it?\",\\n    \"Are there any differences in the activation process for the virtual environment on Windows compared to MacOS and Linux?\"\\n]',\n",
       " '0ec021de': '[\\n    \"What should I do if I encounter an ImportError related to cimpl when trying to run Avro examples?\",\\n    \"How can I check if my Python version is compatible with the Avro library?\",\\n    \"What do I need to add to my code in order to load the required librdkafka DLL?\",\\n    \"Is there a specific command I can use in PowerShell to resolve the DLL load error?\",\\n    \"Where can I find more information about issues related to the cimpl import error from the Avro library?\"\\n]',\n",
       " '1edd4630': '[\\n    \"What should I do if I encounter a ModuleNotFoundError indicating that there is no \\'avro\\' module?\",\\n    \"Is there a specific command I need to run in order to resolve the \\'avro\\' module issue related to confluent-kafka?\",\\n    \"Why doesn\\'t Conda include the \\'avro\\' module when I install confluent-kafka using pip?\",\\n    \"Where can I find more resources about issues related to Anaconda and confluent-kafka?\",\\n    \"Are there any online forums or issues pages that provide assistance for resolving confluent-kafka problems?\"\\n]',\n",
       " '4664ae28': '[\\n    \"What should I do if I encounter an error when executing the command python3 stream.py worker?\",\\n    \"Can you explain the main benefits of using Redpanda as a streaming data platform?\",\\n    \"What underlying algorithm is Redpanda built on, and how does it relate to its performance?\",\\n    \"How does Redpanda maintain compatibility with Kafka while simplifying its use?\",\\n    \"What architecture does Redpanda use, and how is it similar to Kafka\\'s architecture?\"\\n]',\n",
       " '676e1b76': '[\\n    \"What might cause the Negsignal:SIGKILL error when converting dta files to parquet format?\",\\n    \"How does the size of the dta file relate to the memory requirements of the Docker container?\",\\n    \"What solution was implemented to handle the error with the memory exhaustion?\",\\n    \"How can I effectively process large dta files without encountering memory issues?\",\\n    \"What tool can I use to load files in chunks before creating parquet files?\"\\n]',\n",
       " 'a3c84279': '[\\n    \"Where can I find the rides.csv file that is missing in the Python resources?\",\\n    \"Is there an alternative source for the rides.csv file in case I can\\'t find it?\",\\n    \"Which specific Java example contains the necessary rides.csv file I need?\",\\n    \"Can I use the rides.csv file from the Java resources for my Python work?\",\\n    \"What should I do if the rides.csv file is not available in the Python section?\"\\n]',\n",
       " '119c917d': '[\\n    \"What can I do if the audio of the Kafka Python videos is difficult to hear and follow?\",\\n    \"Is there a way to enhance the audio quality of the videos on streaming with Kafka?\",\\n    \"Where can I access the explanation for the rides.csv data used in the producer.py Python program?\",\\n    \"Can the low audio issue in the Kafka Python videos be fixed with any specific software?\",\\n    \"Are there any alternatives to improve my understanding of the rides.csv data structure?\"\\n]',\n",
       " 'f1284c1f': '[\"What does the error NoBrokersAvailable in Kafka indicate?\", \"How can I find out if my Kafka broker is functioning properly?\", \"What command should I run to check the status of my Docker containers?\", \"How do I start the Kafka broker if it\\'s not running?\", \"Where can I find the Docker Compose file to launch the Kafka instances?\"]',\n",
       " '49a7db28': '[\\n    \"What is the primary scaling option we should focus on for Kafka homework Q3?\",\\n    \"How did Ankush suggest we think about scaling in terms of message consumption?\",\\n    \"What concept does horizontal scaling relate to in the context of Kafka?\",\\n    \"Which scaling methods are considered in the Kafka homework Q3 options?\",\\n    \"Can you clarify what is meant by consuming messages via horizontal scaling?\"\\n]',\n",
       " '196cb0f2': '[\\n    \"What should I do if I encounter a pull access denied error for spark-3.3.1 while using Docker Compose?\",\\n    \"What indicates that I have not built my Spark and Jupyter images when running Docker?\",\\n    \"Where can I find the images for Spark and Jupyter that are mentioned in the error?\",\\n    \"How can I resolve the access issue when trying to pull the Spark image from Docker Hub?\",\\n    \"What command should I execute to build the necessary images in the Spark folder before using Docker Compose?\"\\n]',\n",
       " '1e50eab7': '[\"What should I do if I encounter a \\'Permission denied\\' error when running \\'./build.sh\\' in the Python Kafka module?\", \"How can I fix the permission issue with the \\'build.sh\\' script?\", \"What command do I need to change file permissions in the same directory as \\'build.sh\\'?\", \"In which directory should I run the command to resolve permissions for \\'build.sh\\'?\", \"How do I enable execution permission for the \\'build.sh\\' file?\"]',\n",
       " 'a7a6d0d7': '[\"What should I do if I encounter a KafkaTimeoutError while using the producer script in Python?\", \"Is there a common solution for fixing the metadata update issue in Kafka?\", \"How can I resolve the error related to updating metadata that occurs after 60 seconds?\", \"What commands do I need to run to restart the services in my Kafka setup?\", \"Are there any troubleshooting steps recommended for resolving Kafka connectivity issues?\"]',\n",
       " '0996213a': '[\\n    \"What error might I encounter when running the streaming.py script using Spark?\",\\n    \"What information should I verify to resolve the application being killed due to unresponsive masters?\",\\n    \"What specific version of PySpark should I downgrade to if I encounter connection issues?\",\\n    \"How can I check the Spark version that is installed on my local machine?\",\\n    \"What should I do if my Spark version does not match the version specified in the build.sh file?\"\\n]',\n",
       " '311bf368': '[\"What steps should I take to troubleshoot a failed connection to the Spark master?\", \"How can I view the logs for the Spark master container?\", \"What command do I need to use to enter the Spark master container\\'s bash?\", \"Where can I find the error message related to the Spark master connection issue?\", \"Is there a way to search for solutions based on the error message in the logs?\"]',\n",
       " 'c1551650': '[\\n    \"What action should I take if I encounter a Py4JJavaError while running streaming.py with Python Kafka?\",\\n    \"How can I verify the version of Java that is currently installed on my system?\",\\n    \"What command can I use to check all installed Java versions on my machine?\",\\n    \"What steps should I follow if I have Java 11 installed but it\\'s not set as the default version?\",\\n    \"Is it necessary to have Java version 11 or 8 to avoid errors while using Spark with Kafka?\"\\n]',\n",
       " 'f9b673cf': '[\\n    \"What should I do if my Java Kafka project shows errors indicating that a package does not exist after running a Gradle build?\",\\n    \"How can I ensure that all dependencies are included in my Java Kafka project\\'s JAR file when using Gradle?\",\\n    \"Can you explain the steps I need to take to resolve the issues with the <project_name>-1.0-SNAPSHOT.jar in my Kafka setup?\",\\n    \"What modifications do I need to apply in my build.gradle file to avoid missing package errors?\",\\n    \"What command should I use to create a correctly packaged JAR file for my Java Kafka project after updating the build configuration?\"\\n]',\n",
       " '5479dce2': '[\\n    \"What commands should I use to install the required dependencies for the Python Kafka producer example in Module 6?\",\\n    \"Can I install the Faust library for Module 6 despite the mentioned dependency issues?\",\\n    \"Is the Faust repository still actively maintained, and where can I find more information about it?\",\\n    \"If I am not familiar with Java, what resources should I use to follow the Python portion of Module 6?\",\\n    \"Why is it recommended to watch the Java videos for understanding streaming concepts before jumping to the Python videos?\"\\n]',\n",
       " '02cf2317': '[\"How do I execute the Kafka producer and consumer from the terminal?\", \"What command should I use to run kstreams in my project directory?\", \"Can you tell me how to initiate the JsonProducer using Java in the terminal?\", \"What is the proper way to run a Java application with Kafka components from the command line?\", \"How can I test my Kafka setup by running a producer in the terminal?\"]',\n",
       " '947c07a6': '[\\n  \"What should I check if my Java Kafka producer isn\\'t sending any messages?\",\\n  \"Why do I see zero results when I run my JsonConsumer.java script?\",\\n  \"What could cause a SaslAuthenticationException when using JsonProducer.java?\",\\n  \"Where can I find the configuration for the server URL in my Kafka scripts?\",\\n  \"How can I ensure the correct cluster key and secrets are used in my Kafka project?\"\\n]',\n",
       " 'bea22953': '[\"What should I do if I can\\'t see the triangle icon next to my tests in VS Code?\", \"How can I clean the workspace in VS Code to resolve issues with test visibility?\", \"Is there a specific order of steps I need to follow to fix the test icon visibility in VS Code?\", \"Can I add classes and packages directly in the JAVA PROJECTS section of VS Code?\", \"What does the triangle icon next to each test in VS Code signify?\"]',\n",
       " 'a1603359': '[\\n  \"How do I locate the schema registry URL in Confluent Cloud?\",\\n  \"What steps should I follow to access the schema registry URL?\",\\n  \"Where can I find the Endpoint for the Stream Governance API?\",\\n  \"What do I need to do to create credentials for the schema registry?\",\\n  \"What is the navigation path to find the schema registry URL in my environment?\"\\n]',\n",
       " 'a85a6a91': '[\\n  \"What command can I use to verify my local Spark version?\",\\n  \"How can I ensure that my local Spark and container Spark versions are compatible?\",\\n  \"Where should I look to confirm the Spark version in the Python project\\'s build.sh file?\",\\n  \"What should I check regarding pyspark installation to maintain version compatibility?\",\\n  \"Is there a specific command for checking the installed version of Spark?\"\\n]',\n",
       " '343864f5': '[\\n    \"What should I do if I encounter the error \\'ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\\'?\",\\n    \"Is there an alternative to the original kafka-python library that I can use?\",\\n    \"What resource can I refer to for issues related to the kafka-python module?\",\\n    \"Which command should I run to install the suggested alternative for kafka-python?\",\\n    \"Are there any known issues with the current releases of kafka-python?\"\\n]',\n",
       " '6cb3b4a9': '[\\n    \"What is the process for evaluating my capstone project in this course?\",\\n    \"How many peers will review my submitted project, and will I be reviewing others?\",\\n    \"What happens if I do not adhere to the peer review requirements for the capstone project?\",\\n    \"How will the final grade for my project be determined based on peer evaluations?\",\\n    \"Are there specific guidelines I need to follow when reviewing my fellow students\\' projects?\"\\n]',\n",
       " '5959ea3c': '[\\n    \"Is there more than one project to submit for this course?\",\\n    \"What should I do if I miss the first attempt at the project?\",\\n    \"Can I submit a project if I have other commitments during the first attempt?\",\\n    \"How many times can I attempt the project for the course?\",\\n    \"What happens if I fail the first attempt at the project?\"\\n]',\n",
       " '202af70b': '[\"Where can I find a collection of large datasets for my project?\", \"Is there a resource that lists nice datasets for data engineering?\", \"Can someone share a link to datasets that are suitable for analysis?\", \"What is the best source for finding extensive datasets?\", \"Does the course provide any references for large datasets?\"]',\n",
       " 'f2705fe7': '[\\n    \"What is the process for setting up Python as a startup script?\",\\n    \"How can I configure the environment variable for Python to run at start up?\",\\n    \"Is there a specific user account requirement for running Python on startup?\",\\n    \"What steps are needed to change the Python environment variable for my user?\",\\n    \"Can you explain how to make Python run when my computer starts?\"\\n]',\n",
       " '74f412c4': '[\\n  \"What is the first step to begin reading from multiple topics in Spark Streaming?\",\\n  \"How do I initialize a Spark Session for processing streaming data?\",\\n  \"What method is used to reset terminated streams before starting new queries?\",\\n  \"Can you explain how to start multiple queries in Spark Streaming?\",\\n  \"What is the difference between awaitAnyTermination and awaitTermination when managing streams?\"\\n]',\n",
       " '5214eb93': '[\"What is the process to transfer transformed data from Databricks to Azure SQL Database?\", \"Is it necessary to use Azure Blob Storage when moving data from Databricks?\", \"Can transformed data be sent directly to Azure SQL Database from Databricks?\", \"What is the recommended method for moving data after transformation?\", \"Are there any steps involved in transferring data from Azure Blob Storage to Azure SQL DB?\"]',\n",
       " '3cfd16a7': '[\\n    \"What are the requirements for orchestrating dbt with Airflow in the trial dbt account?\",\\n    \"How do I manually add a job when using Airflow to run dbt tasks?\",\\n    \"What information do I need to provide for Airflow to execute a dbt job successfully?\",\\n    \"Where can I find a detailed explanation for integrating dbt with Airflow?\",\\n    \"Is there a source code example available to help me understand how to set up dbt with Airflow?\"\\n]',\n",
       " 'a7cecdf9': '[\"What are the necessary roles for the service account to orchestrate DataProc with Airflow?\", \"Can you provide links for the documentation on orchestrating DataProc with Airflow?\", \"Which operators should I use when working with DataProc in Airflow?\", \"Is there anything specific I need to include when using DataprocSubmitPySparkJobOperator?\", \"Why do I need to add the BigQuery Connector when using DataProc?\"]',\n",
       " '2aad1011': '[\\n    \"How can I initiate a dbt job within my Mage pipeline?\",\\n    \"Where can I locate the dbt cloud API key necessary for integration with Mage?\",\\n    \"What environment variable should I use to store my dbt API trigger information?\",\\n    \"Can you provide an example of how to set up the HTTP request in a custom Mage Python block?\",\\n    \"What content should be included in the body of the POST request to trigger the dbt job?\"\\n]',\n",
       " 'cb478996': '[\\n  \"What is the link to the relevant Slack thread for project evaluation regarding reproducibility?\",\\n  \"How does the evaluation process handle situations where a peer reviewer might struggle to follow the documented steps?\",\\n  \"What should I do if I\\'m unable to re-run the entire project as part of the evaluation criterion?\",\\n  \"Can you explain what Alex suggests if a reviewer is checking the code instead of re-running it?\",\\n  \"Is it adequate to merely look for errors and missing instructions without executing the code for reproducibility assessment?\"\\n]',\n",
       " 'b4ef8ca7': '[\"What is the purpose of the Key Vault in Azure?\", \"How can I securely store passwords in Azure?\", \"In what scenarios would I use Key Vault for SQL database credentials?\", \"Can Key Vault store secrets from multiple tech stacks?\", \"Why should I avoid exposing passwords in my applications?\"]',\n",
       " '8e74f943': '[\\n    \"What should I do if I encounter a \\'ModuleNotFoundError: No module named \\'py4j\\'\\' while trying to import pyspark in Spark Docker?\",\\n    \"How can I check the version of py4j when using Docker for my Spark project?\",\\n    \"Is there a command I can use in Docker to find the py4j version for my PySpark setup?\",\\n    \"What Docker command will help me list the contents of the Spark Python library directory to troubleshoot py4j issues?\",\\n    \"Could you guide me on how to access the shell in the Docker container to check for py4j?\"\\n]',\n",
       " 'a73ed357': '[\"What should I do if psycopg2 is giving me errors related to incompatible architecture?\", \"Can I use both conda and pip at the same time for managing my virtual environment?\", \"How can I install psycopg2 if I\\'m using conda?\", \"Are there specific channels I need to use when installing psycopg2 with conda?\", \"What command should I run to install psycopg2 using pip?\"]',\n",
       " 'd5b6ef5d': '[\"What is the recommended approach for setting up dbt locally using Docker and Postgres?\", \"Can you explain how to create the profiles.yml file for dbt?\", \"What steps should I follow to clone the dbt starter project?\", \"What configuration line do I need to include in the dbt_project.yml file?\", \"How can I troubleshoot issues when running the dbt Docker command?\"]',\n",
       " 'b406d90e': '[\\n    \"What configuration is needed for Pyspark to integrate with BigQuery?\",\\n    \"Can you provide an example of initializing a SparkSession for BigQuery?\",\\n    \"What is the required package for connecting Pyspark to BigQuery?\",\\n    \"In which section of the Pyspark code should I add the BigQuery configuration?\",\\n    \"Is there a specific version of the BigQuery connector to use with Spark 3.5?\"\\n]',\n",
       " '0002ab8b': '[\\n  \"What package do I need to install to run a dbt-core project in Airflow on Google Cloud Composer?\",\\n  \"Where should I place my dbt-core project in relation to the Google Cloud Composer directory structure?\",\\n  \"How do I configure the profiles.yml file for authentication with a service account key?\",\\n  \"What class should I use to create a new DAG for the dbt-core project?\",\\n  \"How can I ensure my dbt lineage graph is organized as tasks inside a task group?\"\\n]',\n",
       " '138b55c7': '[\\n    \"How can I change the display name that appears on the leaderboard?\",\\n    \"What name should I use for the certificate upon course completion?\",\\n    \"What does the \\'Display on Leaderboard\\' option allow me to do?\",\\n    \"Can I use a nickname instead of my real name for the leaderboard display?\",\\n    \"Which data sources are supported for creating external tables in BigQuery?\"\\n]',\n",
       " '154d7705': '[\"What package do I need to install to execute the code successfully?\", \"Is there a specific command I should run for the installation of dependencies?\", \"Do I need to install duckdb separately, and if so, when should I do this?\", \"Can you clarify the importance of the dlt[duckdb] package for running the code?\", \"What should I do if I am running the code locally regarding the duckdb installation?\"]',\n",
       " 'f96517d9': '[\\n  \"What additional packages are necessary for running the starter Jupyter Notebook?\",\\n  \"What should I do if I\\'m using a new Codespace?\",\\n  \"How can I set up my local machine for the course\\'s Jupyter Notebook?\",\\n  \"What command do I need to run to install Jupyter in a new Virtual Environment?\",\\n  \"Is there any package I need to install before using the Jupyter Notebook provided by the instructor?\"\\n]',\n",
       " '773587dd': '[\\n  \"What steps should I take to utilize the DuckDB In-Memory database alongside dlt?\",\\n  \"Is it possible to transition from in-memory to in-file storage while using dlt?\",\\n  \"What alternatives do I have for storing data with dlt instead of using DuckDB in-memory?\",\\n  \"How do I configure in-file storage when working with dlt?\",\\n  \"Can you explain the process for switching to an in-file storage option within dlt?\"\\n]',\n",
       " '73aff710': '[\"What should I expect to find in terms of records after completing Exercise 3 in the homework?\", \"How can I accurately calculate the total sum of ages for the individuals loaded in the dlt Exercise 3?\", \"What should I do if the calculated sum of ages exceeds the available choices?\", \"What is the correct way to specify a file path so that the dlt files save to my desired location?\", \"How do I check the list of Parquet files generated in my specified folder after running the pipeline?\"]',\n",
       " '0728ca67': '[\\n  \"What should I do if I encounter a \\'no such file or directory\\' error for command.sh?\",\\n  \"How can I verify if the command.sh file is present in my project?\",\\n  \"What command can I use to check the contents of the repository?\",\\n  \"How can I confirm that I cloned the correct repository for the workshop?\",\\n  \"Where can I find the URL for the correct repository to clone?\"\\n]',\n",
       " '49a51e24': '[\"What should I do if I encounter a \\'psql - command not found\\' error while trying to use PostgreSQL?\", \"Why do I only have \\'pgcli\\' and not \\'psql\\' when running PostgreSQL?\", \"What is a suitable alternative to \\'psql\\' for executing SQL scripts if I\\'m using a container setup?\", \"How can I install \\'usql\\' on my operating system?\", \"What is the procedure to run the taxi_trips.sql script using \\'usql\\'?\"]',\n",
       " 'f0d552a7': '[\"What should I do if I see an error message indicating that \\'docker-compose\\' is not found while trying to set up Workshop 2?\", \"How can I resolve the issue if I have docker compose installed but it is not recognized during the setup?\", \"Is there a specific way to edit the command.sh file to fix the docker-compose error?\", \"What change should I make to the command.sh file when I receive \\'docker-compose not found\\' during the setup process?\", \"Can you provide an example of how to modify the command for starting the cluster correctly?\"]',\n",
       " '9c750080': '[\"What does the error message regarding \\'Invalid top-level property x-image\\' indicate in my setup?\", \"What are the acceptable top-level sections in a Docker Compose file according to the FAQ?\", \"How can I resolve the issue if I\\'m seeing the \\'Invalid top-level property x-image\\' error?\", \"What should I do if I encounter compatibility issues with docker-compose on Ubuntu machines?\", \"Is there a resource available for understanding different versions of the Docker Compose file format?\"]',\n",
       " '6f4998e6': '[\\n    \"Is it normal to see records being ingested in batches of 10 during Workshop 2?\",\\n    \"Why is it important to observe changes in real-time while working on queries?\",\\n    \"How does the script modify the date timestamp when ingesting records?\",\\n    \"What should I do while the stream-kafka script is running in the background?\",\\n    \"Is it possible to increase the number of records being ingested at once, and if so, how?\" \\n]',\n",
       " '97170587': '[\"Do I need to install Kafka for the RisingWave workshop?\", \"Is it mandatory to have Kafka installed for Workshop 2?\", \"Will the RisingWave workshop require a Kafka setup?\", \"Is the installation of Kafka a prerequisite for this workshop?\", \"Should I worry about Kafka installation before attending RisingWave?\"]',\n",
       " '4def6541': '[\\n  \"What is the minimum amount of free disk space required for the setup?\",\\n  \"How much total disk space should I have available for this workshop?\",\\n  \"Is 7GB of free space sufficient for running all containers?\",\\n  \"Do I need additional disk space beyond what is required for the containers?\",\\n  \"How much free space is needed for psql to run and ingest the data?\"\\n]',\n",
       " '66e117dd': '[\\n    \"What should I do if I encounter issues with Psycopg2 while running the stream-kafka script?\",\\n    \"Is there a specific version of Psycopg2 I need to use for this course?\",\\n    \"Do I need to perform any steps before launching psql in a new terminal session?\",\\n    \"How do I modify the requirements.txt file for this workshop?\",\\n    \"What command must I run in each terminal session before executing psql?\"\\n]',\n",
       " '94fd2476': '[\"What steps should I follow to resolve the psycopg2 wheel installation issue in a Conda environment?\", \"Why is it necessary to install GCC when I encounter an error related to psycopg2 and pyproject.toml?\", \"Can you explain the role of GCC in the installation of Python packages like psycopg2?\", \"How does the Conda base installation affect the availability of GCC for virtual environments?\", \"What command should I execute to activate my RisingWave virtual environment after installing GCC?\"]',\n",
       " '70d83d78': '[\\n    \"What terminal should I use to run the seed-kafka command on Windows?\",\\n    \"How do I activate the Python virtual environment using Git Bash?\",\\n    \"What change should I make to the seed_kafka.py file to resolve the issue?\",\\n    \"How can I connect to the RisingWave cluster using Powershell?\",\\n    \"What is the equivalent command for source commands.sh when using Powershell?\"\\n]',\n",
       " 'accb7285': '[\"What should I do if the stream-kafka script hangs indefinitely due to a connection issue?\", \"How can I check if the message_queue container is having problems in Docker?\", \"What adjustments do I need to make to the memory allocation in the docker-compose file if I encounter an insufficient memory error?\", \"What error message might indicate that the psql command is not working as expected when running the trip_data.sql file?\", \"Why do I need to run the source commands.sh file in each terminal after starting services with default values?\"]',\n",
       " 'cbca4495': '[\\n  \"Is there a required number of records to process for the homework questions?\",\\n  \"What method should I use to obtain a static set of results?\",\\n  \"Can I use stream-kafka for homework or should I stick to seed-kafka?\",\\n  \"What results can I expect when using seed-kafka for homework?\",\\n  \"How do I ensure I get a static set of answers for the homework questions?\"\\n]',\n",
       " '78fce6ad': '[\\n  \"What should I do if I encounter a warning about the materialized view not guaranteeing order?\",\\n  \"How can I ensure consistent results when using a materialized view in my queries?\",\\n  \"What steps must I follow if the homework answers do not align with the given options?\",\\n  \"Which command should I use to clean up my environment before running the homework?\",\\n  \"Is there a specific volume I should use instead of stream-kafka for the homework task?\"\\n]',\n",
       " '68842c02': '[\\n    \"What are the specific steps I need to follow to install PostgreSQL on a Linux-like operating system for Workshop 2?\",\\n    \"Can you provide the commands necessary to set up PostgreSQL if I am following the views from Noel (2024)?\",\\n    \"Is there a way to check if the PostgreSQL service is running after I have installed it?\",\\n    \"What should I do if the PostgreSQL service is down after installation?\",\\n    \"Are there any additional packages required along with PostgreSQL during the installation process?\"\\n]',\n",
       " '71b1984b': '[\"What should I do if I can\\'t open the dashboard because xdg-open isn\\'t launching a browser?\", \"Is there an alternative to using w3m for opening the dashboard?\", \"How can I access the index.html file if my browser isn\\'t working?\", \"Is there a specific method I should follow to open index.html on WSL?\", \"Can I use a different browser to view the dashboard, and how?\"]',\n",
       " 'd452b490': '[\\n    \"What kind of error might occur when running a Python script with a Windows-created shebang line in a Unix-like environment?\",\\n    \"Can you explain the significance of the \\\\r character in the context of executing Python scripts?\",\\n    \"What command should I use to locate the Python 3 interpreter in my environment?\",\\n    \"How can I modify the shebang line of a Python script to ensure it points to the correct interpreter?\",\\n    \"What utility can I use to convert a script\\'s line endings from Windows-style to Unix-style?\"\\n]',\n",
       " '707cae8f': '[\"What is the concept of windowing in streaming SQL?\", \"Can you explain how to set boundaries for data processing?\", \"How does windowing help with analyzing streaming data?\", \"What kind of intervals can be defined for windowing?\", \"In what scenarios would windowing be useful in SQL?\"]',\n",
       " 'ffbf3311': '[\\n  \"What steps should I take to resolve the \\'ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\\' error when attempting to import KafkaProducer in Jupyter Notebook for Module 6 Homework?\",\\n  \"How can I ensure my Mage pipeline runs without failure when some blocks succeed individually?\",\\n  \"What is the correct way to set the path for profiles.yml in order to avoid issues when executing my dbt pipeline?\",\\n  \"Can you explain the process of creating triggers in Mage pipelines using the command line interface?\",\\n  \"Is it possible to perform data partitioning and clustering directly within a dbt model, or do I need to manage this manually in BigQuery?\"\\n]',\n",
       " '3916f4a9': '[\\n    \"What are the commands to create a Docker image from a base image and how do I list them?\",\\n    \"How can I attach to a stopped container using the command line?\",\\n    \"What is the command to create an image from a Dockerfile?\",\\n    \"How can I delete all containers forcefully using the command line?\",\\n    \"What steps do I need to follow to install the GCP Cloud SDK on a Docker machine?\"\\n]',\n",
       " '0227b872': '[\"What is the process to enroll in the Machine Learning course?\", \"Where can I find the frequently asked questions for the course?\", \"Is there a specific document for technical inquiries related to the course?\", \"Can you direct me to the course\\'s GitHub repository?\", \"How was the FAQ document structured in the data engineering course?\"]',\n",
       " '39fda9f0': '[\"Will the course be conducted live or is it pre-recorded?\", \"When can I start watching the course content?\", \"Are there any live sessions for asking questions?\", \"How can I access the recorded office hours?\", \"Where can I find the course videos and office hours on YouTube?\"]',\n",
       " '5170565b': '[\"What happens if I can\\'t attend a session?\", \"Will I have access to the missed content?\", \"How can I address my questions if I miss a class?\", \"Is there a way to interact during the live stream?\", \"Can I use Slack for asking questions after missing a session?\"]',\n",
       " 'ecca790c': '[\\n    \"What is the main focus of the course in terms of content covered?\",\\n    \"How in-depth will the theoretical concepts be discussed during the course?\",\\n    \"Will we focus on practical skills rather than theoretical derivations?\",\\n    \"Is there a specific example of a theory we won\\'t delve into deeply?\",\\n    \"How will the course help us understand results from practical applications?\"\\n]',\n",
       " 'c25b3de4': '[\"Is a math background necessary to enroll in the course?\", \"What specific math topics will we learn during the course?\", \"Will there be a lot of formulas involved in the course content?\", \"Can you recommend any resources to help with linear algebra?\", \"How can I get support if I struggle with the course material?\"]',\n",
       " '6ba259b1': '[\"What should I do if I filled out the form but haven\\'t received any confirmation email yet?\", \"Is it expected to not receive a confirmation email after submitting the form?\", \"Where can I check for the confirmation email if it\\'s not in my inbox?\", \"How can I stay updated on course-related information if I unsubscribed from the newsletter?\", \"Are there alternative ways to receive course updates besides email?\"]',\n",
       " '67e2fd13': '[\"What is the expected duration of the course?\", \"Can the course length vary for different students?\", \"Is it possible to extend the course duration?\", \"How can I extend my time in the course?\", \"Will additional projects affect the overall course length?\"]',\n",
       " 'a6897e8c': '[\\n  \"What is the estimated weekly time commitment for completing this course?\",\\n  \"How many hours per week should I expect to dedicate to this course?\",\\n  \"Is there specific research on the time needed for different modules in the course?\",\\n  \"Who conducted the analysis of time spent by previous students on the course?\",\\n  \"Where can I find detailed information about the time requirements for this course?\"\\n]',\n",
       " '2eba08e3': '[\\n    \"Do I need to complete all projects to receive a certificate?\",\\n    \"What are the requirements for obtaining a certificate in this course?\",\\n    \"Is there a specific deadline for project completion and peer review?\",\\n    \"Can I see examples of the certificate I\\'ll receive upon completion?\",\\n    \"Do I need to review any projects to be eligible for the certificate?\"\\n]',\n",
       " '1d644223': '[\"Can I still receive a certificate if I didn\\'t submit the midterm project?\", \"What happens to my certificate if I miss the midterm project?\", \"Is it possible to earn a certificate despite not attending the midterm project?\", \"Will missing the midterm project affect my eligibility for a certificate?\", \"Are there any conditions related to the midterm project for obtaining a certificate?\"]',\n",
       " '14890cd2': '[\\n  \"What specific Python skills do I need to possess before taking this course?\",\\n  \"Is there a recommended resource for learning Python basics to prepare for the course?\",\\n  \"Can you explain why understanding Jupyter notebooks is important for this course?\",\\n  \"What types of operations related to data analysis should I be familiar with before starting?\",\\n  \"If I find the recommended article challenging, what should I do next?\"\\n]',\n",
       " 'a4fad482': '[\"What are the hardware specifications needed for the Machine Learning part of the course?\", \"Is a laptop sufficient for the Deep Learning section, or are additional resources required?\", \"Can you clarify if we need to rely on cloud services for the Deep Learning part?\", \"Which cloud service is recommended for the Deep Learning section of the course?\", \"Is a stable internet connection essential for participating in this course?\"]',\n",
       " '34b7fd35': '[\\n  \"What steps should I follow to enable GPU support for TensorFlow on Ubuntu?\",\\n  \"Can you recommend a resource for setting up TensorFlow with GPU on an Ubuntu system?\",\\n  \"Is there a specific article that details the installation of TensorFlow with GPU on Ubuntu?\",\\n  \"Where can I find detailed instructions for configuring TensorFlow to use the GPU on Ubuntu?\",\\n  \"What is the best tutorial to follow for getting TensorFlow to run with GPU capabilities on Ubuntu?\"\\n]',\n",
       " '4930aa19': '[\\n  \"How can I find the channel for our course in Slack as I\\'m unfamiliar with the platform?\",\\n  \"What steps do I need to follow to join a specific channel in Slack?\",\\n  \"Is it necessary to provide a GitHub link for my homework submissions?\",\\n  \"What is the process for joining a channel if I can\\'t see the \\'All channels\\' option on Slack?\",\\n  \"Where do I go to find public channels in my Slack workspace?\"\\n]',\n",
       " 'ee58a693': '[\\n  \"Can I still enroll in the course even though it has already begun?\",\\n  \"What is the impact on homework submissions if I join after the course has started?\",\\n  \"What are the requirements for obtaining a certificate in this course?\",\\n  \"If I join late, how many projects do I need to complete for certification?\",\\n  \"Is it possible to receive a certificate if I start the course towards the end of November?\"\\n]',\n",
       " '636f55d5': '[\\n    \"When will the next cohort start for the course?\",\\n    \"Is the course available to take at my own pace?\",\\n    \"What month will the next iteration of the course occur?\",\\n    \"Are there future iterations planned beyond September 2024?\",\\n    \"Can I proceed with the course materials anytime I choose?\"\\n]',\n",
       " 'c839b764': '[\"Is it allowed to turn in homework past the deadline?\", \"What happens if I miss the homework submission deadline?\", \"Will I be penalized for submitting homework late?\", \"Is homework submission essential for completing the course?\", \"Can I still pass the course if I don\\'t submit my homework?\"]',\n",
       " '0a278fb2': '[\\n    \"What steps should I take now that I\\'ve enrolled in the course?\",\\n    \"Where can I find the course materials for my studies?\",\\n    \"Is there a specific location on the course page where I should begin?\",\\n    \"How can I access videos from both my current year and previous cohorts?\",\\n    \"What is the easiest way to view the course syllabus online?\"\\n]',\n",
       " '8de4fefd': '[\"What is the deadline information for this course?\", \"Where can I find the deadlines for the 2023 cohort?\", \"Are the deadlines the same for every cohort?\", \"How do I access the deadlines for my course?\", \"Can I find deadlines specific to the 2023 cohort online?\"]',\n",
       " '94e86808': '[\\n    \"How does the 2023 version of the course differ from 2022?\",\\n    \"Was there any special module included in the last year\\'s course?\",\\n    \"Are the course modules identical between 2022 and 2023?\",\\n    \"What changes were made to the homework for this year\\'s course?\",\\n    \"Is there a significant difference in content from the previous iteration?\"\\n]',\n",
       " 'e7ba6b8a': '[\"Will there be new videos for this course since the current ones are from 2021?\", \"Are the existing course videos still relevant for learning this material?\", \"If I missed the last iteration, can I still benefit from the current videos?\", \"Should I be using Python 3.8 or is there a preferred version for the course?\", \"What version of Python do you recommend using while watching the course videos?\"]',\n",
       " 'f7bc2f65': '[\\n    \"What should I include in my social media posts to get credit for learning in public?\",\\n    \"How should I format multiple links when submitting my homework?\",\\n    \"Is there a limit to the number of points I can earn for posting my learning online?\",\\n    \"Can I use the same link across different social media platforms for the extra score?\",\\n    \"What happens to the points I earn for midterms or capstone projects compared to regular homework submissions?\"\\n]',\n",
       " 'ae52a907': '[\\n    \"How can I share my notes for the course with others?\",\\n    \"What is the process for adding my personal notes to the Community Notes section?\",\\n    \"Is it possible to create my own repository for course materials?\",\\n    \"What are the steps to link my notes to the course repository?\",\\n    \"How do I submit a pull request after adding my notes?\"\\n]',\n",
       " 'dab5a24a': '[\\n    \"What are the links to access the leaderboard for the years 2023 and 2022?\",\\n    \"How can I compute the hash of my email using Python?\",\\n    \"What should I do if I want to generate a SHA-1 hash without writing code?\",\\n    \"Can you provide an example of how to call the Python function to compute the hash of my email?\",\\n    \"Is it necessary to use quotes when entering my email in the compute_hash function?\"\\n]',\n",
       " '49f9bda9': '[\\n    \"What should I do if I see that \\'wget\\' is not recognized as an internal or external command?\",\\n    \"How can I install wget on a Windows system?\",\\n    \"Is there a way to download files using Python without wget, and what would be the method?\",\\n    \"Can I read a CSV file directly from a URL using pandas, and if so, how?\",\\n    \"What should I do if I need to bypass HTTPS checks when downloading a file in Python?\"\\n]',\n",
       " 'd44de7d1': '[\\n    \"How can I download a CSV file directly within my notebook?\",\\n    \"What is the purpose of using the exclamation mark in my notebook commands?\",\\n    \"Can you provide an example of moving a downloaded file to a specific directory?\",\\n    \"Which shell commands can I use inside my notebooks?\",\\n    \"How do I create a new directory for storing my data files?\"\\n]',\n",
       " '314ebe32': '[\\n  \"What steps should I follow to set up WSL on my Windows 11 device?\",\\n  \"How can I connect my WSL environment to VS Code after installation?\",\\n  \"Is there a specific extension I need to download for VS Code to work with WSL?\",\\n  \"Can I access my WSL instance like a virtual machine through VS Code?\",\\n  \"Where can I find resources or instructions for setting up a WSL development environment?\"\\n]',\n",
       " '98cff602': '[\\n  \"What should I do if I encounter an error message while trying to push my code to Github for the first time?\",\\n  \"Can you explain how to resolve the \\'src refspec master does not match any\\' error when using Git?\",\\n  \"Is there a way to upload my homework files to Github without using command line commands?\",\\n  \"If I write my code in Google Colab, how can I share it directly on my Github account?\",\\n  \"Where can I find a tutorial for using Github effectively, especially for beginners?\"\\n]',\n",
       " '54ec0de4': '[\"What does the singular matrix error mean in the context of matrix inversion?\", \"Why am I encountering a singular matrix error while working on my homework?\", \"How does the order of multiplication affect the outcome in matrix operations?\", \"Can you explain why X.dot(Y) is not the same as Y.dot(X)?\", \"What should I consider to avoid the singular matrix error during calculations?\"]',\n",
       " 'f81f4ecb': '[\\n    \"What should I do if I receive an error stating that \\'Conda is not an internal command\\' when trying to execute a command in the terminal?\",\\n    \"Is there a specific Python version that I should use when creating a new environment with Conda, and does it matter if I use 3.8, 3.9, or 3.10?\",\\n    \"If I just installed Anaconda on my Windows machine, which terminal should I use to run Conda commands?\",\\n    \"What steps should I take if I don’t have Anaconda or Miniconda installed on my computer?\",\\n    \"Can I run the command \\'conda create -n ml-zoomcamp python=3.9\\' on my terminal if I am using a different operating system?\"\\n]',\n",
       " 'be760b92': '[\\n  \"What is the proper way to read a dataset using Pandas on a Windows operating system?\",\\n  \"Why doesn\\'t the code I wrote to read the CSV file in Windows work?\",\\n  \"What is the significance of using backslashes in file paths on Windows for Python code?\",\\n  \"How can I avoid conflicts with escape sequences in my file path when using Pandas?\",\\n  \"What should I do to correctly load a CSV file located in my Downloads folder on Windows?\"\\n]',\n",
       " 'a2cfa1c9': '[\"What should I do if I receive a \\'403 Forbidden\\' error when pushing to my GitHub repository?\", \"How can I verify the current remote URL configured for my Git repository?\", \"What command do I need to run to check the remote settings for my repository?\", \"How do I change my GitHub remote URL to ensure it includes my GitHub username?\", \"What format should the remote URL be in after changing it for proper access?\"]',\n",
       " '7b907071': '[\\n  \"What does the authentication error message indicate when pushing code from Git Bash?\",\\n  \"Why did I receive a fatal error stating \\'Authentication failed for https://github.com/username\\'?\",\\n  \"What change regarding password authentication occurred on August 13, 2021?\",\\n  \"What is the recommended solution to resolve the authentication failure when pushing code?\",\\n  \"Where can I find instructions for creating a personal access token for GitHub authentication?\"\\n]',\n",
       " 'fc2e0a61': '[\"What should I do if I encounter an error when trying to wget a dataset from GitHub in Kaggle?\", \"How can I resolve the issue of being unable to resolve the host address when using wget in Kaggle notebooks?\", \"Is there a specific setting I need to adjust in Kaggle to successfully import data using wget?\", \"What steps do I need to follow to enable Internet access for my session in Kaggle?\", \"Do I need to verify my phone number when turning on Internet access in Kaggle?\"]',\n",
       " 'd43e5742': '[\\n    \"What resources are available for setting up a Python environment in VS Code?\",\\n    \"Does VS Code support using Jupyter Notebooks without opening a browser?\",\\n    \"How can I execute remote Jupyter Notebooks files in VS Code?\",\\n    \"Is there GitHub support within VS Code for managing my projects?\",\\n    \"Where can I find guidance on using Jupyter Notebooks in VS Code?\"\\n]',\n",
       " '32bc0538': '[\"Do I need to create a Conda environment every time I start a new project in VS Code?\", \"What command should I run to activate my existing Conda environment for the machine learning project?\", \"Is there a way to save my current Conda environment configuration to reuse later?\", \"Once I create a Conda environment, how do I access it in subsequent sessions?\", \"Can you explain how to recreate a Conda environment using a YAML file?\"]',\n",
       " 'b6730228': '[\\n    \"What issue might I encounter when calculating the inverse of a matrix in Question 7 of Week 1 Homework?\",\\n    \"Why did my multiplication of the inverse matrix with the original matrix not yield a perfect identity matrix?\",\\n    \"Can you explain why floating point precision affects the calculations in our machine learning course?\",\\n    \"Where can I find more information about the limitations of floating point mathematics as mentioned in the FAQ?\",\\n    \"How can I ensure accurate results when working with matrix inverses in future assignments?\"\\n]',\n",
       " '3ce9bbb8': '[\"What is the purpose of using pandas.DataFrame.info() in our analysis?\", \"Can you explain what kind of information is retrieved by the df.info() method?\", \"How does the df.info() method help in understanding the dataset\\'s structure?\", \"What specific details about the dataset can I expect to see when using df.info()?\", \"Is there any particular format in which the output of df.info() is presented?\"]',\n",
       " '4e584d06': '[\"What should I do if I encounter a NameError related to \\'np\\'?\", \"Why am I getting a NameError indicating that \\'pd\\' is not defined?\", \"What libraries need to be imported to avoid NameErrors in my code?\", \"Can you remind me how to properly import pandas and numpy in my script?\", \"What is the common cause of NameErrors when using pandas or numpy?\"]',\n",
       " 'ff4da2b6': '[\\n    \"What is the method to choose numeric columns from a DataFrame?\",\\n    \"How can I filter for object data types within a DataFrame?\",\\n    \"Is there a concise approach to select specific data types in a DataFrame?\",\\n    \"What should I do if I need to manage hundreds of columns and only want certain types?\",\\n    \"Can you explain how to retrieve the column names for numeric data using select_dtypes?\"\\n]',\n",
       " '58c1c168': '[\\n    \"What are some methods to determine the dimensions of a dataset in Pandas?\",\\n    \"How can I find out the number of rows in a DataFrame using Pandas?\",\\n    \"What Pandas attribute would I use to assess the shape of my dataset?\",\\n    \"If I want to know how many columns are in my DataFrame, which command should I use?\",\\n    \"Can you provide an example of how to use the .shape attribute in Pandas?\"\\n]',\n",
       " '96076a1a': '[\"What should I use for matrix multiplication to prevent Value errors in my homework?\", \"Why is the order of multiplication important when doing matrix-matrix multiplication?\", \"What condition must be met regarding the dimensions of the matrices for multiplication to succeed?\", \"How can I rearrange the order of my matrices if I encounter dimension mismatch?\", \"Can you clarify what happens if the columns of the first matrix do not match the rows of the second matrix?\"]',\n",
       " '3218389a': '[\\n  \"What does it mean to impute missing values in a dataset, and why do we need to do it?\",\\n  \"Can you explain the process to calculate the average of a column and how to use it for replacing NaN values?\",\\n  \"Why is it important not to remove rows with NaN values when they contain useful information?\",\\n  \"What steps should I follow in order to replace NaN values with the average in a column?\",\\n  \"Who added the information regarding the method of imputing NaN values in this course?\"\\n]',\n",
       " '183a1c90': '[\"What is the mathematical formula to use for linear regression?\", \"How can I calculate the target variable in linear regression?\", \"What resources are available for understanding ordinary least squares?\", \"Can you explain multiple linear regression in matrix form?\", \"What is the pseudoinverse solution to ordinary least squares?\"]',\n",
       " 'f0bc1c19': '[\\n    \"What might be the reason for having fewer than 5 columns in the final multiplication?\",\\n    \"How can I correct the issue of having a discrepancy in the number of columns during multiplication?\",\\n    \"What did I possibly interchange in the initial step of my multiplication?\",\\n    \"Can you clarify what I might have used incorrectly in my multiplication process?\",\\n    \"Who added the note about the final multiplication issue?\"    \\n]',\n",
       " '735e6c78': '[\\n  \"What operations can the * operator be used for in matrix multiplication?\",\\n  \"Which functions or operators should I use for matrix-matrix multiplication according to the numpy documentation?\",\\n  \"How does the * operator differ from the @ operator in terms of multiplication in numpy?\",\\n  \"When should I use numpy.multiply() instead of other multiplication operators?\",\\n  \"Can you explain why the @ operator or np.matmul() is preferred for certain types of multiplication?\"\\n]',\n",
       " 'b8ca1cd3': '[\\n    \"What should I do if I encounter an ImportError related to Jinja2 when starting Jupyter notebook?\",\\n    \"How can I resolve the error regarding \\'contextfilter\\' from Jinja2 when launching a new notebook?\",\\n    \"What command do I need to run to fix the ImportError when using a new environment for Jupyter?\",\\n    \"Can I resolve Jupyter notebook launch issues by switching to the main environment and upgrading nbconvert?\",\\n    \"What steps should I take if I face an error related to importing Jinja2 while starting a Jupyter notebook?\"\\n]',\n",
       " 'efdb235f': '[\\n  \"What should I do if wget hangs while downloading the housing dataset?\",\\n  \"How can I resolve the issue of seeing IPv6 addresses during wget download?\",\\n  \"Is there a specific setting I need to change in System Settings for the download to work?\",\\n  \"Where do I find the option to configure IPv6 on my MacOS Ventura M1?\",\\n  \"What steps should I take to modify my network connection settings for wget?\"\\n]',\n",
       " '355348f0': '[\\n    \"What should I do if I encounter issues with WGET on macOS?\",\\n    \"Is there an alternative tool that I can use instead of WGET for downloading files?\",\\n    \"Can you explain how to use curl for retrieving information from the internet?\",\\n    \"What does the \\'-o\\' option signify when using curl?\",\\n    \"Where can I find more information about curl and its usage?\"\\n]',\n",
       " '67afabf5': '[\\n  \"What function can I use to round a number to a specific number of decimal places in Python?\",\\n  \"How can I print a floating-point number with only three decimal places using f-strings?\",\\n  \"Is there a method to round all the values in a pandas Series at once?\",\\n  \"What is the syntax for rounding a number to four decimal places using the round function?\",\\n  \"Where can I find more information about the round method for pandas Series?\"\\n]',\n",
       " '50d737e7': '[\\n  \"What are the important links I need to access for Week 2 starting on September 18, 2023?\",\\n  \"Where can I submit my homework for Week 2 of the course?\",\\n  \"Is there a Google Calendar link available for the weekly meetings?\",\\n  \"How can I ask questions during the Live Sessions this week?\",\\n  \"Where can I find all the homework assignments for the course?\"\\n]',\n",
       " 'bbc0fca3': '[\\n  \"What is the recommended method to examine the long tail of our dataset in this course?\",\\n  \"Can you provide a code example to create a histogram for analyzing the distribution of median house values?\",\\n  \"How can skewness be calculated for the \\'median_house_value\\' variable in our dataset?\",\\n  \"What does the skewness value tell us about the distribution of median house values?\",\\n  \"Is it necessary to use seaborn for plotting the histogram, or can we use another library?\"\\n]',\n",
       " '6f3bdd20': '[\\n    \"What does it mean if I encounter a Singular Matrix error while following the course videos?\",\\n    \"Will the reasons behind getting a Singular Matrix error be explained in the course?\",\\n    \"Is it common to experience a Singular Matrix error while working on the exercises?\",\\n    \"Could performing the inverse of X multiple times in my code lead to errors?\",\\n    \"What should I do if I encounter a Singular Matrix error in my implementation?\"\\n]',\n",
       " '27c2d90a': '[\"Where can I find more information about the California housing dataset?\", \"Is there a specific link for the detailed description of the California housing dataset?\", \"What resource provides a thorough explanation of the California housing dataset?\", \"Can you direct me to a website that discusses the California housing dataset in detail?\", \"Where should I look for the dataset description related to California housing?\"]',\n",
       " '88e9600a': '[\\n  \"What steps should I follow if I encounter NaN values when calculating the mean using the .mean() function?\",\\n  \"How did the issue with NaN values in the rmse calculation get resolved in the course example?\",\\n  \"Why did the NaN values appear in the resulting rmse when using for loops with y_val and y_pred?\",\\n  \"What was the approach taken to ensure all datasets (train, validation, test) were processed correctly?\",\\n  \"What method was used to handle missing values in the datasets mentioned in the FAQ record?\"\\n]',\n",
       " 'd59d8df7': '[\"What is the reason for transforming the target variable to a logarithm distribution in machine learning projects?\", \"Is target variable transformation necessary for every machine learning project?\", \"How can I determine if my target variable is highly skewed?\", \"What is the best method to assess the skewness of the target variable distribution?\", \"Where can I find more information on skewness in data distribution?\"]',\n",
       " '0b3eaf92': '[\\n    \"How can I import the dataset from GitHub into a pandas dataframe?\",\\n    \"What is the method to read the dataset directly from the provided GitHub link?\",\\n    \"Is there a specific code example to read the dataset into pandas?\",\\n    \"Can you show me how to load the housing dataset from GitHub?\",\\n    \"What command do I use to read a CSV file from a GitHub URL in pandas?\"\\n]',\n",
       " '8fe56032': '[\\n    \"How can I load the dataset directly when using Kaggle Notebooks?\",\\n    \"What command should I use to load the dataset in Kaggle Notebooks?\",\\n    \"Is there a specific requirement I need to remember when using wget in Kaggle Notebooks?\",\\n    \"After loading the dataset, how can I read it using Pandas?\",\\n    \"Can you provide the complete command to download and read the dataset in a Kaggle Notebook?\"\\n]',\n",
       " 'af833e0a': '[\\n    \"What is the method to filter a dataset based on specific value criteria?\",\\n    \"How can I apply the logical \\'OR\\' operator while filtering a DataFrame?\",\\n    \"Is there an alternative way to filter a dataset using a list of values?\",\\n    \"Can I use both \\'AND\\' and \\'OR\\' operators when filtering data in a DataFrame?\",\\n    \"What syntax should I use to check if a value is in a list when filtering?\"\\n]',\n",
       " '8d209d6d': '[\\n    \"Can you explain how to load the dataset using the requests library instead of directly from GitHub?\",\\n    \"What is the URL provided for retrieving the housing data for our homework using the requests method?\",\\n    \"If the download fails when using the requests library, what message will be printed?\",\\n    \"Could you demonstrate the steps to save the dataset to a file after retrieving it with requests?\",\\n    \"What status code is checked to confirm that the data was successfully downloaded using requests?\"\\n]',\n",
       " '0bc4c3da': '[\\n    \"Why is a null column appearing in my dataframe after using .fillna()?\",\\n    \"What is the difference between a shallow copy and a deep copy in Python?\",\\n    \"How can I create a deep copy of my dataframe to avoid referencing the original?\",\\n    \"What is the proper way to assign a new variable to a dataframe without linking it to the original?\",\\n    \"Can you explain the implications of using X_train = df_train directly?\"\\n]',\n",
       " 'c0ee2665': '[\\n    \"Is it permissible to utilize train_test_split from Scikit-Learn during this week\\'s assignments?\", \\n    \"Are we expected to implement the train_test_split function ourselves this week?\", \\n    \"Can I start using Scikit-Learn\\'s functions early instead of waiting?\", \\n    \"Will we continue to work with our own implementation of train_test_split in the future?\", \\n    \"What is the reasoning behind implementing train_test_split ourselves this week?\"\\n]',\n",
       " '3f60871d': '[\"Is LinearRegression from Scikit-Learn allowed for this week\\'s assignments?\", \"Will we learn how to use LinearRegression next week?\", \"Can I rely on using Scikit-Learn for machine learning this week?\", \"Should I be concerned about using LinearRegression this week?\", \"Is there a plan to cover LinearRegression in future lessons?\"]',\n",
       " 'f30217a7': '[\"What Scikit-Learn function should I use for linear regression without regularization?\", \"Is there a specific Scikit-Learn function for linear regression with regularization?\", \"Where can I find more information about the linear models in Scikit-Learn?\", \"Can you clarify which functions correspond to the linear regression models discussed in week 2?\", \"What is the function name in Scikit-Learn for the Ridge regression model?\"]',\n",
       " '91fc573d': '[\\n    \"Can you explain what the `r` parameter represents in the context of regression?\",\\n    \"How does the regularization parameter `r` in our lesson compare to the `alpha` parameter in sklearn\\'s Ridge regression?\",\\n    \"What mathematical function demonstrates how `alpha` and `r` impact regularization strength?\",\\n    \"In what way does `r` help with multicollinearity when performing linear regression?\",\\n    \"Why is adding `r` to the main diagonal necessary for finding the inverse matrix in regression?\"\\n]',\n",
       " 'fe3139f6': '[\\n  \"What explains why we don\\'t achieve a perfect fit with linear regression in lesson 2.8?\",\\n  \"How does the concept of overfitting relate to the inability of linear regression to fit all data points exactly?\",\\n  \"Can you elaborate on how using non-linear methods like scipy.optimize.curve_fit could impact predictions on new data?\",\\n  \"In terms of model simplicity, why might a perfect fit be undesirable in machine learning?\",\\n  \"What visual representation might help illustrate the fit of a linear model compared to actual data points?\"\\n]',\n",
       " '48aac030': '[\\n  \"What is the significance of using a random seed in our homework assignment?\",\\n  \"Why do all my missing values end up in the training dataframe when I use a seed of 42?\",\\n  \"How does changing the random seed affect the distribution of missing values across dataframes?\",\\n  \"Can you explain what happens if I use a different random seed like 9 instead of 42?\",\\n  \"What is the advantage of using the same random seed in machine learning experiments?\"\\n]',\n",
       " '28321bc2': '[\\n    \"How can I shuffle my dataset using pandas?\",\\n    \"What command should I use to ensure I get a complete shuffled version of my DataFrame?\",\\n    \"Is there a way to maintain the same randomization across different runs when shuffling?\",\\n    \"What does the parameter frac=1 do when using the pandas sample function?\",\\n    \"How can I reset the index after shuffling the DataFrame?\"\\n]',\n",
       " 'edb92d22': '[\"What should I do if my homework answer doesn\\'t match the provided options?\", \"Is it common for answers to differ from the choices given in the homework?\", \"Why might my answer not align with the options available?\", \"How do different environments affect the homework solutions I get?\", \"If my answer is unique, should I still choose one of the given options?\"]',\n",
       " 'f488ce85': '[\\n    \"What does the term \\'mean\\' refer to in the context of Homework 2, specifically in question 3?\",\\n    \"Can you clarify what is meant by using only the training data set to compute the mean for question 3 in HW02?\",\\n    \"How should I calculate the mean based on the instructions in question 3 of Homework 2?\",\\n    \"What is the significance of not using the validation or test data set when calculating the mean in HW02?\",\\n    \"Are there alternative methods for computing the mean mentioned in the instructions for question 3 of HW02?\"\\n]',\n",
       " 'bf395099': '[\\n    \"Under what circumstances is it beneficial to apply a logarithmic transformation to the target variable?\",\\n    \"What is the appropriate method to use when transforming a target variable with a long tail distribution?\",\\n    \"Can logarithmic transformation be used if the target variable contains negative values?\",\\n    \"Why is it important to consider the distribution of the target variable before transformation?\",\\n    \"In which scenarios are long tail distributions commonly found in target variables?\"\\n]',\n",
       " '01cd3b35': '[\\n    \"What does the ValueError related to shapes not being aligned mean in the context of machine learning for regression?\",\\n    \"In what situations might broadcasting fail when performing arithmetic operations on arrays with different shapes?\",\\n    \"How can I resolve the ValueError that occurs when trying to perform operations on arrays of different dimensions?\",\\n    \"Is there an alternative method I can use to perform dot product operations when facing alignment issues with array shapes?\",\\n    \"Can you explain the significance of the * operator in solving the shapes not aligned error during regression analysis?\"\\n]',\n",
       " '5551c92e': '[\\n  \"What is the correct method to duplicate a dataframe while ensuring the original remains unchanged?\",\\n  \"Can you explain the difference between a deep copy and a view in the context of dataframes?\",\\n  \"If I use X_copy = X, what will happen to the original dataframe when I modify X_copy?\",\\n  \"What is the proper syntax to create a true copy of a dataframe in Python?\",\\n  \"What does it mean for a copy of a dataframe to be a \\'view\\' rather than a real copy?\"\\n]',\n",
       " '94f928d2': '[\\n    \"Can you explain the concept of the \\'long tail\\' in relation to statistical distributions?\",\\n    \"How does the \\'long tail\\' affect the relationship between mean, median, and mode in a dataset?\",\\n    \"What changes occur in the distribution when there are a few observations with high values?\",\\n    \"In a \\'long tail\\' distribution, how does the area under the curve differ on each side?\",\\n    \"Why might the mean become unrepresentative in a distribution characterized by a \\'long tail\\'?\"\\n]',\n",
       " '266faa6d': '[\\n  \"Can you explain what standard deviation represents in a set of values?\",\\n  \"How does a low standard deviation affect the values in relation to the mean?\",\\n  \"What does a high standard deviation indicate about the spread of values?\",\\n  \"What is the importance of understanding standard deviation in statistics?\",\\n  \"Is there a specific formula to compute standard deviation?\"\\n]',\n",
       " 'c21f99f5': '[\\n    \"Are there specific situations where regularization techniques are particularly important in machine learning?\",\\n    \"In what scenarios should one consider using regularization when training models?\",\\n    \"How does the size of the dataset influence the need for regularization techniques?\",\\n    \"What factors should be evaluated to determine if regularization is necessary for a machine learning model?\",\\n    \"Can you explain why regularization might be important for complex models in machine learning?\"\\n]',\n",
       " '13702957': '[\\n    \"What is the benefit of defining functions for faster execution in our regression module?\",\\n    \"Could you elaborate on how to prepare multiple dataframes and y-vectors using the provided shortcut?\",\\n    \"Is it possible to use fillna() on the initial_df prior to data splitting, and how would that work?\",\\n    \"Can you remind me how I might reuse the rmse() and train_linear_regression functions from the class notebook?\",\\n    \"What are the names of the function and parameters I should use for data preparation in Section 2?\"\\n]',\n",
       " '7cd652c5': '[\\n    \"What is the process for calculating standard deviation with pandas?\",\\n    \"Can you provide an example of how to create a series in pandas for standard deviation?\",\\n    \"How can I directly compute the standard deviation of a data list using pandas?\",\\n    \"What function do I use in pandas to obtain the standard deviation from a series?\",\\n    \"Is there a specific format required when passing data to pandas for calculating standard deviation?\"\\n]',\n",
       " 'e1f93d10': '[\\n    \"What is the primary difference in how Numpy and Pandas calculate standard deviation?\",\\n    \"Which standard deviation does Numpy calculate by default: population or sample?\",\\n    \"How does the default calculation of standard deviation in Pandas differ from Numpy?\",\\n    \"Can I modify the degree of freedom used in Numpy for calculating standard deviation?\",\\n    \"What will the result be if I change the degree of freedom in Numpy to match Pandas\\' default calculation?\"\\n]',\n",
       " '36b9d1b7': '[\\n    \"How can I compute the standard deviation of a specific column using Pandas?\",\\n    \"What function do I use in Pandas to find the standard deviation?\",\\n    \"Is it possible to calculate the standard deviation for multiple columns in a DataFrame?\",\\n    \"Can you give me an example of how to use the std() function in Pandas?\",\\n    \"What is the syntax for using std() to get standard deviation in Pandas?\"\\n]',\n",
       " '3c8b32a1': '[\\n  \"What function can I use to combine two dataframes in my regression analysis?\",\\n  \"How can I merge my train and validation datasets effectively?\",\\n  \"Is there a specific method for combining numpy arrays in this course?\",\\n  \"What would be the syntax for concatenating train and validation data in pandas?\",\\n  \"Where can I find the documentation for the pandas.concat function?\"\\n]',\n",
       " '05fb3a16': '[\\n    \"What is the significance of Root Mean Squared Error (RMSE) in evaluating regression models?\",\\n    \"Can you explain the process of calculating the RMSE score step by step?\",\\n    \"Which libraries do I need to import in order to calculate RMSE for my regression model?\",\\n    \"How does RMSE provide insight into the model\\'s accuracy in forecasting target variables?\",\\n    \"Could you clarify the formula used for computing the RMSE score based on predicted and actual values?\"\\n]',\n",
       " '225506b9': '[\"What is the correct operator for using logical OR in Pandas syntax?\", \"How can I apply multiple conditions in a Pandas DataFrame?\", \"What happens if I use incorrect syntax with multiple conditions in Pandas?\", \"Which symbol represents the logical AND operation in Pandas?\", \"Can you provide examples of using AND and OR with conditions in Pandas?\"]',\n",
       " 'bd4a1395': '[\\n    \"Can you explain the concept behind the normal equation in regression?\",\\n    \"Where can I find a useful resource for understanding the derivation of the normal equation?\",\\n    \"What is the significance of the normal equation in linear regression analysis?\",\\n    \"Are there any recommended videos that clarify the normal equation derivation process?\",\\n    \"How does the normal equation relate to machine learning for regression?\"\\n]',\n",
       " '81b8e8d0': '[\\n    \"What is a good resource for learning about missing data treatment in regression analysis?\",\\n    \"Can you recommend a guide for handling missing values using Python?\",\\n    \"Where can I find information on dealing with missing data in machine learning?\",\\n    \"Is there a Kaggle notebook that discusses strategies for missing data treatment?\",\\n    \"Who is the author of the resource for handling missing values in Python?\"\\n]',\n",
       " 'a7f6a33c': '[\\n    \"What specific instruction is given for log transformation related to the median_house_value variable before Q3 in the Week-2 homework?\",\\n    \"Why was the log transformation instruction not included in the questions following Q3 in the Week-2 homework?\",\\n    \"What issue did I encounter while working on Q5, and how does it relate to the application of log transformation?\",\\n    \"Can you clarify the importance of applying log transformation to the target variable throughout the homework?\",\\n    \"Is there a specific section in the homework where I can find the guidance on log transformation for the Week-2 cohort?\"\\n]',\n",
       " '129b4ac0': '[\"What is the specific sklearn version used by Alexey in his instructional videos?\", \"Which version of Python does Alexey utilize in his YouTube videos?\", \"Can you tell me the exact versions of sklearn and Python that Alexey references?\", \"Is the version of sklearn mentioned in the videos the latest one?\", \"What Python version accompanies the sklearn version in the videos?\"]',\n",
       " 'b8cca8b7': '[\\n    \"Where can I find the homework for Week 3 of the classification section?\",\\n    \"What is the link to submit my homework for Week 3?\",\\n    \"Is there a place where I can access all the homework assignments for this course?\",\\n    \"Where can I view the evaluation matrix for the assignments?\",\\n    \"What GitHub repository contains the theoretical materials for this part of the course?\"\\n]',\n",
       " '1091b10f': '[\\n    \"What does the error message regarding converting \\'Nissan\\' to float indicate about data types in machine learning?\",\\n    \"How can I address the issue of string values when my model expects numerical inputs?\",\\n    \"What is one-hot encoding, and how does it help in converting categorical variables to numerical values?\",\\n    \"Can you provide an example of how to implement one-hot encoding for a specific column in a pandas DataFrame?\",\\n    \"What will happen to the original column of car brands after applying the one-hot encoding method?\"\\n]',\n",
       " '0c7715a1': '[\\n  \"What is the reason for converting the median_house_value target to a binary format in our homework assignment?\",\\n  \"How does mutual information score determine the relationship between different variable types?\",\\n  \"What issues arise if we keep the median_house_value in its original continuous format for calculating mutual information score?\",\\n  \"Why can\\'t we use continuous variables directly in mutual information score calculations?\",\\n  \"What would happen if the algorithm attempted to bin continuous variables during mutual information score computation?\"\\n]',\n",
       " 'd2043cf5': '[\\n    \"Can you clarify which dataset we are using to create the correlation matrix for the assignment?\",\\n    \"Is it correct to use df_train exclusively for the correlation analysis instead of df_train_full?\",\\n    \"Why is it important to avoid using the validation dataset when working on the current task?\",\\n    \"What is the significance of converting median_house_value from numeric to binary in our analysis?\",\\n    \"Could you explain the implications of making conclusions based on validation data at this stage?\"\\n]',\n",
       " '44d22817': '[\\n    \"How can I color the background of a correlation matrix in a pandas DataFrame?\",\\n    \"What method do I use to apply a background gradient based on numerical values in a DataFrame?\",\\n    \"Can the background color of any DataFrame be customized, or is it just for the correlation matrix?\",\\n    \"What is an example of a color map that can be used with the background gradient method?\",\\n    \"Is it necessary to filter the DataFrame for only numerical values before calculating the correlation?\"\\n]',\n",
       " '1f76dbeb': '[\\n    \"How can I identify highly correlated feature pairs in my dataset?\",\\n    \"What code snippet can I use to create a heatmap of correlations using seaborn?\",\\n    \"Is there a way to plot only a triangle in a heatmap to avoid redundancy?\",\\n    \"Can you provide an example output from the correlation function using the churn dataset?\",\\n    \"What options do I have for refining the appearance of my heatmap?\"\\n]',\n",
       " 'b8071a54': '[\\n    \"What dataset should I primarily use for exploratory data analysis in machine learning?\",\\n    \"Is it acceptable to include the validation dataset when performing exploratory data analysis?\",\\n    \"Why is it important to avoid using the test dataset during exploratory data analysis?\",\\n    \"How should I treat the test dataset while analyzing my data for classification?\",\\n    \"Can you explain the reasoning behind focusing on the train dataset for EDA?\"\\n]',\n",
       " 'b8da9037': '[\\n    \"What is the purpose of using a validation dataset in machine learning models?\",\\n    \"How does the fit method in DictVectorizer determine how to process the input data?\",\\n    \"Why is it not advisable to fit the validation model after fitting the training model?\",\\n    \"What should be done with the training set when using DictVectorizer to avoid overwriting learned data?\",\\n    \"Can you explain the difference between fitting and transforming the training set versus the validation and test sets?\"\\n]',\n",
       " '467e0cec': '[\\n  \"For homework Q5, should the difference in accuracy be calculated in real or absolute values?\",\\n  \"What does it mean when a difference in accuracy is negative in the context of feature elimination?\",\\n  \"When determining the smallest difference in accuracy, should we focus on real values or absolute ones?\",\\n  \"In Q5, is it correct to say that a smaller negative difference indicates an improvement in the model?\",\\n  \"What criteria should we use to decide if we are looking for the smallest or lowest difference in accuracy?\"\\n]',\n",
       " 'b69f32f6': '[\\n    \"What does the FutureWarning regarding get_feature_names indicate?\",\\n    \"How can I resolve the FutureWarning related to get_feature_names in our course materials?\",\\n    \"Will I experience any consequences from the deprecation warning concerning get_feature_names?\",\\n    \"What method should I use instead of get_feature_names according to the FAQ?\",\\n    \"Is it necessary to address the warning about get_feature_names in our current projects?\"\\n]',\n",
       " '3b3b1989': '[\"What should I do if my Jupyter kernel crashes while using logistic regression?\", \"Why does fitting logistic regression take so long?\", \"What happens when I call predict() after fitting my logistic regression model?\", \"Is there a specific type of target variable needed for logistic regression?\", \"Who provided the information regarding logistic regression and kernel issues?\"]',\n",
       " 'eb5771a0': '[\\n    \"What is the purpose of using Ridge regression in predictive modeling?\",\\n    \"Can you explain what the sag solver stands for and its benefits for large datasets?\",\\n    \"How does the alpha parameter influence the regularization strength in Ridge regression?\",\\n    \"What is the relationship between coefficient values and overfitting in Ridge regression?\",\\n    \"How should I implement Ridge regression using sklearn with specific parameters like alpha and solver?\"\\n]',\n",
       " 'bca10281': '[\\n  \"What is the difference in the output format between DictVectorizer(sparse=True) and DictVectorizer(sparse=False)?\",\\n  \"Why might using pandas.get_dummies() be less efficient compared to DictVectorizer(sparse=True) for a large number of classes?\",\\n  \"How does the use of sparse representation affect memory efficiency during model fitting?\",\\n  \"What kind of performance issues may arise when using sparse format with a high number of classes?\",\\n  \"Can you explain the convergence problems that occur with Logistic and Linear/Ridge Regression when using a standard one-hot encoding?\"\\n]',\n",
       " '34a8edb0': '[\\n    \"What should I do if I encounter a ConvergenceWarning related to max_iter when using the sag solver with Ridge?\",\\n    \"How can I ensure that my features are properly scaled when working with the Ridge model in W3Q6?\",\\n    \"Which scalers or encoders are recommended for the numeric and categorical features in this course?\",\\n    \"Is it necessary to separately handle numeric and categorical features before applying the encoder?\",\\n    \"Where can I find guidance on scaling features effectively while working on machine learning classification?\"\\n]',\n",
       " 'f625307b': '[\\n  \"What should I do if I experience convergence errors while training a Ridge regression model in Week 3?\",\\n  \"How can I ensure my numerical features are properly prepared to prevent convergence issues during model training?\",\\n  \"What techniques can be used to convert categorical features into a numerical format for Ridge regression?\",\\n  \"What is the process for creating a single feature matrix after normalizing numerical and encoding categorical features?\",\\n  \"Why is it important to use an appropriate method like OneHotEncoder for categorical features when training a Ridge model?\"\\n]',\n",
       " '7fa98526': '[\"What are the main advantages of using a sparse matrix over a dense matrix in machine learning?\", \"How does a sparse matrix handle non-zero values and their positions in memory?\", \"Can you explain why sparse matrices are beneficial for large datasets with many missing values?\", \"What is the default configuration of DictVectorizer when working with matrices?\", \"Why was using a sparse matrix preferred for week3 Q6 in terms of model training performance?\"]',\n",
       " '0807f0f3': '[\"What is the method to turn off warnings in Jupyter notebooks?\", \"Can you explain how to ignore warnings when using Jupyter notebooks?\", \"What comments should I include to suppress warnings in my Jupyter notebook?\", \"Is there a way to avoid seeing warnings while working in Jupyter notebooks?\", \"What steps need to be taken to disable warnings in a Jupyter notebook environment?\"]',\n",
       " '6d0fb418': '[\"How should I approach the issue of selecting the optimal alpha parameter for Q6 in the course materials?\", \"What is the process for determining the best RMSE when multiple alpha values yield the same score?\", \"Can you explain the reasoning behind choosing the lowest alpha when RMSE scores are equal?\", \"In our week two homework discussion, why did some of us end up with incorrect RMSE scores?\", \"Is there a specific method recommended for calculating RMSE across different alpha values?\"]',\n",
       " 'fbda1f40': '[\\n    \"What is the procedure to compute the mutual information score for HW3 Q3?\",\\n    \"Which training set should I use to calculate the mutual information score?\",\\n    \"How do I binarize the price variable for the analysis?\",\\n    \"What is the categorical variable involved in the mutual information calculation?\",\\n    \"Can you clarify the relationship between the binarized price and the ocean proximity variable?\"\\n]',\n",
       " '0f88b7ac': '[\\n    \"Do we have to only use the specified features total_rooms, total_bedrooms, population, and households for homework Q5, or should we include all features and then remove them one at a time for comparison?\",\\n    \"What is the procedure to evaluate the model\\'s accuracy when working with the features in homework Q5?\",\\n    \"When we remove a feature to compare accuracy, should we focus on the smallest difference or the smallest absolute difference in accuracy scores?\",\\n    \"How do we define the original accuracy score in the context of homework Q5 before removing any features?\",\\n    \"Is the goal to find out which feature has the least effect on model accuracy by looking at the absolute differences in accuracy scores?\"\\n]',\n",
       " '9ffcc895': '[\\n    \"Can you explain how OneHotEncoder and DictVectorizer function to convert categorical features into numerical variables?\",\\n    \"What is the primary input format distinction between OneHotEncoder and DictVectorizer?\",\\n    \"Do OneHotEncoder and DictVectorizer yield similar outcomes in terms of feature representation?\",\\n    \"How does the sorting of features differ when using OneHotEncoder compared to DictVectorizer?\",\\n    \"In what scenarios might I prefer using DictVectorizer over OneHotEncoder for feature transformation?\"\\n]',\n",
       " '94a3b2fb': '[\\n    \"Can you explain the main differences between pandas get_dummies and sklearn OneHotEncoder?\",\\n    \"In what scenarios is it more appropriate to use get_dummies rather than OneHotEncoder?\",\\n    \"How do the input and output types differ between pandas get_dummies and sklearn OneHotEncoder?\",\\n    \"What advantages does OneHotEncoder offer for a scikit-learn machine learning pipeline?\",\\n    \"Are the results from using get_dummies and OneHotEncoder exactly the same for one-hot encoding categorical variables?\"\\n]',\n",
       " 'fb9a45d8': '[\\n    \"In the third week\\'s homework, should we consistently use 42 as the random_state for both the train and test splits?\",\\n    \"Is it required to apply the random seed of 42 to both splits while completing the test_train_split task in HW3?\",\\n    \"For the assignment pertaining to test_train_split, do we need to set random_state = 42 for the first split only or for both splits?\",\\n    \"When completing the week 3 homework, is it necessary to use the same random_state value of 42 for both training and testing datasets?\",\\n    \"In the context of HW3, should we apply the random seed of 42 to the first split and the second split for the test_train_split section?\"\\n]',\n",
       " 'e31051f7': '[\"Should I calculate correlation for my data before I split it?\", \"When is the right time to compute correlation in my workflow?\", \"How can I identify the most correlated features in my dataset?\", \"What process should I follow to find the two features with the highest correlation?\", \"Is it necessary to use the correlation matrix of the training dataset after data splitting?\"]',\n",
       " '493b7b59': '[\"What types of features should I use in a ridge regression model to ensure it functions correctly?\", \"Is it possible to include categorical features in my ridge regression model, and if so, how?\", \"What steps should I follow to prepare categorical features for a ridge regression model?\", \"Why is it important to drop categorical features before training a ridge regression model?\", \"What setting should I use to avoid convergence errors when transforming categorical features?\"]',\n",
       " '4a55c510': '[\\n  \"What features should I include for Homework 3 Question 6?\",\\n  \"Which variable should I use as the target in my analysis?\",\\n  \"Is it necessary to incorporate the average variable we previously created?\",\\n  \"If I utilize DictVectorizer, what setting should I ensure is enabled?\",\\n  \"Can I run my analysis without using StandardScaler for numerical variables?\"\\n]',\n",
       " '3ca0b489': '[\"What methods can I use to convert non-numeric data into numeric format for my model?\", \"Are there specific encoders recommended for transforming categorical variables?\", \"How can I preprocess my dataset to make it suitable for machine learning algorithms?\", \"Which libraries provide tools for encoding and scaling features in my dataset?\", \"What is the significance of using encoders like OneHotEncoder and OrdinalEncoder in classification tasks?\"]',\n",
       " '690d97f1': '[\\n    \"Can you explain the main difference between FeatureHasher and DictVectorizer in terms of memory usage?\",\\n    \"In what scenarios should I prefer using FeatureHasher over DictVectorizer for categorical features?\",\\n    \"How does the cardinality of categorical features influence the choice between FeatureHasher and DictVectorizer?\",\\n    \"What should I consider if I want to preserve feature names when transforming data for machine learning?\",\\n    \"Where can I find additional resources on the topic of FeatureHasher and DictVectorizer?\"\\n]',\n",
       " 'eb5a25cb': '[\"Why is it important to avoid data leakage when working with the test set in machine learning?\", \"What does the scikit-learn documentation recommend regarding data splitting and preprocessing?\", \"Can you explain the implications of using DictVectorizer before splitting the dataset?\", \"How does preprocessing before data splitting affect the validity of the training results?\", \"What common practices should be followed to prevent data leakage in machine learning workflows?\"]',\n",
       " '6d9e0a6f': '[\\n    \"What should I do if my model\\'s accuracy is 1.0?\",\\n    \"How can I address the problem of overfitting in my model?\",\\n    \"Is it advisable to choose the closest option when accuracy is at its maximum?\",\\n    \"Could dropping the column msrp/price improve my model\\'s performance?\",\\n    \"What does it mean if my machine learning model is overfitted?\"\\n]',\n",
       " '618ad97a': '[\\n    \"What are the necessary packages for computing Root Mean Squared Error in this course?\",\\n    \"Can you provide an example of how to implement the RMSE calculation using Python code?\",\\n    \"What function should I use to calculate the mean squared error when working with RMSE?\",\\n    \"Is there a resource where I can find additional information or examples related to RMSE calculation?\",\\n    \"How do I implement the RMSE function that subtracts predicted values from actual values?\"\\n]',\n",
       " '683495d2': '[\\n    \"What should I do if I encounter an AttributeError related to the DictVectorizer object?\",\\n    \"How can I resolve the issue with the get_feature_names function in DictVectorizer?\",\\n    \"Is there an alternative method to get feature names from the DictVectorizer?\",\\n    \"Where can I find more information about the DictVectorizer and its methods?\",\\n    \"What is the correct method to use instead of get_feature_names in DictVectorizer?\"\\n]',\n",
       " 'dc1897b5': '[\\n    \"How can I calculate the Root Mean Squared Error using sklearn without using math or numpy?\",\\n    \"What is the purpose of the squared kwarg in the mean_squared_error function from sklearn.metrics?\",\\n    \"Can you explain how to set the squared parameter to obtain RMSE using sklearn?\",\\n    \"Is there a library function available for calculating RMSE in Python with sklearn?\",\\n    \"Where can I find more details about calculating RMSE using sklearn.metrics?\"\\n]',\n",
       " '826098f2': '[\"What are the different encoding techniques for categorical variables that I should know about?\", \"Where can I find more information regarding encoding techniques for my classification assignment?\", \"Could you provide a resource that explains categorical variable encoding in detail?\", \"Who is the author of the article that discusses encoding techniques?\", \"Is there a specific article that covers all about categorical variable encoding?\"]',\n",
       " '821dfc08': '[\"What is the cause of the TypeError when using accuracy_score from sklearn in Jupyter?\",\"How did you resolve the issue with accuracy_score returning a TypeError?\",\"What does the code \\'accuracy_score(y_val, y_pred >= 0.5)\\' represent?\",\"Can you explain the correct import statement to use for metrics in sklearn?\",\"In which context did you experience the error with accuracy_score in your code?\"]',\n",
       " '27c8d5da': '[\\n    \"What resources do I need to start working on the homework for Week 4?\",\\n    \"Where can I find the complete list of homeworks for this course?\",\\n    \"Is there a spreadsheet available that outlines the evaluation metrics?\",\\n    \"Can you please share the GitHub repository containing the theoretical material for this week?\",\\n    \"How can I access the YouTube video related to Week 4 of the course?\"\\n]',\n",
       " 'a52d4739': '[\"How can I utilize a variable to score in classification metrics?\", \"Where can I find the discussion about scoring with a variable?\", \"Can metrics be applied solely to dataframes in this course?\", \"What are the options for applying metrics in relation to data types?\", \"Who provided the information regarding the use of variables for scoring?\"]',\n",
       " 'dc55359c': '[\\n    \"What is the purpose of using random_state in our evaluations?\",\\n    \"Why is random_state necessary for reproducibility when shuffling datasets?\",\\n    \"In which scenarios should we consider setting both random_state and the shuffle parameters?\",\\n    \"How does the use of random_state differ between module-04 homework questions?\",\\n    \"Can you explain the significance of the sklearn documentation regarding random_state?\"\\n]',\n",
       " '2ab49e43': '[\"What is the method to obtain all relevant classification metrics at once?\", \"Can I calculate precision, recall, f1 score, and accuracy together?\", \"Which function from sklearn should I use to get the classification metrics?\", \"Is there additional information available on obtaining classification metrics?\", \"Who provided the information regarding the evaluation metrics for classification?\"]',\n",
       " 'b431e7eb': '[\\n    \"If I receive multiple thresholds yielding the same F1 score in my results, should I be concerned about my approach or is there a recommended strategy for selecting one?\",\\n    \"Is it advisable to always select the lowest threshold when faced with several options that have identical F1 scores, or is there a better method?\",\\n    \"What tools or libraries can I utilize to confirm the findings from my own code in relation to evaluation metrics like precision, recall, and F1-score?\",\\n    \"Can you explain how the \\'classification_report\\' function from scikit-learn can assist in validating my evaluation metrics?\",\\n    \"Are there any particular metrics or considerations I should keep in mind when dealing with multiple thresholds that produce the same evaluation results?\"\\n]',\n",
       " 'c5fdeba9': '[\\n    \"What does the error message about needing samples of at least 2 classes mean in the context of this course?\",\\n    \"How can I resolve the issue of having only 0\\'s in my churn column while running my classification model?\",\\n    \"Can you clarify what results I should expect if I delete one of the cells mentioned in the solution?\",\\n    \"What does it indicate if the churn column only contains one class, like all 0\\'s, when I\\'m trying to run my analysis?\",\\n    \"Why is it important to have at least 2 classes in the data for running a classification model effectively?\"\\n]',\n",
       " 'b8c9eaf1': '[\\n  \"What is the recommended library for generating attractive classification reports?\",\\n  \"How does Yellowbrick enhance the functionality of scikit-learn?\",\\n  \"Can you explain the purpose of Yellowbrick in relation to visualization?\",\\n  \"What types of visualizations can Yellowbrick produce for model reports?\",\\n  \"Who is associated with the development or mention of Yellowbrick in this context?\"\\n]',\n",
       " 'c54058a1': '[\"Why am I not achieving the precise results for my homework assignments?\", \"What should I do if my answers don\\'t match the exact results?\", \"Is it acceptable to choose an answer that is not exact for my homework?\", \"How should I handle discrepancies in my homework results?\", \"What is the policy regarding close answers for homework evaluations?\"]',\n",
       " 'b4b85c4b': '[\"How can I assess the significance of numerical features using AUC?\", \"Where can I find examples related to AUC from previous course iterations?\", \"Which score should I apply to evaluate ROC metrics?\", \"Is it necessary to refer to prior course materials for feature importance?\", \"What is the recommended method for using AUC in feature evaluation?\"]',\n",
       " '7d40f6f6': '[\"Can you explain how to use numerical values as scores in the ROC AUC score calculation?\", \"What are the parameters required by the sklearn.metrics.roc_auc_score function?\", \"How should I pass the target variable when using the roc_auc_score function?\", \"Is the dataframe needed for calculating the ROC AUC score?\", \"What do the parameters \\'y_true\\' and \\'y_score\\' represent in the context of ROC AUC?\"]',\n",
       " 'f5dc446c': '[\\n    \"Which dataset is necessary for calculating the metrics in Question 3?\",\\n    \"What dataset should I refer to for the metrics mentioned in Question 3?\",\\n    \"Is there a specific dataset required to compute the metrics from Question 3?\",\\n    \"For the calculations in Question 3, which dataset needs to be utilized?\",\\n    \"Do I need to use the same dataset as in Question 2 for Question 3 metrics?\"\\n]',\n",
       " 'd30fc29d': '[\\n    \"Can you explain how KFold works and what it means when we set n_splits?\",\\n    \"What impact does changing the random_state have on the results of KFold?\",\\n    \"Is there a specific reason to define KFold outside of the loop when processing multiple values of C?\",\\n    \"Does KFold create separate training and validation datasets on its own, or is that done in a subsequent step?\",\\n    \"Why might it be more efficient to define KFold before the loop rather than inside it?\"\\n]',\n",
       " '8eca9f73': '[\\n    \"What does the error message \\'ValueError: multi_class must be in (\\'ovo\\', \\'ovr\\')\\' indicate when using roc_auc_score?\",\\n    \"What parameters should I use to avoid the ValueError when evaluating feature importance?\",\\n    \"How can I correctly call the roc_auc_score function with my training data?\",\\n    \"What caused the ValueError I encountered when evaluating numerical variables in question 1?\",\\n    \"Is there a specific order or structure I should follow when passing parameters to roc_auc_score?\"\\n]',\n",
       " '7b9eb7f7': '[\\n    \"What can I use to monitor the execution progress of my code?\",\\n    \"Which library provides a terminal progress bar for tracking wait times?\",\\n    \"How can I visualize the progress of my code execution?\",\\n    \"What is the command to import the tqdm progress bar?\",\\n    \"Who provided the information about monitoring wait times in this section?\"\\n]',\n",
       " 'c4aaeed9': '[\\n    \"Why is it important to invert variables with ROC AUC scores below the threshold?\",\\n    \"How does negating negatively correlated features contribute to model performance?\",\\n    \"What benefits does inverting features provide in terms of feature importance?\",\\n    \"In what scenarios should I consider inverting variables less than the threshold?\",\\n    \"How does the direction of correlation affect the use of machine learning algorithms?\"\\n]',\n",
       " '3af31e2a': '[\\n    \"What is the main difference between using predict(X) and predict_proba(X) in classification tasks?\",\\n    \"Why might the output from predict(X) lead to incorrect evaluation values?\",\\n    \"How does predict_proba(X) provide a solution to relying solely on predict(X)?\",\\n    \"What type of predictions do we get when using predict(X) for binary classification?\",\\n    \"What information does predict_proba(X) give us regarding class membership probabilities?\"\\n]',\n",
       " '746342ff': '[\\n    \"What does a threshold of 1.0 imply for the classification of churn predictions?\",\\n    \"Can you explain why both FPR and TPR are zero when the threshold is set at 1.0?\",\\n    \"How does the nature of the sigmoid function affect the prediction outcomes at a threshold of 1.0?\",\\n    \"Why can g(x) never reach values of exactly 0 or 1 in this binary classification model?\",\\n    \"What are the implications of having no predicted positive values when the threshold is at its maximum?\"\\n]',\n",
       " 'bda2c9b3': '[\"What methods does Matplotlib offer for graph annotation?\", \"Can you explain how to use arrows and text in Matplotlib annotations?\", \"What is the purpose of the coordinates in the annotate method?\", \"How do you specify different locations for the text and the arrow in an annotation?\", \"Could you provide an example of annotating with an optimal threshold and F1 score in Matplotlib?\"]',\n",
       " '41521c92': '[\\n    \"Is it necessary to grasp the ROC curve thoroughly before proceeding with the course?\",\\n    \"How important is it to understand the ROC AUC in the context of Binary Classification?\",\\n    \"What should I do if I find the ROC curve challenging to comprehend?\",\\n    \"Can I find supplementary materials to help me better understand the ROC curve?\",\\n    \"What is the significance of the ROC AUC metric in classification models?\"\\n]',\n",
       " '25481ce5': '[\\n    \"What factors could lead to differing accuracy results compared to the homework options?\",\\n    \"Can you explain how the method of data splitting affects accuracy values?\",\\n    \"Which data splitting method is recommended for consistency with the lessons?\",\\n    \"How does randomness in the train/test split impact the evaluation metrics?\",\\n    \"Why might two different data splitting approaches result in non-matching datasets?\"\\n]',\n",
       " '1427d567': '[\\n    \"What are the necessary columns in the dataframe to find the threshold where precision and recall curves intersect?\",\\n    \"How can I determine the index positions of the intercept between precision and recall using numpy?\",\\n    \"What functions from numpy are mentioned for finding the intercept between precision and recall curves?\",\\n    \"Is there a way to print the threshold value where the precision and recall curves intersect?\",\\n    \"What is the purpose of using np.sign in the process of finding the intercept between the two curves?\"\\n]',\n",
       " '76c91dfb': '[\\n    \"How can I compute the Recall metric using the Scikit Learn library?\",\\n    \"What steps should I follow to calculate the Precision score for my classification results?\",\\n    \"Is there a quick way to obtain the F1 Score without having to define true positives and negatives?\",\\n    \"Where can I find the demonstration video that shows how to manually calculate precision and recall?\",\\n    \"What specific functions from sklearn.metrics should I use to calculate these evaluation metrics?\"\\n]',\n",
       " 'e4dd91cf': '[\\n    \"What is the purpose of using cross-validation in model evaluation?\",\\n    \"How does cross-validation help in selecting the optimal hyperparameters?\",\\n    \"Can you explain how the dataset is utilized during cross-validation?\",\\n    \"In the context of SVM and logistic regression, what does the \\'C\\' hyperparameter signify?\",\\n    \"How do smaller and larger values of \\'C\\' affect model performance and classification accuracy?\"\\n]',\n",
       " 'cc53ae94': '[\\n    \"How can I easily compute model evaluation metrics using a library in Python?\",\\n    \"Which specific metrics can be utilized from the scikit learn library for evaluating a classification model?\",\\n    \"What is the advantage of using scikit learn over manually computing metrics with numpy and pandas?\",\\n    \"Can you provide an example of how to calculate accuracy, precision, recall, F1-Score, and ROC AUC?\",\\n    \"Where can I find the necessary functions for model evaluation in the scikit learn package?\"\\n]',\n",
       " '403bbdd8': '[\\n    \"What is an alternative method to calculate Precision, Recall, and F1 score?\",\\n    \"Can I use Scikit-learn for computing Precision, Recall, and F1 score?\",\\n    \"How do I utilize precision_recall_fscore_support in Scikit-learn?\",\\n    \"Is there a way to handle zero division when calculating these metrics?\",\\n    \"Where can I find an example of using precision_recall_fscore_support?\"\\n]',\n",
       " '7c68ace0': '[\\n  \"What situations warrant the use of ROC curves instead of Precision-Recall curves when evaluating classifiers?\",\\n  \"Why might ROC curves present a misleading assessment of a model\\'s performance on imbalanced datasets?\",\\n  \"Can you explain the difference in how ROC curves and Precision-Recall curves handle true negatives?\",\\n  \"How does the class distribution in a test set impact the performance metrics calculated from a confusion matrix?\",\\n  \"In what way do ROC graphs differ in their sensitivity to changes in class distribution compared to other evaluation metrics?\"\\n]',\n",
       " '147577f5': '[\\n    \"What function can I use to assess feature importance for numeric variables using AUC?\",\\n    \"Which argument should I pass first when using roc_auc_score to evaluate features?\",\\n    \"Where can I find the method for calculating AUC in Python\\'s sklearn library?\",\\n    \"What type of data do I need to provide to the roc_auc_score function?\",\\n    \"What will the roc_auc_score function return when evaluating a feature?\"\\n]',\n",
       " 'd3ffb802': '[\\n  \"How does class imbalance affect the F-score in classification tasks?\",\\n  \"What is the relationship between the precision-recall curve and class ratios?\",\\n  \"Why is it problematic to compare F-scores across different classification problems?\",\\n  \"What can be done to improve the comparison of F-scores with varying class ratios?\",\\n  \"Who provided the information regarding the dependence of the F-score on class imbalance?\"\\n]',\n",
       " 'cc04d27a': '[\\n    \"What method can I use to create a Precision-Recall Curve quickly?\",\\n    \"Which library should I import to access the precision_recall_curve function?\",\\n    \"What are the parameters needed to compute the precision and recall for my validation data?\",\\n    \"How do I visualize the Precision and Recall using a plot?\",\\n    \"What should I include in my plot to differentiate between Precision and Recall?\"\\n]',\n",
       " '927b5e09': '[\"What is the purpose of using Stratified k-fold in multiclass classification?\", \"How does Stratified k-fold ensure class balance in data partitioning?\", \"Can you explain how Stratified k-fold works with respect to sample percentages of each class?\", \"Where can I find more information about implementing Stratified k-fold?\", \"Why is it important to maintain class balance in dataset splitting for multiclass tasks?\"]',\n",
       " 'd22efea7': '[\\n    \"What is the link for the homework assignment for Week 5?\",\\n    \"Where can I find the solutions for Homework 3?\",\\n    \"Is there a resource that outlines all the homework assignments for this course?\",\\n    \"Can you provide the link to the evaluation matrix for the machine learning models?\",\\n    \"What is the YouTube link for Week 5\\'s content?\"\\n]',\n",
       " 'd1409f67': '[\"What are the common errors I might face related to my default environment during week 5 of the course?\", \"Is it necessary to set up a cloud environment for homework in week 5?\", \"Can you recommend a specific cloud provider to use for my homework environment setup?\", \"Where can I find a guide for setting up an AWS EC2 instance for this course?\", \"What should I consider regarding costs when using AWS instances for my homework?\"]',\n",
       " 'e07759e9': '[\\n    \"What steps do I need to take to create a Kaggle API token for downloading data?\",\\n    \"Where should I store the kaggle.json file in relation to my Jupyter Notebook?\",\\n    \"How can I modify the permissions of the kaggle.json file using a command in my Jupyter Notebook?\",\\n    \"What should I do after importing the os library in my Jupyter Notebook for setting the KAGGLE_CONFIG_DIR?\",\\n    \"Once I\\'ve downloaded the dataset, what command allows me to extract the CSV file from the zip archive?\"\\n]',\n",
       " '620fb76e': '[\\n    \"What command should I use to navigate back one directory in Ubuntu?\", \\n    \"How can I view the list of current folders in my Ubuntu system?\", \\n    \"What is the command to change to a specific path in Ubuntu?\", \\n    \"How do I find out my home directory in the Ubuntu terminal?\", \\n    \"Which command allows me to edit a text file in Ubuntu?\"\\n]',\n",
       " '957280d8': '[\\n  \"What terminal command can I use to check the Python version currently installed on my laptop?\",\\n  \"How can I download the latest version of Python for installation on a Windows machine?\",\\n  \"What should I make sure to check during the Python installation process?\",\\n  \"What command do I need to run if I want to upgrade to Python 3 using pip?\",\\n  \"Where can I find the official website to download Python versions?\"\\n]',\n",
       " '185096ad': '[\\n  \"What steps do I need to follow to install WSL on my Windows 10 or 11 machine?\",\\n  \"How can I ensure that the \\'Virtual Machine Platform\\' feature is activated on my Windows system?\",\\n  \"After installing a Linux distribution, how do I verify that I have Python installed in my WSL environment?\",\\n  \"What command can I use to set my preferred folder as the default directory when opening the Ubuntu terminal?\",\\n  \"If I encounter an error while installing pipenv, what steps should I take to create a symbolic link for the library?\"\\n]',\n",
       " 'ec88d101': '[\\n    \"What specific error message might I encounter when building a Docker image on a Mac with M1 silicon?\",\\n    \"What should I modify in the Dockerfile to resolve the error related to the missing ld-linux-x86-64.so.2 file?\",\\n    \"How do I change the base image in the Dockerfile for compatibility with Mac M1 chipset?\",\\n    \"What is the expected build time for the Docker image after making the necessary adjustments?\",\\n    \"Where can I find the Dockerfile that needs to be edited for deploying machine learning models?\"\\n]',\n",
       " '7156679d': '[\"What is the procedure to check the version of installed Python libraries in a Jupyter notebook?\", \"Which library needs to be imported to retrieve its version information?\", \"How do I print the version of the Waitress library after importing it?\", \"Is there a specific command to use after importing the library to display its version?\", \"Who should I credit for providing the information on checking library versions?\"]',\n",
       " '4b2a3181': '[\\n    \"What should I do if I encounter an error related to connecting to the Docker daemon when trying to run a test image?\",\\n    \"Could you explain how to resolve the issue of not being able to connect to the Docker daemon on WSL?\",\\n    \"What commands can I use to start the Docker daemon on a Linux system if I experience connection issues?\",\\n    \"Is there a specific process I need to follow to reinstall Docker on WSL if I face connection errors?\",\\n    \"What steps should I take if Docker Desktop is not installed on my host machine and I need to resolve a Docker connection error?\"\\n]',\n",
       " '73bd7fa1': '[\\n    \"What should I do if I encounter a non-zero code error while running the pipenv install command after building the Docker image?\",\\n    \"How can I determine the correct Python version to use in my Dockerfile for model deployment?\",\\n    \"What is the first line I need to change in my Dockerfile to match my system\\'s Python version?\",\\n    \"What command do I run to check my current Python version before modifying my Dockerfile?\",\\n    \"What action should I take in my Dockerfile if my installed Python version differs from the one specified?\"\\n]',\n",
       " 'a4d3b1e5': '[\\n    \"What should I do if running \\'pipenv install sklearn==1.0.2\\' results in errors?\",\\n    \"Why did the facilitator use sklearn version 0.24.1 during the lectures instead of 1.0.2?\",\\n    \"How can I successfully install scikit-learn version 1.0.2 in my virtual environment?\",\\n    \"I need to install scikit-learn version 1.3.1 for my homework. What command should I use?\",\\n    \"What is the full name I should use to install scikit-learn to avoid errors?\"\\n]',\n",
       " '1d462fe0': '[\\n    \"What happens to the docker images if we use the --rm flag when running containers?\",\\n    \"Why is it considered a best practice to avoid abandoning docker images on our system?\",\\n    \"Can you explain the difference between a docker image and a docker container?\",\\n    \"What command can I use to view all the images that I have pulled or built so far in Docker?\",\\n    \"How does the use of --rm benefit our development and testing process with docker containers?\"\\n]',\n",
       " '366d7563': '[\"What is the correct name for the Dockerfile when creating it?\", \"Why does adding an extension to the Dockerfile cause an error?\", \"What happens if I name my Dockerfile \\'Dockerfile.dockerfile\\'?\", \"How should the Dockerfile be formatted to avoid issues during image build?\", \"Can you explain the importance of not having an extension for the Dockerfile?\"]',\n",
       " 'cef156d1': '[\"How can I install Docker on my Mac?\", \"Is there a specific installation guide for MacOS users?\", \"Where can I find instructions for installing Docker on a Mac?\", \"Do I need to know about my Mac\\'s chip type before installing Docker?\", \"What are the system requirements for installing Docker on MacOS?\"]',\n",
       " 'b632d2ea': '[\"What should I do if I encounter an error when using the docker pull command for an image?\", \"Why am I getting a \\'manifest unknown\\' error when trying to pull the docker image?\", \"What is the reason for the \\'default tag: latest\\' message when I attempt to pull the docker image?\", \"Can you explain how to specify the correct tag when pulling a docker image?\", \"What is the correct command to pull the svizor/zoomcamp-model image with the proper tag?\"]',\n",
       " '514e27bb': '[\"How can I retrieve the size of a specific Docker image instead of all images?\", \"Is there a command to show only the size information for a given Docker image?\", \"What are the commands to list all local Docker images in Docker?\", \"Can I use formatting options to simplify the output for a specific image?\", \"What is the alternative command to dump information for a specified image in Docker?\"]',\n",
       " '5c67e086': '[\\n    \"What is the directory where pipenv creates environments on OSX/Linux systems?\",\\n    \"How can I find the name of the environment created by pipenv?\",\\n    \"What is the path format for a pipenv environment on Windows?\",\\n    \"If I run a pipenv command in a specific project folder, how will this affect the environment name?\",\\n    \"What do I need to do to activate the environment created by pipenv after it has been set up?\"\\n]',\n",
       " '63a81b57': '[\"What command should I use to start a Docker container in interactive mode with bash?\", \"How can I find the container ID of a running Docker container?\", \"What is the purpose of overriding the entrypoint in a Docker container?\", \"If my Docker container is running, how can I execute a bash command inside it?\", \"Who provided the information on debugging Docker containers?\"]',\n",
       " '047f57fb': '[\\n    \"What command should I use to run Docker in interactive mode without encountering the input device not being a TTY error?\",\\n    \"How can I resolve the issue with the input device not being a TTY when using Mintty for Docker?\",\\n    \"What is the purpose of the \\'winpty\\' prefix when executing Docker commands in Git Bash?\",\\n    \"Can you explain what a TTY is and why it is relevant when running Docker commands?\",\\n    \"Where can I find more information about terminal, shell, and console applications?\"\\n]',\n",
       " '11f7371c': '[\\n    \"What does the error message \\'failed to compute cache key: \\\\\"/model2.bin\\\\\" not found\\' indicate when deploying models?\",\\n    \"In what situation did you encounter the error related to model2.bin while using Docker?\",\\n    \"What was your initial assumption regarding the existence of model2.bin when you faced the error?\",\\n    \"What temporary solution did you find to resolve the issue with loading model2.bin?\",\\n    \"How does using \\'COPY [\\\\\"*\\\\\", \\\\\"./\\\\\"]\\' differ from specifically copying model2.bin and dv.bin?\"\\n]',\n",
       " '45f39b76': '[\"How can I resolve the issue of not being able to write dependencies to the pipfile and piplock file?\", \"What command should I use to create a virtual environment for deploying my machine learning models?\", \"Is there a way to write the required packages to a text file easily?\", \"What command will I need to run after creating a virtual environment to manage my project dependencies?\", \"Can you clarify the steps necessary to handle dependency management in my project?\"]',\n",
       " '94e17563': '[\\n    \"What could be the reason for the error I receive after importing pickle when using f-strings?\",\\n    \"How should I correctly format my f-string to avoid errors related to variable C?\",\\n    \"What is the correct syntax for the pickle.dump function when saving a model?\",\\n    \"Why did I encounter an error when my f-string used parentheses instead of curly braces?\",\\n    \"What should I remember about parentheses when using pickle to avoid syntax errors?\"\\n]',\n",
       " '9dd8efd2': '[\\n    \"What does it mean if I see an error stating that \\'pipenv\\' is not recognized when I try to use it?\",\\n    \"Why might I encounter an error indicating that pipenv cannot be accessed from my path?\",\\n    \"What steps should I follow to resolve the issue of pipenv not being recognized on my Windows system?\",\\n    \"Is the solution to my pipenv issue different if I am using Anaconda instead of a standard installation?\",\\n    \"What path locations need to be checked or added to fix the \\'pipenv\\' command error on my computer?\"\\n]',\n",
       " '9531dc92': '[\\n  \"What is the error message related to the collections module that I might encounter during deployment?\",\\n  \"According to the video in week 5.6, what should I ensure about my Python version to avoid installation issues?\",\\n  \"What Python version was recommended in the very first lesson of the zoomcamp to prevent the AttributeError?\",\\n  \"What should I use instead of python==3.10 to resolve the installation error when using pipenv?\",\\n  \"Who contributed the solution regarding the Python version for the deployment error?\"\\n]',\n",
       " '14e0e697': '[\\n    \"What should I do after I enter the command \\'pipenv shell\\' to avoid errors when trying to install packages?\",\\n    \"How can I check if I am currently in the pipenv shell on a Windows system?\",\\n    \"What terminal command can I use to fix the PATH issue related to a missing VIRTUAL_ENV on Windows?\",\\n    \"Is there a way to manually restore a removed virtual environment folder if it is missing?\",\\n    \"What specific location should I check to find the removed environment name causing the ValueError?\"\\n]',\n",
       " '6189375f': '[\"What should I do if I encounter a ConnectionError when deploying my model?\", \"How can I resolve a RemoteDisconnected error during deployment?\", \"What host setting is recommended for the Flask app when using Docker?\", \"Is it necessary to run the URL on localhost after making changes to the Flask app?\", \"Who provided the solution for the deployment connection issue?\"]',\n",
       " '3419ee27': '[\\n  \"What is the reason for the docker build error related to COPY?\",\\n  \"How can I fix the docker build error when using single quotes?\",\\n  \"What type of quotes should I use around filenames to avoid the error?\",\\n  \"Are there specific tips for resolving docker COPY errors during model deployment?\",\\n  \"What common mistakes should I avoid when deploying machine learning models with Docker?\"\\n]',\n",
       " '8b8c1603': '[\"What should I do if I encounter an error while installing the Pipfile in my Docker container?\", \"Is there a specific command I can use to update the Pipfile.lock when using Pipenv?\", \"What alternative method can I try if updating the Pipfile.lock doesn\\'t solve the installation issue?\", \"Can you provide a recommended command to use for Pipenv installation within a Docker container?\", \"How can I bypass the Pipfile when deploying with Pipenv in a Docker setup?\"]',\n",
       " 'e54d5411': '[\\n  \"What should I do if I encounter an error after executing the Docker run command?\",\\n  \"Why was there an issue when trying to remove the orphan container?\",\\n  \"What specific commands need to be run to list Docker containers and images?\",\\n  \"How can I stop and remove a Docker container that is causing issues?\",\\n  \"What steps did the individual take to successfully rebuild and run the Docker image?\"\\n]',\n",
       " 'f7b38587': '[\\n    \"What does the error message \\'Bind for 0.0.0.0:9696 failed: port is already allocated\\' indicate when deploying a model?\",\\n    \"Why did I encounter the \\'port is already allocated\\' error after rebuilding my Docker image if the port seemed available?\",\\n    \"How can I resolve the issue of Docker failing to allocate the specified port during the deployment of a machine learning model?\",\\n    \"What command can I execute to potentially fix the error related to port allocation in Docker?\",\\n    \"Where can I find more information if I continue to experience port allocation issues with Docker?\"\\n]',\n",
       " 'be86b333': '[\\n    \"What error might I encounter when binding to 127.0.0.1:5000?\",\\n    \"What kind of error is thrown on the client side in case of a connection issue?\",\\n    \"How does the gunicorn server respond when there is a binding problem?\",\\n    \"What works well on the server side when gunicorn shows an error?\",\\n    \"What IP addresses should I use to avoid binding errors in most cases?\"\\n]',\n",
       " '4ea80460': '[\"How can I install md5sum on my MacOS system?\", \"What command should I use to verify the hash of a file?\", \"Is there a specific package manager required to install md5sum on MacOS?\", \"What command do I run to compare the hash values of two files?\", \"Who provided the information about installing md5sum?\"]',\n",
       " '8006b496': '[\"What steps should I follow to run a script while my web server is active?\", \"In what environment can I initiate a web server for my project?\", \"Is it possible to execute another Python script while the server is running?\", \"Do I need to open a new terminal to run a script that communicates with the server?\", \"Who can I contact for further questions about deploying machine learning models?\"]',\n",
       " '704f95d8': '[\\n    \"What warning do I receive when running pipenv shell and gunicorn in video 5.5?\",\\n    \"What might happen if I try to unpickle the DictVectorizer using different versions?\",\\n    \"What version of Scikit-Learn should I use for creating a virtual environment?\",\\n    \"Why is it important to match the version of Scikit-Learn with the version used for training?\",\\n    \"What should I do to avoid version conflicts in my model and DV files during deployment?\"\\n]',\n",
       " 'a5b3296b': '[\\n    \"What should I do if I encounter a ValidationError related to python_version and python_full_version after running pipenv install?\",\\n    \"How can I resolve the error that states \\'python_full_version must not be present with python_version\\' during package installation?\",\\n    \"What steps do I need to follow to fix issues related to conflicting Python version specifications in my Pipfile?\",\\n    \"After making changes to the Pipfile regarding python_version and python_full_version, what command should I run next?\",\\n    \"If I successfully edit my Pipfile to correct the Python version error, what should I do to resume my work?\"\\n]',\n",
       " 'a23b276a': '[\\n  \"What should I do if I encounter an error indicating that my Pipfile.lock is out of date during the Docker build process?\",\\n  \"Can you provide a solution for updating my Pipfile.lock file when it\\'s not in sync?\",\\n  \"What commands do I need to run to remove my pipenv environment and start fresh if the docker build command still fails?\",\\n  \"If my Pipfile.lock is out of date, is there a way to quickly rebuild it before attempting to build my Docker image again?\",\\n  \"What specific steps should I take to resolve the error message that mentions an expected but out-of-date Pipfile.lock during deployment?\"\\n]',\n",
       " '3537eeee': '[\\n    \"What should I do if the mlflow server stops running after using waitress in my Windows conda environment?\",\\n    \"Is it necessary to uninstall waitress if I encounter issues with the mlflow server?\",\\n    \"After uninstalling waitress, what do I need to reinstall to fix the mlflow server issue?\",\\n    \"If I\\'ve already built my docker image, do I need to reinstall waitress after fixing mlflow?\",\\n    \"What are the steps to ensure that my mlflow server runs successfully after encountering issues?\"\\n]',\n",
       " '1d6d5b51': '[\"What should I check if I can\\'t find my created environment on AWS?\", \"Is there a specific AWS region I need to be in for my environment?\", \"What do I do if I\\'m in a different region than eu-west-1?\", \"How can I verify the location of my environment in the console?\", \"Why is my environment not visible outside of the eu-west-1 region?\"]',\n",
       " '3a98b6b7': '[\\n    \"What should I do if the \\'waitress-serve\\' command is not found in GitBash after installation?\",\\n    \"How can I properly install waitress on Windows when using GitBash?\",\\n    \"What steps should I take to ensure the \\'waitress-serve.exe\\' file is downloaded successfully?\",\\n    \"What warning might I encounter when installing waitress through a Jupyter notebook?\",\\n    \"How do I add the directory of \\'waitress-serve.exe\\' to my GitBash PATH?\"\\n]',\n",
       " 'd42eb923': '[\\n    \"What does the warning about the environment variable LANG indicate when deploying machine learning models?\",\\n    \"Is the warning regarding the LANG variable critical, or can I ignore it while working in the conda environment?\",\\n    \"What specific version of Scikit-Learn should I install using Pipenv for this course?\",\\n    \"Where can I find a quick solution for the LANG variable warning that appears during model deployment?\",\\n    \"Can I continue with my work in the ml-zoomcamp conda environment despite the LANG variable warning?\"\\n]',\n",
       " '42aebe10': '[\\n    \"What resources are included in the image for question 6 of the homework?\",\\n    \"Which specific files should I utilize for the model and dictvectorizer in this task?\",\\n    \"Can you clarify the source of the image mentioned in the homework?\",\\n    \"Who provided the information regarding the files needed for this assignment?\",\\n    \"What version of the image should I refer to for question 6?\"\\n]',\n",
       " 'e4f62713': '[\\n    \"What terminal software is shown in the videos for Week 5?\",\\n    \"Can you provide a link to the terminal used in the Week 5 instructional content?\",\\n    \"What tool is recommended for deployment in the Week 5 videos?\",\\n    \"Is there a specific terminal featured in the videos from Week 5 of the course?\",\\n    \"Where can I find the Windows terminal discussed in the Week 5 resources?\"\\n]',\n",
       " 'c13d811f': '[\\n  \"What does the error message \\'Malformed application\\' indicate when using waitress-serve?\",\\n  \"What command triggers the ValueError related to the app import?\",\\n  \"Why doesn\\'t Waitress accept a dash in the filename for the machine learning model?\",\\n  \"What is the suggested method to correct the error when importing the module?\",\\n  \"Can you give an example of how to rename the file to resolve the issue?\"\\n]',\n",
       " 'dfb41f7e': '[\"How can I quickly verify if my HTTP POST requests are functioning properly from the command line?\", \"Is there a specific tool I can use to test HTTP POST requests without additional software?\", \"What operating systems support running curl for checking HTTP POST requests?\", \"Can you give an example of how to use curl with JSON data in a POST request?\", \"What are some alternative methods to send JSON data in HTTP POST requests from the command line?\"]',\n",
       " 'd04e77f8': '[\\n  \"What does the NotSupportedError indicate when trying to run eb local?\",\\n  \"How can I resolve the NotSupportedError when using eb local?\",\\n  \"What command should I use to re-initialize and select the docker platform options?\",\\n  \"What file do I need to edit to change the default platform to Amazon Linux 2023?\",\\n  \"What is the potential downside of directly editing the config.yml file?\"\\n]',\n",
       " '451c067f': '[\"What should I do if I encounter a \\'No connection adapters were found\\' error while trying to make a request to my machine learning model?\", \"Could you explain why requests require a protocol scheme when connecting to a server?\", \"Is it possible to use uppercase letters in the protocol scheme when forming a request URL?\", \"What exactly does the error message indicate about my request to \\'localhost:9696/predict\\'?\", \"How can I ensure that my request URL is correctly formatted for successful connections?\"]',\n",
       " '9fbfcd61': '[\\n    \"What should I check if I\\'m getting the same results while using the docker image?\",\\n    \"How can I ensure that I am using the correct model during my prediction test?\",\\n    \"Is there anything specific about the model and Python version that I need to remember?\",\\n    \"What should I do if I want to change the model in my file?\",\\n    \"Who provided the information related to deploying machine learning models?\"\\n]',\n",
       " '1ed8cfde': '[\\n    \"What steps should I follow to run my Docker image successfully?\",\\n    \"How can I confirm that all necessary modules are installed for my container?\",\\n    \"Is there a specific tool I need to use for module installation in my project?\",\\n    \"What is the importance of using pipenv when working with Docker images?\",\\n    \"Could you explain how to utilize pipenv shell for my Docker setup?\"\\n]',\n",
       " '3f97f50f': '[\\n    \"What command should I use to transfer files from my local machine to a Docker container?\",\\n    \"Can you explain the syntax for copying files into a running Docker container?\",\\n    \"Is there a specific command like \\'docker cp\\' to move directories as well as files to a container?\",\\n    \"What is the proper format for specifying the container ID when using the docker cp command?\",\\n    \"Are there any restrictions or specifics I should be aware of when using the docker cp command?\"\\n]',\n",
       " 'a24a874a': '[\\n  \"What command should I use to transfer files from my local machine to a Docker container?\",\\n  \"How can I specify the source folder when copying files into a Docker container?\",\\n  \"What is the syntax for copying multiple files at once into a Docker container?\",\\n  \"Is there a way to define the destination path when using the Dockerfile for copying files?\",\\n  \"Can I copy specific files into the working directory of a Docker container directly?\"\\n]',\n",
       " 'bf563b1f': '[\\n    \"What command should I use to initialize my AWS Elastic Beanstalk environment for a Docker application?\",\\n    \"What error message might I encounter when running the command \\'eb local run\\' on AWS Elastic Beanstalk?\",\\n    \"Why might I be unable to use the \\'eb local\\' command with the original Docker platform configuration?\",\\n    \"What specific Docker platform configuration worked for successfully recognizing the Dockerfile?\",\\n    \"In which AWS region should I set up my tumor-diagnosis-serving application according to the FAQ?\"\\n]',\n",
       " '21e9facf': '[\"What should I do if I encounter an error regarding missing Dockerfile when creating an AWS ElasticBean environment?\", \"How do I resolve the issue of both \\'Dockerfile\\' and \\'Dockerrun.aws.json\\' being absent during deployment?\", \"What steps did you take after getting the docker error with the eb create command?\", \"Why did the deployment fail when I tried to create the tumor-diagnosis-env?\", \"What files need to be committed before running the eb create command successfully?\"]',\n",
       " 'aef786aa': '[\\n  \"What resources do I need to begin Week 6 assignments?\",\\n  \"Where can I find all the homework assignments for this course?\",\\n  \"Is there a specific GitHub link for the solution of Homework 4?\",\\n  \"How can I access the evaluation matrix for my assignments?\",\\n  \"Where can I find the YouTube link for the Week 6 lecture?\"\\n]',\n",
       " '68858294': '[\\n  \"What method can I use to retrieve training and validation metrics from XGBoost without complex steps?\",\\n  \"Is there a simpler way to obtain the auc values during the XGBoost lesson?\",\\n  \"How can I store the training and validation results for easier visualization while using XGBoost?\",\\n  \"What parameters do I need to utilize in XGBoost for capturing the evaluation results?\",\\n  \"Can you explain the process of using a dataframe for plotting metrics obtained from XGBoost?\"\\n]',\n",
       " '85ac722e': '[\\n  \"What object should I create in scikit-learn to address regression issues using random forest?\",\\n  \"How is the RandomForestRegressor different from the RandomForestClassifier in scikit-learn?\",\\n  \"Where can I find additional details on using RandomForestRegressor for regression tasks?\",\\n  \"Is the approach for solving regression problems with random forest similar to that of classification problems?\",\\n  \"What library do I need to import for using RandomForestRegressor in Python?\"\\n]',\n",
       " 'b61d2e92': '[\\n    \"What specific error did you encounter when creating DMatrix for the train and validation datasets?\",\\n    \"Can you explain why the feature names in DMatrix need to be strings and what special characters should be avoided?\",\\n    \"What was the method employed to resolve the ValueError related to feature names?\",\\n    \"Is there an alternative solution to fix the issue with feature names that contain special characters?\",\\n    \"How did Peter Ernicke address the feature name issue differently than Asia Saeed?\"\\n]',\n",
       " '8d7392cb': '[\\n    \"What does the error mean when I see \\'TypeError: Expecting a sequence of strings for feature names, got: <class \\'numpy.ndarray\\'>\\' while training my xgboost model?\",\\n    \"How can I fix the issue of feature names being a numpy.ndarray instead of a list in my xgboost model?\",\\n    \"Is there a specific method I should use to convert the feature names to a list when training an xgboost model?\",\\n    \"What data type should my feature names be in order to avoid the TypeError related to the xgboost model?\",\\n    \"Could you explain the steps to properly format feature names for use in an xgboost model?\"\\n]',\n",
       " 'c920eef3': '[\\n  \"What should I do if I encounter a TypeError related to feature names when using xgb.DMatrix?\",\\n  \"How can I convert the output from dv.get_feature_names_out() to a compatible format for xgb.DMatrix?\",\\n  \"What does it mean if I receive a ValueError indicating that feature_names must be strings and contain invalid symbols?\",\\n  \"What steps can I take to resolve issues with feature names when they include symbols like [, ] or <?\",\\n  \"Is there a way to avoid specifying \\'feature_names=\\' when creating an xgb.DMatrix to prevent errors?\"\\n]',\n",
       " '5017c9a4': '[\\n    \"What is the required version of pip to install Xgboost?\",\\n    \"Can you provide the installation command for Xgboost in Jupyter Notebook?\",\\n    \"How can I update my pip to the latest version?\",\\n    \"Where can I find more information about Xgboost installation?\",\\n    \"Is there a specific platform or environment in which Xgboost should be installed?\"\\n]',\n",
       " '6ffe101d': '[\\n    \"What role does the learning rate play in XGBoost models?\",\\n    \"How does gradient descent relate to the hyperparameters in XGBoost?\",\\n    \"Why is it important to tune the learning rate when training the model?\",\\n    \"Can you explain how eta influences the optimization of weights in XGBoost?\",\\n    \"What happens when you adjust the learning rate in the training process?\"\\n]',\n",
       " 'a55b29ff': '[\\n    \"Can you explain how bagging works and what its main advantages are?\",\\n    \"What is the primary difference in the training process between Random Forest and XGBoost?\",\\n    \"How does boosting address the mistakes made by previous models in the sequence?\",\\n    \"What are the implications of using bagging regarding variance and overfitting?\",\\n    \"Why might boosting be considered more accurate than bagging, and what is the potential downside?\" \\n]',\n",
       " 'eac70ce3': '[\\n  \"How can I capture stdout for each iteration of a loop separately without running the cell multiple times?\",\\n  \"What is the purpose of using the magic command \\'%%capture output\\' when trying to capture output?\",\\n  \"Is there a specific code sample that illustrates how to capture the output from multiple runs in a dictionary?\",\\n  \"Can you explain how the \\'capture_output\\' function is used within a loop for output capture?\",\\n  \"What would the final structure of the dictionary look like after capturing outputs for different iterations?\"\\n]',\n",
       " '5f91f8ca': '[\\n    \"What error might I encounter when using roc_auc_score() for AUC calculation?\",\\n    \"How should I correctly organize the arguments when calling roc_auc_score()?\",\\n    \"What are the required parameters to pass into the roc_auc_score() function?\",\\n    \"In what order do I need to provide the actual and predicted values to avoid errors?\",\\n    \"Who provided the solution to the ValueError related to continuous format in roc_auc_score()?\"\\n]',\n",
       " 'a3be507a': '[\\n    \"In the context of homework 6, if I notice that the RMSE increases after a specific number of n_estimators but decreases again afterwards, which value should I report?\",\\n    \"When analyzing the RMSE behavior, does it indicate that I should stop looking for improvements when it no longer decreases significantly?\",\\n    \"For Question 3 of homework 6, should I focus on the first point of RMSE increase or the lowest overall value when deciding on n_estimators?\",\\n    \"Can you clarify what it means for RMSE to stop improving and how that affects my choice of n_estimators?\",\\n    \"In relation to the homework, does the overall trend of RMSE changes dictate the optimal number of n_estimators I should select?\"\\n]',\n",
       " '9a8faa50': '[\\n    \"How can I effectively visualize decision trees using Python?\",\\n    \"What are some methods to export decision tree data for visualization?\",\\n    \"Can you explain how to use Graphviz for rendering decision trees?\",\\n    \"In which format can the output of the decision tree visualization be generated?\",\\n    \"What Python libraries are recommended for working with decision trees?\"\\n]',\n",
       " 'a6e384fe': '[\\n  \"What should I do if I encounter a ValueError related to \\'unknown label type: continuous\\'?\",\\n  \"How do I know whether to use DecisionTreeClassifier or DecisionTreeRegressor?\",\\n  \"What could be the reason for my model throwing a ValueError during training?\",\\n  \"Are there specific scenarios where I should choose classification over regression for decision trees?\",\\n  \"What is the main difference between using a DecisionTreeClassifier and a DecisionTreeRegressor?\"\\n]',\n",
       " 'ddc14ada': '[\\n    \"Why do I see varying AUC values every time I execute the DecisionTreeClassifier code on my laptop?\",\\n    \"What could be the reason behind the AUC results changing with each kernel restart in Jupyter?\",\\n    \"Can you explain how using a random seed might affect the results of the DecisionTreeClassifier?\",\\n    \"What specific values did the AUC take during my multiple runs of the model in the provided example?\",\\n    \"Where can I find more information on setting the random seed for consistent results in machine learning models?\"\\n]',\n",
       " '593f7569': '[\"Is there a difference between creating the server in the Python file and running gunicorn directly?\", \"Will using one method over the other affect the server\\'s performance?\", \"Is there a recommended approach for server creation in our course?\", \"How does the typing in the script change based on the method used?\", \"Is there a preference between the two methods for handling server creation?\"]',\n",
       " '6cb56405': '[\\n    \"What should I do if I encounter a \\'No module named ping\\' error while running an example from the video?\",\\n    \"How can I successfully import the \\'ping\\' function if the standard import statement does not work?\",\\n    \"Can you explain the steps I need to take to resolve the issue with importing the \\'ping\\' function?\",\\n    \"What is the correct way to import a function named \\'ping\\' from my file if the direct import fails?\",\\n    \"Is there a specific statement I should use to import \\'ping\\' if my initial attempt is unsuccessful?\"\\n]',\n",
       " 'a22a93f1': '[\\n    \"What function does DictVectorizer provide to obtain feature names?\",\\n    \"How can I analyze feature importance using the DictVectorizer?\",\\n    \"What is the return type of the get_feature_names_out() function?\",\\n    \"Do I need to convert the output of get_feature_names_out() for certain uses?\",\\n    \"Is it necessary to fit the predictor and response arrays before accessing feature names?\"\\n]',\n",
       " 'b6259dea': '[\\n    \"What causes the ValueError regarding feature names in decision trees?\",\\n    \"How can I resolve the issue with unsupported characters in feature names?\",\\n    \"Is there a specific method to create a list of features without special characters?\",\\n    \"What characters should I avoid including in my feature names for ensemble learning?\",\\n    \"Can you provide an example of how to replace problematic characters in feature names?\"\\n]',\n",
       " 'bcfdc6f4': '[\\n    \"How can I visualize the importance of features in my model using a chart?\",\\n    \"What steps do I need to follow to extract and sort feature importances?\",\\n    \"What libraries or functions are suggested for creating a horizontal bar chart to display feature importance?\",\\n    \"Can you explain the process of creating a DataFrame from feature importances?\",\\n    \"What do I need to include in my chart to effectively show feature significance?\"\\n]',\n",
       " 'a7e7cdd2': '[\\n  \"How can I calculate RMSE without using np.sqrt()?\",\\n  \"Is there an alternative method to get RMSE in this course?\",\\n  \"What function can I use to directly obtain RMSE from predictions?\",\\n  \"Can you explain how to extract RMSE without a square root step?\",\\n  \"Who provided the information on calculating RMSE in our course?\"\\n]',\n",
       " '55477da8': '[\\n    \"Can you recommend a resource for visualizing feature importance in decision trees?\",\\n    \"How does the features importance graph contribute to model explainability?\",\\n    \"Where can I find an example of feature importance implementation in scikit-learn?\",\\n    \"What additional information does the features importance graph provide about stability?\",\\n    \"Why is tracing the stability of features important for a model?\"\\n]',\n",
       " '6a245a05': '[\"What does the XGBoostError message indicate about the required dependencies?\", \"How can I resolve the xgboost.core.XGBoostError I encountered?\", \"Is there a specific library I need to install for using XGBoost?\", \"What must be included in the requirements to avoid the XGBoost error?\", \"Who provided the information regarding the XGBoost error and its resolution?\"]',\n",
       " '4405bfca': '[\\n    \"What is the meaning of information gain in relation to variables X and Y?\",\\n    \"How does one measure the mutual information between Y and X?\",\\n    \"What does it imply if X does not provide any information about Y?\",\\n    \"What does it mean if X is fully informative about Y?\",\\n    \"Can you explain the concept of entropy in the context of information gain?\"\\n]',\n",
       " '3e0acc25': '[\"What issues arise from filling in missing values before dataset splitting?\", \"Why is it problematic to use the entire dataset for imputation prior to division?\", \"How does data leakage occur in the context of missing value treatment?\", \"Can you explain the risks associated with pre-splitting data imputation?\", \"What is the consequence of addressing missing values using the whole dataset first?\"]',\n",
       " 'abaecdf8': '[\\n    \"What is the recommended method for saving a model in Xgboost?\",\\n    \"How can I load a saved model in the context of Xgboost?\",\\n    \"Who is mentioned in the section regarding the loading of models?\",\\n    \"Where can I find information related to the models after they have been saved?\",\\n    \"Is there any specific function I should use to save the model in Xgboost?\"\\n]',\n",
       " 'ff40f83b': '[\"What steps should I follow to begin with Week 8 of the course?\", \"Is there any specific material we need to review before starting Week 8?\", \"When will additional resources be available for Week 8?\", \"How can I prepare for the content covered in Week 8?\", \"Are there any prerequisites I need to complete before tackling Week 8?\"]',\n",
       " '95a16746': '[\"What steps are necessary to utilize Kaggle for Deep Learning projects?\", \"How can I import my notebook into Kaggle for use?\", \"What should I do after accessing my notebook in Kaggle?\", \"Which type of GPU should I select for optimal deep learning performance?\", \"Who provided the guidelines for using Kaggle for Deep Learning?\"]',\n",
       " '46acdd18': '[\"What are the initial steps to get started with Google Colab for Deep Learning projects?\", \"How can I select the appropriate hardware settings in Google Colab?\", \"Which GPU type should I choose for optimal performance in Deep Learning?\", \"What is the process for importing an existing notebook into Google Colab?\", \"Is there a specific location in the Colab interface where I can change runtime settings?\"]',\n",
       " 'f721d54b': '[\"What are the steps to connect my GPU on Saturn Cloud to a GitHub repository if I prefer automation?\", \"Is it necessary to connect my Saturn Cloud account to GitHub to work on my projects?\", \"Can you explain how to use the default public keys provided by Saturn Cloud for GitHub authentication?\", \"Where can I find the Git SSH keys section to manage my keys in Saturn Cloud?\", \"What command should I run in the terminal on Saturn Cloud to check my GitHub authentication status?\"]',\n",
       " '69cd4897': '[\\n    \"What is the current location of the Python TensorFlow template on Saturn Cloud?\",\\n    \"How can I find the Python Deep Learning tutorials on Saturn Cloud?\",\\n    \"Is the location of the TensorFlow template in video 8.1b still accurate?\",\\n    \"Where should I look on the Saturn Cloud home page for deep learning resources?\",\\n    \"Who provided the information regarding the template\\'s new location for TensorFlow?\"\\n]',\n",
       " '346e799a': '[\\n    \"What should I do if I encounter an error indicating that the module scipy is not found during model training in Saturn Cloud\\'s tensorflow image?\",\\n    \"How can I ensure that the scipy package is installed when creating a Jupyter server resource in Saturn Cloud?\",\\n    \"Is there a way to automatically install additional Python packages when setting up a Jupyter server on Saturn Cloud?\",\\n    \"Where can I find the section to add extra packages while creating a Jupyter server resource in Saturn Cloud?\",\\n    \"What command should I expect to see below the textbox for adding extra packages during Jupyter server creation?\"\\n]',\n",
       " '551461b2': '[\"What steps should I follow to upload Kaggle datasets to Saturn Cloud efficiently?\", \"How do I set up my Kaggle API token for use in Saturn Cloud?\", \"What command do I need to run after uploading the kaggle.json file?\", \"How can I download a specific dataset from Kaggle using a command in my notebook?\", \"What should I do with the downloaded zip file after retrieving a dataset from Kaggle?\"]',\n",
       " 'c3ba4459': '[\\n    \"What is the requirement for running TensorFlow with GPU on my local machine?\",\\n    \"Can you provide a simplified guide for setting up CUDA and cuDNN?\",\\n    \"Is it necessary to install CUDA and cuDNN for TensorFlow on Ubuntu 22.04?\",\\n    \"Who can I refer to for help with installing CUDA and cuDNN?\",\\n    \"What specific versions of CUDA and cuDNN do I need for TensorFlow?\"\\n]',\n",
       " 'a114ad55': '[\\n    \"What should I do if I encounter a ValueError when trying to load weights in HDF5 format into my subclassed Model?\",\\n    \"Why am I getting an error indicating that the Model has not created its variables yet when attempting to load weights?\",\\n    \"Can you explain the necessary step I must take before I can successfully load weights into my subclassed Model?\",\\n    \"What does the error message suggest I do before loading the model to avoid the ValueError?\",\\n    \"Is there a specific function I need to call on my model before loading weights saved in HDF5 format?\"\\n]',\n",
       " 'dd3c8000': '[\"What should I do if I encounter a \\'permission denied\\' error while connecting git on Saturn Cloud?\", \"How can I fix the issue when running \\'ssh -T git@github.com\\' leads to an error?\", \"Is there an alternative method to set up git in the Saturn Cloud environment?\", \"What steps should I follow to generate an SSH key in Saturn Cloud for git access?\", \"Where can I find detailed instructions for managing git through Saturn’s Jupyter server?\"]',\n",
       " '34b0ebfc': '[\"What should I do if I encounter a host key verification error when trying to clone a GitHub repository?\", \"Is there a specific command I should use to successfully clone the clothing dataset repository?\", \"What does the error message indicate about my access rights to the repository?\", \"Why does the host key verification failure occur when cloning a repository with SSH?\", \"Can I use an alternative method to clone the repository if I have issues with SSH?\"]',\n",
       " '7d11d5ce': '[\"What does it mean if accuracy remains unchanged during training epochs?\", \"How can I resolve the issue of constant accuracy and loss while training?\", \"What specific setting should I use for class_mode when reading data for my homework?\", \"Why might the choice of optimizer, batch size, or learning rate affect training outcomes?\", \"What should I do if my training results in unchanged accuracy and loss?\"]',\n",
       " 'e4e45f15': '[\"What should I do if my model experiences high loss and low accuracy after augmentation?\", \"Why does my model show a loss of over 1000 when I resume training?\", \"How can I improve my model\\'s performance after using augmented data?\", \"What settings should I verify in ImageDataGenerator to address model issues post-augmentation?\", \"Is there a specific option I need to check in the ImageDataGenerator for proper rescaling?\"]',\n",
       " 'b3997e6f': '[\\n    \"What should I do if I encounter a \\'Missing channel value\\' error when loading my model with TensorFlow?\",\\n    \"Why am I getting a ValueError related to the channel dimension when executing the load_model function?\",\\n    \"What happens if the number of channels is not defined in the Input layer of my model?\",\\n    \"How can I ensure that the model architecture retains the channel dimension information when saving?\",\\n    \"What changes do I need to make in the model architecture code to avoid issues with undefined channel dimensions?\"\\n]',\n",
       " 'e414df91': '[\\n    \"What is the issue encountered when unzipping a dataset in a Jupyter notebook using the unzip command?\",\\n    \"How can I suppress the output messages generated during the unzipping process in a Jupyter notebook?\",\\n    \"What command should I use in a Jupyter notebook to unzip a folder while avoiding excess output?\",\\n    \"Can you explain the steps to extract files from a zipped folder using the zipfile module in Jupyter?\",\\n    \"What are the commands needed to unzip a dataset and store it in a specified destination folder?\"\\n]',\n",
       " 'f20a3479': '[\\n    \"How does keras flow_from_directory determine the class names of images when processing directories?\",\\n    \"Is the class name derived from the folder name in which the images are stored?\",\\n    \"What happens if I create a folder with a random name like \\'xyz\\' for my images?\",\\n    \"Can you explain how flow_from_directory assigns class labels based on folder names?\",\\n    \"Is there any additional mechanism at play when using flow_from_directory with multiple classes?\"\\n]',\n",
       " 'e7af4968': '[\\n    \"What should I do if I encounter an error related to a missing scipy module while using SaturnCloud?\",\\n    \"I created a new environment in SaturnCloud and am getting an error about scipy. How can I resolve this issue?\",\\n    \"If I select the Tensorflow image in SaturnCloud but face a module error, what steps should I take?\",\\n    \"Could you provide a solution for addressing the scipy missing module error when fitting my model?\",\\n    \"After installing scipy in SaturnCloud, what is the next step to ensure my model fits correctly?\"\\n]',\n",
       " '9fad096e': '[\\n    \"How does the alphabetical order of folders affect numeric class labels when using flow_from_directory in binary class mode?\",\\n    \"What does the single probability output from a binary Keras model represent when predicting labels?\",\\n    \"In a scenario with two folders named dino and dragon, what class label does each folder correspond to?\",\\n    \"How can I determine the probability of class 0 given the model\\'s prediction for class 1?\",\\n    \"What are the implications of using from_logits in terms of the output values for label predictions?\"\\n]',\n",
       " 'bcdf7407': '[\"Do the predicted values from a neural network need to be precise, or is some variation acceptable?\", \"When using a neural network, how important is the accuracy of the predicted values?\", \"Should we consider minor discrepancies in predictions as normal when working with neural networks?\", \"Is it the case that after predicting with a neural network, slight changes in values are to be expected?\", \"Can we treat neural network predictions more like probabilities rather than exact outcomes?\"]',\n",
       " '8d1e7e20': '[\\n    \"What should I do if the accuracy and standard deviation of my training loss differ from the homework results?\",\\n    \"Could the optimizer be the reason for discrepancies in accuracy and training loss when running the model?\",\\n    \"Is there a recommended platform for running the model if I am getting unexpected results on my laptop?\",\\n    \"What runtime configuration should I use in Google Colab to improve model performance?\",\\n    \"Did you notice any differences in results when you used different versions of the SGD optimizer?\"\\n]',\n",
       " '2023a9dc': '[\\n    \"What parameter can I specify to use multi-threading during data generation in model.fit()?\",\\n    \"What is the default setting for the \\'workers\\' parameter in model.fit()?\",\\n    \"How can I determine the optimal worker count for my data loading when using model.fit()?\",\\n    \"Where can I find more information about the model.fit() method in TensorFlow?\",\\n    \"Who added the information regarding multi-threading in the FAQ record?\"\\n]',\n",
       " '468f69ff': '[\"How can I ensure reproducibility in my training runs with TensorFlow?\", \"What instructions do I need to follow for reproducibility using TensorFlow?\", \"Is there a specific seed value I need to set for reproducibility in TensorFlow?\", \"Can you explain how to execute a script multiple times while maintaining reproducibility?\", \"Where can I find the official TensorFlow documentation related to reproducibility and enabling operation determinism?\"]',\n",
       " 'c4ff26e5': '[\\n    \"Is it possible to use PyTorch for the upcoming lessons and homework assignments?\",\\n    \"Are there resources available for creating a CNN in PyTorch?\",\\n    \"Will the functions in PyTorch serve the same purpose as those in Keras?\",\\n    \"Can I submit a pull request for my PyTorch projects related to the lessons?\",\\n    \"What framework will be primarily used for the course assignments?\" \\n]',\n",
       " '62722d72': '[\\n    \"What error might occur during Keras model training related to data adapters?\",\\n    \"What could cause the error about failing to find a data adapter when training a Keras model?\",\\n    \"How should I correctly use ImageDataGenerator while training my Keras model?\",\\n    \"What are the correct variables to use for training and validation data in model.fit?\",\\n    \"What is the suggested fix for the error encountered during Keras model training?\"\\n]',\n",
       " 'd1419be1': '[\\n    \"How can I run the command \\'nvidia-smi\\' repeatedly without employing the \\'watch\\' function?\",\\n    \"Is there a specific command for executing \\'nvidia-smi\\' at regular intervals?\",\\n    \"What does the \\'-l\\' option do when used with \\'nvidia-smi\\'?\",\\n    \"How can I set \\'nvidia-smi\\' to refresh its output every 2 seconds?\",\\n    \"What command should I use to stop \\'nvidia-smi\\' from running in a loop?\"\\n]',\n",
       " 'a5f6f439': '[\"What tool can I use to monitor both GPU and CPU usage interactively?\", \"How does \\'nvitop\\' compare to traditional CPU monitoring tools?\", \"Where can I find more information about the \\'nvitop\\' package?\", \"Is \\'nvitop\\' a Python package or an application for monitoring resources?\", \"Who contributed the information about using \\'nvitop\\' in our course materials?\"]',\n",
       " '879c1ec0': '[\\n    \"What parameters are involved in defining the Conv2D layer, specifically regarding the input shape and filter count?\",\\n    \"How is the number of parameters for the Conv2D layer calculated, and what does each component of the calculation represent?\",\\n    \"Can you explain how the output shape of the MaxPooling2D layer and the Flatten layer relates to the number of features?\",\\n    \"What is the formula used to determine the number of features after applying the Flatten layer in the model?\",\\n    \"What does the output shape of (None, 6272) indicate after the Flatten layer in terms of the data processed?\"\\n]',\n",
       " '3ac604c3': '[\\n    \"What is the main difference between Sequential Model API and Functional Model API in Keras?\",\\n    \"Can you explain how to build a model in Keras using the Sequential Model API?\",\\n    \"Why is it recommended to perform a fresh run when correcting errors in neural network architecture?\",\\n    \"In what scenarios might the Functional Model API be preferred over the Sequential Model API?\",\\n    \"Where can I find a useful example of a Sequential model in Keras for reference?\"\\n]',\n",
       " '0315aa96': '[\\n    \"What can I do to resolve out of memory errors when using TensorFlow on my Nvidia GPU?\",\\n    \"Is there a specific code snippet that can help with OOM issues in TensorFlow?\",\\n    \"Are the solutions for OOM errors on Nvidia GPUs applicable to CPU usage as well?\",\\n    \"What is the purpose of setting memory growth in TensorFlow, and how can I implement it?\",\\n    \"What error might I encounter if I try to modify virtual devices once they are initialized?\"\\n]',\n",
       " 'daf84bc3': '[\\n    \"What can I do to improve the model training speed on the T4 GPU in Google Colab?\",\\n    \"How many workers or threads should I set to optimize training performance in Google Colab?\",\\n    \"Is the default value for the number of workers in Google Colab sufficient for efficient training?\",\\n    \"Where can I find additional information or discussions about optimizing training on Google Colab?\",\\n    \"What changes did you make to the workers variable to mitigate slow training on the T4 GPU?\"\\n]',\n",
       " '1e956ca7': '[\\n  \"What is the recommended method for loading images in new code according to the Keras documentation?\",\\n  \"Why is tf.keras.preprocessing.image.ImageDataGenerator not recommended?\",\\n  \"What should I use instead of ImageDataGenerator for handling image data?\",\\n  \"Where can I find tutorials related to loading and augmenting images?\",\\n  \"What guides are available for understanding preprocessing layers in image loading?\"\\n]',\n",
       " '3ee083ab': '[\"What steps should I follow to begin Week 9?\", \"Are there specific resources I need for Week 9?\", \"Can you provide guidance on what to focus on in Week 9?\", \"Is there a checklist for getting started with Week 9?\", \"When will the materials for Week 9 be available?\"]',\n",
       " 'f826cba4': '[\\n  \"How can I access the model required for week 9 of the course?\",\\n  \"What is the new location for the week 9 model?\",\\n  \"Is there a specific link to fetch the models for week 9?\",\\n  \"Where should I go to find the GitHub link for the week 9 model?\",\\n  \"Can you tell me the URL to retrieve the models for week 9?\"\\n]',\n",
       " '60fa95ed': '[\"What should I do if the command echo ${REMOTE_URI} does not display any output?\", \"How can I set the REMOTE_URI variable to a specific URI address in the terminal?\", \"Will I still have access to the REMOTE_URI variable after I close my terminal session?\", \"What commands did you run to successfully display the REMOTE_URI value?\", \"Is the use of curly brackets necessary when echoing the REMOTE_URI variable?\"]',\n",
       " '53f3ee10': '[\"What command should I use to avoid the invalid choice error while fetching the password from aws-cli?\", \"How can I simplify the login process for AWS ECR using the command line?\", \"What do I need to replace in the login command for it to work correctly?\", \"Is there a specific syntax for exporting the password from the AWS command?\", \"What error do I get if I use aws ecr get-login instead of the recommended command?\"]',\n",
       " '93aa4278': '[\"How can I pass multiple parameters to the model simultaneously?\", \"What function should I use to send various cnn parameters at once?\", \"Is there a recommended method for passing several parameters in a deep learning model?\", \"Can I use Sequential to handle many parameters in my model configuration?\", \"What is the easiest way to define multiple parameters for a cnn in my project?\"]',\n",
       " '0edeb016': '[\\n  \"What does the error message ERROR [internal] load metadata for public.ecr.aws/lambda/python:3.8 indicate when building a Docker image?\",\\n  \"What should I do if I encounter an issue while using the Amazon python base image for Docker?\",\\n  \"Are there any specific steps I can take to resolve the ERROR [internal] load metadata issue?\",\\n  \"How can I ensure that my Docker desktop is up to date to prevent errors while building images?\",\\n  \"What command can I run as a last resort if the previous solutions do not work while building my Docker image?\"\\n]',\n",
       " 'ba186de6': '[\\n    \"What error message do I encounter when running the \\'ls\\' command in Windows Jupyter Notebook?\",\\n    \"What alternative command can I use in a Windows Jupyter Notebook to get similar output to \\'!ls -lh\\'?\",\\n    \"Can you explain why the \\'ls\\' command is not recognized in a Windows environment?\",\\n    \"What is the command I should use instead of \\'!ls -lh\\' when working on a Windows system?\",\\n    \"Who provided the solution for the issue with the \\'ls\\' command in the FAQ record?\"\\n]',\n",
       " 'da2f1cf4': '[\"What should I do if I encounter the error \\'ImportError: generic_type: type \\\\\"InterpreterWrapper\\\\\" is already registered!\\' when trying to use tflite_runtime?\", \"How can I resolve the issue of conflicting imports in my notebook related to TensorFlow and tflite_runtime?\", \"Is there a specific order or method I should follow when importing tflite_runtime to avoid import errors?\", \"What steps can I take to fix the ImportError I see with tflite_runtime when I also import TensorFlow?\", \"If I receive an error regarding \\'InterpreterWrapper\\' when using tflite_runtime, how can I ensure my notebook runs smoothly?\"]',\n",
       " '7fd648ca': '[\\n    \"What error message might I encounter when trying to build a Docker image on Windows?\",\\n    \"How do I know if my Windows version may not be up-to-date when using Docker?\",\\n    \"What should I check if the Docker daemon is not running on my system?\",\\n    \"What command do I use to build a Docker image for dino_dragon?\",\\n    \"What can prevent Docker from running correctly on my Windows system?\"\\n]',\n",
       " '42c09143': '[\\n    \"What is the warning I receive when running the command to build the Docker image for the model?\",\\n    \"How does the version of the Python wheel affect the Docker build process in this week\\'s section?\",\\n    \"What specific version of Python do I need to be using for compatibility with the wheel?\",\\n    \"What is a common mistake that leads to the error when attempting to download the required file?\",\\n    \"Can you provide the correct link format to download the wheel needed for this project?\"\\n]',\n",
       " 'd6d534fc': '[\"What specific steps should I follow for configuring AWS after I have installed awscli?\", \"During the configuration process with aws configure, what information is required, particularly regarding Access Key ID and Secret Access Key?\", \"Is it acceptable to leave the Default output format blank when configuring awscli, and what default settings do you recommend?\", \"Can I use the default values for most of the configuration options in aws configure, and are there any exceptions I should be aware of?\", \"What should I do if I am uncertain about the Default Region Name during the awscli configuration process?\"]',\n",
       " 'b2c0c554': '[\\n    \"Why does my lambda function work locally but produce a float32 serialization error when using Docker?\",\\n    \"What specific error message appears when encountering an issue with JSON serialization in my serverless model?\",\\n    \"How can I convert numpy float32 values to a format that is JSON serializable for my lambda function?\",\\n    \"What changes should I make in the predict function to resolve the serialization issue with float32 outputs?\",\\n    \"Which chapters should I refer to for additional guidance on troubleshooting the float32 serialization problem in serverless deep learning?\"\\n]',\n",
       " '819afebc': '[\\n    \"What could cause the ValueError when using interpreter.set_tensor with the input X?\",\\n    \"How can I convert my input data to the correct type to resolve the error encountered in the video?\",\\n    \"Is there any specific version of TensorFlow that might relate to this issue I am facing with tensor types?\",\\n    \"Where can I find additional information or solutions regarding the ValueError I encountered?\",\\n    \"What is the correct data type that should be used for input when working with interpreter.set_tensor?\"\\n]',\n",
       " '74551c54': '[\\n    \"What command can I use in PowerShell to retrieve file size?\",\\n    \"How do I assign a file item to a variable in a PowerShell script?\",\\n    \"What is the command to display the file size in megabytes using PowerShell?\",\\n    \"Can you provide an example of checking file size in the PowerShell terminal?\",\\n    \"What is the PowerShell command to get the length of a file?\"  \\n]',\n",
       " '4d98cd09': '[\"Can you explain the functionality of lambda container images in detail?\", \"What resources did you find helpful for understanding the initialization of lambda functions?\", \"Where can I access documentation regarding lambda container images?\", \"Is there any specific guide for using lambda images effectively?\", \"What are some key aspects of the runtimes API related to lambda functions?\"]',\n",
       " '59a81fd5': '[\\n    \"What steps are involved in deploying a Docker image on AWS Lambda using the AWS Serverless Framework?\",\\n    \"How can I expose my Lambda function as a REST API via APIGatewayService after deployment?\",\\n    \"Is there any detailed guide available for creating and pushing Docker images to AWS ECR?\",\\n    \"Can I find a comprehensive tutorial for deploying containerized applications to AWS Lambda?\",\\n    \"What resources are recommended for learning about the AWS Serverless Framework integration with AWS services?\"\\n]',\n",
       " '35dbd6e2': '[\"What should I do if I encounter an error when trying to build the Docker image on my M1 Mac during the process described in Section 9.5?\", \"Is there a specific command I can use to resolve the pip install error for the tflite runtime when building the Docker image?\", \"If the provided link for the tflite runtime wheel does not work, what are my alternatives for building the Docker image?\", \"What adjustments do I need to make to the Docker build command to accommodate the arm architecture of my M1 Mac?\", \"How can I run the Docker image once it has been successfully built on my machine?\"]',\n",
       " 'e5fe9efe': '[\\n    \"What error might I encounter when attempting to invoke the API Gateway while testing it locally in section 9.7?\",\\n    \"What specific error message indicates a problem when I try to expose the Lambda Function using the API Gateway?\",\\n    \"What do I need to do if I receive a \\'Missing Authentication Token\\' error while testing my API?\",\\n    \"How can I find the correct URL to use when invoking a deployed API in AWS?\",\\n    \"Can you provide an example of what the API URL should look like when I perform a prediction request?\"\\n]',\n",
       " '5c043c62': '[\\n  \"What error message appears when I attempt to install tflite_runtime using the provided command?\",\\n  \"Where can I find the specific OS and Python version combinations for tflite_runtime availability?\",\\n  \"How can I determine if a compatible version of tflite_runtime is available for my system?\",\\n  \"What are the steps to install a compatible tflite_runtime version using pip from GitHub?\",\\n  \"What alternative methods can I use to run my code if tflite_runtime cannot be installed directly?\"\\n]',\n",
       " 'af0739da': '[\"What should I do if I encounter a Docker run error related to a read-only file system?\", \"How can I resolve the issue with mkdir in Docker when it shows an error response from the daemon?\", \"Is there a specific command I need to run to fix the Docker error involving overlay2?\", \"What steps do I take to address the Docker services error mentioned in the FAQ?\", \"Who can I contact if restarting the Docker services does not fix my issue?\"]',\n",
       " '451bc25d': '[\"How can I save a Docker image to my local machine?\", \"What command should I use to export a Docker image in tar format?\", \"How do I view the contents of a Docker image after saving it?\", \"What should I extract to see the individual layers of a Docker image?\", \"Is there a specific file I need to look for after extracting the Docker image tar?\"]',\n",
       " 'ea2e7458': '[\\n    \"What should I do if my Jupyter notebook doesn\\'t recognize a package after installation?\",\\n    \"Why is my notebook failing to recognize imports after I\\'ve installed a package?\",\\n    \"How can I fix issues with Jupyter notebook not seeing a package I installed?\",\\n    \"What steps should I take if my Jupyter notebook still does not work with my imports?\",\\n    \"Is there a need to restart the Jupyter notebook after installing a package for it to work?\"\\n]',\n",
       " '6ce8e875': '[\\n    \"What should I do if I run out of space on my AWS instance?\",\\n    \"Why doesn\\'t deleting docker images free up space on my instance?\",\\n    \"Is there a specific command I need to run after deleting images to reclaim disk space?\",\\n    \"How much storage does my AWS instance have?\",\\n    \"What is the process for cleaning up space in a Docker environment?\"\\n]',\n",
       " 'b50e9e2b': '[\"Is Tensorflow 2.15 compatible for our AWS deployment?\", \"What version of Tensorflow should I use if 2.15 does not work?\", \"Can I use Python 3.11 with Tensorflow 2.14?\", \"What is the recommended Python version for Tensorflow 2.4.4?\", \"What issues might arise if I use an unsupported Python version with Tensorflow?\"]',\n",
       " '29311ef5': '[\\n  \"Why does running the command aws ecr get-login --no-include-email lead to an error regarding an invalid operation choice?\",\\n  \"What should I do if I receive an error message when using the aws ecr get-login command?\",\\n  \"Is there a resource available to help me understand the invalid choice error from aws ecr get-login?\",\\n  \"Could you explain why the aws ecr get-login command might fail and give an invalid choice error?\",\\n  \"Where can I find more information about the error that occurs with the aws ecr get-login command?\"\\n]',\n",
       " '1e0dc11c': '[\"What steps should I follow after signing into the AWS Console to get to the IAM service?\", \"How can I create a new IAM policy for Week 9: Serverless?\", \"What actions are included in the JSON policy for ECR that I need to create?\", \"What should I do after reviewing my IAM policy before creating it?\", \"What error message might I encounter related to credentials, and how can I fix it?\"]',\n",
       " '1078aeb7': '[\\n  \"What should I do if I encounter a Docker temporary failure in name resolution?\",\\n  \"How can I configure DNS settings in Docker to resolve name issues?\",\\n  \"What changes need to be made in the daemon.json file for Docker DNS?\",\\n  \"After modifying the DNS settings in Docker, what is the next step?\",\\n  \"Who provided the instructions for resolving Docker name resolution errors?\"\\n]',\n",
       " '7daaca73': '[\\n    \"What should I do if my Keras model fails to load with a weight_decay error?\",\\n    \"How can I resolve the issue with loading a Keras model due to a kwargs problem?\",\\n    \"What code modification is needed to successfully load a Keras model that throws an error?\",\\n    \"Is there a specific function argument I need to set when loading a model to avoid errors?\",\\n    \"Can you tell me the correct syntax to use when loading a Keras model that has compatibility issues?\"\\n]',\n",
       " '0cfbe2e2': '[\"What is the role of AWS RIE in local testing of serverless applications?\", \"What command should I use to run my Docker image for testing locally?\", \"How can I test the endpoint after running the Docker container?\", \"What are the differences in curl commands for Windows and Unix testing?\", \"How should I handle the error related to marshaling response in testing?\"]',\n",
       " '1460fb65': '[\"What should I check if I encounter the error related to importing \\'lambda_function\\' in my Python script?\", \"How can I resolve the \\'No module named tensorflow\\' error when running my test script?\", \"Is there any specific library I need to avoid importing in my test.py to prevent this error?\", \"What is the correct way to import tflite to avoid compatibility issues in serverless deep learning?\", \"Why is it important to change the import statement from tensorflow.lite to tflite_runtime.interpreter?\"]',\n",
       " 'd4f9efdc': '[\"How can I install Docker (udocker) while using Google Colab?\", \"What steps should I follow to run Docker commands in Google Colab?\", \"What should I do if I encounter errors related to the Authorization header while using the Lambda API Gateway?\", \"How can I test my API method in Amazon\\'s API Gateway using boto3?\", \"What is the solution for running pip install tflite_runtime from a GitHub wheel link if it fails?\"]',\n",
       " '6a417bfe': '[\\n    \"What steps should I follow to begin Week 10 of the course?\",\\n    \"Is there any specific preparation needed for Week 10 activities?\",\\n    \"Are there any resources recommended for the Kubernetes and TensorFlow Serving section?\",\\n    \"When will the Week 10 materials be available for review?\",\\n    \"Will there be any assignments associated with Week 10 topics?\"\\n]',\n",
       " 'ed8b300d': '[\\n    \"What are the benefits of using TensorFlow with CUDA support on my local machine compared to running a CNN on the CPU?\",\\n    \"Can you provide resources or links for installing TensorFlow in an Ubuntu WSL2 setup?\",\\n    \"What specific version of CUDA should I choose when installing TensorFlow with pip for optimal performance?\",\\n    \"How do I ensure that my hardware is compatible with CUDA support before installing TensorFlow?\",\\n    \"Is there any additional information or resources I should consider when setting up PyTorch alongside TensorFlow?\"\\n]',\n",
       " 'a64aed6b': '[\\n    \"What should I do if I encounter \\'Allocator ran out of memory\\' errors while using TensorFlow on my machine?\",\\n    \"Can you explain how to potentially improve performance when running TensorFlow with memory constraints?\",\\n    \"Is there a specific code snippet I should add to my notebook to address memory allocation issues in TensorFlow?\",\\n    \"What should I expect after implementing the code fix for memory errors in TensorFlow?\",\\n    \"Has anyone experienced the memory allocation error again after applying the suggested solution, and what was the outcome?\"\\n]',\n",
       " '727238ee': '[\\n    \"What error might occur when running the script gateway.py in session 10.3, and what does it indicate?\",\\n    \"If I encounter the TypeError related to descriptors, what should I do to resolve the issue with protobuf?\",\\n    \"What version of protoc do I need to regenerate my generated code if it is out of date?\",\\n    \"What are some alternative solutions if I cannot regenerate my protobufs right away?\",\\n    \"Could you provide the specific pipenv install command that helps avoid the recent version of protobuf issue?\"\\n]',\n",
       " '85d4901d': '[\\n  \"What error message might I encounter when trying to run a docker command in WSL?\",\\n  \"What needs to be checked if Docker Desktop is not connecting to the WSL Linux distro?\",\\n  \"Where can I find the WSL Integration settings in Docker Desktop to resolve connectivity issues?\",\\n  \"What is the solution for fixing connection problems with the Docker daemon in WSL?\",\\n  \"Do I need to enable the same default WSL distro when using additional distros in Docker Desktop?\"\\n]',\n",
       " 'df023a13': '[\\n    \"What should I do if my HPA instance is not functioning as expected despite updating the Metrics Server?\",\\n    \"How can I fix the issue where the targets for my HPA instance show up as <unknown>?\",\\n    \"What specific command do I need to use to edit the metrics-server deployment in the kube-system namespace?\",\\n    \"What line do I need to add to the metrics-server args to resolve the HPA instance problem?\",\\n    \"After making changes to the metrics-server deployment, what command should I run to check the status of the HPA?\"\\n]',\n",
       " '48e92d65': '[\\n    \"What should I do if my HPA instance is not functioning correctly despite having the latest Metrics Server installed?\",\\n    \"How can I check if the targets are displaying as <unknown> for my HPA instance?\",\\n    \"Is there a specific command to fix issues with the HPA instance if the default installation doesn\\'t work?\",\\n    \"What option is included in the metrics server deployment file provided for fixing HPA instances?\",\\n    \"Who added the suggestion to use the metrics server deployment file with the --kubelet-insecure-tls option?\"\\n]',\n",
       " '1685cae4': '[\\n    \"What should I do if I encounter an OSError when trying to install packages on my Windows machine?\",\\n    \"Is there a specific error message I might see when the installation fails due to access issues?\",\\n    \"What command did you use to successfully install the libraries after encountering the access denied error?\",\\n    \"Could you explain the significance of using the `--user` option for the pip install command?\",\\n    \"What steps can I take to fix permission issues when installing Python packages on Windows?\"\\n]',\n",
       " '4fb7b21e': '[\\n  \"What error message did you encounter when you modified the code and created a virtual environment in the course?\",\\n  \"Which command resolved the issue related to the TypeError in your TensorFlow Serving code?\",\\n  \"What version of the protobuf package did you downgrade to in order to fix the error?\",\\n  \"What are two potential workarounds if you cannot regenerate your protos immediately?\",\\n  \"What is the implication of setting PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION to python?\"\\n]',\n",
       " '8bd3bfc2': '[\\n  \"What steps did you take to install kubectl on Windows using the terminal?\",\\n  \"Can you share a tutorial link that explains the installation of kubectl on Windows?\",\\n  \"Which command did you use to download kubectl on Windows?\",\\n  \"What do you need to do after copying the exe file to the specific folder on your C drive?\",\\n  \"Is there a similar installation process for kind on Windows as is for kubectl?\"\\n]',\n",
       " '03b5fc59': '[\"What is the first step to install kind using the choco library?\", \"How do I open a powershell terminal with the necessary permissions?\", \"What command do I need to run in powershell to install the choco library?\", \"What PowerShell command allows me to change the execution policy temporarily?\", \"Where can I find the installation script for the choco library?\"]',\n",
       " '7c31bc9a': '[\\n    \"What should I do if I encounter issues while installing Kind using Windows Powershell?\",\\n    \"Can you guide me on how to verify that Go is installed correctly on my system?\",\\n    \"What command is required to install Kind through Go?\",\\n    \"Is there a specific version of Kind that I should install using the Go command?\",\\n    \"How can I check if Kind has been successfully installed on my machine?\"\\n]',\n",
       " '605efc12': '[\\n  \"What was the error message I encountered when trying to use kubectl?\",\\n  \"What did I find when I searched for a solution to the kubectl issue?\",\\n  \"What did the online discussions suggest I should create to fix the problem?\",\\n  \"What steps did I follow to resolve the connection issue with kubectl?\",\\n  \"What was the result after I recreated the cluster and tried the command again?\"\\n]',\n",
       " 'c5cde96c': '[\\n  \"What problem might I encounter if I experiment with Docker images without monitoring storage usage?\",\\n  \"What solution should I consider if I find that I am running out of storage on my AWS instance?\",\\n  \"What command can I use to check how much storage my Docker images are using?\",\\n  \"Why does deleting Docker images not seem to free up space as expected?\",\\n  \"What additional command should be executed after removing Docker images to reclaim storage?\"\\n]',\n",
       " 'd45d2da6': '[\\n  \"What is the significance of specifying CPU and memory in HW10 Q6?\",\\n  \"Can you clarify if the CPU and memory values are actually arbitrary in context?\",\\n  \"Why does the question specifically mention a correct value for the port?\",\\n  \"What should I instead focus on regarding the CPU and memory setup in the yaml file?\",\\n  \"Could you explain how the port value is determined for this particular homework?\"\\n]',\n",
       " '59823c72': '[\\n    \"Can you explain the significance of the \\'m\\' in the CPU values found in the Kubernetes deployment.yaml file?\",\\n    \"What does a value of \\'100m\\' indicate for a container in terms of CPU resource requests?\",\\n    \"How much CPU power does \\'500m\\' represent for the container\\'s limit in Kubernetes?\",\\n    \"Why does Kubernetes utilize milliCPU units for defining resource specifications?\",\\n    \"In what scenarios would specifying CPU requirements in milliCPUs be beneficial for an application?\"\\n]',\n",
       " '665f7b27': '[\"What should I do if Kind fails to load a Docker image due to an error message about nodes not being found for the cluster?\", \"How can I successfully load a Docker image to my Kubernetes cluster when I have named my cluster using Kind?\", \"What is the command to load the Docker image if I run into issues with no nodes being found?\", \"Is there a specific flag I need to use in the Kind command to target my named cluster when loading a Docker image?\", \"What is the correct syntax for loading a Docker image into a specified cluster using Kind?\"]',\n",
       " '0a406fe0': '[\\n  \"What error message do I get if \\'kind\\' is not recognized in Windows?\",\\n  \"How do I download kind for Windows using curl?\",\\n  \"What should I rename the downloaded kind executable file to?\",\\n  \"After renaming the file to kind.exe, where should I place it?\",\\n  \"What do I need to do to ensure that kind.exe is recognized in the command line?\"\\n]',\n",
       " '64b209b0': '[\"What modifications are necessary to use kind with Rootless Docker on Linux?\", \"Are there any specific configurations needed for Rootless Podman to work with kind?\", \"Can you explain how Rootless Docker impacts running kind?\", \"What is the link to the kind documentation for Rootless configurations?\", \"Is there any troubleshooting advice for using kind with Rootless setups on Linux?\"]',\n",
       " '518c4cb8': '[\"How can I deploy the Kubernetes dashboard in our course project?\", \"Is there a specific method to access the Kubernetes dashboard?\", \"What should I do to set up the Kubernetes dashboard for visualization?\", \"Can you detail the steps for deploying the Kubernetes dashboard?\", \"Where can I find information on accessing the Kubernetes dashboard after deployment?\"]',\n",
       " '00882c83': '[\"What version of the AWS CLI do I need to use eksctl?\", \"How can I verify the version of my AWS CLI?\", \"Is there a specific version requirement for the AWS CLI in this course?\", \"Where can I find information on upgrading to AWS CLI v2?\", \"Why is it important to use AWS CLI v2 for eksctl?\"]',\n",
       " 'd6d483ce': '[\\n    \"What error did I encounter when testing a Flask service in video 10.3?\",\\n    \"What command did I run in one terminal before encountering the error while running gateway.py?\",\\n    \"What specific versions of Flask and Werkzeug did I find using pip freeze?\",\\n    \"What is the underlying cause of the TypeError related to Flask and Werkzeug versions?\",\\n    \"How did I resolve the version conflict that caused the error when importing Flask?\"\\n]',\n",
       " 'f9711723': '[\"What should I do if the command aws ecr get-login --no-include-email gives me an error regarding an invalid choice?\", \"Can you provide the proper command for logging into AWS ECR using Docker?\", \"Is there a way to run the login command without modifying any fields if I have a default region set?\", \"Where can I find the official AWS documentation that relates to pushing images to ECR?\", \"What specific parts of the command do I need to change when using aws ecr get-login-password?\"]',\n",
       " '5bda3b94': '[\"What should I do if I encounter an error when trying to download tensorflow/serving:2.7.0 on my Apple M1 Mac?\", \"Can you explain the error message I might see when running the Docker code for TensorFlow Serving on an M1 Mac?\", \"What is a possible solution to resolve the issue with TensorFlow Serving on the Apple M1 Mac?\", \"How can I run TensorFlow Serving properly on my M1 Mac without facing errors?\", \"Is there an alternative Docker image that I can use for TensorFlow Serving on Apple M1 Macs?\"]',\n",
       " 'cccd31cf': '[\\n  \"What type of error do I encounter when using the tensorflow/serving image on a Mac M2 with Apple Silicon?\",\\n  \"Can you explain why I might be getting an \\'Illegal instruction\\' error when running my docker command?\",\\n  \"What is the reason behind the recommendations for using a different base image for TensorFlow Serving?\",\\n  \"How can I successfully run TensorFlow Serving on my Mac M2 without encountering the illegal instruction error?\",\\n  \"What are the necessary steps to set up TensorFlow Serving using bitnami/tensorflow-serving image in Docker?\"\\n]',\n",
       " '57f49999': '[\\n    \"What could be the reason for the HPA showing \\'Unknown\\' for CPU metrics?\",\\n    \"What steps should I take if my HPA fails to get CPU utilization?\",\\n    \"How do I delete the existing HPA if it is not fetching metrics correctly?\",\\n    \"What file do I need to apply to resolve the CPU metrics issue with HPA?\",\\n    \"After applying the metrics file, what should I do next to recreate the HPA?\"\\n]',\n",
       " '5cb58698': '[\"What should I do if I encounter errors with Istio during the KServe installation process?\", \"How can I verify the version of kubectl I have installed before attempting to install KServe?\", \"What changes do I need to make to the \\'quick_install.bash\\' file before running it?\", \"Where can I find the version matrix for Istio and Knative to ensure compatibility with KServe?\", \"What is the command to download and edit the \\'quick_install.bash\\' file without executing it?\"]',\n",
       " 'de650b41': '[\"What should I include in the problem title for my project?\", \"Can you clarify what needs to be covered in the problem description?\", \"Is there a specific format for the solution description section?\", \"Are there guidelines on who can add information to the project?\",\\n\"What information is optional for the project submissions?\"]',\n",
       " '9ffacaac': '[\"What are the specific deadlines for the projects in this course?\", \"Where can I find the deadlines for my cohort\\'s projects?\", \"Are the deadlines for the midterm and capstone projects the same for all cohorts?\", \"Is there a specific link to view the project deadlines for my group?\", \"How do I access the cohort folder to find my project\\'s deadlines?\"]',\n",
       " '4dfb5d4f': '[\\n  \"Do I need to work alone on my midterm project?\",\\n  \"Are the capstone projects assigned as group activities or individual efforts?\",\\n  \"Is collaboration allowed for midterm and capstone assignments?\",\\n  \"Can I team up with classmates for my midterm project?\",\\n  \"Are midterm and capstone projects designed for individual completion?\"\\n]',\n",
       " '0b8739b7': '[\\n  \"What is the recommended scope of modules for the midterm and capstone projects in this course?\",\\n  \"Are there any specific topics or problem sets that I should focus on for my midterm project?\",\\n  \"Can I incorporate additional content not covered in the syllabus into my capstone project?\",\\n  \"Where can I find past office hours from earlier cohorts for additional guidance?\",\\n  \"How do I access the DTC YouTube channel to look for resources regarding the course?\"\\n]',\n",
       " '9eb52679': '[\\n    \"Are there specific links that I should refer to for my Midterm and Capstone projects, and do these links vary by cohort?\",\\n    \"If I want to submit my Midterm Project, where can I find the submission form?\",\\n    \"What is the first step I should take when starting on my project regarding problem selection?\",\\n    \"Can you clarify what I need to do after preparing my data and performing exploratory data analysis?\",\\n    \"Where can I find datasets to use for my project, and are there multiple sources available?\"\\n]',\n",
       " '7a1fcfd9': '[\\n    \"What are the steps to perform peer reviews for the projects in this course?\",\\n    \"Where can I find the instructions for conducting peer reviews for my projects?\",\\n    \"Is there a specific format or platform we will use to submit our peer reviews?\",\\n    \"When will the links to the submitted projects be available for review?\",\\n    \"Who is responsible for compiling the list of projects for peer review in this course?\"\\n]',\n",
       " '1cfa62c5': '[\\n    \"What should I refer to for guidance on computing the hash for my project review?\",\\n    \"Where can I find information about the hash computation for my project?\",\\n    \"Is there a specific resource that explains how to compute the hash for the project review?\",\\n    \"Can you direct me to the answer regarding hash computation for projects?\",\\n    \"What is the procedure for calculating the hash needed for project review?\"\\n]',\n",
       " '2a78f52e': '[\\n  \"What is the total value assigned to the learning in public for the midterm project?\",\\n  \"How many posts are required for the learning in public component for the midterm project?\",\\n  \"Do we need to create seven posts for each module, or is there a different requirement?\",\\n  \"Is the expectation for the learning in public to be fulfilled in a single post worth 14, or is it separate entries?\",\\n  \"Are we supposed to make a post for each day during the project period?\"  \\n]',\n",
       " '68aeab64': '[\"What should I do if my dataset exceeds GitHub\\'s size limits?\", \"Is there a method to handle large files for my project on GitHub?\", \"How can I upload a large dataset to GitHub without issues?\", \"Can anyone suggest a solution for managing oversized files in my repository?\", \"What tool can I use to upload large datasets to my GitHub project?\"]',\n",
       " '9a7c26e0': '[\"What happens if I only submit two projects and don\\'t submit the third one?\", \"Do I still get the course certificate if I submit two projects?\", \"Is it necessary to submit three projects to receive the certificate?\", \"What are the submission requirements for obtaining the course certificate?\", \"Who should I contact for questions regarding project submissions?\"]',\n",
       " '1fd83eb9': '[\\n  \"Do I need to complete all projects to avoid peer reviews in the capstone?\",\\n  \"Is it true that I only need to submit my project to be assigned a peer review?\",\\n  \"If I skip the last project, will I still have to review peers for my submission?\",\\n  \"How does submitting my project relate to the requirement for peer reviews?\",\\n  \"Who confirmed the information about peer reviews and project submissions?\"\\n]',\n",
       " 'fbaa5b20': '[\"What is the minimum number of models I need to train for my midterm project?\", \"Can you clarify how many models are considered multiple for the midterm requirements?\", \"Is there a recommended limit to the number of models I should train for my project?\", \"Could you explain the importance of training multiple models for the midterm deliverables?\", \"What does training multiple models involve in the context of my midterm assignment?\"]',\n",
       " '37eab341': '[\\n    \"What steps do I need to follow to find my assigned peer projects for evaluation?\",\\n    \"Can I choose any capstone project to review, or is there a specific assignment I need to follow?\",\\n    \"How do I calculate the hash value of my email address for the project evaluation?\",\\n    \"Where can I access the list of all submitted projects that I need to evaluate as a peer reviewer?\",\\n    \"What is the process for locating my peer project based on the hashed email value after generating it?\"\\n]',\n",
       " '57754faf': '[\\n    \"Is the project grading based on individual scores or average scores of the class?\",\\n    \"How is the passing criteria determined for the project?\",\\n    \"Does everyone’s scores influence my project passing status?\",\\n    \"Will my project score be evaluated in relation to my classmates’ scores?\",\\n    \"Who provided the explanation about the project grading system?\"\\n]',\n",
       " '6979c5d1': '[\"What is the purpose of submitting a train.py file if I have already shared a notebook file?\", \"How will my peers utilize the train.py file during the project review?\", \"Why is it necessary for the train.py file to function on a different system?\", \"In what way should the train.py file be integrated with my project environment?\", \"Can you explain the importance of including the train.py file alongside my notebook?\"]',\n",
       " 'a1bd8c34': '[\"How do I install the PILLOW library for my project?\", \"What is the process to load an image using PILLOW?\", \"Which module do I need to import to convert an image to a numpy array?\", \"Can you provide a sample code for converting an image to a numpy array?\", \"Who provided the information in the FAQ record?\"]',\n",
       " 'b2ab0fc1': '[\"Do I need to include a train.py file if there\\'s already a train.ipynb file in my midterm project?\", \"Why is a train.py file preferred over a train.ipynb for model training?\", \"What is the advantage of using a python script for training instead of a notebook?\", \"How do real-life training jobs typically operate regarding scripts and notebooks?\", \"Is it common practice to run training jobs with python files instead of notebooks?\"]',\n",
       " '80c439a9': '[\"What options do I have for users to input data into the model?\", \"Can I create an app specifically for form management?\", \"Is it important to validate data on the backend as well?\", \"Where can I find resources related to building a frontend for data entry?\", \"Does the course recommend any specific tools for creating user interfaces?\"]',\n",
       " 'ff93b86e': '[\"What method should I use to obtain feature importance from an XGBoost model?\", \"What error might occur when using feature_importances_ with an XGBoost model?\", \"How should I train my model to avoid the feature_importances_ error?\", \"What is the correct method to retrieve scores if I trained my model using xgb.train?\", \"Can you explain the difference between feature_importances_ and get_score() in XGBoost?\"]',\n",
       " 'fcd86c8f': '[\\n    \"What does the error message \\'[Errno 12] Cannot allocate memory\\' mean in AWS Elastic Container Service tasks?\",\\n    \"How can I resolve the memory allocation issue in Elastic Container Service?\",\\n    \"Is there a specific solution for the \\'[Errno 12]\\' error in AWS ECS?\",\\n    \"What adjustments should I make to my task definition in AWS ECS to fix memory issues?\",\\n    \"Who provided the advice regarding increasing RAM and CPU for AWS Elastic Container Service tasks?\"\\n]',\n",
       " '236864c2': '[\\n    \"What causes the pickle error saying it can\\'t get attribute XXX on module __main__ when using waitress?\",\\n    \"Why does the pickle error not occur when running the app directly with Flask instead of through waitress?\",\\n    \"How does the custom column transformer class impact the pickle loading process when using waitress?\",\\n    \"What is the recommended solution to avoid the pickle error related to module __main__?\",\\n    \"Where can I find detailed information regarding issues with loading files using pickle and multiple modules?\"\\n]',\n",
       " 'efc4a04f': '[\\n  \"What are some techniques to deal with outliers in my dataset?\",\\n  \"Can you explain the method of log transformation for outlier handling?\",\\n  \"Is it acceptable to drop observations when managing outliers?\",\\n  \"What does clipping high values mean in the context of outliers?\",\\n  \"Are there common practices used to transform datasets with outliers?\"\\n]',\n",
       " '15f361b7': '[\\n    \"What was the error message I encountered when trying to create a Docker image using BentoML?\",\\n    \"What specific module was not found that caused the failed loading of the Bento?\",\\n    \"Which package was incorrectly listed in the bentofile.yaml that led to the issue?\",\\n    \"How was the problem with the module import resolved in the bentofile.yaml?\",\\n    \"What are the correct package names to include in the packages list for the service?\"\\n]',\n",
       " 'dbbce78b': '[\\n    \"What error might I encounter when using BentoML with the --production flag and how does it manifest in the swagger UI?\",\\n    \"What is a potential cause for the error related to sparse matrices when running bentoml serve?\",\\n    \"How does the setting of DictVectorizer or OHE to sparse during training affect the model when it is called in service.py?\",\\n    \"Why does inconsistent length of sparse matrices prevent batching in my BentoML model when it is served?\",\\n    \"What should I set the batchable parameter to in the bentoml model signatures for production if I\\'m using sparse matrices?\"\\n]',\n",
       " 'f3a00e15': '[\"Is it necessary for us to execute every file provided in the course materials?\", \"What should I do if I\\'m unable to run all the provided files, particularly the neural networks?\", \"How can I ensure that I have everything needed for reproducibility?\", \"What steps can I take to verify that there are no obvious errors in the provided materials?\", \"Where can I find the related Slack conversation for further clarification on reproducibility?\"]',\n",
       " '9102b3c0': '[\\n  \"What should I do if my model exceeds the size limit for GitHub?\",\\n  \"How can I compress my model to fit it on GitHub?\",\\n  \"Is there a specific library or method recommended for compressing large models?\",\\n  \"What happens when I use joblib for compression?\",\\n  \"How long does it usually take to compress a model with joblib?\"\\n]',\n",
       " '70d89fdf': '[\"What should I do if I encounter an unauthorized error when pushing an image to Google Container Registry?\", \"How can I configure my Docker to push to Google Container Registry?\", \"What installation is required before using gcloud in the console?\", \"What command do I need to run to resolve permission issues with Google Container Registry?\", \"Who provided the instructions for resolving the push permission issue?\"]',\n",
       " 'c5d6a804': '[\\n    \"What error message did I receive while trying to install tflite_runtime in my pipenv environment?\",\\n    \"Why can\\'t I find a version of tflite_runtime that works with Python 3.10?\",\\n    \"What version of Python do I need to install in order to successfully install tflite_runtime?\",\\n    \"Where can I check for all available versions of tflite_runtime?\",\\n    \"What should I do if I cannot find a suitable tflite_runtime version for my setup?\"\\n]',\n",
       " '8c7f089f': '[\\n    \"What could cause an error when using ImageDataGenerator.flow_from_dataframe?\",\\n    \"How can I resolve the \\'name \\'scipy\\' is not defined\\' error?\",\\n    \"Is there a specific library I need to have installed for ImageDataGenerator?\",\\n    \"What steps should I take if I encounter an error related to scipy?\",\\n    \"What should I do after installing scipy regarding the Jupyter kernel?\"\\n]',\n",
       " '739bcccf': '[\"What resources are available for deploying BentoML content on Amazon Lambda?\", \"Is there a specific tutorial for using Docker containers with Amazon Lambda?\", \"Who created the video on passing BentoML content to Amazon Lambda?\", \"Can I find detailed instructions for deploying Docker containers in AWS Lambda?\", \"Where can I watch the dedicated video tutorial for this use case?\"]',\n",
       " '4603e4e5': '[\\n    \"What do I do if I encounter an UnidentifiedImageError when working on my model?\",\\n    \"Can you explain what causes the UnidentifiedImageError related to image files?\",\\n    \"How can I modify my image URL to avoid the IdentifiedImageError when testing locally?\",\\n    \"What is the proper format for a URL when accessing images from GitHub for my model?\",\\n    \"Is there any specific adjustment I need to make to the URL when retrieving test images?\"\\n]',\n",
       " '0a7c328e': '[\"What does it mean when I see a resolution failure warning during pipenv install?\", \"How can I resolve dependency issues if pipenv install fails?\", \"What actions can I take if there is a mismatch in sub-dependencies?\", \"Is there a command I can run to fix problems with Pipfile and Pipfile.lock?\", \"Who provided the information about resolving pipenv dependency issues?\"]',\n",
       " '77efd069': '[\\n    \"What should I do if I encounter an error stating that \\'get_feature_names()\\' is not found in my code?\",\\n    \"Why does the function \\'dv.get_feature_names()\\' work in the course but not on my local setup?\",\\n    \"Is there a chance that the \\'get_feature_names()\\' function may be removed in future library updates?\",\\n    \"What changes do I need to make to my code regarding the feature extraction method to avoid errors?\",\\n    \"Where can I find more information about the deprecation of the \\'get_feature_names()\\' function?\"\\n]',\n",
       " 'cc60f7bc': '[\\n    \"What causes the error related to decoding JSON responses during prediction tests?\",\\n    \"Can you explain what the correct format for input data should be before sending it to the server?\",\\n    \"Why is it necessary to convert input data to numpy arrays instead of using JSON format?\",\\n    \"What happens if the data sent to the server is not in the expected shape?\",\\n    \"Who provided the information about the JSON decoding error and its solution?\"\\n]',\n",
       " 'aa13dd66': '[\\n  \"What are some free cloud alternatives for deploying my projects that offer more resources than Render?\",\\n  \"Can you explain the benefits of using AWS and GCP for free instances compared to other services?\",\\n  \"Is there a cloud service that provides free GPU instances specifically for ML Zoomcamp students?\",\\n  \"How long can I expect to use the free microinstances offered by AWS and GCP?\",\\n  \"What should I do to get additional GPU hours on Saturn when signing up as a student from ML Zoomcamp?\"\\n]',\n",
       " 'c41e479c': '[\\n    \"What is the process to convert the day_of_the_month column from integer to string format in order to prepare for further calculations?\",\\n    \"How can I transform the month_of_the_year values in my DataFrame from string representations like \\'jan\\' and \\'feb\\' to their corresponding numeric values?\",\\n    \"What method do I use in pandas to create a datetime object after I have converted the day and month columns?\",\\n    \"Can you explain how to derive the day of the year from the newly created date_formatted column using pandas?\",\\n    \"In the provided solution, what specific year is used for creating the datetime object and why is this year chosen?\"\\n]',\n",
       " '2f28dcf1': '[\\n    \"How can I visualize the predictions for different classes after training my neural network?\",\\n    \"What is the procedure to create a bar chart displaying predictions per class?\",\\n    \"Can you explain the steps for plotting the output classifications of my model?\",\\n    \"What is the best way to represent predictions for each class graphically?\",\\n    \"How do I use matplotlib to visualize class predictions from my trained model?\"\\n]',\n",
       " '7a69cccf': '[\"How can I transform dictionary values into a DataFrame structure?\", \"What is the method to create a DataFrame from dictionary output values?\", \"Which function allows me to convert a dictionary\\'s values to a table format in DataFrame?\", \"Can you explain how to use the pandas library to turn a dictionary into a DataFrame?\", \"What parameters do I need to use when creating a DataFrame from a dictionary?\"]',\n",
       " '20174c95': '[\"What is the purpose of the Kitchenware Classification Competition Dataset Generator?\", \"How does the generated image dataset differ from the one used in the dino vs dragon lesson?\", \"Why did you create a script for generating the dataset?\", \"Where can I find the Kitchenware dataset generator?\", \"Who is responsible for the Kitchenware dataset generator on Kaggle?\"]',\n",
       " 'f2cd48b6': '[\\n    \"What are the initial steps for installing the CUDA toolkit and cuDNN for TensorFlow on Windows?\",\\n    \"Can you explain the options available for installing TensorFlow on Windows using Anaconda?\",\\n    \"What are the instructions for setting up CUDA on WSL or Linux for TensorFlow?\",\\n    \"How do I ensure CUDA is properly configured after installation for TensorFlow?\",\\n    \"If I want to share my progress on social media, do I need to include a link to my LinkedIn profile or post about my assignment completion?\"\\n]',\n",
       " '59b4324f': '[\\n    \"Why is the order of multiplication significant in matrix operations?\",\\n    \"What are the dimensions of the resulting matrices when multiplying A and B?\",\\n    \"Can you provide an example of how changing the multiplication order affects results?\",\\n    \"What happens if I multiply two matrices in the opposite order?\",\\n    \"Are the results of matrix multiplication always the same regardless of the order?\"\\n]',\n",
       " 'e1dc1ed9': '[\\n    \"Are there any specific installation instructions for Mac users with an M1 chip?\",\\n    \"Where can I find guidance on setting up the environment for Mac?\",\\n    \"Is there a resource available for installing the course environment on Mac?\",\\n    \"Can someone share the steps for environment installation on Mac?\",\\n    \"What link should I check for environment setup instructions for Mac with M1?\"\\n]',\n",
       " 'fc60bf3b': '[\"Will my late assignment be graded if I submit it?\", \"What determines if the assignment form is still open?\", \"How can I check if the submission form is accessible?\", \"What happens if I miss the deadline for the assignment?\", \"Is there a chance to submit past the due date?\"]',\n",
       " '1e60e888': '[\\n    \"Is it necessary for the GitHub repository to be publicly accessible?\",\\n    \"What steps should I follow to install Conda on my local system?\",\\n    \"Which integrated development environment is best suited for machine learning tasks?\",\\n    \"Who will be able to view the homework repository?\",\\n    \"What are the implications of having a private repository for my assignments?\"\\n]',\n",
       " '44552c2e': '[\"What are the steps to install wget in Google Colab?\", \"Can you explain how to download files using wget in Colab?\", \"What directory should I specify for downloading files with wget in Google Colab?\", \"Is there a command to check if wget is installed in my Google Colab environment?\", \"How can I download data from a specific URL using wget in Google Colab?\"]',\n",
       " '7116b3be': '[\"What format must features be in to work with scikit-learn?\", \"How can I convert a 1D array into a 2D array for scikit-learn?\", \"In what context is reshaping mentioned for arrays in scikit-learn?\", \"Could you give an example of filtering a DataFrame based on \\'ocean_proximity\\'?\", \"What are some key columns I should consider when selecting data for housing analysis?\"]',\n",
       " '5d4d206e': '[\\n    \"What should I do to resolve the FutureWarning I encountered while plotting with Matplotlib?\",\\n    \"Is there an alternative method recommended to avoid the deprecation warning regarding is_categorical_dtype?\",\\n    \"How can I bypass the warning that says is_categorical_dtype will be removed in future Matplotlib versions?\",\\n    \"What is the correct way to check for categorical data types to prevent the FutureWarning?\",\\n    \"Can you explain why is_categorical_dtype is being deprecated and what I should use instead?\"\\n]',\n",
       " '387093cc': '[\\n  \"What error might I encounter when rerunning the Docker file in Windows compared to WSL/Linux?\",\\n  \"How can I resolve the issue of Python 3.11 not being found on my system when using Docker?\",\\n  \"What should I do if neither \\'pipenv\\' nor \\'asdf\\' is available to install Python on my Windows setup?\",\\n  \"Is there a specific procedure I need to follow to add the Python311 installation folder to my PATH?\",\\n  \"What steps should I take after modifying the PATH to ensure my Docker file runs successfully again?\"\\n]',\n",
       " 'd12a2657': '[\\n    \"What are the steps involved in deploying a project to DigitalOcean App Cloud?\",\\n    \"How much does it cost to deploy a project on DigitalOcean each month?\",\\n    \"What should I do if my project is not located in the root of the repository when deploying?\",\\n    \"Is there anything important I need to remember about the Dockerfile during the deployment process?\",\\n    \"Do I need to manually add model files during the container build process, or are they added automatically?\"\\n]',\n",
       " 'eb7a57a6': '[\\n    \"What do the lessons in week 3 tell us about feature importance for categorical values?\",\\n    \"In lesson 3.10, which model is trained using all categorical variables?\",\\n    \"Why might it not be sufficient to train a model only on the most important features?\",\\n    \"What should you do if excluding a feature leads to a drop in model performance?\",\\n    \"Which method among those learned in the course performs implicit feature selection?\"\\n]',\n",
       " 'd6f0c6ea': '[\\n    \"What are some effective strategies for analyzing large datasets like the New York Yellow Taxi dataset that contains over a million rows?\",\\n    \"How can I handle memory limitations when working with extensive data collections during data processing?\",\\n    \"What is the significance of using sampling during the exploratory phase of data analysis?\",\\n    \"Can you explain how optimizing data types can help in reducing memory usage when dealing with large datasets?\",\\n    \"What is Dask and how does it assist in working with large datasets in Python?\"\\n]',\n",
       " '9f261648': '[\\n    \"Is it possible to take the course using programming languages other than Python, such as R or Scala?\",\\n    \"What are the main reasons for not recommending the use of languages other than Python for the course?\",\\n    \"How might using a different programming language affect my homework submissions?\",\\n    \"Will my fellow students be able to review my work effectively if I use a language other than Python?\",\\n    \"Can I create a separate repository for personal practice if I write the course materials in another language?\"\\n]',\n",
       " 'aa7ff0f7': '[\"Are libraries such as fast.ai or huggingface permitted for use in the capstone project?\", \"Is it acceptable to use tools like fast.ai and huggingface during the competition?\", \"What is the stance on using fast.ai or huggingface in our final project?\", \"Are there any restrictions on using libraries like fast.ai and huggingface for the capstone?\", \"Can I utilize libraries such as fast.ai or huggingface in the competition without issues?\"]',\n",
       " '387bdc5f': '[\"What should I check if my TensorFlow Serving image fails to test successfully?\", \"How can I ensure that my TF versions are compatible for serving?\", \"Is there a specific version for TF Serving that I should be aware of?\", \"Why was the Flask image tested successfully while TensorFlow Serving wasn\\'t?\", \"Where can I find more information about matching TF and TF Serving versions?\"]',\n",
       " 'c6a22665': '[\\n  \"What are some suggested titles to use when listing my Machine Learning Zoomcamp experience on LinkedIn?\",\\n  \"Can I categorize my experience with DataTalksClub as an official job or internship?\",\\n  \"Which LinkedIn sections are suitable for showcasing my DataTalksClub experience?\",\\n  \"How can I highlight my Machine Learning project on my CV?\",\\n  \"What additional tips are there for sharing my progress on LinkedIn?\"\\n]',\n",
       " '0560e827': '[\\n  \"What is the purpose of the MLOps Zoomcamp FAQ document?\",\\n  \"How was the FAQ document structured for the data engineering course?\",\\n  \"Are there specific formats recommended for posing questions in the FAQ?\",\\n  \"What kind of information can I find in the FAQ?\",\\n  \"Is it possible to see examples of questions and answers in the document?\"\\n]',\n",
       " '59812e77': '[\\n    \"How long does the course typically take to complete in total?\",\\n    \"What is the time frame for each individual module in the course?\",\\n    \"Are there any options for extending deadlines for the modules?\",\\n    \"What is the duration allocated for working on the final capstone project?\",\\n    \"How much time is set aside for the peer review process at the end of the course?\"\\n]',\n",
       " 'dce0bb09': '[\"What modules are new in the 2023 course compared to 2022?\", \"Will the videos for the Orchestration and Monitoring modules be updated?\", \"Are the homeworks for the 2023 cohort different from the previous year?\", \"Can you explain the changes made between the 2022 and 2023 versions of the course?\", \"Is the overall content of the course mostly unchanged from 2022 to 2023?\"]',\n",
       " '4920d4e9': '[\\n  \"Is a new cohort scheduled for 2024?\",\\n  \"When is the beginning date for the 2024 cohort?\",\\n  \"Can you confirm if there will be a cohort next year?\",\\n  \"What month will the 2024 cohort launch?\",\\n  \"Are we expecting a cohort to be available in May 2024?\"\\n]',\n",
       " '0f1d2765': '[\\n    \"How should I handle my answer if it differs slightly from the options given?\",\\n    \"What steps should I take if my response doesn\\'t match the provided choices?\",\\n    \"Am I allowed to share my answer in the course\\'s slack channel if it isn\\'t a perfect match?\",\\n    \"What should I do if I feel that none of the choices accurately reflect my answer?\",\\n    \"Is there a specific way to select the best option if my answer is not an exact match?\"\\n]',\n",
       " '4eef2f81': '[\"Can students select their own subjects for the final project?\", \"Are there recommended sources for datasets for our final project?\", \"Is it acceptable to work on a problem of personal interest for the final assignment?\", \"Where can I find datasets to use for the final project?\", \"Do we have the freedom to choose the issue we want to address in our final project?\"]',\n",
       " '7f93c032': '[\"Is completing weekly homework essential for graduation?\", \"What happens if I miss homework for week x?\", \"Do I need to finish all homework to get my certificate?\", \"How does optional homework affect my course ranking?\", \"Is the final capstone project the only requirement for graduation?\"]',\n",
       " 'ee6f7c89': '[\\n  \"For my final project, do I have to deploy it on the cloud?\",\\n  \"Is using Kubernetes necessary for cloud points in the final project?\",\\n  \"Can I receive cloud points for a local deployment of my project?\",\\n  \"Is it acceptable to simulate AWS for the project without using the cloud?\",\\n  \"What options do I have for cloud points if I choose not to use a cloud deployment?\"\\n]',\n",
       " 'b63b12e0': '[\\n    \"How can I set up port-forwarding for Jupyter Notebook if I\\'m not using Visual Studio Code?\",\\n    \"What specific line do I need to add to my ~/.ssh/config file for automating port-forwarding?\",\\n    \"Which command should I use to launch Jupyter Notebook on port 8899 without opening a browser?\",\\n    \"After setting up port-forwarding, how do I access my Jupyter Notebook in a web browser?\",\\n    \"Where should I add the LocalForward line in my SSH configuration for it to work correctly?\"\\n]',\n",
       " '892c22c1': '[\\n    \"How can I open Jupyter notebooks in Visual Studio Code?\",\\n    \"What do I need to install to use Jupyter in VSCode?\",\\n    \"Is there a specific extension for Jupyter in Visual Studio Code?\",\\n    \"Can I use Jupyter notebooks within VSCode?\",\\n    \"What steps are necessary to access Jupyter in VSCode?\"\\n]',\n",
       " '13d38e8d': '[\\n  \"What steps should I follow to configure GitHub for use with the remote virtual machine?\",\\n  \"Are there any recommended tutorials for setting up a GitHub repository for homework assignments?\",\\n  \"How can I set up GitHub on an AWS instance effectively?\",\\n  \"Is there a specific guide for configuring keys on an AWS instance?\",\\n  \"Once set up, will I be able to push my changes to the repository without issues?\"\\n]',\n",
       " '7d64e9e0': '[\"What steps should I follow to open Jupyter Notebook in AWS?\", \"What issue did I encounter when trying to access Jupyter from my desktop?\", \"What command do I need to run to generate the Jupyter Notebook configuration file?\", \"Which file do I need to edit to change the Jupyter Notebook settings?\", \"What specific line should I add to the jupyter_notebook_config.py file to resolve the access issue?\"]',\n",
       " '645f0a55': '[\\n    \"What are the steps to set up WSL on my Windows machine for this course?\",\\n    \"How can I download Anaconda once I\\'ve installed WSL?\",\\n    \"Is there a command I need to run to get Docker Desktop working with WSL?\",\\n    \"What is the command for cloning a GitHub repository for our study materials?\",\\n    \"How do I install Jupyter within the WSL environment for the course assignments?\"\\n]',\n",
       " '7297b7fc': '[\\n  \"What steps should I follow to effectively create a .gitignore file for my project?\",\\n  \"How can I exclude all files in a specific folder from being pushed to my remote repository?\",\\n  \"Is there a way to ignore multiple file types with a single rule in the .gitignore file?\",\\n  \"Where can I find more detailed information about using .gitignore rules and patterns?\",\\n  \"What file extension will I need to specify in my .gitignore file to ignore all parquet files?\"\\n]',\n",
       " '68154f64': '[\\n  \"What visual indicators can I look for to confirm the status of my EC2 instance when I stop it?\",\\n  \"Are there any additional charges I should expect even after stopping my EC2 instance?\",\\n  \"What happens to data that is uploaded to an EC2 instance once it is stopped?\",\\n  \"Is there a method to receive notifications or alerts regarding my billing on AWS services?\",\\n  \"Can you provide guidance on how to set up billing alerts for my AWS account?\"\\n]',\n",
       " 'dc7b6f51': '[\\n    \"How can I obtain an invitation code for IBM Cloud?\",\\n    \"What is the process to verify my account on IBM Cloud?\",\\n    \"Are there any significant differences between IBM Cloud and AWS?\",\\n    \"Is there a resource where I can learn more about IBM Cloud features?\",\\n    \"Can you share your personal experience with IBM Cloud?\"\\n]',\n",
       " 'b25c6ca3': '[\\n  \"What strategies can I use to minimize costs while running an AWS instance during this course?\",\\n  \"If I run my AWS instance for around 5 hours each day, what would my estimated monthly cost be?\",\\n  \"How will using the AWS instance affect my public IP address when I restart it?\",\\n  \"Is it possible to receive alerts if I exceed my budget for AWS expenses?\",\\n  \"Where can I find a tutorial to help me set up budget alerts in AWS?\"\\n]',\n",
       " '9f69ca26': '[\"Can I complete the course using only the AWS free tier?\", \"Are there any AWS services that are not included in the free tier?\", \"Will I need to use localstack for certain tasks in this course?\", \"Is it necessary to pay for AWS services while taking this course?\", \"Which specific AWS services should I be aware of that are not part of the free tier?\"]',\n",
       " '0f1ddc9e': '[\\n    \"What should I do if I encounter the error message \\'This site can’t be reached\\' when trying to access an AWS EC2 instance using its IP address?\",\\n    \"Is it necessary to open the IP address of my AWS EC2 instance in a browser for it to work?\",\\n    \"How can I connect to my running AWS EC2 instance from my local machine?\",\\n    \"What command should I use to connect to an EC2 instance with a specific IP address and key file?\",\\n    \"What is the proper location for storing the downloaded key file when connecting to an AWS EC2 instance?\"\\n]',\n",
       " '01f61154': '[\"What does the error message \\'unprotected private key file\\' indicate when using SSH?\", \"Can you explain how to resolve the \\'unprotected private key file\\' error when connecting to an EC2 instance?\", \"What command is needed to fix the file permissions of my private key file?\", \"Where can I find a resource that provides guidance on fixing SSH permission errors?\", \"What permission level should I set for my private key file to avoid security issues?\"]',\n",
       " 'd43c32ba': '[\\n    \"What could be causing my AWS EC2 instance to drop my SSH connection intermittently?\",\\n    \"How can I troubleshoot recurring SSH connection issues with my AWS EC2 instance?\",\\n    \"Is there a reason why my SSH connection drops only after running specific code like \\'import mlflow\\'?\",\\n    \"What steps can I take to reconnect to my EC2 instance after losing the SSH connection?\",\\n    \"How can I prevent my instance from running out of memory and causing SSH disconnections?\"\\n]',\n",
       " 'a044d267': '[\"What happens to my EC2 instance\\'s IP address when I restart it?\", \"How can I avoid manually updating the config file for my EC2 instance\\'s IP?\", \"Is there a solution for automatically updating the IP address on my EC2 instance?\", \"Where can I find a script to help with IP address updates for EC2?\", \"Does the IP address change every time I restart my EC2 instance?\"]',\n",
       " 'abf8ccdc': '[\"What should I do if I experience crashes in VS Code while trying to connect to Jupyter?\", \"How can I ensure that my instance has sufficient compute resources for running Jupyter with VS Code?\", \"Is there a specific instance type recommended for using Jupyter in VS Code without crashes?\", \"Where can I monitor the performance of my EC2 instance while running Jupyter?\", \"What steps can I take to prevent VS Code from crashing during Jupyter usage?\"]',\n",
       " '26918af3': '[\"What should I do if I encounter a ValueError stating that X has 526 features while expecting 525 features in my Linear Regression Model?\", \"How can I fix the problem of having a mismatch in the number of features when running my validation dataset?\", \"What is the purpose of using transform instead of fit_transform when working with DictVectorizer on my validation dataset?\", \"What steps do I need to take to ensure that my validation dataset has the correct feature mapping after training?\", \"Why does the DictVectorizer throw an error regarding the number of features during my Linear Regression Model execution?\"]',\n",
       " 'a5234ac0': '[\\n    \"What should I do if I encounter missing dependencies while working on Module 1?\",\\n    \"Which packages do I need to install to resolve the missing dependencies issue?\",\\n    \"How can I specifically fix the error related to pandas.read_parquet()?\",\\n    \"Is there a difference between using pip and Conda for installing the necessary packages?\",\\n    \"What package is recommended for installation if I am using Conda instead of pip?\"\\n]',\n",
       " 'af22c52a': '[\\n    \"What should I do if the RMSE I calculate does not match the options provided?\",\\n    \"How can I filter outliers when evaluating the model on the February data?\",\\n    \"Is there a specific method to round my RMSE result to two decimal points?\",\\n    \"What is the warning about deprecated Python modules, and how can I address it?\",\\n    \"How can I handle null values in my dataset to improve RMSE calculations?\"\\n]',\n",
       " '2aaac94c': '[\\n  \"What is the method for substituting distplot with histplot in my code?\",\\n  \"Can you provide an example of how to implement histplot in place of distplot?\",\\n  \"What additional parameters should I consider when using histplot instead of distplot?\",\\n  \"How do I ensure that the output of histplot closely matches that of distplot?\",\\n  \"Is it necessary to adjust any settings when transitioning from distplot to histplot?\"\\n]',\n",
       " '9d15c9e9': '[\\n    \"What should I do if I encounter a KeyError related to \\'PULocationID\\' or \\'DOLocationID\\'?\",\\n    \"Can you explain how to fix the error involving \\'PULocationID\\' or \\'DOLocationID\\'?\",\\n    \"What is the recommended way to resolve a KeyError for those specific identifiers?\",\\n    \"How can I address a KeyError that mentions \\'PULocationID\\' or \\'DOLocationID\\' in my work?\",\\n    \"What adjustment is needed to fix the KeyError associated with those location IDs?\"\\n]',\n",
       " '79b88d0b': '[\\n    \"What issue did you encounter when attempting to read large parquet files?\",\\n    \"What error message did you receive while trying to read the parquet file in Jupyter?\",\\n    \"How did you resolve the problem with the large parquet file?\",\\n    \"What suggestion was given regarding using a different library for reading large parquet files?\",\\n    \"Who reported the initial problem with reading large parquet files?\"\\n]',\n",
       " '45485322': '[\\n    \"What should I do to improve the speed of my distplot?\",\\n    \"Are there any specific data points I need to consider before plotting?\",\\n    \"How can I identify trips with unusual duration?\",\\n    \"What steps can I take to handle outliers in my dataset?\",\\n    \"Is it necessary to remove outliers prior to creating a distplot?\"\\n]',\n",
       " 'd5eab395': '[\\n    \"What could be the reason for experiencing a high RMSE on the test set during the model evaluation?\",\\n    \"How does the usage of OneHotEncoder with handle_unknown set to \\'ignore\\' affect the test set RMSE?\",\\n    \"Are there alternative transformers that can be used instead of OneHotEncoder to avoid high RMSE issues?\",\\n    \"In what way do OneHotEncoder and DictVectorizer differ when processing categorical features for the homework?\",\\n    \"How are unknown categories represented in the hot-encoded matrix to ensure proper RMSE results?\"\\n]',\n",
       " '282957fb': '[\\n    \"What are the differences in handling missing data between OneHotEncoder and DictVectorizer as discussed in the module?\",\\n    \"How might using OneHotEncoder affect the consistency of columns in training and validation datasets?\",\\n    \"Can you explain why DictVectorizer ignores missing data during training according to the FAQ record?\",\\n    \"Are there any video resources available that address the use of OneHotEncoder instead of DictVectorizer?\",\\n    \"Where can I find additional sources for understanding when to use OneHotEncoder versus DictVectorizer?\"\\n]',\n",
       " '39ad14fd': '[\\n    \"What are the advantages of using DictVectorizer over OneHotEncoder in our module?\",\\n    \"Can you explain why we opted for DictVectorizer instead of get_dummies from pandas for one-hot encoding?\",\\n    \"Is OneHotEncoder from scikit-learn considered less useful compared to DictVectorizer in this context?\",\\n    \"Are there alternative methods for one-hot encoding besides DictVectorizer and OneHotEncoder that we should be aware of?\",\\n    \"What specific matrix outputs does DictVectorizer support that might differ from OneHotEncoder?\"\\n]',\n",
       " 'e34df2a5': '[\"What method can I use to confirm that outliers have been successfully removed from the dataset?\", \"How can I utilize pandas to gain insights into the data distribution after outlier removal?\", \"Which pandas function offers a summary report of the data\\'s statistical characteristics?\", \"Can I check the minimum and maximum values of a specific column after applying a boolean expression for clipping?\", \"What kind of statistics will determine the status of outliers in my data analysis?\"]',\n",
       " 'c91b6b57': '[\\n    \"What method can I use to create one-hot encoding for pickup and drop-off locations?\",\\n    \"How do I handle NaN values in the PUlocationID and DOlocationID columns when encoding?\",\\n    \"Why is it necessary to convert PUlocationID and DOlocationID values to string?\",\\n    \"Does using \\'nan\\' as a string representation for NaN values affect RMSE when using DictVectorizer?\",\\n    \"Can I choose a different string representation instead of \\'-1\\' for NaN values in my dataset?\"\\n]',\n",
       " '4aa8eafc': '[\\n  \"Is it common for the RSME from LinearRegression to be very close to the actual value but not exactly the same?\",\\n  \"What should I do if my LinearRegression model is yielding slightly different RSME values on different runs?\",\\n  \"How can I ensure that my outliers are treated correctly in both the training and validation sets?\",\\n  \"What is the significance of checking the shape of the one hot encoded feature matrix?\",\\n  \"How do I properly encode the drop off and pick up codes for my LinearRegression model?\"\\n]',\n",
       " 'a9daaab0': '[\\n    \"What steps should I take if I encounter an extremely low RMSE score while training my model?\",\\n    \"How can I verify that my model is actually learning the target variable instead of just predicting it?\",\\n    \"What are the potential issues if my target variable is included as a parameter during model fitting?\",\\n    \"How can I ensure that my training data does not inadvertently include the target values?\",\\n    \"What should I do to confirm that my validation set is set up correctly in relation to my training data?\"\\n]',\n",
       " '931f9626': '[\\n    \"What is the issue with enabling auto-completion in Jupyter Notebook?\",\\n    \"How can I resolve the problem with the Tab key not functioning correctly?\",\\n    \"What specific package needs to be upgraded to enable auto-completion?\",\\n    \"Who provided the solution for enabling auto-completion in Jupyter Notebook?\",\\n    \"What version of the jedi package should I install to fix the auto-completion issue?\"\\n]',\n",
       " '782e1723': '[\\n    \"What should I do if I encounter a 403 Forbidden error while trying to download the NY Taxis datasets?\",\\n    \"Can you explain the reason behind the 403 Forbidden error when using wget to download the files?\",\\n    \"Is there a recommended approach to download the datasets without facing the access issues mentioned?\",\\n    \"Where can I find the official NYC trip record page to download the dataset directly?\",\\n    \"How can I modify the dataset link to avoid the forbidden access error while downloading?\"\\n]',\n",
       " '4e08c86a': '[\\n    \"What should I do if PyCharm does not recognize the conda environment path during remote development?\",\\n    \"How can I activate my conda environment on a remote server to ensure it works with PyCharm?\",\\n    \"What command do I need to use in the command line to find the Python execution path for my conda environment?\",\\n    \"Can you explain the steps to add a new interpreter in PyCharm after obtaining the Python path?\",\\n    \"Is it necessary to use a specific command to activate the conda environment before using it in PyCharm on a remote server?\"\\n]',\n",
       " '34bcad27': '[\\n    \"What memory issues might I encounter when using DictVectorizer?\",\\n    \"Why did my linear regression model fail to run on my 16 GB machine?\",\\n    \"How can I reduce memory usage when using DictVectorizer?\",\\n    \"What happens if I set the \\'sparse\\' parameter to False in DictVectorizer?\",\\n    \"What is the default setting for the \\'sparse\\' parameter in DictVectorizer?\"\\n]',\n",
       " '96144e66': '[\\n  \"What should I do if Anaconda didn\\'t update my .bashrc after installation?\",\\n  \"How can I add Anaconda entries to my .bashrc if they are missing?\",\\n  \"What commands do I need to run to initialize the conda environment in bash?\",\\n  \"Is there a way to automatically edit my .bashrc for Anaconda configuration?\",\\n  \"What command do I use to reload my .bashrc after making changes?\"\\n]',\n",
       " '840f739d': '[\\n    \"Why are the feature sizes different for the training and validation data sets?\",\\n    \"What specific operation should I use on the dictionary vectorizer during HW1?\",\\n    \"Is it necessary to perform \\'fit\\' on the premade dictionary vectorizer provided?\",\\n    \"What should I do instead of executing the fit pipeline on my model?\",\\n    \"Who can I reach out to if I have more questions about the module?\"\\n]',\n",
       " 'bf006ff9': '[\\n    \"What should I do if I encounter a \\'Permission denied (publickey)\\' error after removing my public key on an AWS machine?\",\\n    \"Can you provide a guide for regaining access to my instance after losing my public key?\",\\n    \"Which command do I need to use to retrieve my old public key after removing it?\",\\n    \"Is there a link that can help me log in to my instance via Session Manager to recreate my public key?\",\\n    \"Where can I find additional information about retrieving a public key on AWS EC2?\"  \\n]',\n",
       " 'f178d4a0': '[\\n  \"What is the reason behind getting an excessively high RMSE for the validation dataset?\",\\n  \"Why is it important to ensure that the validation dataset is treated similarly to the training dataset?\",\\n  \"Can you explain what steps were taken to remove outliers from the February dataset?\",\\n  \"What issues arise from converting the sparsematrix result from DictVectorizer into an ndarray?\",\\n  \"How did you resolve the problem with obtaining the correct RMSE results?\"\\n]',\n",
       " 'b80401a2': '[\\n    \"What should I do if I\\'m unable to import sklearn in my project?\",\\n    \"How can I resolve the issue with importing DictVectorizer from sklearn.feature_extraction?\",\\n    \"Is there a specific command I need to run to fix sklearn import issues?\",\\n    \"What error signal indicates trouble with sklearn imports in my code?\",\\n    \"Who experienced a similar issue with sklearn and how did they fix it?\"\\n]',\n",
       " '88002d35': '[\"Why am I unable to access Localhost:5000?\", \"What should I do if I encounter an authorization issue on Localhost?\", \"How can I resolve the problem with Localhost Denied messages?\", \"Is there a specific solution for Chrome users facing access issues?\", \"What does flushing socket pools do in resolving this authorization problem?\"]',\n",
       " 'fe61aa5b': '[\\n    \"What should I do if I encounter a message indicating that port 5000 is already in use?\",\\n    \"How can I identify the process that is currently using port 5000 on my Mac terminal?\",\\n    \"What command can I execute to terminate the process using port 5000 after finding its process ID?\",\\n    \"Is there a command available that can forcibly kill all processes using port 5000 at once?\",\\n    \"If I want to avoid the conflict with port 5000, what alternative port can I use when launching the MLflow UI?\"\\n]',\n",
       " 'b9adeb39': '[\\n    \"What does the error \\'ValueError: could not convert string to float\\' indicate when I run register_model.py?\",\\n    \"Can you explain the significance of the \\'with\\' statement in the objective function for logging parameters?\",\\n    \"What modifications should I make to prevent the parameters from being logged in a group?\",\\n    \"Where should I place the mlflow.log_params function in my hyper-parameter tuning code?\",\\n    \"What effect does the order of parameter logging have on the execution of register_model.py?\"\\n]',\n",
       " 'ebc13686': '[\\n    \"What should I do if I can\\'t see my experiment in the MLflow UI?\",\\n    \"How can I ensure that MLflow UI launches from the correct directory?\",\\n    \"What is the correct format for specifying the tracking URI if my database is located in a subdirectory?\",\\n    \"Is there a way to use an absolute path for the mlflow.db instead of a relative one?\",\\n    \"Can I launch the MLflow UI directly from my notebook, and if so, how?\"\\n]',\n",
       " '939f9c33': '[\"What specific error message might I encounter when trying to install MLFlow with pip on Windows?\", \"What could cause the hash mismatch error while installing the Numpy package through MLFlow?\", \"What steps can I take to resolve the issue of package hashes not matching during installation?\", \"If I experience the hash mismatch error, what alternative approach might help in successfully installing MLFlow?\", \"Is there a possibility that the hash mismatch issue could be related to tampering with the package contents?\"]',\n",
       " 'b5c3e6af': '[\\n    \"What are the steps required to ensure an experiment is completely removed from the MLFlow database?\",\\n    \"Is it true that an experiment remains in the database even after it\\'s deleted from the UI?\",\\n    \"Can you explain how to install the necessary package for using SQL in Jupyter notebooks?\",\\n    \"Which command should I use to load the SQLite database in my notebook?\",\\n    \"What SQL command do I need to execute to permanently delete an experiment from the database?\"\\n]',\n",
       " '80554fc2': '[\\n    \"What should I do to avoid losing my changes when trying to update from a public repository?\",\\n    \"Is it necessary to fork a repo instead of cloning it if I want to keep my changes?\",\\n    \"Can you explain how to fetch and merge updates from the upstream repository?\",\\n    \"What are the steps to configure my Git settings to work with my own repository?\",\\n    \"Where can I find the option to fetch and merge updates on GitHub?\"\\n]',\n",
       " '943df153': '[\\n    \"What is the maximum allowable image size for the module?\",\\n    \"How can I resolve the issue of image size exceeding the limit?\",\\n    \"Which specific version of xgboost causes the large image size issue?\",\\n    \"What command do I need to run to downgrade to xgboost version 1.6.0?\",\\n    \"Is there an alternative way to change the xgboost version in my project?\"\\n]',\n",
       " 'b8d3c55e': '[\"What should I use instead of the deprecated list_experiments method?\", \"What happened to the list_experiments method in version 1.29?\", \"Is the list_experiments method still available in the latest version?\", \"Who provided the information regarding the change in the MlflowClient object?\", \"What is the recommended method to track experiments now?\"]',\n",
       " '67bf60c6': '[\\n    \"What should I check if MLflow Autolog is not functioning as expected?\",\\n    \"Where should I place the mlflow.autolog() function in my code?\",\\n    \"Are there specific packages I need to install for the autologger to work properly?\",\\n    \"What happens if I forget to install the required dependencies for autologging?\",\\n    \"Will I receive any notifications if some dependencies for autologging are missing?\"\\n]',\n",
       " '336f5e36': '[\\n    \"What should I do if the MLflow URL doesn\\'t open when I try to access it?\",\\n    \"How can I forward the port for MLflow if I\\'m using a remote virtual machine?\",\\n    \"Is there a different URL I can try if 127.0.0.1:5000 displays a blank page?\",\\n    \"What steps should I take to connect my server to VS Code for MLflow?\",\\n    \"Do I need to add a specific port number when accessing MLflow in VS Code?\"\\n]',\n",
       " 'fd2b9972': '[\\n    \"What should I do if I encounter a warning message when using mlflow.xgboost.autolog()?\",\\n    \"How can I verify if my model has been tracked in MLflow after using autolog?\",\\n    \"Is the warning message I received regarding mlflow.xgboost.autolog() something I need to worry about?\",\\n    \"What steps should I take to ensure that there are no \\'tag\\' filters applied in the MLflow UI?\",\\n    \"Who can I contact if I experience issues with experiment tracking in MLflow?\"\\n]',\n",
       " '75cd9b7a': '[\"What should I do if I encounter an MlflowException while trying to set a deleted experiment as active?\", \"Is it possible to restore a deleted experiment in MLflow, and how would I do that?\", \"Can I permanently delete an experiment in MLflow if I no longer need it?\", \"What are my options for resolving an MlflowException related to a deleted experiment?\", \"Where can I find more information on deleting experiments in MLflow?\"]',\n",
       " '51c99586': '[\\n    \"What should I do if I encounter an OSError with Errno 28 while trying to install requirements?\",\\n    \"How can I increase the disk space on my instance if I\\'m running out of storage?\",\\n    \"What steps do I need to take to configure conda installation on an external disk?\",\\n    \"Is there a specific command I can use to confirm that my disk is properly mounted on the VM?\",\\n    \"What alternatives can I use instead of Anaconda if I need more disk space for installations?\"\\n]',\n",
       " '089c8c18': '[\\n  \"What caused the parameters mismatch in Homework Question 3?\",\\n  \"Which version of sklearn led to the incorrect number of parameters?\",\\n  \"What specific function was deprecated in the latest version of sklearn?\",\\n  \"What action did I take to resolve the parameters mismatch issue?\",\\n  \"How did upgrading sklearn help in fixing my homework problem?\"\\n]',\n",
       " 'f4b82056': '[\\n  \"What should I do if I encounter a Protobuf error when trying to install MLflow?\",\\n  \"How can I resolve the issue with MLflow if I have a version conflict with the Protobuf module?\",\\n  \"What is the recommended version of the Protobuf library to use with MLflow?\",\\n  \"What command do I need to execute to downgrade the Protobuf module to make MLflow work?\",\\n  \"I installed all the libraries as per the requirements.txt, but I\\'m facing an error. What steps can I take to fix it?\"\\n]',\n",
       " 'dd2e7dc9': '[\\n  \"How can I ensure I\\'m in the correct directory when using the mlflow ui command?\",\\n  \"What should I verify about my current directory before running mlflow ui?\",\\n  \"Is there a specific directory I need to be in for mlflow server commands?\",\\n  \"What command do I need to run after checking my current directory?\",\\n  \"How do I correctly set up Artifacts folders while using mlflow?\"\\n]',\n",
       " '3fcbd80e': '[\\n    \"How can I resolve issues with setting up MLflow for experiment tracking on Google Cloud Platform?\",\\n    \"Are there any helpful links for configuring MLflow on GCP that I can refer to?\",\\n    \"What resources are available for troubleshooting MLflow experiment tracking setup on GCP?\",\\n    \"Can you provide specific URLs to guide me through the MLflow setup process on GCP?\",\\n    \"Where can I find detailed instructions for using MLflow with Google Cloud Platform?\"\\n]',\n",
       " '924fcf47': '[\"What should I do if I encounter a warning related to MLflow autologging?\", \"Is there a recommended version of setuptools to avoid issues?\", \"How can I resolve the warning caused by Distutils in my module?\", \"What steps can I take to downgrade setuptools effectively?\", \"Which specific version of setuptools is suggested in the solution to the MLflow issue?\"]',\n",
       " '58240887': '[\"How can I sort my runs in the MLflow interface?\", \"What view should I be in to sort runs in MLflow?\", \"Is there a specific view I need to use for sorting in MLflow?\", \"Can I sort my runs in the list view of MLflow?\", \"Who provided the information about sorting runs in MLflow?\"]',\n",
       " '67d343f2': '[\\n    \"What issue might I encounter when launching the MLflow UI on a remote server?\",\\n    \"Why does the MLflow UI not load in my local browser after executing the command?\",\\n    \"What steps can I take to resolve the TypeError I encountered with send_file()?\",\\n    \"How can I fix the compatibility issue with Flask when using a conda environment?\",\\n    \"What specific commands should I run to uninstall the old Flask version and install the updated one?\"\\n]',\n",
       " '6de95c2a': '[\\n    \"What should I do if I encounter a FileNotFoundError when running mlflow ui on Windows?\",\\n    \"Why does the mlflow ui command produce an error after installing mlflow with pip?\",\\n    \"What specific error message might I see when trying to use mlflow ui on a Windows system?\",\\n    \"How can I resolve the issue related to mlflow ui not being found on my Windows machine?\",\\n    \"What directory do I need to add to my PATH to fix the mlflow ui error on Windows?\"\\n]',\n",
       " '2ff28e5b': '[\\n    \"What error occurs when I run the command for the homework using hpo.py?\",\\n    \"Can you explain the cause of the TypeError related to unsupported operand types in hpo.py?\",\\n    \"How should I define the max_evals argument to avoid the TypeError in hpo.py?\",\\n    \"What is the appropriate datatype for the --max_evals argument when using hpo.py?\",\\n    \"What change do I need to implement to ensure the script runs correctly without errors?\"\\n]',\n",
       " '29c6bbf1': '[\\n    \"What should I do if I receive a warning about using an unsupported Scikit-Learn version while running mlflow.sklearn?\",\\n    \"How can I resolve errors that arise during autologging in MLflow due to Scikit-Learn version issues?\",\\n    \"Is there a specific range of Scikit-Learn versions that I should be using with MLflow to avoid compatibility problems?\",\\n    \"What steps can I take if upgrading my Scikit-Learn version does not fix the warnings related to MLflow?\",\\n    \"Where can I find more detailed information about the Scikit-Learn compatibility requirements for MLflow?\"\\n]',\n",
       " 'bd09df94': '[\"Why aren\\'t my experiments showing up when using Mlflow CLI commands?\", \"What command do I use to list experiments in Mlflow?\", \"What should I do if the CLI fails to return any experiments?\", \"Is there an environment variable that needs to be set for tracking URI?\", \"How do I set the MLFLOW_TRACKING_URI correctly?\"]',\n",
       " 'af887c59': '[\\n    \"What should I do if I cannot view my MLflow experiments after starting the tracking server using the MLflow CLI?\",\\n    \"How do I set the environment variable for the MLflow tracking URI to access my sqlite database?\",\\n    \"What is the correct format to export the MLFLOW_TRACKING_URI variable for viewing experiments?\",\\n    \"Why do some MLflow CLI commands fail to locate the experiments when using the tracking server?\",\\n    \"Do I need to specify the tracking URI every time when running certain MLflow commands, such as \\'mlflow gc\\'?\"\\n]',\n",
       " 'ee7c59ea': '[\"How can I view the raw data stored in the SQLite database for my experiments?\", \"Is it possible to delete experiments manually from the SQLite database?\", \"What type of database does mlflow use for experiment tracking information?\", \"How can I inspect the tables within the SQLite database using PyCharm?\", \"Can I use other SQL databases like Postgres for experiment tracking with mlflow?\"]',\n",
       " 'a2531c75': '[\\n    \"Can you explain what it means to launch the tracking server locally in the context of our course?\",\\n    \"Why would we choose to run the mlflow server on a remote host instead of on an individual laptop?\",\\n    \"What is the benefit of having multiple colleagues connect to the same mlflow server?\",\\n    \"In what scenarios would launching the tracking server locally be most useful?\",\\n    \"How does remote hosting of an mlflow server support collaboration among team members?\"\\n]',\n",
       " 'bc4b2320': '[\\n  \"What should I do if a parameter like max_depth is not recognized during model registration?\",\\n  \"How can I ensure parameters are accepted before the model registry process?\",\\n  \"Is there a specific function to add parameters to the model before registry?\",\\n  \"How can I append parameters to data.run.params appropriately?\",\\n  \"Who provided the solution for the parameter recognition issue in Module 2?\"\\n]',\n",
       " 'f69fb077': '[\"Why is the max_depth parameter not recognized when using mlflow.log_params in my script?\", \"What should I do if mlflow.log_params is not logging the max_depth parameter correctly?\", \"How do I modify my hpo.py script to properly log the parameters with mlflow?\", \"What happens if I run my experiment again after adding mlflow.log_params for max_depth?\", \"Should I delete the previous experiment or how can I change it to fix the max_depth logging issue?\"]',\n",
       " 'e223524c': '[\\n    \"What error message do I encounter when running the register_model.py script in a Jupyter notebook?\",\\n    \"What is the suggested solution for fixing the error related to \\'tuple\\' when using register_model.py?\",\\n    \"What specific decorators need to be removed to resolve the AttributeError in my homework?\",\\n    \"Can you explain what causes the AttributeError: \\'tuple\\' object has no attribute \\'tb_frame\\' in the context of this course?\",\\n    \"Is there any documentation or guidance on handling errors when copying scripts into Jupyter notebooks?\"\\n]',\n",
       " '0f08bec7': '[\\n    \"What kind of error might I encounter while running the preprocess_data.py file related to WandB?\",\\n    \"How can I resolve the WandB API error that mentions the API key not being configured?\",\\n    \"Where can I find my API key to fix the WandB login issue?\",\\n    \"What steps should I follow to add my WandB API key before running the preprocess_data.py script?\",\\n    \"Who can I contact for assistance if I\\'m still having issues with the WandB API after following the instructions?\"\\n]',\n",
       " '8b4b1685': '[\\n    \"What should I check if I receive a warning about failing to infer model signature in mlflow.xgboost?\",\\n    \"Is there a specific order I need to follow when enabling autologging for my XGBoost model?\",\\n    \"What is the correct method to enable MLflow autologging for XGBoost?\",\\n    \"Could the format of my dataset affect the ability to enable autologging in MLflow?\",\\n    \"What steps should I take after enabling autologging to successfully train my XGBoost model?\"\\n]',\n",
       " 'ecfc5c07': '[\"What should I do if wget command fails to work for downloading files?\", \"How can I solve the issue of pip not being recognized in Windows?\", \"Is there an alternative way to use pip with Python virtual environments?\", \"What command should I use instead of wget if it doesn\\'t function properly?\", \"Who provided the solution for the wget issue in the course?\"]',\n",
       " 'a1b68c52': '[\\n    \"How can I open a GitHub notebook directly in Google Colab?\",\\n    \"What is the process to change the URL for opening a GitHub notebook in Colab?\",\\n    \"Is it possible to open notebooks from private repositories in Google Colab?\",\\n    \"What should I do if I find using the Wandb UI challenging?\",\\n    \"Where can I find official documentation for navigating Wandb UI?\"\\n]',\n",
       " '483e7d61': '[\"What are the key reasons for using a time-based data split instead of a random one during model training, testing, and validation?\", \"How do we determine whether our time-based validation approach reveals seasonality in our data?\", \"Can you explain what the potential risks are when using a random sample for train and test sets in model development?\", \"What are the implications of using out-of-time validations for reporting model performance to stakeholders?\", \"What specific steps do I need to take if I encounter an error related to urllib3 while running the mlflow server on AWS?\"]',\n",
       " 'e5c33f50': '[\\n    \"What information is included in the problem title section of Module 3?\",\\n    \"Can you explain what the problem description entails?\",\\n    \"What details are provided in the solution description for each problem?\",\\n    \"How can I identify who added a problem in Module 3?\",\\n    \"Is it necessary to include a solution description when submitting a problem?\"\\n]',\n",
       " 'cbf13b19': '[\\n    \"Can you tell me where I can find answers for Prefect-related inquiries?\",\\n    \"Is there a specific location for the FAQ regarding Prefect questions?\",\\n    \"Where can I look up frequently asked questions about Prefect?\",\\n    \"Could you guide me to the Prefect FAQ section?\",\\n    \"What is the reference point for questions concerning Prefect?\"\\n]',\n",
       " '39861d6e': '[\"What should I do if I encounter an \\'Invalid choice\\' error when trying to login to ECR using Docker?\", \"How can I properly login to ECR with Docker on Windows?\", \"Is there a specific version of AWS CLI required to avoid errors when using Docker with ECR?\", \"Can you provide a reference for the correct command to login to ECR using Docker?\", \"What command should I use instead of \\'aws ecr get-login\\' to authenticate Docker with ECR?\"]',\n",
       " '3dac15ff': '[\"How do I structure multiline commands in Windows Powershell correctly?\", \"What is the purpose of using the backtick (`) at the end of each line in a Powershell command?\", \"How can I create non-persistent environment variables in Powershell?\", \"What is the correct syntax for escaping double quotes in a multiline string?\", \"Can you provide an example of using the aws kinesis command with environment variables?\"]',\n",
       " '32686722': '[\\n    \"What common issue might arise when trying to install Pipenv using the system Python version 3.10?\",\\n    \"How can I resolve the AttributeError related to \\'MutableMapping\\' when using Pipenv?\",\\n    \"What command should I use to remove Pipenv if it was initially installed via apt-get?\",\\n    \"What is the recommended way to have a non-system Python environment for Pipenv?\",\\n    \"Can you explain the steps to reinstall Pipenv after setting up a non-system Python?\"\\n]',\n",
       " '22521751': '[\"What should I do if I cannot access the module due to an HTTPS URL issue?\", \"How can I verify if the SSL module is configured correctly?\", \"What command do I need to use to check the SSL configuration?\", \"What steps should I take if the SSL output is empty?\", \"How do I upgrade the pipenv package in my environment to fix the module issue?\"]',\n",
       " '81ad4784': '[\\n  \"What error is displayed when trying to install scikit-learn version 1.0.2 using pipenv?\",\\n  \"What should I do if I encounter a \\'No module named pip._vendor.six\\' error during installation?\",\\n  \"Which command do I need to run to resolve the \\'ModuleNotFoundError\\' while installing scikit-learn?\",\\n  \"Is there a specific package I need to install before attempting to reinstall scikit-learn?\",\\n  \"What is the command to remove the existing pipenv environment before reinstalling scikit-learn?\"\\n]',\n",
       " '29b5651e': '[\\n    \"How can I integrate Jupyter notebooks with my Pipenv environment effectively?\",\\n    \"What steps should I take to register a kernel for Jupyter when using Pipenv?\",\\n    \"Is there a specific command I need to run to install jupyter and ipykernel in Pipenv?\",\\n    \"Will adding the virtual environment in VS Code allow me to use it easily with Jupyter notebooks?\",\\n    \"Where can I find additional guidance on using Jupyter with Pipenv if I need further help?\"\\n]',\n",
       " 'ca79bbe8': '[\\n    \"What should I do if I encounter no output when running a Jupyter notebook in a Pipenv environment?\",\\n    \"Which version of Tornado caused issues with output on prints in my Jupyter notebook?\",\\n    \"How did downgrading Tornado resolve the issue with my Jupyter notebook?\",\\n    \"Is there a specific version of scikit-learn that I should use to avoid this problem?\",\\n    \"Where can I find more information about the bug related to Tornado and Jupyter notebooks?\"\\n]',\n",
       " '668f1ad9': '[\\n  \"What should I do if I encounter an \\'Invalid base64\\' error when executing the aws kinesis put-record command?\",\\n  \"Why might the \\'Invalid base64\\' error occur when using aws kinesis put-record on my local machine?\",\\n  \"How does the AWS CLI version affect the occurrence of the \\'Invalid base64\\' error?\",\\n  \"What is the recommended method to resolve the \\'Invalid base64\\' error in the AWS CLI?\",\\n  \"Where can I find a reference for the AWS CLI version mentioned with a warning in the course video?\"\\n]',\n",
       " '7a6f23eb': '[\\n    \"What error might I encounter when executing the starter.ipynb for homework\\'s Q1?\",\\n    \"What does the error message index 311297 indicate when dealing with a parquet file?\",\\n    \"How can I resolve the issue related to the error mentioned in Module 4?\",\\n    \"Is it necessary to update pandas even if the version is the latest when facing this error?\",\\n    \"Who provided the solution for the out of bounds error in the module record?\"\\n]',\n",
       " '232e5557': '[\"What should I do if I notice that Pipfile.lock is missing after generating Pipfile?\", \"How can I ensure that Pipfile.lock gets created when I have a Pipfile?\", \"Is there a specific command I need to run to generate Pipfile.lock?\", \"What command do I use with Pipenv to create a Pipfile.lock file?\", \"If my Pipfile.lock wasn\\'t generated, is there a way to force its creation?\"]',\n",
       " 'e44ec04a': '[\\n  \"What causes the Permission Denied error when using Pipenv?\",\\n  \"How can I fix the Permission Denied issue with Pipenv?\",\\n  \"Which module is typically responsible for the Permission Denied error in Pipenv?\",\\n  \"Is there a specific method for resolving the Python Finder issue in Pipenv?\",\\n  \"Who provided the solution for the Permission Denied error related to Pipenv?\"\\n]',\n",
       " '55fdb8b9': '[\\n    \"What should I do if I encounter a ValueError regarding unknown format codes while using the command line interface?\",\\n    \"Why am I getting an error related to argument parsing when trying to convert command line inputs to integers?\",\\n    \"How can I properly pass a year as an argument to a script to avoid formatting errors?\",\\n    \"What is the cause of the error that appears when attempting to format a year using f-strings in Python?\",\\n    \"How can I utilize the click library to correctly handle year inputs for my function?\"\\n]',\n",
       " 'bf9082a2': '[\"What is the importance of using the correct image when Dockerizing a project?\", \"How do I properly copy data into my Docker image during the build process?\", \"Why should I avoid using absolute paths in my Docker image?\", \"What is the recommended working directory to set before executing code in a Docker container?\", \"Can you explain the commands needed to build and run a Docker container for my project?\"]',\n",
       " 'e7906e44': '[\"How can I run both Flask and MLFlow server in a single Docker container?\", \"What should be included in the Dockerfile to ensure both services can run?\", \"Is there a script arrangement needed for running multiple services inside a container?\", \"How do I make sure that all necessary scripts have executable permissions?\", \"What is the functionality of the wrapper script in managing multiple processes?\"]',\n",
       " '76d8892e': '[\"What should I do if I encounter an InstallationError related to pipfile.lock during deployment?\", \"How can I resolve the issue where the command \\'python setup.py egg_info\\' fails with error code 1?\", \"Is there a specific command I need to run to fix issues with pipenv and wheel during deployment?\", \"What does the error message \\'Cannot generate pipfile.lock\\' indicate in Module 4?\", \"Why is it necessary to force an upgrade of pipenv and wheel when facing InstallationError?\"]',\n",
       " 'c5c2c82a': '[\"What is the recommended method for connecting an S3 bucket to MLFLOW?\", \"Why are access keys necessary when using boto3 to connect to AWS servers?\", \"What could happen if I don\\'t have the correct access keys for my S3 bucket?\", \"Is it possible to configure my S3 bucket to be publicly accessible without using access keys?\", \"Where can I find more information about using boto3 and AWS access keys?\"]',\n",
       " '82b6c143': '[\\n    \"What should I do if I receive an InvalidAccessKeyId error when uploading to S3?\",\\n    \"Why does the upload succeed with aws cli and boto3 in Jupyter notebook but fail otherwise?\",\\n    \"How can I resolve the issue with my AWS Access Key Id when using S3?\",\\n    \"What environment variable needs to be set to fix the S3 upload error?\",\\n    \"Is there a specific default profile I should be using for AWS uploads?\"\\n]',\n",
       " '77d9a742': '[\\n    \"What is the problem related to lib_lightgbm.so in Module 4?\",\\n    \"Why is the image not found when using lightgbm?\",\\n    \"What should I add to my Dockerfile to resolve the lightgbm issue?\",\\n    \"How do I change the installer command based on my operating system?\",\\n    \"Who provided the solution for dockerizing lightgbm?\"\\n]',\n",
       " '1667e95d': '[\\n    \"What kind of error might occur when using mlflow\\'s pyfunc.load_model in a lambda function?\",\\n    \"What does the warning message from mlflow indicate when an error is raised?\",\\n    \"How can I view the complete traceback of the error encountered in the lambda function?\",\\n    \"What specific adjustment can I make to the lambda function to resolve the memory issue?\",\\n    \"Who contributed the solution regarding the lambda function\\'s memory increase?\"\\n]',\n",
       " '624a3525': '[\\n    \"What is the final outcome of the video in Module 4?\",\\n    \"Can you explain the relationship between the notebook and the video in this module?\",\\n    \"Is the FYI Notebook related to mlflow pipelines as mentioned in the video?\",\\n    \"What should I do if I experience issues while following the video?\",\\n    \"Who provided the information about the notebook and video in Module 4?\"\\n]',\n",
       " '1db86601': '[\"How can I ensure that my Docker image reads AWS credentials correctly?\", \"What command format should I use to pass environment variables while running my Docker container?\", \"Is it possible to use AWS configuration files in Docker, and if so, how?\", \"What should I do if my Python script can\\'t access AWS credentials from environment variables?\", \"Can I pass multiple environment variables to my Docker container, and how would I do that?\"]',\n",
       " '047baefe': '[\\n  \"What steps do I need to follow to view the contents of the model in the docker container located in the app directory?\",\\n  \"Can you explain the purpose of the Dockerfile in the context of troubleshooting the model image?\",\\n  \"How do I ensure that my files are included when I build the Docker image for the model?\",\\n  \"What is the role of the CMD command in the Dockerfile, and how does it differ from the RUN commands?\",\\n  \"Is there a way to have a script run automatically when starting the docker container, and how can I implement that?\"\\n]',\n",
       " '4f240372': '[\\n    \"How can I fix the platform mismatch warning when deploying my image?\",\\n    \"What command should I use to build a docker image with a specific platform?\",\\n    \"Is there a way to specify the platform when building my docker image?\",\\n    \"What happens if the requested image\\'s platform does not match the host platform?\",\\n    \"Can you provide an example of how to include the platform tag in a docker build command?\"\\n]',\n",
       " '7aef625b': '[\\n    \"What should I do if I encounter an HTTP 403 error when using apply_model() in score.ipynb?\",\\n    \"Is there an alternative URL for the input file in case of a forbidden error?\",\\n    \"What format should the input_file variable follow to avoid an HTTP error?\",\\n    \"Can you clarify the correct structure for the input_file when accessing trip data?\",\\n    \"What is the updated link to access the NYC taxi trip data instead of the previous one?\"\\n]',\n",
       " 'a3aa3a7d': '[\\n    \"What does the error message \\'ModuleNotFoundError: No module named \\'pipenv.patched.pip._vendor.urllib3.response\\'\\' indicate?\",\\n    \"How can I resolve the error related to missing modules in pipenv?\",\\n    \"What command can I use to reinstall pipenv to fix the module not found error?\",\\n    \"Is there a specific command to update pip that might help with this issue?\",\\n    \"What should I do if I encounter an error in the connection pool related to urllib3?\"\\n]',\n",
       " 'd2719204': '[\"What should I do if I encounter a login prompt in Grafana after following the video instructions?\", \"What are the default credentials for Grafana when accessing localhost:3000?\", \"How can I change my password after logging in to Grafana?\", \"Where can I find additional information regarding the login issue in Grafana?\", \"What steps are involved if I run into problems with Docker Compose while accessing Grafana?\"]',\n",
       " '30b8e8e6': '[\"What should I do if I encounter an error when starting monitoring services in Linux?\", \"Why does the command \\'docker compose up --build\\' not work for me?\", \"How can I resolve the \\'unknown flag: --build\\' message in the command prompt?\", \"Is there a difference between \\'docker compose\\' and \\'docker-compose\\' in Linux?\", \"What command should I use to successfully start services using Docker Compose?\"]',\n",
       " 'f33fc6e9': '[\"What should I do if I encounter a KeyError \\'content-length\\' when executing prepare.py?\", \"Is there a specific reason why I am receiving a KeyError while running the script?\", \"What changes did Emeli Dral make to the prepare.py file to resolve the issue?\", \"Can you provide the updated URL that should be used in prepare.py to download the taxi data?\", \"Is the original URL mentioned in prepare.py no longer functional for accessing the taxi data?\"]',\n",
       " 'd828de2a': '[\\n    \"What problem occurs when I execute the command \\'docker-compose up --build\\' for the real-time prediction service?\",\\n    \"Why does my evidently service exit with code 2 and what specific error message do I receive?\",\\n    \"What are the recommended solutions if my service fails to run due to the inability to import the pyarrow module?\",\\n    \"What should I do if installing the pyarrow module and restarting my machine does not resolve the issue?\",\\n    \"How did commenting out the pyarrow import in the app.py file of the evidently service help solve the problem?\"\\n]',\n",
       " '03f20ec1': '[\"What should I do if I encounter a ValueError related to metrics in Module 5?\", \"Can you explain the cause of a ValueError in Evidently while working on Report?\", \"What steps should I follow to resolve an error involving incorrect items in Module 5?\", \"How can I fix a ValueError that mentions metrics or metric presets?\", \"Is there any specific syntax I should check if I receive a ValueError in this module?\"]',\n",
       " '249726fe': '[\"What error might occur when using RegressionQualityMetric()?\", \"What do I need to specify when using RegressionQualityMetric()?\", \"Is it necessary to include target=\\'duration_min\\' when calling RegressionQualityMetric()?\", \"How should I modify current_data to use RegressionQualityMetric()?\", \"Who provided the information about the RegressionQualityMetric() error?\"]',\n",
       " '4e492af0': '[\\n    \"What does the error message about finding an array with 0 samples mean in the context of LinearRegression?\",\\n    \"Why does the training dataset become empty when using an early date for generating data?\",\\n    \"How can I modify the starting date to avoid the issue of an empty training dataset?\",\\n    \"What minimum data requirement does LinearRegression need to function correctly?\",\\n    \"Can you explain how adjusting the beginning date impacts the training dataset generation process?\"\\n]',\n",
       " '10011dc1': '[\\n    \"What should I do if I encounter errors related to target or prediction columns after including a new metric?\",\\n    \"Where can I find detailed guidelines on requirements for adding a new metric?\",\\n    \"Can you give an example of a metric that doesn’t require any parameters?\",\\n    \"Is there a specific metric recommended for evaluating feature correlations?\",\\n    \"Who can I contact for further assistance regarding issues with metrics in Module 5?\"\\n]',\n",
       " '92fb909a': '[\"What should I do if I encounter an error when logging into Grafana with the default credentials?\", \"How can I resolve the issue of not being able to log in to Grafana?\", \"Is there a specific command to reset the admin password in the Grafana container?\", \"What steps do I need to take if the standard login credentials for Grafana do not work?\", \"Who contributed the solution for the login issue in Grafana?\"]',\n",
       " '2b8cb640': '[\"Why are the charts in Grafana not refreshing like I expected?\",\"What steps should I take to ensure my Grafana charts display updated data?\",\"How often should I set the refresh interval for Grafana to get timely updates?\",\"What timezone settings do I need to change for Grafana to update correctly?\",\"Is there a specific example of a timezone that caused issues in Grafana updates?\"]',\n",
       " 'd4ceab0b': '[\"What should I do if the Prefect server doesn\\'t run on my local machine?\", \"How can I resolve the issue of the Prefect server stopping immediately after starting it?\", \"Is there a way to run my script if the Prefect server isn\\'t operational locally?\", \"Did anyone else encounter issues with the Prefect server not running locally?\", \"What steps can I take if I need to report problems regarding the Prefect server on GitHub?\"]',\n",
       " '482e575f': '[\"What should I do when I encounter a \\'no disk space left\\' error during the \\'docker compose up\\' command?\", \"How can I remove unused items in Docker to free up space?\", \"Is there a way to check what is consuming disk space in Docker before I delete anything?\", \"What command can I use to clean up Docker\\'s build cache, containers, and images?\", \"Who provided the solution for the \\'no disk space left\\' issue in the FAQ record?\"]',\n",
       " '33e775eb': '[\\n  \"What error might I encounter when I run \\'docker-compose up --build\\'?\",\\n  \"How can I resolve the issue related to \\'php_network_getaddresses\\' when using Docker?\",\\n  \"What should I add to the adminer block in the yml file to fix the address family error?\",\\n  \"Can you provide the command that needs to be added in the yml file to resolve the mentioned problem?\",\\n  \"Which image is referenced in the example provided to fix the issue during deployment?\"\\n]',\n",
       " '19a3d34a': '[\"What is the main issue when trying to create Evidently charts in Grafana?\", \"What kind of panels can we use in Grafana to approximate Evidently chart features?\", \"Is there a quick way to replicate the entire Evidently dashboard in Grafana?\", \"How can I export Evidently output for use in external visualizations?\", \"Why might it be more beneficial to use Evidently for certain plots during debugging?\"]',\n",
       " '55c68f23': '[\\n  \"What should I do if I encounter the error \\'Unable to locate credentials\\' while using localstack with kinesis?\",\\n  \"Which additional environment variables need to be added in the docker-compose.yaml file to resolve credential errors?\",\\n  \"Can you explain how to configure AWS credentials using the AWS CLI to avoid issues with localstack?\",\\n  \"Is it necessary to provide real values for AWS Access Key ID and Secret Access Key when fixing the credentials error?\",\\n  \"What are some common solutions for resolving the \\'Unable to locate credentials\\' error in localstack?\"\\n]',\n",
       " '54020f0a': '[\\n    \"What does the error \\'unspecified location constraint is incompatible\\' mean when creating a bucket?\",\\n    \"How can I resolve the \\'IllegalLocationConstraintException\\' error while using localstack?\",\\n    \"What is the correct syntax for creating a bucket with the LocationConstraint in boto3?\",\\n    \"Why do I encounter a location constraint error when trying to create a bucket in a specific region?\",\\n    \"Can you explain the parameters needed for the create_bucket function to avoid this error?\"\\n]',\n",
       " 'b6249d2c': '[\\n    \"What should I do if I encounter an error message that includes \\'<botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>\\' after running an AWS CLI command?\",\\n    \"Is there a specific AWS CLI command that might trigger the error message \\'<botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>\\'?\",\\n    \"What environment variables do I need to set to resolve the error I received after executing an AWS CLI command?\",\\n    \"Do the values I set for AWS environment variables need to be correct to fix the AWS CLI error?\",\\n    \"Who provided the instructions on how to fix the error message related to the AWS CLI command?\"\\n]',\n",
       " '31543d95': '[\"What error occurs at every commit when using pre-commit hooks?\", \"Why are pre-commit hooks not running during commits?\", \"What should I check in the .pre-commit-config.yaml file if I encounter an error?\", \"Is there a specific indentation requirement for the repo statements in the configuration file?\", \"Who provided the information regarding the pre-commit error and its solution?\"]',\n",
       " 'e147bbb6': '[\\n  \"What should I do if I cannot reconfigure pytest after using a previous folder?\",\\n  \"Is there a way to completely remove pytest test from a folder?\",\\n  \"Where can I find the .vscode folder that needs to be deleted?\",\\n  \"What folder was used as an example for testing in Module 6?\",\\n  \"Whose input was added regarding pytest and the .vscode folder?\"\\n]',\n",
       " 'dc55657f': '[\"What issue can occur when using Kinesis Get Records in LocalStack as demonstrated in video 6.3?\", \"At what time in video 6.3 does the problem with empty records happen?\", \"What specific command modification is needed to resolve the issue with empty records in Kinesis?\", \"What endpoint URL must be used for the Kinesis get records command when working with LocalStack?\", \"Is there any additional option required in the Kinesis command to avoid signing issues during the get records call?\"]',\n",
       " 'f6979915': '[\"What issue might occur when attempting to commit changes using Powershell with a pre-commit yaml file?\", \"Can you explain the error message related to utf-8 encoding when running git commit?\", \"What command should I use to set utf-8 encoding for the pre-commit yaml file?\", \"Who provided the solution for the utf-8 encoding error in the pre-commit yaml file?\", \"What does the error InvalidConfigError indicate when trying to commit in Git?\"]',\n",
       " '1076a121': '[\"What error might occur when performing a Git commit with a pre-commit hook?\", \"What is the error message related to \\'PythonInfo\\' when trying to commit?\", \"How do I resolve the issue with the pre-commit hook error?\", \"What command must be run to clear app-data of the virtual environment?\", \"Who provided the solution to the pre-commit hook error?\"]',\n",
       " 'aa203ca7': '[\\n    \"What causes the \\'module not found\\' error when using Pytest with custom packages?\",\\n    \"Can you explain the correct project structure that should be followed to avoid errors in Pytest?\",\\n    \"Why does running \\'python test_model_service.py\\' work while \\'pytest ./test/unit_tests\\' fails?\",\\n    \"What is the recommended solution for resolving the module not found error in this context?\",\\n    \"What does the command \\'python -m pytest\\' do differently compared to running pytest directly?\"\\n]',\n",
       " '8b04605d': '[\\n  \"What is the issue encountered when using pre-commit hooks with pytest and custom packages?\",\\n  \"Can you explain the specific project structure that leads to the \\'No module named production\\' error?\",\\n  \"What adjustments should be made to the pre-commit hook configuration to resolve the pytest error?\",\\n  \"How should the run.sh script be configured to ensure pytest runs correctly in this context?\",\\n  \"What commands are necessary within the run.sh script to set the correct directory and run pytest?\"\\n]',\n",
       " 'a3b9af04': '[\"What do I do if I encounter a permission denied error while running a script in GitHub Actions?\", \"Can you provide an example of a step in the CI YAML file that might cause a permission error?\", \"What does error code 126 indicate when using GitHub CI action?\", \"How can I solve a permission issue with a script file in my project?\", \"What command should I use to add execution permission to a script before committing?\"]',\n",
       " 'b16aae74': '[\"What does it mean when a docker-compose file has too many containers and how does it affect resource usage?\", \"How can I select a specific group of containers in a docker-compose setup during testing?\", \"What is the method to add profiles in the service definition of a docker-compose file?\", \"What command should I use when starting a service with a specific profile in docker-compose?\", \"Who contributed to the solution of managing multiple Docker containers with profiles?\"]',\n",
       " '66326a87': '[\\n    \"What should I check if I am experiencing issues with integration tests and Kinesis?\",\\n    \"How can I ensure that my AWS regions are correctly aligned in my docker-compose setup?\",\\n    \"What specific configuration should I use for the AWS region in both my local setup and docker-compose?\",\\n    \"If my AWS regions do not match, what could potentially go wrong when creating a stream?\",\\n    \"Can you provide an example of how to set the AWS region in the config file and docker-compose.yaml?\"\\n]',\n",
       " 'fb3c4150': '[\\n    \"What issue should I be aware of regarding the pre-commit command and the isort repository?\",\\n    \"What version should I set for isort to resolve the pre-commit command failure?\",\\n    \"Who contributed the solution for the isort pre-commit command issue?\",\\n    \"Is there a specific version number I need to adjust to fix the problem with isort?\",\\n    \"Can you explain the problem related to the pre-commit command when using isort?\"\\n]',\n",
       " '886d1617': '[\"What steps are necessary to dismantle infrastructure using GitHub Actions?\", \"How can I initiate the destruction of AWS infrastructure created by CD-Deploy Action?\", \"What command do I use to initialize Terraform before destroying infrastructure?\", \"What does the backend configuration key look like for my project?\", \"What file should I specify when executing the terraform destroy command?\"]'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5aba496-31c5-47a6-80d1-5fccff05ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results['c02e79ef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77bd1d0b-1527-4cb1-9c57-5f88c33a1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results['f476a606']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30722ae6-c7bd-4027-915b-aafb5d68d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results['e41b100c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bdda3f5c-96a2-4cb2-b088-57637ca35078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c02e79ef\n",
      "parsed\n",
      "1f6520ca\n",
      "parsed\n",
      "7842b56a\n",
      "parsed\n",
      "0bbf41ec\n",
      "parsed\n",
      "63394d91\n",
      "parsed\n",
      "2ed9b986\n",
      "parsed\n",
      "93e2c8ed\n",
      "parsed\n",
      "a482086d\n",
      "parsed\n",
      "eb56ae98\n",
      "parsed\n",
      "4292531b\n",
      "parsed\n",
      "ea739c65\n",
      "parsed\n",
      "cb257ee5\n",
      "parsed\n",
      "04aa4897\n",
      "parsed\n",
      "9681be3b\n",
      "parsed\n",
      "a1daf537\n",
      "parsed\n",
      "be5bfee4\n",
      "parsed\n",
      "0e424a44\n",
      "parsed\n",
      "29865466\n",
      "parsed\n",
      "016d46a1\n",
      "parsed\n",
      "47972cb1\n",
      "parsed\n",
      "ddf6c1b3\n",
      "parsed\n",
      "ac25d3af\n",
      "parsed\n",
      "251218fc\n",
      "parsed\n",
      "3c0114ce\n",
      "parsed\n",
      "f43f5fe7\n",
      "parsed\n",
      "d061525d\n",
      "parsed\n",
      "1cd01b2c\n",
      "parsed\n",
      "e4a7c3b0\n",
      "parsed\n",
      "7cd1912e\n",
      "parsed\n",
      "52393fb3\n",
      "parsed\n",
      "10515af5\n",
      "parsed\n",
      "cdb86a97\n",
      "parsed\n",
      "3e0114ad\n",
      "parsed\n",
      "b2799574\n",
      "parsed\n",
      "2f19301f\n",
      "parsed\n",
      "7c700adb\n",
      "parsed\n",
      "44b14808\n",
      "parsed\n",
      "76e4baf6\n",
      "parsed\n",
      "48b533a8\n",
      "parsed\n",
      "954044d1\n",
      "parsed\n",
      "a820b9b3\n",
      "parsed\n",
      "f2945cd2\n",
      "parsed\n",
      "eb9d376f\n",
      "parsed\n",
      "72f25f6d\n",
      "parsed\n",
      "a1e59afc\n",
      "parsed\n",
      "71c10610\n",
      "parsed\n",
      "17a5aea1\n",
      "parsed\n",
      "5a275db7\n",
      "parsed\n",
      "7ec0f9b0\n",
      "parsed\n",
      "bb1ba786\n",
      "parsed\n",
      "2f83dbe7\n",
      "parsed\n",
      "543ff080\n",
      "parsed\n",
      "d407d65b\n",
      "parsed\n",
      "c9375c56\n",
      "parsed\n",
      "e866156b\n",
      "parsed\n",
      "16370470\n",
      "parsed\n",
      "316df755\n",
      "parsed\n",
      "f3aa9252\n",
      "parsed\n",
      "a4abe7a5\n",
      "parsed\n",
      "fb930700\n",
      "parsed\n",
      "aa187680\n",
      "parsed\n",
      "b000e899\n",
      "parsed\n",
      "9c66759f\n",
      "parsed\n",
      "e3106e07\n",
      "parsed\n",
      "72229da5\n",
      "parsed\n",
      "58c9f99f\n",
      "parsed\n",
      "bc42139a\n",
      "parsed\n",
      "a146e3ee\n",
      "parsed\n",
      "593a85ba\n",
      "parsed\n",
      "50bd1a71\n",
      "parsed\n",
      "f409f751\n",
      "parsed\n",
      "7d217da3\n",
      "parsed\n",
      "09081824\n",
      "parsed\n",
      "4df80c55\n",
      "parsed\n",
      "3aee7261\n",
      "parsed\n",
      "6497b659\n",
      "parsed\n",
      "a02f2039\n",
      "parsed\n",
      "c6db65aa\n",
      "parsed\n",
      "f476a606\n",
      "parsed\n",
      "e41b100c\n",
      "parsed\n",
      "cd0f9300\n",
      "parsed\n",
      "7f845a1c\n",
      "parsed\n",
      "36e54439\n",
      "parsed\n",
      "32e8450c\n",
      "parsed\n",
      "96606db2\n",
      "parsed\n",
      "0882bfac\n",
      "parsed\n",
      "7d067f5c\n",
      "parsed\n",
      "ff352621\n",
      "parsed\n",
      "2d653208\n",
      "parsed\n",
      "f09ea61e\n",
      "parsed\n",
      "fbd3d2bb\n",
      "parsed\n",
      "0b014d0c\n",
      "parsed\n",
      "d21bff1d\n",
      "parsed\n",
      "6afb7b55\n",
      "parsed\n",
      "b51c3b82\n",
      "parsed\n",
      "326af690\n",
      "parsed\n",
      "c2ec9047\n",
      "parsed\n",
      "3b711e73\n",
      "parsed\n",
      "cfe07c9d\n",
      "parsed\n",
      "acf42bb8\n",
      "parsed\n",
      "176ce516\n",
      "parsed\n",
      "3e5d1e9b\n",
      "parsed\n",
      "78833f32\n",
      "parsed\n",
      "63823f21\n",
      "parsed\n",
      "b36ea564\n",
      "parsed\n",
      "e2a46ce5\n",
      "parsed\n",
      "27bdbc3f\n",
      "parsed\n",
      "f7c5d8da\n",
      "parsed\n",
      "c91ad8f2\n",
      "parsed\n",
      "88bf31a0\n",
      "parsed\n",
      "23524e6d\n",
      "parsed\n",
      "9211bbd6\n",
      "parsed\n",
      "5db86809\n",
      "parsed\n",
      "20c604dd\n",
      "parsed\n",
      "b11b8c15\n",
      "parsed\n",
      "a6475348\n",
      "parsed\n",
      "1ea7680e\n",
      "parsed\n",
      "10acd478\n",
      "parsed\n",
      "752e8452\n",
      "parsed\n",
      "aa6f52b8\n",
      "parsed\n",
      "3dacbb98\n",
      "parsed\n",
      "8b71a398\n",
      "parsed\n",
      "aa244fa0\n",
      "parsed\n",
      "eac816d7\n",
      "parsed\n",
      "d44d1c77\n",
      "parsed\n",
      "ed34766a\n",
      "parsed\n",
      "fd714677\n",
      "parsed\n",
      "9de2c3e9\n",
      "parsed\n",
      "827dd4af\n",
      "parsed\n",
      "a42a7e8c\n",
      "parsed\n",
      "4eefdd01\n",
      "parsed\n",
      "0282578d\n",
      "parsed\n",
      "bd3e60fd\n",
      "parsed\n",
      "c4e9bc60\n",
      "parsed\n",
      "f10b49be\n",
      "parsed\n",
      "3184bd8b\n",
      "parsed\n",
      "8bea4d53\n",
      "parsed\n",
      "86d11cc0\n",
      "parsed\n",
      "2cb48591\n",
      "parsed\n",
      "9523c813\n",
      "parsed\n",
      "4f8d9174\n",
      "parsed\n",
      "29f84a82\n",
      "parsed\n",
      "20a01fd0\n",
      "parsed\n",
      "5a712a20\n",
      "parsed\n",
      "06021091\n",
      "parsed\n",
      "df8ea7e8\n",
      "parsed\n",
      "1093daf5\n",
      "parsed\n",
      "947213b1\n",
      "parsed\n",
      "002d4943\n",
      "parsed\n",
      "8dc77677\n",
      "parsed\n",
      "29d3d343\n",
      "parsed\n",
      "e2095203\n",
      "parsed\n",
      "22a2b9f2\n",
      "parsed\n",
      "5d7588f0\n",
      "parsed\n",
      "5276a695\n",
      "parsed\n",
      "70c159df\n",
      "parsed\n",
      "f55efcf0\n",
      "parsed\n",
      "2b7a8512\n",
      "parsed\n",
      "1cd746c4\n",
      "parsed\n",
      "6d367222\n",
      "parsed\n",
      "84e601e1\n",
      "parsed\n",
      "4cf83cc2\n",
      "parsed\n",
      "5adc5188\n",
      "parsed\n",
      "3ef0bb96\n",
      "parsed\n",
      "a41ce360\n",
      "parsed\n",
      "b1cf59e5\n",
      "parsed\n",
      "f9d6f8bd\n",
      "parsed\n",
      "f3adb937\n",
      "parsed\n",
      "eb3d6d36\n",
      "parsed\n",
      "a76e1f4d\n",
      "parsed\n",
      "934facf8\n",
      "parsed\n",
      "a2c7b59f\n",
      "parsed\n",
      "997d4aaa\n",
      "parsed\n",
      "bc269b95\n",
      "parsed\n",
      "10ea342e\n",
      "parsed\n",
      "4bd23594\n",
      "parsed\n",
      "b0d48cd7\n",
      "parsed\n",
      "70a37f2c\n",
      "parsed\n",
      "8ab78bee\n",
      "parsed\n",
      "54c6db2f\n",
      "parsed\n",
      "c5b998f3\n",
      "parsed\n",
      "eec29536\n",
      "parsed\n",
      "727e5a69\n",
      "parsed\n",
      "da899638\n",
      "parsed\n",
      "dde58c8f\n",
      "parsed\n",
      "207be93b\n",
      "parsed\n",
      "f0617e65\n",
      "parsed\n",
      "6290a1a6\n",
      "parsed\n",
      "5a06248c\n",
      "parsed\n",
      "c46a2e9e\n",
      "parsed\n",
      "0513ab8a\n",
      "parsed\n",
      "a9385356\n",
      "parsed\n",
      "c30468c0\n",
      "parsed\n",
      "305aead7\n",
      "parsed\n",
      "77410975\n",
      "parsed\n",
      "0952abde\n",
      "parsed\n",
      "7c4326eb\n",
      "parsed\n",
      "a1fc1a14\n",
      "parsed\n",
      "6d67fba9\n",
      "parsed\n",
      "06876291\n",
      "parsed\n",
      "690ba010\n",
      "parsed\n",
      "b6fdd91d\n",
      "parsed\n",
      "155aa868\n",
      "parsed\n",
      "e78cf960\n",
      "parsed\n",
      "9afa1f74\n",
      "parsed\n",
      "fac138a7\n",
      "parsed\n",
      "0174dde5\n",
      "parsed\n",
      "1023ee65\n",
      "parsed\n",
      "effd2bfa\n",
      "parsed\n",
      "5b55273c\n",
      "parsed\n",
      "1835bfe0\n",
      "parsed\n",
      "04656af5\n",
      "parsed\n",
      "2d6536d3\n",
      "parsed\n",
      "0516ccbe\n",
      "parsed\n",
      "6052513d\n",
      "parsed\n",
      "7a71fa2c\n",
      "parsed\n",
      "f83d9435\n",
      "parsed\n",
      "dbf65e11\n",
      "parsed\n",
      "c489266b\n",
      "parsed\n",
      "ebd63566\n",
      "parsed\n",
      "f7252f17\n",
      "parsed\n",
      "47a43bb0\n",
      "parsed\n",
      "f3f13def\n",
      "parsed\n",
      "4fd37712\n",
      "parsed\n",
      "8abeca36\n",
      "parsed\n",
      "16c16ff9\n",
      "parsed\n",
      "c65d8fd9\n",
      "parsed\n",
      "c1a95536\n",
      "parsed\n",
      "bba0da04\n",
      "parsed\n",
      "a2120335\n",
      "parsed\n",
      "a4ba2478\n",
      "parsed\n",
      "74c361fe\n",
      "parsed\n",
      "b9b3ef9f\n",
      "parsed\n",
      "009ac612\n",
      "parsed\n",
      "68815ec2\n",
      "parsed\n",
      "c8ad08b3\n",
      "parsed\n",
      "d68b433f\n",
      "parsed\n",
      "e265ee5a\n",
      "parsed\n",
      "0e7dfddc\n",
      "parsed\n",
      "0a059700\n",
      "parsed\n",
      "feca7402\n",
      "parsed\n",
      "1f519b1a\n",
      "parsed\n",
      "43c454c7\n",
      "parsed\n",
      "d7ad69da\n",
      "parsed\n",
      "03fdb780\n",
      "parsed\n",
      "9c85f3aa\n",
      "parsed\n",
      "63026349\n",
      "parsed\n",
      "6ba02f77\n",
      "parsed\n",
      "8b14286c\n",
      "parsed\n",
      "14a876ea\n",
      "parsed\n",
      "1cf5be74\n",
      "parsed\n",
      "315ac3cc\n",
      "parsed\n",
      "c5c3beba\n",
      "parsed\n",
      "f19be91b\n",
      "parsed\n",
      "33db7dc7\n",
      "parsed\n",
      "67ef8f87\n",
      "parsed\n",
      "6acf2e77\n",
      "parsed\n",
      "18430f10\n",
      "parsed\n",
      "afb7a40a\n",
      "parsed\n",
      "d6a5b80e\n",
      "parsed\n",
      "de426d2f\n",
      "parsed\n",
      "354f0e10\n",
      "parsed\n",
      "98fae8d0\n",
      "parsed\n",
      "cb678fde\n",
      "parsed\n",
      "39bfb043\n",
      "parsed\n",
      "351a078a\n",
      "parsed\n",
      "61da1919\n",
      "parsed\n",
      "6528c6ae\n",
      "parsed\n",
      "c0d3a2e8\n",
      "parsed\n",
      "859a97c5\n",
      "parsed\n",
      "32469a2d\n",
      "parsed\n",
      "c599b3a0\n",
      "parsed\n",
      "179df18d\n",
      "parsed\n",
      "1ce1a275\n",
      "parsed\n",
      "b529b0bc\n",
      "parsed\n",
      "2e51a111\n",
      "parsed\n",
      "6e1a0834\n",
      "parsed\n",
      "a8657e65\n",
      "parsed\n",
      "2678d8c2\n",
      "parsed\n",
      "aa85c6ae\n",
      "parsed\n",
      "de06929d\n",
      "parsed\n",
      "b087fa95\n",
      "parsed\n",
      "3c41892d\n",
      "parsed\n",
      "4842f3e8\n",
      "parsed\n",
      "5eaf61fe\n",
      "parsed\n",
      "8ed36cea\n",
      "parsed\n",
      "46aebc79\n",
      "parsed\n",
      "e2d2bc58\n",
      "parsed\n",
      "137aab88\n",
      "parsed\n",
      "a260e651\n",
      "parsed\n",
      "da8d9fcc\n",
      "parsed\n",
      "2314e3c4\n",
      "parsed\n",
      "e7bdbba6\n",
      "parsed\n",
      "52cccade\n",
      "parsed\n",
      "11a814ea\n",
      "parsed\n",
      "0d1e02d5\n",
      "parsed\n",
      "0a0cc4c3\n",
      "parsed\n",
      "cb912983\n",
      "parsed\n",
      "2d4e434f\n",
      "parsed\n",
      "bb6655b9\n",
      "parsed\n",
      "fc2eb036\n",
      "parsed\n",
      "25daead9\n",
      "parsed\n",
      "2221d75e\n",
      "parsed\n",
      "94524a9d\n",
      "parsed\n",
      "1f1ecbb7\n",
      "parsed\n",
      "c5af32ab\n",
      "parsed\n",
      "1e6b7da1\n",
      "parsed\n",
      "259481c4\n",
      "parsed\n",
      "edbae698\n",
      "parsed\n",
      "67217f4c\n",
      "parsed\n",
      "2aadd232\n",
      "parsed\n",
      "adcd914a\n",
      "parsed\n",
      "bbf094b3\n",
      "parsed\n",
      "2fdc5057\n",
      "parsed\n",
      "95e302f7\n",
      "parsed\n",
      "1ac2c13c\n",
      "parsed\n",
      "5cc0e4d9\n",
      "parsed\n",
      "17090545\n",
      "parsed\n",
      "d17e30c6\n",
      "parsed\n",
      "1520b5bc\n",
      "parsed\n",
      "e86ca928\n",
      "parsed\n",
      "3b5b4eb3\n",
      "parsed\n",
      "489c366f\n",
      "parsed\n",
      "59381b15\n",
      "parsed\n",
      "220b1cf3\n",
      "parsed\n",
      "d970a0da\n",
      "parsed\n",
      "5fa98bd0\n",
      "parsed\n",
      "ce508f3c\n",
      "parsed\n",
      "b7b9487d\n",
      "parsed\n",
      "a74de125\n",
      "parsed\n",
      "e5270303\n",
      "parsed\n",
      "cabe8a5b\n",
      "parsed\n",
      "e3c0f777\n",
      "parsed\n",
      "50c009ef\n",
      "parsed\n",
      "3fe85b16\n",
      "parsed\n",
      "0fe0c76a\n",
      "parsed\n",
      "18c5bafe\n",
      "parsed\n",
      "59e86b40\n",
      "parsed\n",
      "1ac3ea8f\n",
      "parsed\n",
      "e04529ac\n",
      "parsed\n",
      "a602a7f8\n",
      "parsed\n",
      "9336ce2c\n",
      "parsed\n",
      "bac4e0f7\n",
      "parsed\n",
      "13dad632\n",
      "parsed\n",
      "ddc3c75b\n",
      "parsed\n",
      "095b667f\n",
      "parsed\n",
      "56a67c23\n",
      "parsed\n",
      "7fed7813\n",
      "parsed\n",
      "a0e7e259\n",
      "parsed\n",
      "4ca14331\n",
      "parsed\n",
      "6fdd09eb\n",
      "parsed\n",
      "64bfb2c3\n",
      "parsed\n",
      "33dd4516\n",
      "parsed\n",
      "504b8570\n",
      "parsed\n",
      "42e933c5\n",
      "parsed\n",
      "fe9240b0\n",
      "parsed\n",
      "c0a46e5d\n",
      "parsed\n",
      "943c2466\n",
      "parsed\n",
      "f41ef231\n",
      "parsed\n",
      "6b26d73c\n",
      "parsed\n",
      "830e2936\n",
      "parsed\n",
      "02007b7c\n",
      "parsed\n",
      "1ebb9a47\n",
      "parsed\n",
      "80125745\n",
      "parsed\n",
      "f01df45b\n",
      "parsed\n",
      "06014eec\n",
      "parsed\n",
      "54653ca9\n",
      "parsed\n",
      "f95304db\n",
      "parsed\n",
      "591df4e6\n",
      "parsed\n",
      "5cb7f597\n",
      "parsed\n",
      "c5de1f96\n",
      "parsed\n",
      "70ac8e80\n",
      "parsed\n",
      "f6551ffb\n",
      "parsed\n",
      "0ec021de\n",
      "parsed\n",
      "1edd4630\n",
      "parsed\n",
      "4664ae28\n",
      "parsed\n",
      "676e1b76\n",
      "parsed\n",
      "a3c84279\n",
      "parsed\n",
      "119c917d\n",
      "parsed\n",
      "f1284c1f\n",
      "parsed\n",
      "49a7db28\n",
      "parsed\n",
      "196cb0f2\n",
      "parsed\n",
      "1e50eab7\n",
      "parsed\n",
      "a7a6d0d7\n",
      "parsed\n",
      "0996213a\n",
      "parsed\n",
      "311bf368\n",
      "parsed\n",
      "c1551650\n",
      "parsed\n",
      "f9b673cf\n",
      "parsed\n",
      "5479dce2\n",
      "parsed\n",
      "02cf2317\n",
      "parsed\n",
      "947c07a6\n",
      "parsed\n",
      "bea22953\n",
      "parsed\n",
      "a1603359\n",
      "parsed\n",
      "a85a6a91\n",
      "parsed\n",
      "343864f5\n",
      "parsed\n",
      "6cb3b4a9\n",
      "parsed\n",
      "5959ea3c\n",
      "parsed\n",
      "202af70b\n",
      "parsed\n",
      "f2705fe7\n",
      "parsed\n",
      "74f412c4\n",
      "parsed\n",
      "5214eb93\n",
      "parsed\n",
      "3cfd16a7\n",
      "parsed\n",
      "a7cecdf9\n",
      "parsed\n",
      "2aad1011\n",
      "parsed\n",
      "cb478996\n",
      "parsed\n",
      "b4ef8ca7\n",
      "parsed\n",
      "8e74f943\n",
      "parsed\n",
      "a73ed357\n",
      "parsed\n",
      "d5b6ef5d\n",
      "parsed\n",
      "b406d90e\n",
      "parsed\n",
      "0002ab8b\n",
      "parsed\n",
      "138b55c7\n",
      "parsed\n",
      "154d7705\n",
      "parsed\n",
      "f96517d9\n",
      "parsed\n",
      "773587dd\n",
      "parsed\n",
      "73aff710\n",
      "parsed\n",
      "0728ca67\n",
      "parsed\n",
      "49a51e24\n",
      "parsed\n",
      "f0d552a7\n",
      "parsed\n",
      "9c750080\n",
      "parsed\n",
      "6f4998e6\n",
      "parsed\n",
      "97170587\n",
      "parsed\n",
      "4def6541\n",
      "parsed\n",
      "66e117dd\n",
      "parsed\n",
      "94fd2476\n",
      "parsed\n",
      "70d83d78\n",
      "parsed\n",
      "accb7285\n",
      "parsed\n",
      "cbca4495\n",
      "parsed\n",
      "78fce6ad\n",
      "parsed\n",
      "68842c02\n",
      "parsed\n",
      "71b1984b\n",
      "parsed\n",
      "d452b490\n",
      "parsed\n",
      "707cae8f\n",
      "parsed\n",
      "ffbf3311\n",
      "parsed\n",
      "3916f4a9\n",
      "parsed\n",
      "0227b872\n",
      "parsed\n",
      "39fda9f0\n",
      "parsed\n",
      "5170565b\n",
      "parsed\n",
      "ecca790c\n",
      "parsed\n",
      "c25b3de4\n",
      "parsed\n",
      "6ba259b1\n",
      "parsed\n",
      "67e2fd13\n",
      "parsed\n",
      "a6897e8c\n",
      "parsed\n",
      "2eba08e3\n",
      "parsed\n",
      "1d644223\n",
      "parsed\n",
      "14890cd2\n",
      "parsed\n",
      "a4fad482\n",
      "parsed\n",
      "34b7fd35\n",
      "parsed\n",
      "4930aa19\n",
      "parsed\n",
      "ee58a693\n",
      "parsed\n",
      "636f55d5\n",
      "parsed\n",
      "c839b764\n",
      "parsed\n",
      "0a278fb2\n",
      "parsed\n",
      "8de4fefd\n",
      "parsed\n",
      "94e86808\n",
      "parsed\n",
      "e7ba6b8a\n",
      "parsed\n",
      "f7bc2f65\n",
      "parsed\n",
      "ae52a907\n",
      "parsed\n",
      "dab5a24a\n",
      "parsed\n",
      "49f9bda9\n",
      "parsed\n",
      "d44de7d1\n",
      "parsed\n",
      "314ebe32\n",
      "parsed\n",
      "98cff602\n",
      "parsed\n",
      "54ec0de4\n",
      "parsed\n",
      "f81f4ecb\n",
      "parsed\n",
      "be760b92\n",
      "parsed\n",
      "a2cfa1c9\n",
      "parsed\n",
      "7b907071\n",
      "parsed\n",
      "fc2e0a61\n",
      "parsed\n",
      "d43e5742\n",
      "parsed\n",
      "32bc0538\n",
      "parsed\n",
      "b6730228\n",
      "parsed\n",
      "3ce9bbb8\n",
      "parsed\n",
      "4e584d06\n",
      "parsed\n",
      "ff4da2b6\n",
      "parsed\n",
      "58c1c168\n",
      "parsed\n",
      "96076a1a\n",
      "parsed\n",
      "3218389a\n",
      "parsed\n",
      "183a1c90\n",
      "parsed\n",
      "f0bc1c19\n",
      "parsed\n",
      "735e6c78\n",
      "parsed\n",
      "b8ca1cd3\n",
      "parsed\n",
      "efdb235f\n",
      "parsed\n",
      "355348f0\n",
      "parsed\n",
      "67afabf5\n",
      "parsed\n",
      "50d737e7\n",
      "parsed\n",
      "bbc0fca3\n",
      "parsed\n",
      "6f3bdd20\n",
      "parsed\n",
      "27c2d90a\n",
      "parsed\n",
      "88e9600a\n",
      "parsed\n",
      "d59d8df7\n",
      "parsed\n",
      "0b3eaf92\n",
      "parsed\n",
      "8fe56032\n",
      "parsed\n",
      "af833e0a\n",
      "parsed\n",
      "8d209d6d\n",
      "parsed\n",
      "0bc4c3da\n",
      "parsed\n",
      "c0ee2665\n",
      "parsed\n",
      "3f60871d\n",
      "parsed\n",
      "f30217a7\n",
      "parsed\n",
      "91fc573d\n",
      "parsed\n",
      "fe3139f6\n",
      "parsed\n",
      "48aac030\n",
      "parsed\n",
      "28321bc2\n",
      "parsed\n",
      "edb92d22\n",
      "parsed\n",
      "f488ce85\n",
      "parsed\n",
      "bf395099\n",
      "parsed\n",
      "01cd3b35\n",
      "parsed\n",
      "5551c92e\n",
      "parsed\n",
      "94f928d2\n",
      "parsed\n",
      "266faa6d\n",
      "parsed\n",
      "c21f99f5\n",
      "parsed\n",
      "13702957\n",
      "parsed\n",
      "7cd652c5\n",
      "parsed\n",
      "e1f93d10\n",
      "parsed\n",
      "36b9d1b7\n",
      "parsed\n",
      "3c8b32a1\n",
      "parsed\n",
      "05fb3a16\n",
      "parsed\n",
      "225506b9\n",
      "parsed\n",
      "bd4a1395\n",
      "parsed\n",
      "81b8e8d0\n",
      "parsed\n",
      "a7f6a33c\n",
      "parsed\n",
      "129b4ac0\n",
      "parsed\n",
      "b8cca8b7\n",
      "parsed\n",
      "1091b10f\n",
      "parsed\n",
      "0c7715a1\n",
      "parsed\n",
      "d2043cf5\n",
      "parsed\n",
      "44d22817\n",
      "parsed\n",
      "1f76dbeb\n",
      "parsed\n",
      "b8071a54\n",
      "parsed\n",
      "b8da9037\n",
      "parsed\n",
      "467e0cec\n",
      "parsed\n",
      "b69f32f6\n",
      "parsed\n",
      "3b3b1989\n",
      "parsed\n",
      "eb5771a0\n",
      "parsed\n",
      "bca10281\n",
      "parsed\n",
      "34a8edb0\n",
      "parsed\n",
      "f625307b\n",
      "parsed\n",
      "7fa98526\n",
      "parsed\n",
      "0807f0f3\n",
      "parsed\n",
      "6d0fb418\n",
      "parsed\n",
      "fbda1f40\n",
      "parsed\n",
      "0f88b7ac\n",
      "parsed\n",
      "9ffcc895\n",
      "parsed\n",
      "94a3b2fb\n",
      "parsed\n",
      "fb9a45d8\n",
      "parsed\n",
      "e31051f7\n",
      "parsed\n",
      "493b7b59\n",
      "parsed\n",
      "4a55c510\n",
      "parsed\n",
      "3ca0b489\n",
      "parsed\n",
      "690d97f1\n",
      "parsed\n",
      "eb5a25cb\n",
      "parsed\n",
      "6d9e0a6f\n",
      "parsed\n",
      "618ad97a\n",
      "parsed\n",
      "683495d2\n",
      "parsed\n",
      "dc1897b5\n",
      "parsed\n",
      "826098f2\n",
      "parsed\n",
      "821dfc08\n",
      "parsed\n",
      "27c8d5da\n",
      "parsed\n",
      "a52d4739\n",
      "parsed\n",
      "dc55359c\n",
      "parsed\n",
      "2ab49e43\n",
      "parsed\n",
      "b431e7eb\n",
      "parsed\n",
      "c5fdeba9\n",
      "parsed\n",
      "b8c9eaf1\n",
      "parsed\n",
      "c54058a1\n",
      "parsed\n",
      "b4b85c4b\n",
      "parsed\n",
      "7d40f6f6\n",
      "parsed\n",
      "f5dc446c\n",
      "parsed\n",
      "d30fc29d\n",
      "parsed\n",
      "8eca9f73\n",
      "parsed\n",
      "7b9eb7f7\n",
      "parsed\n",
      "c4aaeed9\n",
      "parsed\n",
      "3af31e2a\n",
      "parsed\n",
      "746342ff\n",
      "parsed\n",
      "bda2c9b3\n",
      "parsed\n",
      "41521c92\n",
      "parsed\n",
      "25481ce5\n",
      "parsed\n",
      "1427d567\n",
      "parsed\n",
      "76c91dfb\n",
      "parsed\n",
      "e4dd91cf\n",
      "parsed\n",
      "cc53ae94\n",
      "parsed\n",
      "403bbdd8\n",
      "parsed\n",
      "7c68ace0\n",
      "parsed\n",
      "147577f5\n",
      "parsed\n",
      "d3ffb802\n",
      "parsed\n",
      "cc04d27a\n",
      "parsed\n",
      "927b5e09\n",
      "parsed\n",
      "d22efea7\n",
      "parsed\n",
      "d1409f67\n",
      "parsed\n",
      "e07759e9\n",
      "parsed\n",
      "620fb76e\n",
      "parsed\n",
      "957280d8\n",
      "parsed\n",
      "185096ad\n",
      "parsed\n",
      "ec88d101\n",
      "parsed\n",
      "7156679d\n",
      "parsed\n",
      "4b2a3181\n",
      "parsed\n",
      "73bd7fa1\n",
      "parsed\n",
      "a4d3b1e5\n",
      "parsed\n",
      "1d462fe0\n",
      "parsed\n",
      "366d7563\n",
      "parsed\n",
      "cef156d1\n",
      "parsed\n",
      "b632d2ea\n",
      "parsed\n",
      "514e27bb\n",
      "parsed\n",
      "5c67e086\n",
      "parsed\n",
      "63a81b57\n",
      "parsed\n",
      "047f57fb\n",
      "parsed\n",
      "11f7371c\n",
      "parsed\n",
      "45f39b76\n",
      "parsed\n",
      "94e17563\n",
      "parsed\n",
      "9dd8efd2\n",
      "parsed\n",
      "9531dc92\n",
      "parsed\n",
      "14e0e697\n",
      "parsed\n",
      "6189375f\n",
      "parsed\n",
      "3419ee27\n",
      "parsed\n",
      "8b8c1603\n",
      "parsed\n",
      "e54d5411\n",
      "parsed\n",
      "f7b38587\n",
      "parsed\n",
      "be86b333\n",
      "parsed\n",
      "4ea80460\n",
      "parsed\n",
      "8006b496\n",
      "parsed\n",
      "704f95d8\n",
      "parsed\n",
      "a5b3296b\n",
      "parsed\n",
      "a23b276a\n",
      "parsed\n",
      "3537eeee\n",
      "parsed\n",
      "1d6d5b51\n",
      "parsed\n",
      "3a98b6b7\n",
      "parsed\n",
      "d42eb923\n",
      "parsed\n",
      "42aebe10\n",
      "parsed\n",
      "e4f62713\n",
      "parsed\n",
      "c13d811f\n",
      "parsed\n",
      "dfb41f7e\n",
      "parsed\n",
      "d04e77f8\n",
      "parsed\n",
      "451c067f\n",
      "parsed\n",
      "9fbfcd61\n",
      "parsed\n",
      "1ed8cfde\n",
      "parsed\n",
      "3f97f50f\n",
      "parsed\n",
      "a24a874a\n",
      "parsed\n",
      "bf563b1f\n",
      "parsed\n",
      "21e9facf\n",
      "parsed\n",
      "aef786aa\n",
      "parsed\n",
      "68858294\n",
      "parsed\n",
      "85ac722e\n",
      "parsed\n",
      "b61d2e92\n",
      "parsed\n",
      "8d7392cb\n",
      "parsed\n",
      "c920eef3\n",
      "parsed\n",
      "5017c9a4\n",
      "parsed\n",
      "6ffe101d\n",
      "parsed\n",
      "a55b29ff\n",
      "parsed\n",
      "eac70ce3\n",
      "parsed\n",
      "5f91f8ca\n",
      "parsed\n",
      "a3be507a\n",
      "parsed\n",
      "9a8faa50\n",
      "parsed\n",
      "a6e384fe\n",
      "parsed\n",
      "ddc14ada\n",
      "parsed\n",
      "593f7569\n",
      "parsed\n",
      "6cb56405\n",
      "parsed\n",
      "a22a93f1\n",
      "parsed\n",
      "b6259dea\n",
      "parsed\n",
      "bcfdc6f4\n",
      "parsed\n",
      "a7e7cdd2\n",
      "parsed\n",
      "55477da8\n",
      "parsed\n",
      "6a245a05\n",
      "parsed\n",
      "4405bfca\n",
      "parsed\n",
      "3e0acc25\n",
      "parsed\n",
      "abaecdf8\n",
      "parsed\n",
      "ff40f83b\n",
      "parsed\n",
      "95a16746\n",
      "parsed\n",
      "46acdd18\n",
      "parsed\n",
      "f721d54b\n",
      "parsed\n",
      "69cd4897\n",
      "parsed\n",
      "346e799a\n",
      "parsed\n",
      "551461b2\n",
      "parsed\n",
      "c3ba4459\n",
      "parsed\n",
      "a114ad55\n",
      "parsed\n",
      "dd3c8000\n",
      "parsed\n",
      "34b0ebfc\n",
      "parsed\n",
      "7d11d5ce\n",
      "parsed\n",
      "e4e45f15\n",
      "parsed\n",
      "b3997e6f\n",
      "parsed\n",
      "e414df91\n",
      "parsed\n",
      "f20a3479\n",
      "parsed\n",
      "e7af4968\n",
      "parsed\n",
      "9fad096e\n",
      "parsed\n",
      "bcdf7407\n",
      "parsed\n",
      "8d1e7e20\n",
      "parsed\n",
      "2023a9dc\n",
      "parsed\n",
      "468f69ff\n",
      "parsed\n",
      "c4ff26e5\n",
      "parsed\n",
      "62722d72\n",
      "parsed\n",
      "d1419be1\n",
      "parsed\n",
      "a5f6f439\n",
      "parsed\n",
      "879c1ec0\n",
      "parsed\n",
      "3ac604c3\n",
      "parsed\n",
      "0315aa96\n",
      "parsed\n",
      "daf84bc3\n",
      "parsed\n",
      "1e956ca7\n",
      "parsed\n",
      "3ee083ab\n",
      "parsed\n",
      "f826cba4\n",
      "parsed\n",
      "60fa95ed\n",
      "parsed\n",
      "53f3ee10\n",
      "parsed\n",
      "93aa4278\n",
      "parsed\n",
      "0edeb016\n",
      "parsed\n",
      "ba186de6\n",
      "parsed\n",
      "da2f1cf4\n",
      "parsed\n",
      "7fd648ca\n",
      "parsed\n",
      "42c09143\n",
      "parsed\n",
      "d6d534fc\n",
      "parsed\n",
      "b2c0c554\n",
      "parsed\n",
      "819afebc\n",
      "parsed\n",
      "74551c54\n",
      "parsed\n",
      "4d98cd09\n",
      "parsed\n",
      "59a81fd5\n",
      "parsed\n",
      "35dbd6e2\n",
      "parsed\n",
      "e5fe9efe\n",
      "parsed\n",
      "5c043c62\n",
      "parsed\n",
      "af0739da\n",
      "parsed\n",
      "451bc25d\n",
      "parsed\n",
      "ea2e7458\n",
      "parsed\n",
      "6ce8e875\n",
      "parsed\n",
      "b50e9e2b\n",
      "parsed\n",
      "29311ef5\n",
      "parsed\n",
      "1e0dc11c\n",
      "parsed\n",
      "1078aeb7\n",
      "parsed\n",
      "7daaca73\n",
      "parsed\n",
      "0cfbe2e2\n",
      "parsed\n",
      "1460fb65\n",
      "parsed\n",
      "d4f9efdc\n",
      "parsed\n",
      "6a417bfe\n",
      "parsed\n",
      "ed8b300d\n",
      "parsed\n",
      "a64aed6b\n",
      "parsed\n",
      "727238ee\n",
      "parsed\n",
      "85d4901d\n",
      "parsed\n",
      "df023a13\n",
      "parsed\n",
      "48e92d65\n",
      "parsed\n",
      "1685cae4\n",
      "parsed\n",
      "4fb7b21e\n",
      "parsed\n",
      "8bd3bfc2\n",
      "parsed\n",
      "03b5fc59\n",
      "parsed\n",
      "7c31bc9a\n",
      "parsed\n",
      "605efc12\n",
      "parsed\n",
      "c5cde96c\n",
      "parsed\n",
      "d45d2da6\n",
      "parsed\n",
      "59823c72\n",
      "parsed\n",
      "665f7b27\n",
      "parsed\n",
      "0a406fe0\n",
      "parsed\n",
      "64b209b0\n",
      "parsed\n",
      "518c4cb8\n",
      "parsed\n",
      "00882c83\n",
      "parsed\n",
      "d6d483ce\n",
      "parsed\n",
      "f9711723\n",
      "parsed\n",
      "5bda3b94\n",
      "parsed\n",
      "cccd31cf\n",
      "parsed\n",
      "57f49999\n",
      "parsed\n",
      "5cb58698\n",
      "parsed\n",
      "de650b41\n",
      "parsed\n",
      "9ffacaac\n",
      "parsed\n",
      "4dfb5d4f\n",
      "parsed\n",
      "0b8739b7\n",
      "parsed\n",
      "9eb52679\n",
      "parsed\n",
      "7a1fcfd9\n",
      "parsed\n",
      "1cfa62c5\n",
      "parsed\n",
      "2a78f52e\n",
      "parsed\n",
      "68aeab64\n",
      "parsed\n",
      "9a7c26e0\n",
      "parsed\n",
      "1fd83eb9\n",
      "parsed\n",
      "fbaa5b20\n",
      "parsed\n",
      "37eab341\n",
      "parsed\n",
      "57754faf\n",
      "parsed\n",
      "6979c5d1\n",
      "parsed\n",
      "a1bd8c34\n",
      "parsed\n",
      "b2ab0fc1\n",
      "parsed\n",
      "80c439a9\n",
      "parsed\n",
      "ff93b86e\n",
      "parsed\n",
      "fcd86c8f\n",
      "parsed\n",
      "236864c2\n",
      "parsed\n",
      "efc4a04f\n",
      "parsed\n",
      "15f361b7\n",
      "parsed\n",
      "dbbce78b\n",
      "parsed\n",
      "f3a00e15\n",
      "parsed\n",
      "9102b3c0\n",
      "parsed\n",
      "70d89fdf\n",
      "parsed\n",
      "c5d6a804\n",
      "parsed\n",
      "8c7f089f\n",
      "parsed\n",
      "739bcccf\n",
      "parsed\n",
      "4603e4e5\n",
      "parsed\n",
      "0a7c328e\n",
      "parsed\n",
      "77efd069\n",
      "parsed\n",
      "cc60f7bc\n",
      "parsed\n",
      "aa13dd66\n",
      "parsed\n",
      "c41e479c\n",
      "parsed\n",
      "2f28dcf1\n",
      "parsed\n",
      "7a69cccf\n",
      "parsed\n",
      "20174c95\n",
      "parsed\n",
      "f2cd48b6\n",
      "parsed\n",
      "59b4324f\n",
      "parsed\n",
      "e1dc1ed9\n",
      "parsed\n",
      "fc60bf3b\n",
      "parsed\n",
      "1e60e888\n",
      "parsed\n",
      "44552c2e\n",
      "parsed\n",
      "7116b3be\n",
      "parsed\n",
      "5d4d206e\n",
      "parsed\n",
      "387093cc\n",
      "parsed\n",
      "d12a2657\n",
      "parsed\n",
      "eb7a57a6\n",
      "parsed\n",
      "d6f0c6ea\n",
      "parsed\n",
      "9f261648\n",
      "parsed\n",
      "aa7ff0f7\n",
      "parsed\n",
      "387bdc5f\n",
      "parsed\n",
      "c6a22665\n",
      "parsed\n",
      "0560e827\n",
      "parsed\n",
      "59812e77\n",
      "parsed\n",
      "dce0bb09\n",
      "parsed\n",
      "4920d4e9\n",
      "parsed\n",
      "0f1d2765\n",
      "parsed\n",
      "4eef2f81\n",
      "parsed\n",
      "7f93c032\n",
      "parsed\n",
      "ee6f7c89\n",
      "parsed\n",
      "b63b12e0\n",
      "parsed\n",
      "892c22c1\n",
      "parsed\n",
      "13d38e8d\n",
      "parsed\n",
      "7d64e9e0\n",
      "parsed\n",
      "645f0a55\n",
      "parsed\n",
      "7297b7fc\n",
      "parsed\n",
      "68154f64\n",
      "parsed\n",
      "dc7b6f51\n",
      "parsed\n",
      "b25c6ca3\n",
      "parsed\n",
      "9f69ca26\n",
      "parsed\n",
      "0f1ddc9e\n",
      "parsed\n",
      "01f61154\n",
      "parsed\n",
      "d43c32ba\n",
      "parsed\n",
      "a044d267\n",
      "parsed\n",
      "abf8ccdc\n",
      "parsed\n",
      "26918af3\n",
      "parsed\n",
      "a5234ac0\n",
      "parsed\n",
      "af22c52a\n",
      "parsed\n",
      "2aaac94c\n",
      "parsed\n",
      "9d15c9e9\n",
      "parsed\n",
      "79b88d0b\n",
      "parsed\n",
      "45485322\n",
      "parsed\n",
      "d5eab395\n",
      "parsed\n",
      "282957fb\n",
      "parsed\n",
      "39ad14fd\n",
      "parsed\n",
      "e34df2a5\n",
      "parsed\n",
      "c91b6b57\n",
      "parsed\n",
      "4aa8eafc\n",
      "parsed\n",
      "a9daaab0\n",
      "parsed\n",
      "931f9626\n",
      "parsed\n",
      "782e1723\n",
      "parsed\n",
      "4e08c86a\n",
      "parsed\n",
      "34bcad27\n",
      "parsed\n",
      "96144e66\n",
      "parsed\n",
      "840f739d\n",
      "parsed\n",
      "bf006ff9\n",
      "parsed\n",
      "f178d4a0\n",
      "parsed\n",
      "b80401a2\n",
      "parsed\n",
      "88002d35\n",
      "parsed\n",
      "fe61aa5b\n",
      "parsed\n",
      "b9adeb39\n",
      "parsed\n",
      "ebc13686\n",
      "parsed\n",
      "939f9c33\n",
      "parsed\n",
      "b5c3e6af\n",
      "parsed\n",
      "80554fc2\n",
      "parsed\n",
      "943df153\n",
      "parsed\n",
      "b8d3c55e\n",
      "parsed\n",
      "67bf60c6\n",
      "parsed\n",
      "336f5e36\n",
      "parsed\n",
      "fd2b9972\n",
      "parsed\n",
      "75cd9b7a\n",
      "parsed\n",
      "51c99586\n",
      "parsed\n",
      "089c8c18\n",
      "parsed\n",
      "f4b82056\n",
      "parsed\n",
      "dd2e7dc9\n",
      "parsed\n",
      "3fcbd80e\n",
      "parsed\n",
      "924fcf47\n",
      "parsed\n",
      "58240887\n",
      "parsed\n",
      "67d343f2\n",
      "parsed\n",
      "6de95c2a\n",
      "parsed\n",
      "2ff28e5b\n",
      "parsed\n",
      "29c6bbf1\n",
      "parsed\n",
      "bd09df94\n",
      "parsed\n",
      "af887c59\n",
      "parsed\n",
      "ee7c59ea\n",
      "parsed\n",
      "a2531c75\n",
      "parsed\n",
      "bc4b2320\n",
      "parsed\n",
      "f69fb077\n",
      "parsed\n",
      "e223524c\n",
      "parsed\n",
      "0f08bec7\n",
      "parsed\n",
      "8b4b1685\n",
      "parsed\n",
      "ecfc5c07\n",
      "parsed\n",
      "a1b68c52\n",
      "parsed\n",
      "483e7d61\n",
      "parsed\n",
      "e5c33f50\n",
      "parsed\n",
      "cbf13b19\n",
      "parsed\n",
      "39861d6e\n",
      "parsed\n",
      "3dac15ff\n",
      "parsed\n",
      "32686722\n",
      "parsed\n",
      "22521751\n",
      "parsed\n",
      "81ad4784\n",
      "parsed\n",
      "29b5651e\n",
      "parsed\n",
      "ca79bbe8\n",
      "parsed\n",
      "668f1ad9\n",
      "parsed\n",
      "7a6f23eb\n",
      "parsed\n",
      "232e5557\n",
      "parsed\n",
      "e44ec04a\n",
      "parsed\n",
      "55fdb8b9\n",
      "parsed\n",
      "bf9082a2\n",
      "parsed\n",
      "e7906e44\n",
      "parsed\n",
      "76d8892e\n",
      "parsed\n",
      "c5c2c82a\n",
      "parsed\n",
      "82b6c143\n",
      "parsed\n",
      "77d9a742\n",
      "parsed\n",
      "1667e95d\n",
      "parsed\n",
      "624a3525\n",
      "parsed\n",
      "1db86601\n",
      "parsed\n",
      "047baefe\n",
      "parsed\n",
      "4f240372\n",
      "parsed\n",
      "7aef625b\n",
      "parsed\n",
      "a3aa3a7d\n",
      "parsed\n",
      "d2719204\n",
      "parsed\n",
      "30b8e8e6\n",
      "parsed\n",
      "f33fc6e9\n",
      "parsed\n",
      "d828de2a\n",
      "parsed\n",
      "03f20ec1\n",
      "parsed\n",
      "249726fe\n",
      "parsed\n",
      "4e492af0\n",
      "parsed\n",
      "10011dc1\n",
      "parsed\n",
      "92fb909a\n",
      "parsed\n",
      "2b8cb640\n",
      "parsed\n",
      "d4ceab0b\n",
      "parsed\n",
      "482e575f\n",
      "parsed\n",
      "33e775eb\n",
      "parsed\n",
      "19a3d34a\n",
      "parsed\n",
      "55c68f23\n",
      "parsed\n",
      "54020f0a\n",
      "parsed\n",
      "b6249d2c\n",
      "parsed\n",
      "31543d95\n",
      "parsed\n",
      "e147bbb6\n",
      "parsed\n",
      "dc55657f\n",
      "parsed\n",
      "f6979915\n",
      "parsed\n",
      "1076a121\n",
      "parsed\n",
      "aa203ca7\n",
      "parsed\n",
      "8b04605d\n",
      "parsed\n",
      "a3b9af04\n",
      "parsed\n",
      "b16aae74\n",
      "parsed\n",
      "66326a87\n",
      "parsed\n",
      "fb3c4150\n",
      "parsed\n",
      "886d1617\n",
      "parsed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "parsed_results = {}\n",
    "\n",
    "for doc_id, json_questions in results.items():\n",
    "    print(doc_id)\n",
    "    cleaned = re.sub(r',\\s*\\]', ']', json_questions)  # remove \", ]\"\n",
    "    parsed_results[doc_id] = json.loads(cleaned)\n",
    "    print(\"parsed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69192af7-a711-43e4-9c2b-68c9a113c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results['c02e79ef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50ef1a30-21c5-45b0-8b5f-d0f8c09db072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsed_results['e41b100c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c989b63-7269-41de-aeb6-e973b9d956ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e670e8e4-8649-45e5-8c8e-48f06fea567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "35e7b1a7-08b1-41ee-9989-5b1ebf50fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0741578c-6b99-4ed4-9361-1eca96a2b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lh results.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62fdccfd-f340-4d4f-89e5-30aefb61ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink('results.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "723fd7d3-ccc1-4d87-bc6b-8376b2b21912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c02e79ef': ['What is the specific date and time when the course is set to begin?',\n",
       "  'How can I stay updated with course announcements and important dates?',\n",
       "  'Is there a registration process required before the course starts?',\n",
       "  \"What platform should I use to access the course's public calendar?\",\n",
       "  'Where can I find the link to register for the course?'],\n",
       " '1f6520ca': ['What specific skills or knowledge do I need before enrolling in this course?',\n",
       "  'Can you point me to where I can find the requirements for this course?',\n",
       "  'Are there any prior courses or experiences necessary for joining this program?',\n",
       "  'Is there a resource that outlines the prerequisites for this course?',\n",
       "  'What should I have completed before I start this course?'],\n",
       " '7842b56a': ['Is it possible to enroll in the course after it has begun?',\n",
       "  'If I miss the registration, can I still participate in homework assignments?',\n",
       "  'Are there any specific deadlines I should know about for the final project?',\n",
       "  'What happens if I complete my final project after the deadline?',\n",
       "  'Should I manage my time carefully to avoid last-minute submissions?'],\n",
       " '0bbf41ec': ['When will I get a confirmation email after registering for the bootcamp?',\n",
       "  'Is it necessary to wait for a confirmation email to start the course?',\n",
       "  'Can I begin submitting my assignments without formal registration?',\n",
       "  'What is the purpose of the registration for the Data Engineering Bootcamp?',\n",
       "  'How does the registration process work for this course?'],\n",
       " '63394d91': ['What steps should I take to prepare for the course prior to its start?',\n",
       "  'Are there any specific software or accounts I need to set up before the course begins?',\n",
       "  \"What prerequisites should I review to ensure I'm ready for the course?\",\n",
       "  'Is there a particular programming language I need to have installed before the course starts?',\n",
       "  'What tools and technologies should I familiarize myself with ahead of the course?'],\n",
       " '2ed9b986': ['How many Zoom Camps are offered annually for this course?',\n",
       "  'What are the specific time frames for each Zoom Camp throughout the year?',\n",
       "  'Is there only one live cohort available for the Data-Engineering Zoom Camp each year?',\n",
       "  \"Can I participate in any Zoom Camp at my own pace if I don't want a certificate?\",\n",
       "  'Are the schedules for each cohort consistent across different Zoom Camps?'],\n",
       " '93e2c8ed': ['Will the 2024 cohort have different tools compared to the previous one?',\n",
       "  'What AI tool will be used in the 2024 edition of the course?',\n",
       "  'Are there any updated videos for the 2024 course cohort?',\n",
       "  'What was used in the course for the 2023 edition instead of Airflow?',\n",
       "  'How does the 2024 course differ from the one in 2023?'],\n",
       " 'a482086d': ['Is it possible to access course materials after the course ends?',\n",
       "  'Can I work on assignments after completion of the course?',\n",
       "  'Will I be able to prepare for the next cohort after the course finishes?',\n",
       "  'Can I start my capstone project after the course is over?',\n",
       "  'How can I continue my learning journey after the course concludes?'],\n",
       " 'eb56ae98': ['Is there any support available for students in the self-paced course format?',\n",
       "  'Where can I find answers to my questions about the course?',\n",
       "  'How should I approach getting help if I encounter an issue while studying?',\n",
       "  'Can I use the Slack channel for support while taking the course at my own pace?',\n",
       "  'What should I do before asking a question in the Slack channel?'],\n",
       " '4292531b': ['Where can I find the main videos for our course on YouTube?',\n",
       "  'Is there a specific GitHub repository that lists the video thumbnails linking to the playlist?',\n",
       "  'Are there any additional playlists for this year available in the course materials?',\n",
       "  'How do I access the year-specific playlist for office hours videos?',\n",
       "  'Where is the main playlist for the DATA ENGINEERING course pinned in our communication tools?'],\n",
       " 'ea739c65': ['What is the weekly time commitment for this course?',\n",
       "  'How should I determine my expected hours per week?',\n",
       "  'Is the required study time the same for everyone?',\n",
       "  'Can I assess my own time investment for the course?',\n",
       "  'What factors influence the number of hours needed weekly?'],\n",
       " 'cb257ee5': ['Is it possible to earn a certificate while taking the course at my own pace?',\n",
       "  'What are the requirements for obtaining a certificate in this course?',\n",
       "  \"Why can't I receive a certificate if I choose the self-paced option?\",\n",
       "  'Are peer-reviews necessary for earning the course certificate?',\n",
       "  'When can I peer-review projects during the course?'],\n",
       " '04aa4897': ['Where can I find the video link for the Office Hour sessions?',\n",
       "  'How do students submit questions during the workshop sessions?',\n",
       "  'Is the Zoom link available to students for the Office Hours?',\n",
       "  'When will the video URL for the sessions be announced?',\n",
       "  'What platform should I use to watch the Office Hour sessions live?'],\n",
       " '9681be3b': ['Will the Office Hours be recorded if I cannot make it to the live session?',\n",
       "  'How soon after the Office Hours ends will the recording be available?',\n",
       "  'Can I watch the recorded Office Hours at my convenience?',\n",
       "  'Is there a way to access past Office Hours recordings?',\n",
       "  'What happens if I miss the live workshop during Office Hours?'],\n",
       " 'a1daf537': ['What is the best way to keep track of my homework and project deadlines for this course?',\n",
       "  'Where can I find the most current deadlines for assignments and projects?',\n",
       "  'How should I stay updated on possible extensions or changes to deadlines?',\n",
       "  'Is there a specific link to check for deadlines and updates throughout the course?',\n",
       "  'What should I do if I believe a deadline has been changed or extended?'],\n",
       " 'be5bfee4': ['Is it permitted to submit homework after the due date?',\n",
       "  'What happens if I miss the deadline for homework submissions?',\n",
       "  'Can I turn in my homework if the submission process is still open?',\n",
       "  \"How can I confirm my homework submission after it's due?\",\n",
       "  'Are there any exceptions to the late submission policy for homework?'],\n",
       " '0e424a44': ['What specific URL do I need to provide for homework submissions?',\n",
       "  'Where should I store my code for the homework assignments?',\n",
       "  'Is it acceptable to use platforms other than GitHub for my homework?',\n",
       "  'What criteria should my homework repository meet?',\n",
       "  'How should I ensure my code is accessible for review?'],\n",
       " '29865466': ['How is homework graded and how can I check my points for it?',\n",
       "  'What does the leaderboard display in terms of my total points?',\n",
       "  'Can you explain how points are earned from FAQ submissions?',\n",
       "  'How many points can I earn from sharing my learning publicly?',\n",
       "  \"Where can I find the points I've accumulated for each homework task?\"],\n",
       " '016d46a1': ['How was my display name determined when I created my account for the course?',\n",
       "  'Where can I find my current display name to check my leaderboard status?',\n",
       "  'Is it possible to change my display name once I see it?',\n",
       "  'What steps should I follow to view my display name in the course profile?',\n",
       "  'Why am I not appearing on the leaderboard and how can I confirm my display name?'],\n",
       " '47972cb1': ['Is Python 3.9 the preferred version for this course in 2024?',\n",
       "  'Will using Python 3.10 or 3.11 cause issues with the course?',\n",
       "  'Why is Python 3.9 recommended over other versions?',\n",
       "  'Are there any advantages to using Python 3.9 in this course?',\n",
       "  'What should I do if I have Python 3.10 or 3.11 installed?'],\n",
       " 'ddf6c1b3': ['What are the options for setting up my environment for this course?',\n",
       "  'Are there any specific challenges for Windows users when working locally?',\n",
       "  'What should I do if I want to start with Docker for my local setup?',\n",
       "  'How can I use GitHub Codespaces for my virtual machine environment?',\n",
       "  'Is it possible to work from different devices during the boot camp?'],\n",
       " 'ac25d3af': ['Can I use GitHub Codespaces instead of CLI or Git Bash for data ingestion?',\n",
       "  'What resources does GitHub Codespaces provide for my project?',\n",
       "  'Does GitHub Codespaces come with pre-installed tools I might need?',\n",
       "  'Is it possible to access GitHub repositories directly from a Codespace?',\n",
       "  'How can GitHub Codespaces assist in creating a Docker file?'],\n",
       " '251218fc': ['Is GitHub Codespaces mandatory for this course?',\n",
       "  'Can I use my own installed PostgreSQL and Docker for the assignments?',\n",
       "  'Are there alternative environments besides GitHub Codespaces?',\n",
       "  'Is it acceptable to complete the course using my personal laptop?',\n",
       "  'Do I have to use the recommended platforms for the course?'],\n",
       " '3c0114ce': ['Do I have to use both GitHub Codespaces and GCP for the course?',\n",
       "  'Which option should I choose for my final project development?',\n",
       "  'Is it necessary to learn BigQuery during the course?',\n",
       "  'Can I create a local environment instead of using the cloud platforms?',\n",
       "  'What environment suits my project idea best?'],\n",
       " 'f43f5fe7': ['What steps should I follow to open the Run command window on my Windows machine?',\n",
       "  'How can I access the Registry Editor to change registry values?',\n",
       "  'What specific registry value do I need to modify to resolve the GCP VM connection issue?',\n",
       "  'Is there an alternative way to address connection problems with a GCP VM besides changing registry values?',\n",
       "  'Where can I find the known_hosts file on my Windows machine to delete the saved fingerprint?'],\n",
       " 'd061525d': ['What are the main reasons for choosing GCP as the primary cloud provider for this course?',\n",
       "  'Am I allowed to use other cloud platforms like AWS instead of GCP during the course?',\n",
       "  'Is there any cost involved when signing up for a free GCP account?',\n",
       "  'What benefits do new users receive when they start using GCP?',\n",
       "  'Can you explain the relationship between BigQuery and GCP in the context of this course?'],\n",
       " '1cd01b2c': ['Is it necessary to pay for cloud services during the course?',\n",
       "  'What are the cloud service options available to us?',\n",
       "  'How can I utilize GCP for free?',\n",
       "  'Are there any costs associated with using cloud platforms in this course?',\n",
       "  'Will using cloud services incur any fees while enrolled?'],\n",
       " 'e4a7c3b0': ['Is it feasible to complete the course without using cloud platforms like GCP?',\n",
       "  'Are there local alternatives available for all the tools covered in the course?',\n",
       "  'Can the course be entirely done using a home setup instead of cloud services?',\n",
       "  'Will there be any materials provided for running elements of the course locally?',\n",
       "  'Is BigQuery the only component of the course that requires cloud access?'],\n",
       " '7cd1912e': ['Is it allowed to utilize AWS for the course assignments, and what should I keep in mind while doing so?',\n",
       "  'What are the main tasks I need to focus on for the final capstone project?',\n",
       "  'Will there be enough peers available for assistance if I choose AWS over GCP?',\n",
       "  'How does my choice of AWS impact my collaboration with other students in the course?',\n",
       "  'Are there any specific guidelines I need to follow when adapting the course content for AWS?'],\n",
       " '52393fb3': ['What additional live Zoom sessions might occur apart from the Office Hour?',\n",
       "  'Will there be scheduled calls during the Capstone phase to address any inquiries?',\n",
       "  'How will we be notified if there are extra Zoom calls during Capstone?',\n",
       "  'Are live calls planned to assist with questions throughout the Capstone period?',\n",
       "  'When can I expect announcements regarding potential Capstone Zoom sessions?'],\n",
       " '10515af5': ['Will we continue to use the NYC Trip data from January 2021 for our project?',\n",
       "  \"Is the project for this year the same as last year's?\",\n",
       "  'Are we switching to the 2022 NYC Trip data for our assignments?',\n",
       "  'Where can I access the NYC Trip data for January 2021?',\n",
       "  'Is there a significant change in the project compared to last year?'],\n",
       " 'cdb86a97': ['Is the repository from 2022 still available?',\n",
       "  'Where can I find the materials from 2022?',\n",
       "  'Has the 2022 content been removed?',\n",
       "  'What happened to the 2022 resources?',\n",
       "  'Can I access the 2022 information somewhere?'],\n",
       " '3e0114ad': ['Is Airflow an acceptable tool for my final project?',\n",
       "  'Am I allowed to choose any tool for my project?',\n",
       "  'Can I select a different software for my final assignment?',\n",
       "  'Are there restrictions on the tools I can use for my project?',\n",
       "  'Is it mandatory to use a specific tool for the final project?'],\n",
       " 'b2799574': ['Can I utilize tools like Airflow or Prefect in place of the designated tool in the course?',\n",
       "  'Is it acceptable to choose AWS or Snowflake instead of the prescribed GCP products for my projects?',\n",
       "  'Am I permitted to use Tableau instead of Metabase or Google Data Studio in the course?',\n",
       "  'What are the implications of selecting an alternative tool or stack for my capstone project?',\n",
       "  \"Will there be support available if I decide to go with a different data stack than what's provided?\"],\n",
       " '2f19301f': ['What are some ways I can add value to this course?',\n",
       "  'Is there a specific way to share the course with others?',\n",
       "  'How can I suggest improvements or changes to the course materials?',\n",
       "  'What should I do if I find something in the repository that needs better organization?',\n",
       "  'Can you explain how to create a PR for the repository?'],\n",
       " '7c700adb': ['Is there a preferred operating system for this course?',\n",
       "  'Can I use Windows for the course assignments?',\n",
       "  'Are students in the course using different operating systems?',\n",
       "  'Which operating system works best with the course material?',\n",
       "  'Is Linux necessary for successful course completion?'],\n",
       " '44b14808': ['What issues might Windows users experience in the course when dealing with shell scripts in *.sh files?',\n",
       "  'Why is it important to use WSL for the course modules involving shell scripts?',\n",
       "  'How did past cohorts manage to overcome the challenges with shell scripts on Windows?',\n",
       "  'Are there any alternatives for Windows users who do not want to use WSL when running the course materials?',\n",
       "  'What specific modules will require the use of shell scripts that might pose problems for non-WSL Windows users?'],\n",
       " '76e4baf6': ['Are there any recommended books for this course?',\n",
       "  'What additional resources should I check out?',\n",
       "  'Is there a document that lists useful materials?',\n",
       "  'Can you provide a link to the resources for data engineering?',\n",
       "  'Do you suggest any particular readings for this curriculum?'],\n",
       " '48b533a8': ['Can you explain what Project Attempt #1 and Project Attempt #2 are in detail?',\n",
       "  \"What happens if I'm late for the first project deadline?\",\n",
       "  'Is there a possibility to resubmit the project after a failed first attempt?',\n",
       "  'How does the second attempt for the project work?',\n",
       "  'What are the consequences of missing the first project submission?'],\n",
       " '954044d1': ['What are some effective strategies for troubleshooting technical issues on my own before seeking help?',\n",
       "  'How can I find solutions to common errors I encounter while coding?',\n",
       "  'What should I include in my question when seeking assistance from others on platforms like Stackoverflow?',\n",
       "  'What is the recommended approach for using Slack to resolve technical problems with my peers?',\n",
       "  'How can taking a break help me with solving coding issues, and what activities do you suggest for a mental reset?'],\n",
       " 'a820b9b3': ['What should I include when I ask a question for help?',\n",
       "  'When is it appropriate to seek assistance rather than relying on the troubleshooting guide?',\n",
       "  'What specific details about my coding environment should I mention when asking for help?',\n",
       "  'Why is it important to describe what I have already attempted when asking a question?',\n",
       "  'What types of errors should I report, and how should I present them?'],\n",
       " 'f2945cd2': ['What steps should I follow after creating a GitHub account for this course?',\n",
       "  'How can I ensure that my local Git repository is properly set up for accessing course materials?',\n",
       "  'What should I do if I want to make modifications to the content of the course using Git?',\n",
       "  'Are there any specific types of files that I need to ignore when creating my repositories?',\n",
       "  'Where can I find helpful resources for learning how to manage my Git repositories effectively?'],\n",
       " 'eb9d376f': ['What error message might I encounter if I use spaces instead of tabs in my Makefile?',\n",
       "  'How can I resolve the issue of missing separators in a document?',\n",
       "  'What should I replace spaces with in my Makefile to avoid errors?',\n",
       "  'Is there a specific solution or guide I should follow for fixing tab issues in VS Code?',\n",
       "  \"What steps do I need to take if I see a 'missing separator' error in my Makefile?\"],\n",
       " '72f25f6d': ['How can I open an HTML file using a Windows browser while working on Linux in WSL?',\n",
       "  'What command do I need to use to view an HTML file from WSL?',\n",
       "  'Is it possible to choose a specific browser for viewing HTML files in WSL?',\n",
       "  'What should I do if I want to use Firefox to open an HTML file from Linux?',\n",
       "  'Do I need to install any additional tools to open HTML files in a Windows browser from WSL?'],\n",
       " 'a1e59afc': ['How do I set up Chrome Remote Desktop on a Debian Linux virtual machine in Compute Engine?',\n",
       "  'What should I do if I encounter an ERROR 403: Forbidden when trying to download the 2021 Yellow Taxi Trip Records?',\n",
       "  'Where can I find a backup of the 2021 Yellow Taxi Trip Records data if the original link fails?',\n",
       "  'What command should I use to properly unzip a gzipped file that I downloaded?',\n",
       "  \"Can I use the standard 'unzip' command to extract contents from a .gz file?\"],\n",
       " '71c10610': ['What is the correct naming convention for taxi data files when handling them in our project?',\n",
       "  'What alternative approach can I take to name the data file if it is downloaded with a csv.gz extension?',\n",
       "  'How can I extract the file name from the URL provided for the yellow taxi data?',\n",
       "  'Can you explain how to adjust the csv_name variable in the context of the video?',\n",
       "  'What function can I use to read taxi data files that have the csv.gz extension in Python?'],\n",
       " '17a5aea1': ['What is the data dictionary for Yellow Taxi trips in New York?',\n",
       "  'Can you provide the link for the Green Taxi data dictionary?',\n",
       "  'Where can I find the Yellow Trips data dictionary for NYC?',\n",
       "  'Is there an online resource for Green Taxi trip records?',\n",
       "  'How do I access the data dictionary for Yellow and Green Taxi trips?'],\n",
       " '5a275db7': ['How can I unzip a downloaded parquet file using the command line?',\n",
       "  'What command should I use to extract the parquet file into a CSV format?',\n",
       "  'Can you explain how to read a parquet file directly in a Python script?',\n",
       "  'What do I need to include in the main function to handle parquet files?',\n",
       "  'How can I convert a parquet file to CSV after downloading it?'],\n",
       " '7ec0f9b0': [\"What are the steps to install wget on an Ubuntu system if I encounter the error 'wget is not recognized as an internal or external command'?\",\n",
       "  'Can you explain how to install wget on MacOS using Brew if the command is not recognized?',\n",
       "  'What options do I have for installing wget on a Windows machine when the command is unrecognized?',\n",
       "  'If I prefer using Python to download files, how can I utilize the wget library instead of the command line tool?',\n",
       "  'Is there a way to bypass using wget entirely when attempting to download a file, and if so, what is the method?'],\n",
       " 'bb1ba786': ['What should I do if I encounter a certificate verification error while using wget on MacOS?',\n",
       "  \"Can you explain the importance of adding '!' before wget when using it in a Jupyter Notebook?\",\n",
       "  'What are the two methods I can use to bypass the certificate verification for wget?',\n",
       "  'How do I utilize the Python library wget as a potential solution for my issue on MacOS?',\n",
       "  'What is the correct command format to run wget while ignoring certificate verification?'],\n",
       " '2f83dbe7': ['How can I set the backslash as an escape character in Git Bash for Windows?',\n",
       "  'What command do I need to use in the terminal for setting the escape character?',\n",
       "  'Do I need to include the escape character setting in my .bashrc file?',\n",
       "  'Is the escape character setting in Git Bash specific to any user or can anyone use it?',\n",
       "  'What specific environment is mentioned for using the backslash as an escape character?'],\n",
       " '543ff080': ['What steps do I need to follow to securely store secrets in GitHub Codespaces?',\n",
       "  'Is there a guide for managing account-specific secrets in GitHub Codespaces?',\n",
       "  'Where can I find instructions for storing secrets in GitHub Codespaces?',\n",
       "  'Can you explain how to handle my secrets while using GitHub Codespaces?',\n",
       "  'What documentation is available for secret management in GitHub Codespaces?'],\n",
       " 'd407d65b': ['What should I do if I encounter an error about not being able to connect to the Docker daemon?',\n",
       "  'How can I verify if the Docker daemon is running properly?',\n",
       "  'Is there a specific command to update WSL in PowerShell?',\n",
       "  'What steps should I follow to troubleshoot Docker connection issues?',\n",
       "  \"Can you explain how to start the Docker daemon if it's not running?\"],\n",
       " 'c9375c56': ['What are the requirements for running Docker on Windows Pro versions?',\n",
       "  'How can Windows Home users run Docker if Hyper-V is not available?',\n",
       "  'What should I do if I encounter an error related to WSL2 installation?',\n",
       "  'Is it necessary to enable Hyper-V before using Docker on Windows 10 Pro?',\n",
       "  'Where can I find instructions to install WSL2 on Windows 11?'],\n",
       " 'e866156b': ['What steps should I take to download an image from a public repository using Docker, and do I need to log in?',\n",
       "  \"If I get an error saying 'access denied' when pulling an image, what could be causing this issue?\",\n",
       "  'What should I do if I face a permission denied error while creating a PostgreSQL container on macOS M1?',\n",
       "  'Why is it necessary to install Docker Desktop instead of using Rancher Desktop for running PostgreSQL containers?',\n",
       "  \"Can you explain the potential reasons for a 'repository does not exist' error when pulling a Docker image?\"],\n",
       " '16370470': ['Why is it impossible for me to delete a local folder that is mounted to a Docker volume?',\n",
       "  'What ownership and permissions might prevent me from deleting a folder created by a Docker container?',\n",
       "  'How do I resolve access errors in Obsidian that result from Docker volume permissions?',\n",
       "  'What command should I use to forcefully delete a folder created during a Docker process?',\n",
       "  'Can you explain the meaning of the options used in the command to remove the Docker test folder?'],\n",
       " '316df755': ['What should I do if Docker on my Windows 10/11 is not starting or appears to be stuck in the settings?',\n",
       "  'How can I check if I am using the latest version of Docker for Windows?',\n",
       "  'Is there a way to switch between containers if Docker is stuck on starting?',\n",
       "  'Do I need to enable Hyper-V on Windows 10/11 to run Docker smoothly?',\n",
       "  'What are the steps to enable WSL2 for Docker on Windows?'],\n",
       " 'f3aa9252': ['Is it better to execute Docker commands from the Windows file system or a Linux distribution file system in WSL?',\n",
       "  'What should I do if Docker does not work even after setting up WSL2 or Hyper-V correctly?',\n",
       "  'Can I use Docker on Windows 10 Home Edition with the help of WSL2, and how?',\n",
       "  'What steps should I take if my Docker installation remains stuck after setup?',\n",
       "  'Is there a way to reset Docker to resolve issues after installation on Windows?'],\n",
       " 'a4abe7a5': ['What is the recommended way to store code for optimal file system performance in Docker?',\n",
       "  'Where can I find more information about Docker best practices?',\n",
       "  'Which backend does Docker run on by default for Windows 10 Home users?',\n",
       "  'What does the default setup for Windows 11 Home users imply for Docker usage?',\n",
       "  'How does WSL2 affect Docker performance on my machine?'],\n",
       " 'fb930700': ['What error might I encounter when running a Docker command in Windows?',\n",
       "  \"How can I resolve the 'input device is not a TTY' error when using Docker?\",\n",
       "  'Is there a command I should use before my Docker command if I am using mintty?',\n",
       "  \"Can I create an alias to avoid typing 'winpty' before Docker commands every time?\",\n",
       "  'Where should I add the alias command to make it permanent for Docker on my system?'],\n",
       " 'aa187680': ['What could be causing the error when I try to pip install in a Docker container on Windows?',\n",
       "  'Is there a specific error message I should look for when having issues with pip install on Docker?',\n",
       "  \"What DNS settings should I try if I'm experiencing temporary name resolution failures in Docker?\",\n",
       "  'Can you provide a command that might resolve issues with pip install in a Windows Docker container?',\n",
       "  'Which version of Python is suggested for use in the Docker command to troubleshoot pip install issues?'],\n",
       " 'b000e899': ['What should I do if the ny_taxi_postgres_data folder remains empty after running the Docker script?',\n",
       "  'Can you provide the specific command to run for populating the ny_taxi_postgres_data on a Windows machine?',\n",
       "  'What are the environment variable settings needed for the Docker command to work correctly?',\n",
       "  'Why is it important to specify the absolute path in the -v parameter of the Docker command?',\n",
       "  'How can I verify that all the files are present in the ny_taxi folder within VS Code after running the command?'],\n",
       " '9c66759f': ['What should I refer to for guidance on installing Docker on a Mac?',\n",
       "  'Are there any known issues with the previous method for setting up Docker on macOS?',\n",
       "  'What alternative method did you find effective for installing Docker?',\n",
       "  \"Has Docker's licensing model impacted installation procedures on macOS?\",\n",
       "  'Where can I find the latest instructions for downloading Docker on a Mac?'],\n",
       " 'e3106e07': [\"What is the solution if I encounter a permission error when trying to change the directory permissions for '/var/lib/postgresql/data' in Docker?\",\n",
       "  'How can I create a local Docker volume and utilize it for the PostgreSQL data directory?',\n",
       "  'What are the necessary environment variables to set when running the PostgreSQL container?',\n",
       "  \"What should I do if I see an error stating that the directory '/var/lib/postgresql/data' exists but is not empty?\",\n",
       "  'How can I verify that my Docker volume has been created and is listed in Docker Desktop?'],\n",
       " '72229da5': ['What should I do if my Docker volume mapping is not working on Windows?',\n",
       "  'Can you suggest some folder names that are compatible for data mapping in Docker on Windows?',\n",
       "  'What options are available for specifying volume paths in Docker commands on Windows?',\n",
       "  'How can I check and correct volume mapping issues if Docker creates an unexpected folder on Windows?',\n",
       "  'Is it possible to use a volume name instead of a path for Docker on Windows, and how would I do that?'],\n",
       " '58c9f99f': ['What should I do if I get an error related to the daemon when using Docker?',\n",
       "  'How can I resolve the invalid mode error when working with PostgreSQL in Docker?',\n",
       "  'Is there a specific format for mounting paths in Docker that I need to follow?',\n",
       "  'Are there alternative mounting paths I can use instead of the one provided?',\n",
       "  \"What does adding a leading slash before 'c:' achieve in the mounting path for Docker?\"],\n",
       " 'bc42139a': ['What causes the specific Docker error related to creating a build mount source path?',\n",
       "  'Is there a way to fix the error when running the Docker command a second time?',\n",
       "  'What command can I use on subsequent runs of the Docker container to avoid the error?',\n",
       "  'Which environment variables do I need to set for the PostgreSQL Docker container?',\n",
       "  'What port should I use for PostgreSQL when running it in Docker?'],\n",
       " 'a146e3ee': ['What error occurs when running the command docker build -t taxi_ingest:v001?',\n",
       "  'Why did the user encounter a permission issue with the ny_taxi_postgres_data directory?',\n",
       "  'What files do I need present to avoid the build error when using Docker?',\n",
       "  'How can I resolve the permission issue on an Ubuntu system?',\n",
       "  'Where can I find more details about the Docker build error related to checking context?'],\n",
       " '593a85ba': ['What should I do if I encounter an error waiting for a container in Docker?',\n",
       "  'How can I check the status of my Docker installation if I used snap to install it?',\n",
       "  'What steps should I take if I receive an unknown command error while checking Docker with snap?',\n",
       "  'What might cause a failure when binding to the port 5432 in Docker?',\n",
       "  'Is there a recommended method for installing Docker if I need to uninstall it first?'],\n",
       " '50bd1a71': ['What could be the reason for the build error in Docker related to my project folder?',\n",
       "  'How can I resolve the issue of not having the proper authorization rights to my host folder in PopOS?',\n",
       "  'Why does the folder appear empty when I encounter the Docker build error?',\n",
       "  'What command should I use to change permissions for the folder causing the build error?',\n",
       "  'Can you provide an example of how to set folder permissions for Docker in my case?'],\n",
       " 'f409f751': ['What causes the permission denied error when trying to build a Docker container on Ubuntu/Linux?',\n",
       "  'What command can I use to build the Docker container for the taxi ingest project?',\n",
       "  'What folder is created when I run the Docker build command for this project?',\n",
       "  'How can I resolve the permission issues when rebuilding the pipeline or creating a new one?',\n",
       "  'What does the chmod command do when applied to the ny_taxi_postgres_data folder?'],\n",
       " '7d217da3': ['How can I find the name of the Docker network?',\n",
       "  'What command should I use to list Docker networks?',\n",
       "  'Is there a specific way to retrieve the network name in Docker?',\n",
       "  'What steps do I follow to obtain the Docker network name?',\n",
       "  'Can you tell me how to view the available Docker networks?'],\n",
       " '09081824': [\"What should I do if I encounter a conflict error stating that the container name 'pg-database' is already in use?\",\n",
       "  \"Can you explain how to resolve the issue when I'm trying to restart a Docker image and face a container name conflict?\",\n",
       "  'What command do I need to run to stop a running container before I can remove it?',\n",
       "  'How can I restart a Docker image without removing the container that has the same name?',\n",
       "  \"Is there an alternative command to using 'docker run' if I want to restart the Docker image safely?\"],\n",
       " '4df80c55': ['What could be the cause of receiving a name translation error when using docker-compose for ingestion?',\n",
       "  'How can I determine the correct network to use in my ingestion script when running docker-compose?',\n",
       "  'What is the significance of the error message from SQLAlchemy regarding operational issues with the database?',\n",
       "  'Can you explain how to identify the correct database name when encountering host name translation issues?',\n",
       "  'What are the specific naming conventions for networks and databases I should be aware of when using Docker and Terraform?'],\n",
       " '3aee7261': ['What should I do if I cannot install Docker on my MacOS or Windows 11 VM running on Linux?',\n",
       "  'Is there a command I need to run to enable nested virtualization for Docker installation?',\n",
       "  'What are the specific commands to run on an Intel CPU before starting my VM?',\n",
       "  'Are there any different commands for enabling nested virtualization on an AMD CPU?',\n",
       "  'What happens if nested virtualization is not enabled when using Docker in this environment?'],\n",
       " '6497b659': ['How can I manage Docker containers and images using VS Code?',\n",
       "  'What do I need to do to connect VS Code with my Docker setup?',\n",
       "  'Is it possible to use VS Code with Docker running on WSL2?',\n",
       "  'What command should I use to stop a Docker container?',\n",
       "  'Where can I find the official VS Code extension for Docker management?'],\n",
       " 'a02f2039': ['What does it mean when the logs indicate that the PostgreSQL database directory contains a database but the system is shut down?',\n",
       "  'Why is my PostgreSQL container not accepting requests?',\n",
       "  'What error am I likely to encounter if my PostgreSQL server terminates abnormally?',\n",
       "  'What should I do if I see a connection failure from my PostgreSQL container?',\n",
       "  'How can I resolve the issue with the PostgreSQL database shutting down unexpectedly?'],\n",
       " 'c6db65aa': [\"How can I install Docker if I'm using an unsupported version of Ubuntu?\",\n",
       "  'What is the command to install Docker using snap on Ubuntu?',\n",
       "  'Is there a specific command I need to use for Docker installation on Ubuntu?',\n",
       "  'Can I use snap to install Docker on my Ubuntu version?',\n",
       "  \"Are there alternatives to install Docker if snap isn't available on my Ubuntu?\"],\n",
       " 'f476a606': ['What should I do if I encounter a mounting error related to directory permissions when using Docker-Compose?',\n",
       "  \"How can I specify a named volume in my Docker-Compose file if I've set up a local Docker volume earlier?\",\n",
       "  'What command can I use to inspect the location of my named volume in Docker?',\n",
       "  'Why did my composed service create a mounting directory with a different name than the one I expected?',\n",
       "  'What steps did the author take to resolve the naming issue with the Docker volume in their setup?'],\n",
       " 'e41b100c': ['What steps should I follow if I encounter an error related to translating a host name to an address while working with Docker Compose?',\n",
       "  'How can I ensure that my PostgreSQL database is running when using Docker Compose?',\n",
       "  'What command do I need to use to start my Docker containers in detached mode?',\n",
       "  \"What should I do if the output of 'docker ps' does not show my PostgreSQL database container as running?\",\n",
       "  'How can I check the logs of a specific Docker container to troubleshoot issues?'],\n",
       " 'cd0f9300': [\"What should I do if I encounter an error indicating that Docker can't translate the host name 'pg-database' after running 'docker-compose up'?\",\n",
       "  'How can I retrieve the default network name created by Docker Compose to update my Ingestion script?',\n",
       "  \"What actions should I take if I lose database data after executing 'docker-compose up'?\",\n",
       "  'In case of persistent issues with pgcli, what alternative tools can I use to connect to my database?',\n",
       "  'Where can I find the logs for Docker Compose execution to check the network name?'],\n",
       " '7f845a1c': ['What error do I get if the hostname does not resolve in Docker-Compose?',\n",
       "  'What command can I use to view all stopped and running containers?',\n",
       "  'How can I resolve an issue where the server cannot connect on localhost:8080?',\n",
       "  'What is a recommended format for a hostname to avoid resolution issues?',\n",
       "  'In the docker-compose.yml file, how should I configure networks for multiple containers?'],\n",
       " '36e54439': ['What is the common issue when running docker-compose on Google Cloud Platform regarding Postgres data persistence?',\n",
       "  'How can I ensure that PGAdmin data persists when using Docker on GCP?',\n",
       "  'What is the recommended way to modify the volume configuration for PGAdmin in a docker-compose file?',\n",
       "  'What should I change in the docker-compose file to make PGAdmin use Docker Volume for data persistence?',\n",
       "  \"Can you explain the difference between using a local path and Docker Volume for PGAdmin's data storage?\"],\n",
       " '32e8450c': ['What should I do if my Docker engine keeps crashing?',\n",
       "  'How can I check if I have the latest version of Docker installed?',\n",
       "  'What steps should I take if updating Docker does not resolve my issue?',\n",
       "  'Is it necessary to reinstall Docker if the problem continues?',\n",
       "  'Will I lose any important data if I need to fetch images again after reinstalling Docker?'],\n",
       " '96606db2': ['How can I ensure that my pgAdmin configuration is saved across container restarts?',\n",
       "  'What specific YAML configuration should I use to set up pgAdmin with persistent storage?',\n",
       "  'Before executing the docker-compose command, what permission changes must I make to the pgAdmin_data folder?',\n",
       "  'What are the default environment variables required for setting up pgAdmin in Docker?',\n",
       "  'Which user and group does the pgAdmin container run as, and how does that relate to folder permissions?'],\n",
       " '0882bfac': ['What should I do if I encounter a permission denied error when using Docker-Compose?',\n",
       "  'How can I ensure my user has the necessary permissions for Docker?',\n",
       "  'What steps should I follow to create a volume for pgAdmin to retain previous connections?',\n",
       "  'Can you explain how to modify the docker-compose.yaml file for pgAdmin?',\n",
       "  'What do I need to do after adding my user to the docker group?'],\n",
       " '7d067f5c': ['What should I do if docker-compose does not seem to work after I modified my .bashrc file?',\n",
       "  'Why did my docker-compose file from GitHub get named docker-compose-linux-x86_64 instead of docker-compose?',\n",
       "  'Is there a specific reason why using the command docker-compose is more convenient than the file I downloaded?',\n",
       "  'What steps should I take to rename the downloaded docker-compose file for it to function correctly?',\n",
       "  'Can you explain why the naming of the docker-compose file might affect its usability in my Google Cloud VM?'],\n",
       " 'ff352621': ['What should I do if I encounter an error related to credentials when using docker-compose up?',\n",
       "  'How can I resolve the issue of getting credentials errors in Docker-Compose?',\n",
       "  'Is there a specific solution for the Docker-Compose credentials error?',\n",
       "  'Where can I find more information regarding the credentials error in Docker-Compose?',\n",
       "  'What command is recommended to fix the Docker-Compose error related to getting credentials?'],\n",
       " '2d653208': ['What steps should I follow if I encounter errors with the docker-compose.yml file and pgadmin setup while using Docker-Compose?',\n",
       "  'What adjustments do I need to make to my docker-compose.yml file to resolve issues with PostgreSQL data retrieval?',\n",
       "  'How should I handle low_memory settings when importing a CSV file during the data ingestion process?',\n",
       "  'What is the correct order of operations to ensure successful execution of my Docker setup for PostgreSQL and pgAdmin?',\n",
       "  'How can I ensure that my pgAdmin server configuration matches the settings in my docker-compose.yml file?'],\n",
       " 'f09ea61e': ['How can I resolve the Docker Compose up -d error related to credentials in my environment?',\n",
       "  'What should I do if I encounter an executable file not found error with docker-credential-desktop?',\n",
       "  'Where can I find the config.json file for Docker on my system?',\n",
       "  'What changes do I need to make to the credsStore in the config.json file?',\n",
       "  'What steps should I follow after modifying the config.json file to address the error?'],\n",
       " 'fbd3d2bb': ['What steps should I follow to determine the correct docker-compose binary for my WSL setup?',\n",
       "  'Where can I find the docker-compose releases for download?',\n",
       "  'What commands can I use to check my system prior to downloading docker-compose?',\n",
       "  'Is there a specific command I can run to download the appropriate version of docker-compose directly?',\n",
       "  'What will the commands uname -s and uname -m return when executed?'],\n",
       " '0b014d0c': ['What should I do if I see an error about an undefined volume in my Docker-Compose setup on Windows/WSL?',\n",
       "  'Can you explain how to resolve the issue of a service referring to an undefined volume in my docker-compose.yaml file?',\n",
       "  'What specific changes do I need to make in my docker-compose.yaml file to fix volume errors?',\n",
       "  'How should I structure the volumes section in my docker-compose file to avoid errors?',\n",
       "  'Is there a specific format I need to follow when adding volumes to the docker-compose file for my project?'],\n",
       " 'd21bff1d': ['What causes the permission errors when using Docker with WSL?',\n",
       "  'How can I resolve permission conflicts between WSL and Windows when using Docker?',\n",
       "  'Why should I prefer using Docker volumes instead of local drives?',\n",
       "  'What are the benefits of utilizing Docker volumes for data storage?',\n",
       "  \"Is it necessary to specify the 'user:' option when using Docker volumes?\"],\n",
       " '6afb7b55': ['What should I do if pgadmin is malfunctioning when querying in Postgres?',\n",
       "  'Why does pgadmin have issues when run on Git Bash or a VM in Windows?',\n",
       "  'What are the required libraries for pgadmin to work correctly with Postgres?',\n",
       "  'Can you suggest an alternative to pgadmin for executing queries in Postgres?',\n",
       "  'How do I install the necessary libraries for using Postgres with Python?'],\n",
       " 'b51c3b82': [\"What might cause the error message stating 'Insufficient system resources exist to complete the requested service' when using WSL?\",\n",
       "  'How can I check if there are any pending updates for Windows Terminal and WSL?',\n",
       "  'What steps should I follow to update the Windows Terminal app on my system?',\n",
       "  'Is there a specific section of Windows updates where I can find pending security updates?',\n",
       "  'What should I do after updating my apps and security updates to ensure changes take effect?'],\n",
       " '326af690': ['What should I do if my WSL integration with Ubuntu stops unexpectedly with exit code 1?',\n",
       "  'Can you provide a solution for a potential DNS issue related to WSL on Windows?',\n",
       "  'What steps can I follow to resolve the Docker icon issue where I need to switch to Linux containers?',\n",
       "  'Why am I receiving an error about an uninitialized database and missing superuser password?',\n",
       "  'Is there a specific registry command I need to run to fix the DNS service for WSL?'],\n",
       " 'c2ec9047': ['What might be the reason for the error when trying to run the GPC VM through SSH in WSL2?',\n",
       "  'How can I resolve the permission issue with my SSH private key file in WSL2?',\n",
       "  'What command can I use to create a .ssh directory in the home directory of WSL2?',\n",
       "  'Is there a way to ensure that WSL2 uses the correct .ssh keys for SSH connections?',\n",
       "  'What steps should I take to copy my Windows .ssh folder contents to the new .ssh folder in WSL2?'],\n",
       " '3b711e73': ['What should I do if I encounter a host name resolution issue in WSL2?',\n",
       "  'How do I create a .ssh/config file in WSL2?',\n",
       "  'What commands do I need to run to set up the .ssh directory in WSL2?',\n",
       "  'Where should I place the configuration details for my GPC VM in WSL2?',\n",
       "  'What steps should I follow to ensure WSL2 references the correct .ssh/config path?'],\n",
       " 'cfe07c9d': ['What should I do if I encounter a PGCLI connection error indicating a failure to receive data from the server?',\n",
       "  'How can I resolve the issue of the connection being refused when trying to connect to port 5432?',\n",
       "  'What command do I need to use to connect to the database if I get an SSL negotiation packet error?',\n",
       "  'Is there a specific host that I should use when attempting to connect via PGCLI in this course?',\n",
       "  'Can you provide the correct connection string for accessing the ny_taxi database using PGCLI?'],\n",
       " 'acf42bb8': ['What should I do if I encounter a PGCLI --help error during the course?',\n",
       "  'Is there a way to resolve a potential installation error related to PGCLI?',\n",
       "  'How can I troubleshoot the PGCLI --help error we discussed in Module 1?',\n",
       "  'Where can I find additional resources if I experience installation issues with PGCLI?',\n",
       "  'What steps should I take to verify my installation if PGCLI is not functioning correctly?'],\n",
       " '176ce516': ['Is it necessary to run pgcli within a separate Docker container?',\n",
       "  'What port do we need to map for pgsql in this module?',\n",
       "  'Can pgcli be accessed directly from my local computer?',\n",
       "  'What is the role of port 5432 in this section?',\n",
       "  'Should pgcli be run locally or within another container?'],\n",
       " '3e5d1e9b': [\"What should I do if I encounter a fatal password authentication error for user 'root' when using PGCLI?\",\n",
       "  'How can I resolve conflicts with my local Postgres installation when running a Docker container?',\n",
       "  'What port should I use to connect to my Postgres Docker container to avoid authentication issues?',\n",
       "  'Is there a specific command I can use to check for applications using a port on my MacOS?',\n",
       "  'What steps do I need to take to unload and start the PostgreSQL service on MacOS to free up a port?'],\n",
       " '78833f32': ['What should I do if I encounter a PermissionError when running pgcli?',\n",
       "  'How can I resolve the error related to creating the config directory for pgcli?',\n",
       "  'What is the recommended method for installing pgcli without encountering permission issues?',\n",
       "  \"What should I do if conda install gets stuck at the 'Solving environment' step?\",\n",
       "  'Can using sudo for installing pgcli lead to permission errors, and what is the alternative?'],\n",
       " '63823f21': ['What specific error does the PGCLI report when there is no valid pq wrapper available?',\n",
       "  'What is the minimum Python version required to properly install psycopg2-binary?',\n",
       "  'What command should I use to create a new conda environment with Python 3.9?',\n",
       "  'What is the recommended method to install pgcli after ensuring the correct Python version?',\n",
       "  'What alternative command can I run to install psycopg with binary and pool options?'],\n",
       " 'b36ea564': ['What should I do if my Bash terminal is stuck at the password prompt for pgcli when trying to connect to PostgreSQL?',\n",
       "  'Can you suggest any alternative terminals to use if I encounter issues with pgcli on my current setup?',\n",
       "  'What steps should I take if I receive the error message stating \\'password authentication failed for user \"root\"\\' despite entering the correct password?',\n",
       "  'What are the potential solutions if the PostgreSQL service is causing connection issues on my Windows machine?',\n",
       "  'Why do I need to keep my database connection active while following the tutorial, especially after running a PostgreSQL container?'],\n",
       " 'e2a46ce5': [\"What should I do if my system shows the 'command not found' error for pgcli after installation?\",\n",
       "  'How can I confirm the installation location of pgcli on my Windows system?',\n",
       "  'What steps do I need to take to add Python Scripts to my Windows PATH variable?',\n",
       "  'Is there a possibility that my Python installation might be under a different directory than the one provided?',\n",
       "  'Where can I find more information or a reference regarding the pgcli command error?'],\n",
       " '27bdbc3f': ['Is there a way to use pgcli without installing it on my local machine?',\n",
       "  'What Docker command should I run to execute pgcli in a container?',\n",
       "  'Can you tell me the Docker network name used in the course videos for pgcli?',\n",
       "  'What are the PostgreSQL connection details necessary to use pgcli in Docker?',\n",
       "  \"What is the version of pgcli being used in this course's Docker example?\"],\n",
       " 'f7c5d8da': ['Why is PULocationID not recognized in queries?',\n",
       "  'How should I format column names with capital letters in PGCLI?',\n",
       "  'What happens if I do not use quotations around capitalized columns?',\n",
       "  'Can you explain the case sensitivity issue with local identifiers?',\n",
       "  'Where can I find more information about case sensitivity in PGCLI?'],\n",
       " 'c91ad8f2': [\"What error might I encounter when executing the command '\\\\d <database name>' in PGCLI?\",\n",
       "  \"What steps should I take if I face the error 'column c.relhasoids does not exist'?\",\n",
       "  \"How can I resolve the issue of the database 'ny_taxi' not being found?\",\n",
       "  'What should I do if I experience problems with PGCLI?',\n",
       "  'Is restarting my computer necessary after reinstalling PGCLI?'],\n",
       " '88bf31a0': ['What should I do if I encounter an OperationalError related to password authentication while trying to connect to Postgres in Jupyter Notebook?',\n",
       "  'Why am I experiencing a connection issue with my Postgres database on localhost when using Docker?',\n",
       "  'What steps can I take to resolve the problem if I get a connection error at port 5432 while working with my database?',\n",
       "  'Is there a specific port I need to use when accessing my Postgres database through Docker, and how can I find that?',\n",
       "  'How can I check if there is another Postgres service running on my Windows machine that might be causing connection issues?'],\n",
       " '23524e6d': [\"What could be the reason for receiving an OperationalError related to the role 'root' when connecting to Postgres?\",\n",
       "  \"How can I check if a 'root' user exists with login capabilities in my Postgres setup?\",\n",
       "  'What steps should I take to change the default port if it conflicts with an existing Postgres installation?',\n",
       "  'What alternative user settings can be applied in the Docker setup to resolve connection issues with Postgres?',\n",
       "  'What actions should I perform to reset my Docker Postgres setup if I experience persistent connection errors?'],\n",
       " '9211bbd6': ['What does the OperationalError related to psycopg2 indicate about the database connection to localhost?',\n",
       "  'How can I verify if the Postgres server is running on my machine?',\n",
       "  \"What should I do if I encounter a connection error stating that the database 'ny_taxi' does not exist?\",\n",
       "  'Is there a recommended port to use for Postgres if port 5432 is unavailable on my system?',\n",
       "  'Where can I find the psycopg2 code referenced in the error message regarding the database connection?'],\n",
       " '5db86809': ['What should I do if I encounter a ModuleNotFoundError related to psycopg2 when working with Postgres in Module 1?',\n",
       "  'Can you explain the steps I should take if the initial installation of psycopg2-binary does not resolve the error?',\n",
       "  'Is there a specific command I should use to update conda or pip before reinstalling psycopg2?',\n",
       "  'What actions should I take if I still have issues with psycopg2 indicating that pg_config is not found?',\n",
       "  'How do I install PostgreSQL on a Mac if required for resolving psycopg2 installation problems?'],\n",
       " '20c604dd': [\"What might cause a 'column does not exist' error when using Postgres on a MacBook Pro M2?\",\n",
       "  'How should I properly reference column names in join queries to avoid SQL errors?',\n",
       "  'What specific quoting method should I use for column names to prevent errors in Pyscopg2?',\n",
       "  'Is there a difference between using single quotes and double quotes for column names in PostgreSQL?',\n",
       "  'What error message indicates an issue with column names when executing queries in Postgres?'],\n",
       " 'b11b8c15': [\"Why doesn't the Create server dialog appear in pgAdmin?\",\n",
       "  \"What should I do if pgAdmin's Create server dialog is missing?\",\n",
       "  'Is there a reason the Create server dialog is not showing in the latest version of pgAdmin?',\n",
       "  \"How can I create a server in pgAdmin if the dialog doesn't show?\",\n",
       "  'What alternative action can I take to create a server in pgAdmin?'],\n",
       " 'a6475348': ['What could cause a blank or white screen when logging into pgAdmin in a browser?',\n",
       "  'What error message was displayed in the terminal of the pgAdmin container when I encountered the login issue?',\n",
       "  'What environment variable needs to be set to avoid the CSRF error when running pgAdmin in Docker?',\n",
       "  \"What modifications are needed in the 'docker run' command to resolve the issue with pgAdmin?\",\n",
       "  'How can using VSCode locally help prevent the blank screen issue when working with GitHub Codespaces?'],\n",
       " '1ea7680e': ['What should I do if I cannot access the pgAdmin interface through my web browser after starting the container?',\n",
       "  \"How did you modify the 'docker run' command to successfully access pgAdmin?\",\n",
       "  'What changes did you make to the docker-compose.yaml to allow pgAdmin access?',\n",
       "  \"I encountered a ModuleNotFoundError for 'pysqlite2'; how did you resolve this issue?\",\n",
       "  'Where can I find the missing sqlite3.dll file to fix the DLL load error I am experiencing?'],\n",
       " '10acd478': ['What should I do if I am missing 100000 records while ingesting data using the Jupyter notebook?',\n",
       "  'Can you explain why I only see about 1.2 million rows instead of the expected 1.3 million when running the script again?',\n",
       "  'Is there a recommended video that I should watch to understand how to properly ingest the NY Taxi Data?',\n",
       "  'Why does running the entire script in the Jupyter notebook result in skipping the first chunk of records?',\n",
       "  'What specific change do I need to make in the notebook to ensure I ingest all the records correctly?'],\n",
       " '752e8452': ['How can I read a CSV file properly in Python without encountering errors?',\n",
       "  'What is the advantage of using a compressed CSV file?',\n",
       "  'What command do I need to run to install gunzip on an Ubuntu machine?',\n",
       "  'Is there a way to preview uncompressed CSV files easily?',\n",
       "  'What specific warning should I be aware of when executing my Python script?'],\n",
       " 'aa6f52b8': ['How can I configure Pandas to automatically handle date conversion when reading a CSV file?',\n",
       "  'What parameter do I need to use with pd.read_csv to specify which columns should be parsed as dates?',\n",
       "  'Can you provide an example of using parse_dates with the pd.read_csv function?',\n",
       "  'What will be the data types of the columns after using parse_dates with my CSV data?',\n",
       "  'Is it necessary to convert date strings to datetime types after importing data with Pandas if I use the appropriate parameter?'],\n",
       " '3dacbb98': ['How can I download data using curl in my Python script?',\n",
       "  'What command should I use to retrieve a CSV file from a GitHub link?',\n",
       "  'Is there a specific format for the curl command in Python?',\n",
       "  'What function allows me to execute system commands like curl?',\n",
       "  'Can you provide a Python example for using curl to get data from a URL?'],\n",
       " '8b71a398': ['How can I read a Gzip compressed CSV file in Pandas?',\n",
       "  'What file extension is used for a Gzip compressed CSV file?',\n",
       "  'Which function in Pandas do I use to read CSV files?',\n",
       "  'What parameters can the read_csv() function accept?',\n",
       "  'Can you give an example of reading a Gzip compressed CSV file with Pandas?'],\n",
       " 'aa244fa0': ['What is the recommended method for processing parquet files in Python?',\n",
       "  \"How does the process of ingesting parquet files differ from using pandas' read_csv method?\",\n",
       "  'Can you provide an example of how to clear an existing SQL table before ingesting new data?',\n",
       "  'What library do we need to use to handle parquet files effectively in Python?',\n",
       "  'What steps are involved in iterating through a parquet file and inserting its data into a PostgreSQL database?'],\n",
       " 'eac816d7': ['What error might occur when executing a Jupyter notebook cell that imports SQLAlchemy?',\n",
       "  \"How can I resolve an ImportError related to 'TypeAliasType' in Python?\",\n",
       "  \"Is there a specific version requirement for the 'typing_extensions' module to avoid the error?\",\n",
       "  \"What are the methods I can use to update the 'typing_extensions' module in my environment?\",\n",
       "  'What is the import statement that triggers the error in the SQLAlchemy library?'],\n",
       " 'd44d1c77': [\"What connection string should I use to avoid the 'TypeError: module object is not callable' when working with SQLAlchemy?\",\n",
       "  'How can I correctly create an engine for a PostgreSQL database using SQLAlchemy?',\n",
       "  'What is the appropriate format for the connection string for connecting to a local PostgreSQL database?',\n",
       "  'Why do I receive a TypeError when attempting to use create_engine with my original connection string?',\n",
       "  'Can you provide a corrected example for creating a connection with SQLAlchemy and PostgreSQL?'],\n",
       " 'ed34766a': ['What error might occur when executing a cell in Jupyter Notebook related to SQLAlchemy?',\n",
       "  \"How can I resolve the ModuleNotFoundError for 'psycopg2'?\",\n",
       "  'Which Python module needs to be installed for PostgreSQL connectivity?',\n",
       "  \"What commands can I use to install the missing 'psycopg2' module?\",\n",
       "  'Under what circumstances would I see the error related to the PostgreSQL engine connection?'],\n",
       " 'fd714677': ['What should I do if I receive an error about adding Google Cloud SDK to the PATH on Windows?',\n",
       "  'Are there steps I need to follow to set up Git Bash correctly on my Windows system?',\n",
       "  'How can I ensure that Conda is added to the PATH when installing Anaconda Navigator?',\n",
       "  'What options should I select during the Git Bash installation process?',\n",
       "  'Is there a way to make Git Bash my default terminal in Windows?'],\n",
       " '9de2c3e9': ['What should I do if I encounter a project creation failure due to the error message stating that the requested entity already exists?',\n",
       "  'Why does the FAQ suggest that I might not need this information regarding project creation failures?',\n",
       "  'Where should I go to create a project instead of relying on command-line instructions?',\n",
       "  \"What are the implications of using a common project ID like 'testproject' when creating a new project in GCP?\",\n",
       "  'Can you explain what the status code 409 signifies in the response I receive during project creation attempts?'],\n",
       " '827dd4af': [\"What should I do if I encounter a '403: absent billing account' error on GCP?\",\n",
       "  'How can I find my unique project ID on the GCP Dashboard?',\n",
       "  'What might prevent my billing account from linking to my current project?',\n",
       "  'Where can I locate the project ID that I need to enter?',\n",
       "  'Why is it important to enter my specific project ID in the GCP setup?'],\n",
       " 'a42a7e8c': ['What should I do if my credit card is not accepted by Google for my GCP account?',\n",
       "  'Is there a particular bank that has been successful for making payments in GCP?',\n",
       "  'What other payment options do you recommend if my card is refused?',\n",
       "  'How likely is it that Google support will assist with account issues?',\n",
       "  'Are there any alternative payment methods that are known to work with Google Cloud?'],\n",
       " '4eefdd01': ['Could you please explain how I can locate the ny-rides.json file in Google Cloud Platform?',\n",
       "  'What are the specific steps I need to follow to access my private file in GCP?',\n",
       "  'In GCP, how do I navigate to the Service Accounts Keys tab to find the ny-rides.json file?',\n",
       "  'Can you clarify where I should click in GCP after selecting my project to create a JSON key?',\n",
       "  \"What should I do after clicking the email in the Service Accounts Keys tab to find the 'KEYS' option?\"],\n",
       " '0282578d': ['Is it necessary to remove my instance in Google Cloud after watching the lecture?',\n",
       "  'What happens if I delete my instance in Google Cloud?',\n",
       "  \"Will I need to delete instances more than once if I don't follow instructions?\",\n",
       "  'Could you clarify if deleting the instance is required in this course?',\n",
       "  'What advice do you have regarding instances on Google Cloud during this module?'],\n",
       " 'bd3e60fd': ['What commands can I use to monitor the system resources on my virtual machine?',\n",
       "  'Which command will show me the disk usage of a specific directory?',\n",
       "  'How can I check the currently active network connections on my virtual machine?',\n",
       "  'What command should I use to view the hardware configuration of my system?',\n",
       "  'How can I find out who is currently logged into my system along with their activities?'],\n",
       " 'c4e9bc60': ['What should I do if I receive an error message stating that billing has not been enabled for my project, even though I believe I have already set it up?',\n",
       "  \"Can you give me a solution if I've confirmed my billing account is enabled but still see the billing error?\",\n",
       "  'What is the specific error message I might encounter related to billing when working on my dataset?',\n",
       "  \"Is there a recommended action to take if I'm facing a billing-related error with my project on Google Cloud?\",\n",
       "  \"How can I resolve the issue if I get a 403 error indicating that billing is not enabled for my project's dataset?\"],\n",
       " 'f10b49be': ['What should I do if I encounter an error related to Application Default Credentials when installing the Google Cloud SDK on Windows?',\n",
       "  'How can I resolve the issue of not being able to find a quota project while using the Google Cloud SDK?',\n",
       "  'What steps did you take after reinstalling the Google Cloud SDK to ensure it was functioning correctly?',\n",
       "  'How do I create a new Virtual Machine instance from an image if my original VM cannot start due to resource issues?',\n",
       "  'What adjustments do I need to make on the settings page when creating a new VM instance from an image in GCP?'],\n",
       " '3184bd8b': ['Is it really necessary to use a GCP VM for this course?',\n",
       "  'What issues did students face that led to the creation of the GCP VM video?',\n",
       "  'Can I work with my own environment instead of using the GCP VM?',\n",
       "  'What are the benefits of using my own environment while working on the course material?',\n",
       "  \"Why can't I commit changes directly from the repo cloned in the GCP VM?\"],\n",
       " '8bea4d53': [\"What should I do if I encounter a 'Permission denied' error while trying to create the '.ssh' directory?\",\n",
       "  'Where is the correct location to create the directory for SSH?',\n",
       "  'Why does the command fail when executed in the root folder instead of my home directory?',\n",
       "  'Is there a tutorial or resource that can help me understand this issue better?',\n",
       "  \"Can I create the '.ssh' directory in any other location besides my home directory?\"],\n",
       " '86d11cc0': ['What should I do if I encounter a permissions error when saving files in a GCP VM using VS Code?',\n",
       "  'How can I change the ownership of files that I need to edit in my GCP VM?',\n",
       "  \"What command do I use to fix the 'permission denied' error when attempting to save files in my VM?\",\n",
       "  'Is there a specific command I can run to resolve saving issues in VS Code related to file permissions?',\n",
       "  'What steps should I take to ensure I have access to edit files located in my GCP VM directory?'],\n",
       " '2cb48591': ['How can I troubleshoot a timeout issue when connecting to my GCP VM via SSH?',\n",
       "  'What steps should I take if my VM was accessible last week but is timing out this week?',\n",
       "  'What should I do to ensure my VM is running before trying to connect?',\n",
       "  'How do I locate and edit the config file within my ~/.ssh folder?',\n",
       "  'What is the process for retrieving the External IP of my VM?'],\n",
       " '9523c813': ['How can I fix the issue of not being able to connect to my GCP VM on port 22?',\n",
       "  'What steps do I need to take to edit my VM settings in GCP?',\n",
       "  'Where do I find the Automation section to add a startup script in my VM?',\n",
       "  'What specific command should I include in the startup script to allow SSH connections?',\n",
       "  'Do I need to stop and restart my VM after adding the startup script?'],\n",
       " '4f8d9174': ['How can I forward the ports for pgAdmin, postgres, and Jupyter Notebook from GCP without relying on VS Code?',\n",
       "  'What command do I need to execute on my local machine to establish the SSH connection for port forwarding?',\n",
       "  'After running the Jupyter Notebook command, where can I find the access token if I encounter credential issues?',\n",
       "  'What specific ports do I need to use for accessing pgAdmin and Jupyter Notebook from my local browser?',\n",
       "  'Is there a combined SSH command for forwarding both pgAdmin and postgres at the same time, and if so, what is it?'],\n",
       " '29f84a82': ['What should I do if gcloud authentication hangs while using MS VS Code in WSL2?',\n",
       "  'Why do I see an error message when attempting to login to GCP via the gcloud CLI?',\n",
       "  'How can I successfully open the login page after clicking the prompt in gcloud auth?',\n",
       "  'What steps should I follow to configure Trusted Domains for gcloud auth?',\n",
       "  'How can I ensure that gcloud auth works seamlessly next time I try to log in?'],\n",
       " '20a01fd0': ['What could cause the error when Terraform fails to query available provider packages?',\n",
       "  'How can I resolve the issue of Terraform not accessing the online registry?',\n",
       "  'What steps should I take if I encounter a request failure for the provider hashicorp/google?',\n",
       "  \"Could my VPN or Firewall settings be affecting Terraform's ability to connect to the registry?\",\n",
       "  'What actions might I take to fix the error after checking my network settings?'],\n",
       " '5a712a20': [\"What might cause the network error related to Terraform when trying to access Google's storage service?\",\n",
       "  'How does using a VPN affect the connectivity issues I may face with Terraform?',\n",
       "  'What steps did you take to resolve the Terraform error you encountered?',\n",
       "  'Why does the terminal program not automatically use the system proxy when running Terraform commands?',\n",
       "  'What should I do if I continue to have connectivity issues while using Terraform and a VPN?'],\n",
       " '06021091': ['How can I install Terraform specifically for WSL on my system?',\n",
       "  \"Is there a guide available for configuring Terraform on Windows 10's Linux Subsystem?\",\n",
       "  'Where can I find detailed instructions for setting up Terraform in a WSL environment?',\n",
       "  'Are there any steps outlined for installing Terraform on Windows 10 with WSL?',\n",
       "  'Can you recommend a resource for configuring Terraform using the Windows 10 Linux Subsystem?'],\n",
       " 'df8ea7e8': ['What should I do if I encounter a state lock error while using Terraform?',\n",
       "  'Is there a specific GitHub issue I can refer to regarding state lock errors in Terraform?',\n",
       "  'Where can I find more information on resolving state lock issues in Terraform?',\n",
       "  'Can you guide me on troubleshooting the state lock error in Terraform?',\n",
       "  \"Where is the link to the GitHub discussion about Terraform's state lock error?\"],\n",
       " '1093daf5': ['What error message might I encounter when executing terraform apply on WSL2?',\n",
       "  'What causes the invalid JWT token error when using Terraform on WSL2?',\n",
       "  'How can I resolve the 400 Bad Request error related to OAuth2 when running Terraform?',\n",
       "  'What command can I use to synchronize my system time and potentially fix the JWT issue?',\n",
       "  'What should I check in the JWT claim if I receive an invalid grant error during Terraform operations?'],\n",
       " '947213b1': ['What does the Error 403 message indicate when using Terraform?',\n",
       "  'How can I resolve the Access Denied issue with Google Cloud?',\n",
       "  'Where should the GOOGLE_APPLICATION_CREDENTIALS point to?',\n",
       "  'What command should I run to activate the service account?',\n",
       "  'What is the format of the file referenced in GOOGLE_APPLICATION_CREDENTIALS?'],\n",
       " '002d4943': ['Is it necessary to create a separate service account for Terraform during the course?',\n",
       "  'How many service accounts do I need for the services in this course?',\n",
       "  'What should I do after obtaining the JSON file with my credentials?',\n",
       "  'Will one service account cover all resources I use in the course?',\n",
       "  'What is the importance of setting my environment variable after getting my credentials?'],\n",
       " '8dc77677': ['Where is the download link for Terraform 1.1.3 for Linux AMD 64?',\n",
       "  'Can you provide me with the location of Terraform version 1.1.3 for Linux using AMD 64 architecture?',\n",
       "  'Where can I access the download for Terraform 1.1.3 specifically for Linux AMD 64?',\n",
       "  'Is there a direct link available for downloading Terraform 1.1.3 for Linux with AMD 64?',\n",
       "  'What is the URL for obtaining Terraform version 1.1.3 for Linux AMD 64?'],\n",
       " '29d3d343': ['What does the error message regarding Terraform initialization mean?',\n",
       "  'How should I properly set up my working directory for Terraform?',\n",
       "  'What command do I need to run after navigating to my working directory?',\n",
       "  'Why is it incorrect to run terraform init outside the working directory?',\n",
       "  'What files do I need to create before starting to work with Terraform?'],\n",
       " 'e2095203': ['What does the error message regarding insufficient authentication scopes indicate?',\n",
       "  'How can I solve the error related to creating a dataset in Terraform?',\n",
       "  'What command should I run to check the status of GOOGLE_APPLICATION_CREDENTIALS?',\n",
       "  'What does the command echo $? do in the context of this error?',\n",
       "  'Where can I find instructions on setting GOOGLE_APPLICATION_CREDENTIALS correctly?'],\n",
       " '22a2b9f2': [\"What does the error message 'Error: googleapi: Error 403' indicate when using Terraform?\",\n",
       "  'How can I resolve the issue of being denied permission to create a bucket in Google Cloud?',\n",
       "  \"What specific permission is lacking if I encounter 'storage.buckets.create access' error in Terraform?\",\n",
       "  'Is it necessary to use the Project ID instead of the Project name to avoid this error?',\n",
       "  'Where can I find the correct Project ID for my Google Cloud project?'],\n",
       " '5d7588f0': ['How do I manage the GCP credentials securely within my Docker container?',\n",
       "  'What is the format for specifying the Google provider in Terraform?',\n",
       "  'Can I avoid hardcoding the credentials directly into my Terraform files?',\n",
       "  'Which variables are necessary for configuring the Google provider in Terraform?',\n",
       "  'Is there a specific method to input sensitive information like credentials in Terraform?'],\n",
       " '5276a695': ['What is the correct SQL query to retrieve data from the zones_taxi table for the Astoria Zone?',\n",
       "  \"Why does the error indicate that the column 'Zone' doesn't exist in the database?\",\n",
       "  'How do I properly reference columns that start with uppercase letters in SQL queries?',\n",
       "  \"Can you clarify if 'Astoria Zone' actually exists in the dataset or if it's listed as 'Astoria'?\",\n",
       "  'What steps can I take to avoid similar issues with column names in my future SQL queries?'],\n",
       " '70c159df': [\"What should I do if I get an error stating that the Zone column doesn't exist when running SQL on taxi zones?\",\n",
       "  'How can I avoid using quotation marks repeatedly in my SQL queries?',\n",
       "  'Is there a preferred format for the data when putting it into the database?',\n",
       "  'What steps should I take after loading the CSV file in Pandas to align column names?',\n",
       "  'How can I ensure that my column names are consistently formatted in lowercase?'],\n",
       " 'f55efcf0': ['What steps should I follow to resolve the host issue when using CURL?',\n",
       "  'Can you provide a solution for the CURL error related to output.csv?',\n",
       "  'What command should Mac users use to solve the CURL error?',\n",
       "  'How can I download a file using CURL if I encounter a host resolution problem?',\n",
       "  'Is there a specific command format for CURL that Mac users need to follow?'],\n",
       " '2b7a8512': ['What should I check if I encounter an SSH error related to hostname resolution?',\n",
       "  'Where should I verify the location of my SSH config file?',\n",
       "  \"What steps can I take to fix the error indicating 'Name or service not known'?\",\n",
       "  'In case of SSH issues, how can I ensure proper configuration?',\n",
       "  'What is the correct directory path for the SSH config file on Windows?'],\n",
       " '1cd746c4': [\"What steps do I need to follow to add Anaconda's Python to the PATH on a Linux or MacOS system?\",\n",
       "  'How can I check if Python and pip are installed in the correct locations when using Git Bash on Windows?',\n",
       "  'What command should I use to permanently add Anaconda to my PATH on a Linux system?',\n",
       "  \"What should I do if I'm using Windows without Git Bash to add Anaconda to the PATH?\",\n",
       "  'How can I refresh my environment after making changes to the PATH variable?'],\n",
       " '6d367222': ['What should I do if I encounter the error stating that the address is already in use when starting the userland proxy?',\n",
       "  'How can I resolve the permission denied error when attempting to stop a Docker container?',\n",
       "  'What command do I need to run in Linux to fix the issue of not being able to import the psycopg2 module?',\n",
       "  'What could be causing the Docker build error related to file context, and how can I resolve it?',\n",
       "  'If Docker requires permission to access a file during a build, what steps can I take to address this issue?'],\n",
       " '84e601e1': ['How can I create a requirements.txt file that is compatible with pip from Anaconda?',\n",
       "  'What command should I run to install pip using Anaconda?',\n",
       "  \"Why doesn't conda list -d > requirements.txt work for creating a requirements file?\",\n",
       "  'What is the correct way to export a pip-friendly requirements.txt file from Anaconda?',\n",
       "  'Will using pip freeze > requirements.txt provide accurate paths for my dependencies?'],\n",
       " '4cf83cc2': ['Can you provide the links to the FAQ documents for Prefect and Airflow from previous cohorts?',\n",
       "  'Where can I find the FAQ questions pertaining to the orchestration module for past classes?',\n",
       "  'Is there a specific document that contains the previous cohort questions for the orchestration module?',\n",
       "  'Are there separate documents for Prefect and Airflow containing FAQ questions from earlier cohorts?',\n",
       "  'What URLs should I visit to access the FAQ records related to the orchestration module?'],\n",
       " '5adc5188': ['What should I do if my Docker containers exit with code 132 when I run docker compose up?',\n",
       "  \"Is the issue with Docker containers due to my computer's architecture or hardware?\",\n",
       "  'What alternative solution can I try if purchasing a new computer is not an option?',\n",
       "  'What version of Ubuntu and Docker is mentioned in the issue recorded about Mage?',\n",
       "  'Why is it inconclusive to determine the cause of the Docker containers exiting without knowing the VirtualBox configuration?'],\n",
       " '3ef0bb96': ['What is the primary reason behind unexpected kernel restarts in WSL 2 when using Docker?',\n",
       "  'How can I check if my .wslconfig file exists in my Bash environment?',\n",
       "  'What should I do if I notice WSL 2 not allocating enough CPU cores to Docker?',\n",
       "  'How can I modify my .wslconfig file to improve Docker performance in WSL 2?',\n",
       "  'What steps should I take after editing my .wslconfig file to ensure changes are applied?'],\n",
       " 'a41ce360': ['What is the link to find the issue and solution for configuring Postgres in Module 2?',\n",
       "  'Where can I access the discussion about Postgres configuration problems?',\n",
       "  'Is there a specific Slack channel for questions related to Postgres setup?',\n",
       "  'Can you share the resource for troubleshooting Postgres mentioned in the course?',\n",
       "  'What do I do if I encounter issues while configuring Postgres?'],\n",
       " 'b1cf59e5': ['What should I do if I encounter an OperationalError while trying to connect to my PostgreSQL database?',\n",
       "  'How can I resolve the issue if the connection to the server at localhost fails?',\n",
       "  'What is the correct port to set for the POSTGRES_PORT variable in the io_config.yml file?',\n",
       "  'Is it necessary to change the POSTGRES_PORT to match a conflicting PostgreSQL installation on my host machine?',\n",
       "  'Where can I find the POSTGRES_PORT variable that needs to be configured for the mage container?'],\n",
       " 'f9d6f8bd': ['What could cause a KeyError when executing SELECT 1 in module 2?',\n",
       "  'How do I avoid the KeyError when using PostgreSQL in MAGE?',\n",
       "  'What should I check if I encounter a KeyError while working on workflow orchestration?',\n",
       "  'Which profile do I need to select to successfully execute queries?',\n",
       "  \"Where can I find the dropdown menu to select the 'dev' profile?\"],\n",
       " 'f3adb937': ['What steps should I take if I encounter the ConnectionError with a timeout during my workflow orchestration?',\n",
       "  'How can I resolve the 404 Not Found error when testing the BigQuery connection for my dataset?',\n",
       "  'What specific timeout value should I set in the mage io_config.yaml file to fix the connection issue?',\n",
       "  'Is there a specific setting I need to check if my service account has all the necessary roles but still returns a Not Found error?',\n",
       "  'What should I do after I update the timeout value in my configuration file to ensure the changes take effect?'],\n",
       " 'eb3d6d36': ['What should I do if I encounter a RefreshError related to invalid JWT while working with workflow orchestration?',\n",
       "  'Can you guide me on how to resolve a problem where the error states my JWT must be short-lived?',\n",
       "  'Where can I find more information on fixing the invalid grant issue related to JWT tokens?',\n",
       "  \"What does the error message about checking 'iat' and 'exp' values in the JWT claim mean?\",\n",
       "  'Is there a reliable source or link for troubleshooting the invalid JWT token issue?'],\n",
       " 'a76e1f4d': ['What causes the IndexError: list index out of range in the Mage workflow?',\n",
       "  'How can I find the original solution for the IndexError in Mage version 0.9.61?',\n",
       "  'What steps should I take to resolve the error that arises after addressing the issue in 2.2.4?',\n",
       "  'Is there a newer version of Mage that I should consider using to avoid this error?',\n",
       "  'What changes need to be made in the docker-compose.yaml file to fix this problem?'],\n",
       " '934facf8': ['What should I do if I encounter an OSError indicating that I cannot save a file into a non-existent directory in Module 2?',\n",
       "  'How can I ensure that the directory for saving a file exists before attempting to save it?',\n",
       "  'What specific code should I add to handle the situation where the directory does not exist?',\n",
       "  'Is there a way to convert a file path to a posix format in this module?',\n",
       "  'Where can I find more information or discussion related to saving files and handling directories in this course?'],\n",
       " 'a2c7b59f': ['What specific steps do I need to follow for deploying Mage to GCP using Terraform?',\n",
       "  'Is there any information available about enabling the Cloud Filestore API in Google Cloud?',\n",
       "  'During the deployment process, what does Terraform prompt me to enter?',\n",
       "  \"Can you explain what I need to do after the 'terraform apply' command is executed?\",\n",
       "  'Where can I find the video that has the details about deploying Mage to GCP?'],\n",
       " '997d4aaa': ['What steps should I follow to run multiple Docker containers from different directories without issues?',\n",
       "  'How can I customize the host port in my Docker setup for Mage on my local machine?',\n",
       "  'What should I do if I encounter an insufficient authentication scopes error while terraforming resources in a GCP VM?',\n",
       "  'What specific permission changes are necessary in the GCP console to resolve the insufficient permission error?',\n",
       "  'How can I ensure that my GCP virtual machine has the correct access scopes for Google APIs?'],\n",
       " 'bc269b95': ['What issues might I encounter when deploying infrastructures using Terraform on a free trial account in GCP?',\n",
       "  \"Is the Load Balancer service available for users on GCP's free trial?\",\n",
       "  'What steps should I take if I face a Security Policies quota problem while using Terraform?',\n",
       "  'Can you explain how to modify the main.tf file to resolve the load balancer issue?',\n",
       "  'What command should I run after deleting the load_balancer.tf file to clean up the created infrastructure?'],\n",
       " '10ea342e': ['What should I do if I encounter an error when executing terraform apply for the GCP module?',\n",
       "  'How can I ensure that my project-id, region, and zones are set correctly in the GCP workflow?',\n",
       "  'What steps should I take if the MAGE Terraform files are taking longer than expected to deploy?',\n",
       "  'Why might some GCP resources not be destroyed after running terraform destroy, and how can I find them?',\n",
       "  'How can I check my GCP billing account to monitor charges related to the MAGE Terraform IaC?'],\n",
       " '4bd23594': [\"What does the error message indicate regarding the permission 'vpcaccess.connectors.create'?\",\n",
       "  \"How can I resolve the 'Permission denied' error when creating a Connector?\",\n",
       "  'What role should I assign to the Service Account to fix the error?',\n",
       "  'What is the specific resource mentioned in the error details for the denied permission?',\n",
       "  'In which part of the Terraform configuration does the error occur related to the Connector?'],\n",
       " 'b0d48cd7': ['Why is it that I cannot save a file in a folder that does not exist within my project?',\n",
       "  'What should I do if Git fails to push my empty directory to GitHub?',\n",
       "  'Can you explain how to create a directory in my code if it is not already present?',\n",
       "  'Why might my local relative path not function properly when using GitHub storage?',\n",
       "  'What are the recommended practices for handling file paths when uploading to GCS buckets?'],\n",
       " '70a37f2c': ['What are the names of the pickup datetime columns in the green and yellow datasets?',\n",
       "  'How should I adjust my scripts based on the dataset I am using?',\n",
       "  'Is there a difference between lpep_pickup_datetime and tpep_pickup_datetime?',\n",
       "  'Can I use the same script for both datasets?',\n",
       "  'Which dataset contains lpep_pickup_datetime?'],\n",
       " '8ab78bee': ['What should I use to download the VSC utilizing Pandas?',\n",
       "  'How do I handle large datasets in Pandas when reading from a URL?',\n",
       "  'What method is recommended for appending data to a parquet file?',\n",
       "  'Which compression technique should I use when saving to parquet format?',\n",
       "  'What engine should be specified when appending data to parquet files?'],\n",
       " '54c6db2f': ['What does it mean when I encounter a push to Docker image failure?',\n",
       "  \"What should I do if I see a 'requested access to the resource is denied' error?\",\n",
       "  'How can I ensure that I am properly logged into Docker Desktop before pushing an image?',\n",
       "  'Is it important to use the correct username when pushing Docker images, and why?',\n",
       "  'What commands do I need to run for building and pushing a Docker image with my username?'],\n",
       " 'c5b998f3': [\"What does it mean when my flow script fails and displays a 'killed' message?\",\n",
       "  'How can I determine if memory issues are causing my flow script failures?',\n",
       "  'What is the recommended RAM for a VM to prevent flow script termination?',\n",
       "  \"If my VM has 8GB of RAM, how much should I upgrade it to if I'm experiencing issues?\",\n",
       "  'Are there any specific indicators that confirm my flow script is failing due to memory shortage?'],\n",
       " 'eec29536': ['What should I do if I encounter a situation where my GCP VM disk space is full?',\n",
       "  'How can I check which directories are consuming the most disk space on my VM?',\n",
       "  'Where are cached flows stored that might be taking up too much space?',\n",
       "  'What steps should I take to delete older flows from my VM and prevent errors when running new ones?',\n",
       "  'How can I resolve the SSL certificate verification error I received while trying to run flows on my MAC?'],\n",
       " '727e5a69': ['What does it indicate when my Docker container crashes with a status code of 137?',\n",
       "  'Why does my container use so much RAM when executing tasks in the homework?',\n",
       "  'What steps can I take if restarting my computer does not resolve the issue with the container?',\n",
       "  'Can you suggest ways to allocate more resources to Docker on my workstation?',\n",
       "  'Is there a free online compute environment I can use if my local machine struggles with container memory requirements?'],\n",
       " 'da899638': ['What was the issue that caused the timeout during the task running the ETL script in Q3?',\n",
       "  'Can you explain the process involved in uploading data from the web to GCS as described in the record?',\n",
       "  'What kind of errors might occur due to slow internet connections, as mentioned in the FAQ?',\n",
       "  'What is the recommended method for handling large data uploads to GCS when experiencing timeout issues?',\n",
       "  'How should I adjust the timeout setting when uploading parquet files to accommodate larger datasets?'],\n",
       " 'dde58c8f': ['What does the UndefinedColumn error mean when exporting green_taxi data to PostgreSQL?',\n",
       "  'How can I resolve the issue of missing columns during the export process?',\n",
       "  'What steps should I take if I encounter a re-run problem with the export block?',\n",
       "  'Is there a specific SQL command to drop the table in Mage for the green_taxi data?',\n",
       "  'Will re-running the block work after dropping the table in PostgreSQL?'],\n",
       " '207be93b': ['What is the cause of the SettingWithCopyWarning error in pandas?',\n",
       "  'How can I avoid encountering the SettingWithCopyWarning in my homework?',\n",
       "  'What syntax should I use to set values in a DataFrame without triggering a warning?',\n",
       "  'Is there a recommended method for assigning new columns in a DataFrame?',\n",
       "  'What does the error indicate about the DataFrame I am working with?'],\n",
       " 'f0617e65': ['What are the advantages of using the Pyspark kernel in Mage over the Python kernel when working with large CSV files?',\n",
       "  'Is there any specific documentation available for utilizing the Pyspark kernel in Mage?',\n",
       "  'How does the performance of Pyspark compare to Pandas when handling large datasets?',\n",
       "  'Can you provide guidance on switching from the Python kernel to the Pyspark kernel in Mage?',\n",
       "  'Are there any limitations or challenges I should be aware of when using Pyspark for large CSV files?'],\n",
       " '6290a1a6': ['What steps should I follow to delete a block from a pipeline without encountering errors?',\n",
       "  'Is it necessary to delete connections before removing a block in a pipeline?',\n",
       "  'Can you explain the process of removing a connection between blocks in a pipeline?',\n",
       "  'What should I do if I face an error while trying to delete a block in my pipeline?',\n",
       "  'Are there any prerequisites to consider before deleting a block in my workflow orchestration?'],\n",
       " '5a06248c': ['What should I do if I encounter a permission denied error while trying to edit the Pipeline name in Mage UI?',\n",
       "  'Is there a workaround for editing the Pipeline name if the UI does not allow it?',\n",
       "  'Can I save my work and edit the Pipeline name later if I face an error?',\n",
       "  'What steps should I take if I cannot change the Pipeline name in Mage UI?',\n",
       "  'Why does Mage UI throw a permission denied error when I attempt to rename the Pipeline?'],\n",
       " 'c46a2e9e': ['What are the steps to load all partitioned files I created into BigQuery using Mage?',\n",
       "  'Can you explain how to load specific date ranges from partitioned files into BigQuery with Mage?',\n",
       "  \"What should I do if I encounter an 'undefined column' error while connecting to the green_taxi table?\",\n",
       "  'Is there a way to delete the green_taxi table if it already exists before loading new data?',\n",
       "  \"How can I adjust the Data Extractor's settings for loading data from the dataframe in Mage?\"],\n",
       " '0513ab8a': ['Where can I find the necessary mage files for Homework 2 on my local machine?',\n",
       "  'What specific folders should I look for in my mage directory to complete the homework submission?',\n",
       "  'How do I download the entire pipeline and what additional files will I receive?',\n",
       "  'What types of files do I need to download from the mage folders for the blocks in my pipeline?',\n",
       "  'Once I have downloaded the required files, what should I do with them before submitting on GitHub?'],\n",
       " 'a9385356': ['What steps do I need to follow to integrate files from the Mage repository into my personal Data Engineering Zoomcamp repository?',\n",
       "  'Why do I need to move the contents of the .gitignore file to include the Mage repo files in my Zoomcamp repo?',\n",
       "  'What commands should I run in the terminal after accessing the Mage folder to prepare it for inclusion in my main repo?',\n",
       "  'How does GitHub treat the Mage repo and my Data Engineering Zoomcamp repo when I try to include their files?',\n",
       "  \"What does the command 'git remote remove origin' accomplish when working with the Mage repository?\"],\n",
       " 'c30468c0': ['What error did I encounter when adding multiple assertions in Module 2?',\n",
       "  'What should I do if I receive a ValueError about the truth value of a Series?',\n",
       "  'How can I correctly filter data based on multiple conditions in my code?',\n",
       "  \"Which operator should I use instead of 'and' for combining conditions in a DataFrame?\",\n",
       "  'Where can I find more discussions or solutions related to this ValueError issue?'],\n",
       " '305aead7': ['What should I do if I notice that my Mage AI files are missing after starting my PC and running docker compose up?',\n",
       "  'Is there a specific command I need to use to properly shut down the Mage Docker before restarting it?',\n",
       "  'How can I ensure that I am in the correct directory before executing the docker compose up command?',\n",
       "  'What steps should I take if I continue encountering issues with disappearing files while using Mage?',\n",
       "  'Where can I find additional discussions or solutions regarding issues with Mage AI files in the course community?'],\n",
       " '77410975': ['What kind of errors can occur in the io.config.yaml file in relation to the Mage section?',\n",
       "  'How should I fix errors that are caused by incorrect quotes in the io.config.yaml file?',\n",
       "  'What specific modifications are necessary for fixing trailing side errors in the io.config.yaml file?',\n",
       "  'Who can I refer to for help with issues related to the io.config.yaml file in Module 2?',\n",
       "  'Are there particular characters that should be avoided in the io.config.yaml file to prevent errors?'],\n",
       " '0952abde': ['What error occurs when exporting data from Mage to a GCS bucket using pyarrow?',\n",
       "  'What does the ArrowException indicate about permissions when accessing the GCP credentials file?',\n",
       "  'How do I resolve the issue of Mage being unable to open the credentials file?',\n",
       "  'What steps should I follow to create the necessary credentials folder for Mage?',\n",
       "  'Where do I update the code to specify the path to my GCP service account credentials?'],\n",
       " '7c4326eb': ['What does the OSError related to Google Cloud indicate when working with Mage?',\n",
       "  'Why might I encounter a retry policy exhaustion error while trying to get bucket metadata?',\n",
       "  'What is required to successfully complete a request for Google Cloud resources?',\n",
       "  'Where can I find more information about Google Cloud authentication?',\n",
       "  'What does the underlying error message suggest about the issue with performing the work?'],\n",
       " 'a1fc1a14': ['What issue arises when I try to export data from Mage to a Google Cloud Storage bucket?',\n",
       "  \"What does the error message indicate regarding the service account's permissions?\",\n",
       "  'How can I resolve the PermissionError related to Google Cloud Storage access?',\n",
       "  'What steps do I need to follow to add the necessary role to my service account?',\n",
       "  'What role should I assign to the service account for it to gain access to the storage bucket?'],\n",
       " '6d67fba9': ['What preparations do I need to make for my pyspark script before sending it to the Dataproc cluster?',\n",
       "  'How do I create a Dataproc Cluster in the GCP Console?',\n",
       "  'What changes must be made to the service account in order to add the Dataproc Editor role?',\n",
       "  'Where should I place my python script in the GCS bucket and how do I access it?',\n",
       "  'Is there a specific requirement for installing the gcloud CLI to allow Mage to access Dataproc?'],\n",
       " '06876291': ['What is a potential solution for the long installation time of zip and unzip packages in Docker-compose?',\n",
       "  'How can I automate the installation of additional packages when using apt-get?',\n",
       "  'Is there an alternative method for unpacking datasets besides using zip and unzip?',\n",
       "  'Why might Docker-compose take a long time to install required packages for datasets on Linux?',\n",
       "  'Is the Python ZipFile package available in all current Python environments?'],\n",
       " '690ba010': ['What should I do if I encounter an error when writing data from the web to GCS?',\n",
       "  'Are there specific data types I should use to avoid errors with GCS Buckets?',\n",
       "  'Can you provide guidance on the types of data I should consider using for GCS?',\n",
       "  'Is there a recommendation for handling Nullable data types when writing to a GCS Bucket?',\n",
       "  'What data types are suggested to prevent errors in Module 3: Data Warehousing?'],\n",
       " 'b6fdd91d': ['What is the importance of having a consistent schema in BigQuery while ingesting data?',\n",
       "  'Can you explain why all files in a directory must have the same schema for successful ingestion into BigQuery?',\n",
       "  'How does the schema definition work when importing multiple parquet files into BigQuery?',\n",
       "  'What steps should I take to prevent errors related to data type mismatches when uploading to BigQuery?',\n",
       "  'What are the data types used in the FHV Datasets from 2019, and how do they affect schema consistency?'],\n",
       " '155aa868': ['What should I do if I get a gzip error while importing FHV data to GCS?',\n",
       "  \"How can I resolve the 'Not a gzipped file' error when working with FHV dataset?\",\n",
       "  'What is the correct URL format for the FHV dataset in GCS?',\n",
       "  'Can you clarify the specific part of the URL I need to emphasize for importing FHV data?',\n",
       "  'Why does specifying the wrong URL lead to a gzip error when importing data?'],\n",
       " 'e78cf960': ['Who should I contact regarding loading data from a URL list to a GCP bucket in Module 3?',\n",
       "  'Is there a specific individual responsible for assistance with the GCS bucket tasks?',\n",
       "  'In the context of Module 3, who can help with data loading into GCP?',\n",
       "  'If I have questions about GCS buckets, who can provide guidance?',\n",
       "  'For issues related to loading data from URLs to GCP, whom should I reach out to?'],\n",
       " '9afa1f74': ['What should I do if I encounter a Bad character (ASCII 0) error while querying my dataset in the GCS Bucket?',\n",
       "  'Is there a specific aspect of the data that I need to check when facing a Bad character error?',\n",
       "  'How can I ensure that my CSV.GZ files are correctly formatted for upload?',\n",
       "  'Are there any alternative methods to upload my CSV.GZ files aside from using pandas?',\n",
       "  'Where can I find helpful tips regarding this issue discussed among peers?'],\n",
       " 'fac138a7': ['How can I verify if the BigQuery Command Line Tool is installed on my system?',\n",
       "  \"What command should I use to troubleshoot the 'bq: command not found' error?\",\n",
       "  \"Is there an alternative way to run the BigQuery command if 'bq' is not recognized?\",\n",
       "  'What steps should I follow to check the installation status of Cloud components?',\n",
       "  \"Can I use a different command in place of 'bq' to execute BigQuery functions?\"],\n",
       " '0174dde5': ['What precautions should I take when using BigQuery within GCP?',\n",
       "  'Why did I receive an $80 bill for using BigQuery on my project?',\n",
       "  'How can I prevent unexpected charges while using BigQuery?',\n",
       "  'What is the recommendation regarding managing datasets in BigQuery?',\n",
       "  'Is there a specific action I should take regarding billing while using BigQuery?'],\n",
       " '1023ee65': ['What happens if my GCP resources are in different regions when attempting to load data into BigQuery?',\n",
       "  'How can I successfully load data from a GCS bucket to BigQuery if they are in separate regions?',\n",
       "  'Is it possible to keep my existing datasets and still load data from a GCS bucket in a different region?',\n",
       "  'What should I do if I forgot to align the regions for my GCS bucket and BigQuery dataset during creation?',\n",
       "  'Can I create a new BigQuery dataset in the same region as my GCS bucket to resolve the region issue?'],\n",
       " 'effd2bfa': ['What should I do if I cannot read and write in different locations in GCP BQ?',\n",
       "  'How can I ensure my BigQuery dataset is compatible with my GCS Bucket?',\n",
       "  'Is it necessary for the BigQuery dataset and GCS Bucket to be in the same region?',\n",
       "  'Can I create a BigQuery dataset in a different location from my GCS Bucket?',\n",
       "  'What is an example of how to set the same location for both GCS Bucket and BigQuery dataset?'],\n",
       " '5b55273c': ['What should I do to prevent losing my work in BigQuery SQL Editor?',\n",
       "  'Is there a specific button I need to click to save my queries in BigQuery?',\n",
       "  \"What happened to someone's SQL script when their Chrome Tab froze?\",\n",
       "  'Can I save my queries in a different format outside of BigQuery?',\n",
       "  'Which editors can I use to save my SQL scripts with color formatting?'],\n",
       " '1835bfe0': ['Is BigQuery suitable for real-time analytics in this project?',\n",
       "  'Does BigQuery support real-time data streaming?',\n",
       "  'Can I integrate real-time analytics using BigQuery later?',\n",
       "  'Is real-time analytics a feature of BigQuery for this course?',\n",
       "  'What capabilities does BigQuery offer for real-time analytics?'],\n",
       " '04656af5': ['What should I do if I encounter a timestamp parsing issue when loading data into a materialized table in BigQuery?',\n",
       "  'How can I identify invalid timestamp data when importing to a materialized table in BigQuery?',\n",
       "  \"What is the cause of the invalid timestamp error related to the 'pickup_datetime' field?\",\n",
       "  'Is there a way to filter out invalid rows during the loading process into a materialized table?',\n",
       "  'What datatype should I use when defining the schema from the external table to avoid timestamp errors?'],\n",
       " '2d6536d3': ['What error message do I encounter in BigQuery related to timestamps?',\n",
       "  'How can I resolve the issue with timestamps being recognized as integers in BigQuery?',\n",
       "  'What function do I need to modify in order to handle deprecated INT96 timestamps correctly?',\n",
       "  'Where can I find resources to understand compatibility issues between Parquet files created with PyArrow and Pyspark?',\n",
       "  'What parameter should I include in the pq.write_to_dataset function to fix timestamp formatting errors?'],\n",
       " '0516ccbe': ['What is the issue with datetime columns in Parquet files created from Pandas when using BigQuery?',\n",
       "  'What should I do if I am using Mage and facing problems with datetime columns in my data?',\n",
       "  'How can I ensure that datetime columns are loaded correctly into BigQuery from Parquet files?',\n",
       "  'Is there a way to use explicit schema in PyArrow when writing Parquet files for Google Cloud Storage?',\n",
       "  'What specific logical type should I use for datetime columns in my PyArrow schema to avoid conversion issues in BigQuery?'],\n",
       " '6052513d': ['What is the process for creating an external table in BigQuery using Python?',\n",
       "  'Which external source format should I specify when creating the external table?',\n",
       "  'How do I point to my data in Google Cloud when setting up source URIs?',\n",
       "  'What is the purpose of the ExternalConfig object in this context?',\n",
       "  'How do I confirm that the external table has been successfully created?'],\n",
       " '7a71fa2c': ['How can I verify if a table exists in BigQuery using Python?',\n",
       "  'What is the method to delete an existing table in BigQuery?',\n",
       "  'Is there a specific function to check for the existence of a table before creating it?',\n",
       "  'Where can I find additional resources on handling BigQuery tables programmatically?',\n",
       "  \"What should I do if an error occurs while checking for a table's existence in BigQuery?\"],\n",
       " 'f83d9435': ['How can I resolve the error related to a missing close double quote in GCP BQ?',\n",
       "  'What command should I use to upload data from Google Cloud Storage to BigQuery?',\n",
       "  'Is there a way to avoid issues with quoted newlines when loading data into BigQuery?',\n",
       "  'Where can I find the data files to upload to my BigQuery table?',\n",
       "  'What is the recommended source format for loading CSV files into BigQuery?'],\n",
       " 'dbf65e11': [\"What should I do if I'm unable to read and write data in different locations in GCP BigQuery?\",\n",
       "  'How can I check the region of my Google Cloud Storage bucket?',\n",
       "  'What steps should I take to create a dataset in BigQuery with the correct region?',\n",
       "  'Why does the error occur when my GCS and BigQuery are set up in different regions?',\n",
       "  'Which icon do I need to click on to create a new dataset in BigQuery?'],\n",
       " 'c489266b': ['What are the advantages of using Cloud Functions for automating tasks in Google Cloud?',\n",
       "  'How do I modify the provided Cloud Function script to use my own project, dataset, and table IDs?',\n",
       "  'Can you explain how the LoadJobConfig schema is defined in the script?',\n",
       "  'What happens when I run the script for loading data from the first month versus subsequent months?',\n",
       "  'What steps should I take to ensure successful data loading into BigQuery in the specified location?'],\n",
       " 'ebd63566': ['What should I do in query settings to avoid caching when analyzing two tables?',\n",
       "  'How can I ensure that my query results for external and materialized tables are accurate?',\n",
       "  'Is there a specific option I need to change in the query settings when using GCP BQ?',\n",
       "  'Why do I get the same count when querying different types of tables in BigQuery?',\n",
       "  'What action can I take to differentiate the query outputs of external and materialized tables?'],\n",
       " 'f7252f17': ['What specific issue can arise when inserting data into GCS with Pandas related to DOlocationID and PUlocationID?',\n",
       "  'How does the default behavior of Pandas affect the data type consistency between parquet files and BigQuery schema?',\n",
       "  'What solution is recommended to resolve data type discrepancies before loading data into GCS?',\n",
       "  'Which method should be used to cast the data types of DOlocationID and PUlocationID to avoid errors in BigQuery?',\n",
       "  'Why is it important to define the data type of all columns in the Transformation section of the ETL pipeline?'],\n",
       " '47a43bb0': [\"What does the error message regarding the Parquet column 'DOlocationID' indicate about data type mismatches?\",\n",
       "  'How can I resolve the issue related to invalid project IDs in GCP BQ?',\n",
       "  'What should I check for if I encounter an error while reading a table in BigQuery?',\n",
       "  'Are there any specific formatting requirements for project IDs in GCP BQ?',\n",
       "  'What common mistakes can lead to errors when writing SQL queries in BigQuery?'],\n",
       " 'f3f13def': ['What kind of error occurs when reading the trips_data_all.external_fhv_tripdata table?',\n",
       "  'What is the data type mismatch situation with the DOlocationID column?',\n",
       "  'Can you explain if BigQuery allows multiple columns for partitioning?',\n",
       "  'What does the documentation say about partitioning in BigQuery?',\n",
       "  'Is it possible to have more than one column partitioned in BigQuery?'],\n",
       " '4fd37712': [\"What does the error message regarding 'DOlocationID' indicate about the data type mismatch in BigQuery?\",\n",
       "  'What is the specified requirement for the PARTITION BY expression in BigQuery when encountering a DATE() error?',\n",
       "  'Can you clarify the types of columns that can be used in a PARTITION BY expression in BigQuery?',\n",
       "  'What steps should I follow to resolve the issue related to the DATETIME columns in my DataFrame?',\n",
       "  'How do I convert my pickup and dropoff datetime columns to the correct format before using them in BigQuery?'],\n",
       " '8abeca36': ['What is the primary difference between native tables and external tables in BigQuery?',\n",
       "  'How does data storage differ between native and external tables in BigQuery?',\n",
       "  'Can you explain what happens to metadata in external tables within BigQuery?',\n",
       "  'Where is the data stored when using external tables in BigQuery?',\n",
       "  'What resources can I consult for more information on BigQuery tables?'],\n",
       " '16c16ff9': [\"Why am I receiving an error about the Parquet column 'DOlocationID' when trying to read my table?\",\n",
       "  'What should I do if my ML model export command is failing due to a dataset not found error in BigQuery?',\n",
       "  'How can I ensure that my dataset and GCS bucket are properly configured to avoid location errors?',\n",
       "  'What is the correct command syntax for exporting an ML model from BigQuery to Google Cloud Storage?',\n",
       "  'Can you explain why my project ID and GCS bucket folder address might be causing an issue during the export process?'],\n",
       " 'c65d8fd9': ['What error do I encounter when trying to read the trips_data_all.external_fhv_tripdata table?',\n",
       "  'How can I address the issue with the DOlocationID type mismatch when running my queries?',\n",
       "  'What specific configuration change do I need to make to the dim_zones table to resolve the dataset not found error?',\n",
       "  'In which location should I specify the parameter when creating the dim_zones table?',\n",
       "  'What steps do I need to follow after updating the dim_zones table configuration to ensure my fact_trips.sql runs successfully?'],\n",
       " 'c1a95536': ['What error might I encounter when reading the trips_data_all.external_fhv_tripdata table in GCP BQ ML?',\n",
       "  'Can you explain the solution for running an ML model export on a MacBook with an Apple M1 chip?',\n",
       "  'What command should I use to pull the Docker image for TensorFlow serving on an Apple M1 Mac?',\n",
       "  'How do I set up the serving directory on my computer according to the extract_model.md file?',\n",
       "  'What should I do after running the Docker command to get predictions for my model?'],\n",
       " 'bba0da04': ['What steps should I take if I find that my virtual machine is running low on storage space?',\n",
       "  'Are there any specific types of files I should focus on when trying to free up space in my VM?',\n",
       "  'What actions should I take regarding processes if I delete files in my virtual machine?',\n",
       "  'Is there a recommended tool I can use to identify large files on my virtual machine?',\n",
       "  'What should I remember to do with my flow code if I delete files related to Prefect?'],\n",
       " 'a2120335': ['What should I do if I encounter an error related to the trips_data_all.external_fhv_tripdata table?',\n",
       "  'Can you clarify what the instruction means regarding stopping the loading of files into a bucket?',\n",
       "  'Is it necessary to clean the data before creating the external table after loading it into the bucket?',\n",
       "  'What should be the format of the files after loading them into the bucket for the external table creation?',\n",
       "  'Are there specific file types we are allowed to load into the bucket for our project?'],\n",
       " 'a4ba2478': ['What specific error might occur when trying to read parquet files directly from nyc.gov into pandas?',\n",
       "  'Can you explain the cause of the out of bounds error when reading timestamp data from the dataset?',\n",
       "  'What is the recommended method to read parquet files from nyc.gov to avoid the out of bounds error?',\n",
       "  'How can I handle errant records in datetime columns when loading data with pandas?',\n",
       "  'Is there a way to filter out offending rows that cause errors in datetime columns when working with parquet files?'],\n",
       " '74c361fe': ['What should I do if I encounter an error related to the Parquet column type while reading a table?',\n",
       "  \"Is it necessary to download each month's green taxi parquet file separately for 2022?\",\n",
       "  'How can I refer to all 12 parquet files in a single string when creating an external table in BigQuery?',\n",
       "  'Do I need to upload the parquet files to a specific location in my GCS bucket?',\n",
       "  'Can I use a wildcard to access the green taxi data files for 2022 efficiently?'],\n",
       " 'b9b3ef9f': ['What should I do if I encounter an error while reading the trips_data_all.external_fhv_tripdata table?',\n",
       "  'How can I avoid schema issues when completing the homework?',\n",
       "  'What is the recommended method for uploading files to GCS?',\n",
       "  'Is it possible to upload multiple files at the same time to GCS?',\n",
       "  'Can I upload an entire folder to GCS instead of individual files?'],\n",
       " '009ac612': ['What should I do if my partitioned table is not providing the expected prediction?',\n",
       "  'Could you clarify what steps I need to take regarding the date format for Homework Qn 5?',\n",
       "  'Is it possible that the issue with my predictions relates to how dates are formatted in the dataset?',\n",
       "  'What is the connection between date formats and the accuracy of predictions in our assignments?',\n",
       "  'Can you explain why the table error I encountered might affect the results of my homework?'],\n",
       " '68815ec2': [\"What is the error that occurs when reading the table 'trips_data_all.external_fhv_tripdata'?\",\n",
       "  \"What type mismatch is causing the error related to 'DOlocationID' in the Parquet column?\",\n",
       "  'Did anyone achieve an exact answer for the options in Module 3 homework question 6?',\n",
       "  'How are students faring in terms of matching their answers for Homework Q6?',\n",
       "  \"What should students do if their answers are not exact according to Alexey's guidance?\"],\n",
       " 'c8ad08b3': ['What should I do if I encounter a Parquet column type mismatch error when reading the trips data?',\n",
       "  'How can I resolve a UnicodeDecodeError related to invalid start bytes when working with data in Python?',\n",
       "  'What encoding should I specify when reading a CSV file from the web into a pandas dataframe?',\n",
       "  'How do I write a pandas dataframe to Google Cloud Storage as a CSV file while ensuring the correct encoding?',\n",
       "  'Is there an alternative method for reading data from a URL instead of using the standard CSV approach in pandas?'],\n",
       " 'd68b433f': ['What is a generator in Python and how does it differ from other iterables like lists or tuples?',\n",
       "  'Can you explain the role of the yield keyword in creating a generator function?',\n",
       "  'How do generators help with memory efficiency when working with large datasets?',\n",
       "  'What does it mean for a generator to generate values on-the-fly?',\n",
       "  'Could you provide examples of situations where using a generator would be more advantageous than using a list?'],\n",
       " 'e265ee5a': [\"What is the error message related to the Parquet column 'DOlocationID' in the trips_data_all dataset?\",\n",
       "  'How does the read_parquet function handle multiple files?',\n",
       "  'Can I merge multiple files into one table using read_parquet?',\n",
       "  \"What type does the column 'DOlocationID' have in the dataset, and how does it affect reading it?\",\n",
       "  'Is it possible to pass a list of files to the read_parquet function for processing?'],\n",
       " '0e7dfddc': [\"What type must the 'DOlocationID' column be when working with the trips_data_all table?\",\n",
       "  \"What error can occur if the data type is not correctly set for 'DOlocationID'?\",\n",
       "  \"How should I correctly convert the 'DOlocationID' column to avoid errors?\",\n",
       "  \"What is the alternative way to convert 'DOlocationID' if I encounter type mismatches?\",\n",
       "  \"Is it acceptable to use astype(int) for the 'DOlocationID' column?\"],\n",
       " '0a059700': [\"What should I do if I encounter an error while trying to read the Parquet column 'DOlocationID' in my data?\",\n",
       "  'How can I resolve the ValueError regarding the missing path when running my Prefect flow?',\n",
       "  'Is there a specific parameter I need to remove from my function to successfully run the flow again?',\n",
       "  'What is the purpose of the cache key in my Prefect flow, and how does it affect execution?',\n",
       "  'Can using the cache key in my initial run lead to any issues when I try to rerun my code?'],\n",
       " 'feca7402': ['What is the purpose of the @task decorator in the code snippet provided?',\n",
       "  'Can you explain how the download_file function works in detail?',\n",
       "  'What type of file is being downloaded using the provided code sample?',\n",
       "  'How is the flow function extract_from_web related to the downloading process?',\n",
       "  'Is there a specific library that needs to be imported to use the requests.get method in this context?'],\n",
       " '1f519b1a': ['What should I do if I encounter an error stating that the prod dataset is not available in the correct location during production deployment?',\n",
       "  'How can I resolve the issue of my DBT models creating a dataset in the US location instead of the EU location on DBT Cloud?',\n",
       "  'Is there a specific configuration I need to adjust in the dbt_project.yaml file to fix seed column type errors?',\n",
       "  'What steps did you take to successfully run your DBT job in production after encountering location errors?',\n",
       "  'Why does everything work fine in development mode but fail in production when using DBT Cloud?'],\n",
       " '43c454c7': ['What should I do if I encounter an error regarding a missing development environment?',\n",
       "  'How can I configure my development credentials for dbt IDE?',\n",
       "  'Where can I find the guide to resolve the development environment issue?',\n",
       "  'Which video contains information about setting up the development environment?',\n",
       "  'Is there a specific Slack chat where I can ask about the development environment error?'],\n",
       " 'd7ad69da': ['What is the reason for the Runtime Error when connecting dbt Cloud with BigQuery?',\n",
       "  \"How can I resolve the 'Access Denied' error for my dbt service account?\",\n",
       "  'What permissions does my service account need to create BigQuery jobs?',\n",
       "  'What steps should I follow in Google Cloud to grant my service account the necessary access?',\n",
       "  'What additional roles should I assign to prevent permission issues during the course?'],\n",
       " '03fdb780': ['What causes a dbt Cloud run to be cancelled?',\n",
       "  'How can I check if my dbt project is set up correctly?',\n",
       "  'What file should be present for a valid dbt project?',\n",
       "  'What should I do if my dbt project is in a subdirectory?',\n",
       "  'Where can I specify the location of my dbt project in dbt Cloud?'],\n",
       " '9c85f3aa': ['What should I do if I encounter an error stating that the repository failed to clone?',\n",
       "  'How can I resolve the permission denied error when trying to clone the GitHub repository?',\n",
       "  'What are the steps to clone the repository with my GitHub username?',\n",
       "  'Is there an alternative way to set up a fresh repository for my dbt lessons?',\n",
       "  'What is the recommended method for cloning the repository if I want to avoid permission issues?'],\n",
       " '63026349': ['What should I do if the option to create a Continuous Integration job in dbt Cloud is disabled when I try to set it up?',\n",
       "  'Is it possible to set up a CI Job in dbt Cloud while on the Developer Plan?',\n",
       "  'What are the prerequisites for creating a Continuous Integration job in dbt Cloud?',\n",
       "  'If I am currently in the Team Plan trial, but the CI job option is disabled, what can I do?',\n",
       "  'What plan do I need to upgrade to in order to utilize CI Jobs in dbt Cloud?'],\n",
       " '6ba02f77': ['What should I do if the DBT cloud IDE fails to start and shows an error?',\n",
       "  'Where can I find instructions for setting up my DBT cloud environment?',\n",
       "  'How can I resolve the issue of the DBT cloud IDE loading indefinitely?',\n",
       "  'What steps are necessary to import a repository into my DBT project?',\n",
       "  'How do I create an SSH key for my DBT cloud setup?'],\n",
       " '8b14286c': ['What should I do if I encounter datatype problems with columns while using DBT and BigQuery?',\n",
       "  'How can I define the schema when converting from CSV to Parquet to avoid datatype issues?',\n",
       "  'What steps can I take to fix a task failure in DBT due to mismatched data types in Parquet columns?',\n",
       "  'Is there a way to specify data types while importing a CSV file to a pandas DataFrame to prevent errors?',\n",
       "  \"What are the potential solutions for handling the 'ehail_fee' column if it causes errors during DBT runs?\"],\n",
       " '14a876ea': ['What should I do if the quick script for loading trip data into GCS returns an Access Denied error from the S3 bucket?',\n",
       "  'Is there an alternative way to download the trip data if the provided URL does not work?',\n",
       "  'How can I use the GitHub CLI to obtain the trip data required for my project?',\n",
       "  'What commands do I need to execute with the GitHub CLI to download the yellow and green trip data?',\n",
       "  'After downloading the trip data using the GitHub CLI, how can I upload the files to a GCS bucket?'],\n",
       " '1cf5be74': ['What is the specific error encountered when converting the fhv_tripdata_2020-01.csv file using Airflow?',\n",
       "  'What is the cause of the error thrown by the format_to_parquet_task during the ingestion process?',\n",
       "  'How can I fix the issue related to the random line breaks in the fhv_tripdata_2020-01.csv file?',\n",
       "  'What command should I manually run in the bash of the container to solve the conversion error?',\n",
       "  'What should I do in Airflow after fixing the CSV file to ensure it re-executes properly?'],\n",
       " '315ac3cc': ['What approach did you initially use to load yellow and green trip data for 2019 and 2020?',\n",
       "  'What issue did you encounter when trying to load the yellow trip data using the initial method?',\n",
       "  'What alternative method worked for you when handling the parquet files and loading them to GCS?',\n",
       "  'Who shared the hack that helped resolve the schema inconsistency when creating the BigQuery table?',\n",
       "  'Is there a recommended resource to watch regarding schema changes needed for loading data to BigQuery?'],\n",
       " 'c5c3beba': ['What is the format of the files I need to move from the Google Cloud Storage bucket to BigQuery?',\n",
       "  'How do I specify multiple files when transferring data to BigQuery?',\n",
       "  'Is there a specific syntax I should use to include all files in a folder?',\n",
       "  'What path do I need to use for referencing the files in Google Cloud Storage?',\n",
       "  'Do I need to state the file extension when moving files from Google Cloud Storage to BigQuery?'],\n",
       " 'f19be91b': ['What might cause SSH to stop working on my GCP VM after a restart?',\n",
       "  'How can I resolve SSH issues related to my GCP VM?',\n",
       "  \"What should I check in the '.prefect/storage' folder if I encounter problems?\",\n",
       "  'Is there a way to prevent SSH issues from occurring after running prefect?',\n",
       "  \"How often should I delete logs in the '.prefect/storage' folder to avoid problems?\"],\n",
       " '33db7dc7': [\"What should I do if I can't access my GCP VM due to insufficient space?\",\n",
       "  'How can I regain SSH access to my machine after a space issue?',\n",
       "  'What steps can I take if I receive a permission denied error when trying to SSH?',\n",
       "  'Is there a way to recover access to a GCP VM that I cannot connect to?',\n",
       "  \"What causes the 'permission denied (publickey)' error when accessing my VM?\"],\n",
       " '67ef8f87': [\"What should I do if I encounter a '404 Not Found' error regarding a dataset in BigQuery?\",\n",
       "  'How can I check the location of the source dataset and the schema I am writing to in BigQuery?',\n",
       "  'What steps should I take to resolve issues related to dataset locations in BigQuery when using dbt?',\n",
       "  'Is there a way to specify a single-region location for my datasets instead of using a multi-regional location in dbt?',\n",
       "  'What are the steps to update the location settings in dbt Cloud for my BigQuery project?'],\n",
       " '6acf2e77': ['What should I do if I receive a warning after running dbt with the latest version of dbt-utils?',\n",
       "  'How can I fix the error related to dbt_utils.surrogate_key when running a dbt command?',\n",
       "  \"What steps should I take if I encounter an 'Access Denied' error in BigQuery after creating fact_trips.sql?\",\n",
       "  'Which role do I need to add to the service account to resolve the permission issue in BigQuery?',\n",
       "  'Are there any additional permissions required for the service account in Google Cloud Storage related to dbt?'],\n",
       " '18430f10': ['What should I do if I encounter an error stating that dbt_utils is not found?',\n",
       "  'How can I add the necessary packages to my dbt project?',\n",
       "  'Is it required to create a packages.yml file in the main project directory?',\n",
       "  'What version of dbt_utils should I specify in the packages.yml?',\n",
       "  'What steps should I follow after creating the packages.yml file?'],\n",
       " 'afb7a40a': ['What should I do if the lineage feature is not accessible in my project?',\n",
       "  'How can I confirm that my yml file is formatted correctly?',\n",
       "  'Where can I find the build logs to verify the success of my run?',\n",
       "  'What steps can I take to view error messages or warnings in my command history console?',\n",
       "  'Who should I contact if the lineage issue continues after checking for compilation errors?'],\n",
       " 'd6a5b80e': ['What command should I use to ensure my Fact_trips includes all available data?',\n",
       "  'Is there a specific variable I need to set to get complete data in my Fact_trips?',\n",
       "  'What should I do if my Fact_trips is missing data for certain days?',\n",
       "  'Are there any formatting issues I need to be aware of when typing commands?',\n",
       "  \"What alternative syntax can I use if the standard command doesn't work for my data build?\"],\n",
       " 'de426d2f': ['What should I check if my fact_trips show data for only one month?',\n",
       "  'How do the if_exists settings affect my data uploads to BigQuery?',\n",
       "  \"What happens if I use if_exists='replace' while running my automated flow?\",\n",
       "  'How can I ensure that I include data from all months when uploading to BigQuery?',\n",
       "  \"What is the difference between if_exists='replace' and if_exists='append' in terms of data retention?\"],\n",
       " '354f0e10': ['What change should I make in the dm_monthly_zone_revenue.sql model after the second SELECT statement?',\n",
       "  'How should I format the month argument in the date_trunc function for BigQuery?',\n",
       "  'What error might I encounter when running the dm_monthly_zone_revenue.sql model?',\n",
       "  'What should I avoid when writing the month parameter in date_trunc for my SQL model?',\n",
       "  'Can you clarify the correct way to use date_trunc for truncating dates by month in BigQuery?'],\n",
       " '98fae8d0': ['What is the correct syntax for generating a surrogate key in dbt?',\n",
       "  'How can I replace the old surrogate key function in my project?',\n",
       "  'What function should I use to create surrogate keys for multiple fields?',\n",
       "  'Is there a new method for surrogate key generation in dbt?',\n",
       "  'What change should I make to the surrogate key definition in Module 4?'],\n",
       " 'cb678fde': ['What should I do if my dbt run fails after changing the dataset location?',\n",
       "  \"How can I resolve the error I'm encountering in dbt run after altering the location?\",\n",
       "  \"Is there a way to fix the issue with dbt run if I've modified the dataset's location?\",\n",
       "  'What steps do I need to take to correct errors in dbt after changing its location?',\n",
       "  'If I encounter errors after changing a location in dbt, how can I correct them?'],\n",
       " '39bfb043': ['What should I do if running dbt run with a specified variable value does not change the number of rows in my table?',\n",
       "  'Why is a new dataset created in BigQuery after I run my CI/CD job?',\n",
       "  'How can I ensure that my development models are merged into production models when using dbt?',\n",
       "  \"What happens if I select 'defer to another environment' in my CI/CD job setup?\",\n",
       "  'Is it necessary to remove the existing dataset before rerunning dbt to see the updated row count?'],\n",
       " '351a078a': ['What role does the Staging dataset play in the analytics process?',\n",
       "  'Can you explain why the Staging dataset is materialized as views instead of tables?',\n",
       "  'In the context of the project, how did Vic utilize the production dataset?',\n",
       "  'What alternative datasets did Vic create during the course videos?',\n",
       "  'Does the Staging dataset have to be used when working with the dbt framework?'],\n",
       " '61da1919': [\"What should I do if I see a message indicating that DBT Docs are served but I can't access them in my browser?\",\n",
       "  'Is there a specific line I need to delete from docker-compose to fix the access issue with DBT Docs?',\n",
       "  'What changes should I make to my docker-compose file if the DBT Docs are not accessible?',\n",
       "  'How can I troubleshoot the problem of DBT Docs being served but not shown in the browser?',\n",
       "  'What configuration in docker-compose might be preventing me from accessing DBT Docs through my web browser?'],\n",
       " '6528c6ae': ['How can I resolve the 404 error related to my BigQuery dataset not being found in the specified location?',\n",
       "  'What steps should I follow to check and adjust the location settings for my BigQuery connection?',\n",
       "  'Is there a specific procedure for re-uploading my GCP key after adjusting the location?',\n",
       "  'What should I do if my dataset is still not found after rebuilding the project with dbt?',\n",
       "  'Do I need to delete my dataset in GBQ before rebuilding the project with dbt?'],\n",
       " 'c0d3a2e8': ['How can I make changes to the main branch in dbt?',\n",
       "  'What should I do if I want to edit files in dbt?',\n",
       "  'Is the main branch in dbt editable?',\n",
       "  'Where can I find more information about branching in dbt?',\n",
       "  'What steps should I take to modify the main branch using git?'],\n",
       " '859a97c5': [\"How can I make changes to files in dbt when I'm in read-only mode?\",\n",
       "  'What steps should I take to create a new branch for development in dbt?',\n",
       "  'After creating a new branch, how do I merge my changes back to the main branch?',\n",
       "  'What does it mean to commit and push changes in the context of dbt?',\n",
       "  'Can you explain the process of switching branches when working with dbt and git?'],\n",
       " '32469a2d': ['What error occurs when trying to create CI checks for deployment to Production in dbt?',\n",
       "  'What triggers the error related to pull requests in dbt deploy with Git CI?',\n",
       "  'Which repository connections are required for the CI checks feature in dbt?',\n",
       "  'What solution should I follow instead of using the Git Clone option when deploying?',\n",
       "  'Where can I find the step-by-step guide for unlinking Git Clone and linking with Github?'],\n",
       " 'c599b3a0': ['How can I resolve the issue of not seeing the Run on Pull Requests option when setting up Continuous Integration with Github?',\n",
       "  'What steps should I follow to reconnect my Github account with my dbt project?',\n",
       "  'Where do I find the option to disconnect my current Github configuration within the dbt settings?',\n",
       "  'What should I do after disconnecting the current Github configuration in order to set it up again properly?',\n",
       "  'After reconnecting Github, how do I configure the job to ensure I see the Run on Pull Requests option?'],\n",
       " '179df18d': ['What should I do if I encounter a Compilation Error related to a missing source in my DBT project?',\n",
       "  'How can I fix the issue with the Lineage graph not displaying during the tutorial in Module 4?',\n",
       "  'Is there a specific moment in the DE Zoomcamp video where I should pay attention to avoid issues?',\n",
       "  'What file do I need to save to resolve the Compilation Error mentioned in the FAQ?',\n",
       "  'After saving the schema.yml file, will I be able to view the Lineage graph without problems?'],\n",
       " '1ce1a275': [\"What does the error 'NoneType' object is not iterable imply in the context of a macro?\",\n",
       "  \"Which macro is associated with the error related to 'NoneType' being not iterable?\",\n",
       "  'What is the significance of the vars section in the dbt_project.yml file?',\n",
       "  'What values should I include for payment_type_values in the dbt_project.yml?',\n",
       "  'Where can I find the definition of the macro test_accepted_values that caused the error?'],\n",
       " 'b529b0bc': ['What specific issue might arise if I directly copy the dbt macro for get_payment_type_description from the data-engineering-zoomcamp repository?',\n",
       "  'Why am I receiving a BadRequest error related to the CASE operator while using the get_payment_type_description macro?',\n",
       "  'What changes do I need to make to the payment_type data type for the macro to function correctly?',\n",
       "  'Can you explain the process required to convert numeric values to text within the dbt macro?',\n",
       "  'What does the dbt macro get_payment_type_description return when given different payment_type input values?'],\n",
       " '2e51a111': ['How can I access the error log in dbt to troubleshoot issues?',\n",
       "  'What happens when I click the link in the dbt error log?',\n",
       "  'Will I be able to see the exact line causing the error in my query?',\n",
       "  'Is there a specific module that covers troubleshooting in dbt?',\n",
       "  'Where can I find resources for analytics engineering with dbt?'],\n",
       " '6e1a0834': [\"What is the reason behind dbt creating a schema named 'dbt_marts' when I set the target schema to 'marts'?\",\n",
       "  'Can you explain how to change the default behavior of schema naming in dbt?',\n",
       "  'What steps do I need to follow to create a macro for overriding the default schema name in dbt?',\n",
       "  'Is there a specific file where I need to adjust the custom schema settings in dbt?',\n",
       "  'What syntax should I use for the macro to successfully modify the schema name in dbt?'],\n",
       " 'a8657e65': ['What steps should I follow to designate a subdirectory of my GitHub repository as the root for my dbt project?',\n",
       "  'Is there a specific setting in dbt Cloud that lets me configure the project subdirectory?',\n",
       "  'How can I adjust settings in dbt Cloud to point to a subdirectory for my project?',\n",
       "  'Can I set a specific folder within my GitHub repo to be the main dbt project folder?',\n",
       "  'What do I need to do in dbt Cloud to change the root project directory for my dbt project?'],\n",
       " '2678d8c2': ['What should I do if I encounter a compilation error indicating a model depends on a source that cannot be found?',\n",
       "  'How can I ensure that my SQL models in dbt reference the correct table names within BigQuery or Postgres?',\n",
       "  'Is there a specific way to write SQL queries in dbt to pull data from existing tables?',\n",
       "  'What example should I follow to correctly reference a table in my dbt models?',\n",
       "  'Are there any specific practices I should follow to avoid model compilation errors related to missing sources?'],\n",
       " 'aa85c6ae': ['What steps should I take if I encounter a Compilation Error related to a missing node in my model?',\n",
       "  'How can I ensure that my seed file is correctly referenced in the Production Environment?',\n",
       "  'Is there a specific branch I need to create a pull request from before checking for the seed file?',\n",
       "  'What should I verify in my .gitignore file to avoid issues with my seed file?',\n",
       "  'Can you clarify where I should look for the seed file if I run into a Compilation Error?'],\n",
       " 'de06929d': [\"What should I do if I encounter an 'Access Denied' message during dbt run with fhv_tripdata?\",\n",
       "  'How can I resolve permission issues while executing dbt run with external tables?',\n",
       "  \"What roles need to be added to fix the 'Permission denied' error in BigQuery?\",\n",
       "  'Where can I find my dbt cloud service account to manage permissions?',\n",
       "  'Is there a specific role that should be added alongside BigQuery Admin for dbt functionality?'],\n",
       " 'b087fa95': ['What problem might arise when injecting data to BigQuery due to pandas handling of columns with missing values?',\n",
       "  'How can I address the issue of pandas parsing integer columns with missing values as floats?',\n",
       "  'What is one method for specifying the data type of integer columns during data transformation?',\n",
       "  \"Is there a simpler way to ensure pandas infers the correct data type for my dataframe's integer columns?\",\n",
       "  'What steps should I follow to prepare my dataframe for data injection to avoid type errors?'],\n",
       " '3c41892d': ['What should I do if I get an exception saying ‘taxi_zone_lookup’ is not found while loading my GitHub repository?',\n",
       "  'Why is it necessary to rename the directory from ‘data’ to ‘seed’ for loading seed files?',\n",
       "  'In Module 4, what specific directory name must I use to ensure seed files are recognized?',\n",
       "  'Can you explain why the directory structure is important for loading seed files in dbt?',\n",
       "  'Is there a specific naming convention for directories when working with seed files in this course?'],\n",
       " '4842f3e8': [\"What should I verify in the .gitignore file if I encounter the 'taxi_zone_lookup' not found error?\",\n",
       "  'If I receive a 404 error for my dbt job, what should I check regarding the location of my datasets?',\n",
       "  'How can I ensure that the region for my datasets is set correctly in dbt to avoid errors?',\n",
       "  'Where can I adjust the location settings in dbt to ensure they match the required region for my project?',\n",
       "  'What is the specific error message I might encounter if a table is not found in the specified location?'],\n",
       " '5eaf61fe': ['What is the best way to prevent data type errors during ingestion when working with parquet files?',\n",
       "  'Can you explain how to create an external table using .csv.gz files?',\n",
       "  'What file format should I use to avoid data type problems in week 4?',\n",
       "  'Is there a specific command to replace the table when ingesting data?',\n",
       "  'Where can I find the .csv.gz files for the fhv_tripdata?'],\n",
       " '8ed36cea': ['What is causing the varying number of rows when I rerun the fact_trips model in Module 4?',\n",
       "  'How can I ensure that the number of rows in the fact_trips table remains consistent across multiple runs?',\n",
       "  'Why does the current deduplication method result in different first row selections during each execution?',\n",
       "  'What specific changes need to be made in the staging files to resolve this issue with row consistency?',\n",
       "  'Can you explain why the presence of an unknown borough affects the number of rows discarded in the fact_trips model?'],\n",
       " '46aebc79': ['What should I do if I face a data type error while executing the fact table in Module 4?',\n",
       "  'How can a nan value cause issues in the trip_type column?',\n",
       "  \"Is the trip_type column error related to BigQuery's handling of null values?\",\n",
       "  'What data type should I use to resolve the data type error on trip_type?',\n",
       "  'Can I use NUMERIC to fix the issue with the trip_type column in my fact table?'],\n",
       " 'e2d2bc58': ['What could be the reason for encountering an error regarding duplicate column names in the CREATE TABLE statement?',\n",
       "  'How can I avoid the issue of duplicate column names when performing joins in my SQL query?',\n",
       "  \"What specific SQL query structure could lead to the error related to duplicated 'locationid' columns?\",\n",
       "  'Can you explain how modifying my SELECT statement helps to resolve the issue of column name duplication?',\n",
       "  'What is the recommended SQL syntax for selecting from multiple tables to prevent naming conflicts?'],\n",
       " '137aab88': [\"What does the error 'Bad int64 value: 0.0' indicate in relation to ehail fees?\",\n",
       "  'How can I resolve the issue of null ehail fees causing casting errors in my dbt project?',\n",
       "  'What is the purpose of using safe_cast in dbt, particularly for handling integer conversions?',\n",
       "  'Can you provide an example of how to implement safe_cast for ehail_fee in Jinja code?',\n",
       "  'Is it possible to use safe_cast without the dbt_utils function, and if so, how would that look?'],\n",
       " 'a260e651': ['What specific error might I face when building the fact_trips.sql model?',\n",
       "  'How can I resolve the issue with the payment_type_description field causing the bad int64 value error?',\n",
       "  'What is the recommended method to handle decimal values before casting them to integer?',\n",
       "  'Which columns in the Green_tripdata table are known to cause bad int64 value errors?',\n",
       "  'Can you share the queries to properly cast ratecodeid and trip_type to avoid errors?'],\n",
       " 'da8d9fcc': ['What error message might I encounter when building the fact_trips.sql file in DBT?',\n",
       "  \"What type mismatch issue is mentioned regarding the 'ehail_fee' column in the Parquet file?\",\n",
       "  \"Which file path is referenced in the error related to the double type of 'ehail_fee'?\",\n",
       "  \"What solution did you use in stg_green_trips.sql to resolve the error with 'ehail_fee'?\",\n",
       "  \"How can I cast the 'ehail_fee' column to match the expected type in DBT?\"],\n",
       " '2314e3c4': ['What format should the - vars argument be in for dbt?',\n",
       "  'How can I ensure my YAML dictionary is correctly interpreted?',\n",
       "  'What does the error about the - vars argument indicate?',\n",
       "  'Can you clarify the correct way to structure the dbt run command with variables?',\n",
       "  'What should I check if my variable and value seem to be incorrectly formatted?'],\n",
       " 'e7bdbba6': ['Why is the Environment Type option greyed out for me?',\n",
       "  'Can I change the Environment Type while following the course?',\n",
       "  \"What should I do if I can't access the Environment Type settings?\",\n",
       "  'Is it necessary to modify the Environment Type during the course?',\n",
       "  'What does it mean to create a Production Deployment in this context?'],\n",
       " '52cccade': [\"What might cause the 'Access Denied' error when querying the yellow_tripdata table in dbt?\",\n",
       "  \"How can I change the branch I'm working on in dbt Cloud to avoid database permission issues?\",\n",
       "  \"If I encounter an error stating 'Could not parse the dbt project,' what should I check in my repository?\",\n",
       "  'What should I do if the dbt job continues to fail after changing the branch settings?',\n",
       "  'How can I ensure that my dbt environment runs on the correct custom branch instead of the master branch?'],\n",
       " '11a814ea': ['What should I do if my job still uses the old file after I committed changes to my modelling files?',\n",
       "  'How can I ensure that my recent modifications in the development branch are reflected in the job run?',\n",
       "  'Is there a specific process to follow when I want to merge my changes to the main branch?',\n",
       "  'After making changes in my development branch, what are the steps to rerun my job successfully?',\n",
       "  'Where do I need to go to approve the merging of my changes after creating a pull request?'],\n",
       " '0d1e02d5': ['What steps are needed to see my developments in the Develop tab after setting up Github and Bigquery?',\n",
       "  'Is there a specific environment I need to create before working on my models in dbt?',\n",
       "  'After developing a model in dbt, what environment do I need to set up next?',\n",
       "  'Could you explain the parameters that need to be configured in the development environment?',\n",
       "  'What is the process for running jobs once my model development is complete?'],\n",
       " '0a0cc4c3': ['What should I do if my Prefect Agent encounters an httpx.LocalProtocolError when retrieving runs?',\n",
       "  'How can I address the ProtocolError indicating invalid input in the context of my Prefect Agent?',\n",
       "  'Is there a solution available for when the Prefect Agent fails due to ConnectionState issues?',\n",
       "  'What steps can I take if the run retrieval process from the queue fails intermittently?',\n",
       "  'How long should I wait before attempting to rerun the Prefect Agent if it encounters an error?'],\n",
       " 'cb912983': [\"What should I do if I encounter an error when running 'dbt run' in BigQuery?\",\n",
       "  \"Can you explain why I'm seeing a type mismatch error related to the 'passenger_count' column during my dbt run?\",\n",
       "  'What transformations did you apply to resolve the error with column types in your parquet data?',\n",
       "  'Where can I find additional discussions or solutions for common errors related to dbt in BigQuery?',\n",
       "  'Has anyone else experienced similar issues with column formats in their parquet files when using dbt?'],\n",
       " '2d4e434f': [\"What command should I use instead of dbt run --models stg_green_tripdata --var 'is_test_run: false' if it doesn't return results?\",\n",
       "  'How can I modify the dbt run command for the stg_green_tripdata model?',\n",
       "  'What is the correct syntax for running dbt with the is_test_run variable set to false?',\n",
       "  \"If I encounter issues with the tutorial's code, what alternative command can I try?\",\n",
       "  'Can you provide the appropriate command to execute dbt for stg_green_tripdata without getting empty results?'],\n",
       " 'bb6655b9': [\"What should I do if I encounter a 'No module named pytz' error when setting up dbt with Docker?\",\n",
       "  \"Can you explain the steps to resolve the 'ModuleNotFoundError' for pytz while initializing dbt?\",\n",
       "  'Where exactly should I add the command to install pytz in the Dockerfile?',\n",
       "  'What is the command needed to install the pytz module in the Dockerfile for dbt?',\n",
       "  'Is the version of Python being used in the Dockerfile relevant to the pytz installation issue?'],\n",
       " 'fc2eb036': ['What should I do if I encounter a permission denied error when trying to edit dbt_project.yml after initializing with Docker?',\n",
       "  \"How can I change the profile from 'taxi_rides_ny' to 'bq-dbt-workshop' if I have run into issues?\",\n",
       "  'What command do I need to run to resolve file permission issues in my dbt project directory?',\n",
       "  'What should I do if I see an internal error stating that the profile should not be None after loading is completed?',\n",
       "  'When using dbt debug, how can I ensure I am in the correct directory to execute the command successfully?'],\n",
       " '25daead9': [\"What should I do if I receive a 'table is not on the specified location' error when querying on BigQuery?\",\n",
       "  'How can I make sure my BigQuery bucket, datasets, and tables are in the same location?',\n",
       "  'Where can I find the option to change the location settings for my BigQuery query?',\n",
       "  'How can I verify if the paths in my BigQuery query are correct?',\n",
       "  'What steps can I take to troubleshoot location-related issues in BigQuery?'],\n",
       " '2221d75e': ['What should I do if I encounter an error message stating that a valid dbt project was not found during a dbt Cloud run?',\n",
       "  'Could the cancellation of my dbt Cloud run be a result of moving the dbt project to a different directory?',\n",
       "  'What steps do I need to follow to ensure the project settings in dbt Cloud match my local file explorer path?',\n",
       "  \"How do I set up the PROD environment to check in the appropriate branch if it's not the default main branch?\",\n",
       "  'Is it necessary to manually merge and close the PR after triggering the CI check job in dbt Cloud?'],\n",
       " '94524a9d': [\"What issue may arise if my dataset on BigQuery is located in the 'EU' region during a pull request with dbt?\",\n",
       "  'How does dbt determine the schema location when creating a pull request for BigQuery?',\n",
       "  'What default location does dbt use when creating a new schema in BigQuery?',\n",
       "  'How can I change the location setting for my BigQuery connection in dbt?',\n",
       "  'Where in the dbt project settings can I find the option to set the location for BigQuery?'],\n",
       " '1f1ecbb7': ['What steps should I take if I encounter an error while deploying my dbt project on production?',\n",
       "  'How can I ensure that my changes are reflected in the latest version of the repository before running the dbt project?',\n",
       "  'What should I do if the dbt_project.yml file is not accessible to my project?',\n",
       "  'Where can I find a solution if I see a message indicating that my dbt Cloud run was cancelled due to a missing dbt project?',\n",
       "  'How do I verify that the dataset name in BigQuery matches the one I configured for the production environment on dbt Cloud?'],\n",
       " 'c5af32ab': ['What error message did you receive after building from stg_green_tripdata.sql in the video?',\n",
       "  'What is the default location for dbt Bigquery when a location is not specified?',\n",
       "  \"How can I fix the '404 Not Found' error related to the dataset location in my dbt project?\",\n",
       "  'What steps should I follow to specify the location as EU for my Bigquery connection?',\n",
       "  'Where can I find the option to edit the location details for my dbt connection settings?'],\n",
       " '1e6b7da1': ['What steps should I take if I encounter issues while loading the FHV_20?? data into GCS and BQ?',\n",
       "  'Can you clarify how to correctly format the URL Template link for accessing FHV_20?? data?',\n",
       "  'What value should I use for URL_PREFIX when working with the FHV_20?? data?',\n",
       "  \"Why is it important to ensure the link contains the word 'blob' instead of 'tree' when accessing the FHV_20?? data?\",\n",
       "  'Is there anything else I need to do besides updating the URL Template and URL_PREFIX to load the FHV_20?? data successfully?'],\n",
       " '259481c4': ['What is the recommended method for uploading datasets from GitHub for our homework?',\n",
       "  'Can you tell me about the script that simplifies the dataset upload process?',\n",
       "  'Is there a specific script I should use for the NYC TLC data ingestion task?',\n",
       "  'Who provided a script that is similar to git_csv_to_gcs.py?',\n",
       "  'Where can I find the script referenced in relation to web_to_gcs.py?'],\n",
       " 'edbae698': ['What is the recommended method for securely storing project credentials before pushing to a git repository?',\n",
       "  'Which two environment variables should be set for the scripts web_to_gcs.py or git_csv_to_gcs.py?',\n",
       "  'How can you install the dotenv package to manage environment variables in a project?',\n",
       "  'What code is needed to access environment variables after loading them from a .env file?',\n",
       "  'How can you reference the GCP_GCS_BUCKET environment variable after loading it using dotenv?'],\n",
       " '67217f4c': ['What should I do if I encounter invalid date types after uploading FHV data through CSV files?',\n",
       "  'How can I define the pickup_datetime and dropoff_datetime columns when creating an external table in BigQuery?',\n",
       "  'What SQL command do I need to use to ensure the pickup_datetime and dropoff_datetime are correctly parsed as timestamps in dbt?',\n",
       "  'Is there a specific format I need to specify for uploading CSV files in BigQuery?',\n",
       "  \"What should I do if my FHV data has a borough marked as 'Unknown'?\"],\n",
       " '2aadd232': ['What specific errors might I encounter when ingesting FHV data via parquet files?',\n",
       "  'What is the recommended approach to avoid data type issues when creating an external table for the FHV 2019 data?',\n",
       "  'How should I define the schema for the external table to ensure a successful load of the FHV data?',\n",
       "  'Is there a way to upload multiple months of FHV data in one go, and if so, how?',\n",
       "  'What are the essential columns to include in the schema definition for the external table of FHV trips?'],\n",
       " 'adcd914a': ['How can I access Looker Studio after my trial ends?',\n",
       "  'What happens if I encounter subscription prompts in Looker Studio?',\n",
       "  'Where should I go to access the free version of Looker Studio?',\n",
       "  'What errors might I see when trying to use Looker Studio after the trial?',\n",
       "  'Is there a way to avoid the Pro version subscription for Looker Studio?'],\n",
       " 'bbf094b3': ['What mechanism does dbt use to manage dependencies between models during execution?',\n",
       "  'What should I do if loading FHV Data into Mage results in issues?',\n",
       "  'How can I load data into a pandas dataframe for manipulation before uploading to GCP?',\n",
       "  \"What region setting should I use in dbt when working with datasets copied from BigQuery's public datasets?\",\n",
       "  'How can I change the location of my dbt profile when working with BigQuery?'],\n",
       " '2fdc5057': ['How can I quickly upload taxi data to dbt-postgres?',\n",
       "  'What feature should I use for uploading CSV files to dbt-postgres?',\n",
       "  'Is there a specific command I need to use for the COPY function?',\n",
       "  'Can I specify columns when using the COPY FROM feature?',\n",
       "  'Are there options available when uploading data with COPY FROM?'],\n",
       " '95e302f7': [\"What should I do if I encounter an error regarding 'invalid: '5432' in my profiles.yml for dbt-postgres?\",\n",
       "  'Can you tell me how to resolve the issue related to environment variables in my Jinja templates?',\n",
       "  \"What does the error message regarding 'type integer' indicate in my dbt-postgres profile configuration?\",\n",
       "  'Is there a specific format I need to follow when updating the line in profiles.yml?',\n",
       "  \"What steps should I take to fix the credentials issue shown in the error for profile 'PROFILE_NAME'?\"],\n",
       " '1ac2c13c': ['What is the process to install SDKMAN on a Linux system?',\n",
       "  'How can I install Java 11 using SDKMAN?',\n",
       "  'What command do I use to install Spark 3.3.2 through SDKMAN?',\n",
       "  'After installing, how can I refresh the environment variables in the same terminal?',\n",
       "  'What commands should I run to verify the installations of Java and Spark?'],\n",
       " '5cc0e4d9': ['What should I do if I am having difficulties with the local setup for Spark?',\n",
       "  'Is there a specific guide available for running Spark in Google Colab?',\n",
       "  'Where can I find a starter notebook for using Spark in Google Colab?',\n",
       "  'Why is it recommended to set up Spark locally before using Google Colab?',\n",
       "  'What does the local setup mean in the context of this course?'],\n",
       " '17090545': ['What should I do if I encounter an error when running spark-shell at CMD on Windows?',\n",
       "  'Is there a specific version of Java that Spark requires for proper functionality?',\n",
       "  'What error message indicates a problem related to native-hadoop library loading?',\n",
       "  'Which versions of Java are incompatible with Spark 3.x?',\n",
       "  'Where can I find the instructions to install the correct version of Java for Spark?'],\n",
       " 'd17e30c6': ['What error message did you encounter when trying to execute the user defined function in Spark?',\n",
       "  'Can you explain the issues related to the PYSPARK_PYTHON environment variable while using conda?',\n",
       "  'What specific command should I run on the command line to resolve the PySpark installation problem?',\n",
       "  'What do I need to add at the top of my script to properly initialize findspark?',\n",
       "  'How does the conda environment affect the Python paths when using PySpark on Windows?'],\n",
       " '1520b5bc': ['What is the reason for the TypeError when I try to import PySpark on Windows with Spark 3.0.3 and Python 3.11?',\n",
       "  \"How can I resolve the TypeError that mentions 'code() argument 13 must be str, not int' in my PySpark installation?\",\n",
       "  'Is using Python 3.11 with Spark 3.0.3 compatible, or should I consider downgrading my Python version?',\n",
       "  'What versions of Python are recommended for use with older Spark to avoid compatibility issues?',\n",
       "  'Can installing a newer version of PySpark help with compatibility problems I am experiencing with Python 3.11?'],\n",
       " 'e86ca928': ['What steps should I follow to set up a conda environment for PySpark on MacOS while ensuring all Python dependencies are managed?',\n",
       "  'Can you explain what to do if I encounter a Py4JJavaError related to connection issues while using Spark?',\n",
       "  'Which versions of JDK and Python are compatible with the current version of Spark, and how do I ensure I use them correctly?',\n",
       "  'Is it necessary to install findspark or similar packages when setting up PySpark, and why?',\n",
       "  'What actions should I take if I face errors while writing a DataFrame to a file, specifically regarding the required environment configurations?'],\n",
       " '3b5b4eb3': ['What can I do if I encounter a RuntimeError related to the Java gateway process when running my PySpark script in Jupyter Notebook?',\n",
       "  'Is there a specific command I need to run to resolve the issue of the Java gateway process exiting unexpectedly?',\n",
       "  'How can I verify if PySpark is configured to point to the correct location on my system?',\n",
       "  'What steps should I take to permanently set the environment variables for Spark on my computer?',\n",
       "  'If the error persists after following the initial troubleshooting steps, what additional resources can I refer to for help with setting up PySpark?'],\n",
       " '489c366f': ['What should I do if I encounter a Module Not Found Error while using Jupyter Notebook after installing pyspark on my VM?',\n",
       "  'Can you outline the steps needed to set up findspark in my Jupyter Notebook to resolve the pyspark import issue?',\n",
       "  'Is there a specific command I need to use in Jupyter Notebook to install pyspark if the regular pip install command does not work?',\n",
       "  'How can I filter data based on multiple conditions across different columns using PySpark?',\n",
       "  \"What is the import statement required for using the 'col' function in PySpark when filtering DataFrames?\"],\n",
       " '59381b15': [\"What should I do if I encounter a 'ModuleNotFoundError' when trying to import pyspark?\",\n",
       "  'How can I determine the correct version of the Py4J file for my setup?',\n",
       "  'What specific command do I need to run to check the contents of the python/lib directory in Spark?',\n",
       "  'If I find a mismatch between the Py4J filename and my export command, how should I modify it?',\n",
       "  'What additional step can I take if updating the PYTHONPATH does not resolve the issue with py4j?'],\n",
       " '220b1cf3': [\"What should I do if I encounter a Py4J Error related to ModuleNotFoundError and can't find the 'py4j' module?\",\n",
       "  'Can you explain how to resolve the issue with py4j not being recognized in my PySpark installation?',\n",
       "  'What steps must I take to ensure that I have the latest version of py4j installed through conda?',\n",
       "  'How do I add the necessary exports to my .bashrc file to fix the py4j error in PySpark?',\n",
       "  'Is there a specific way to check for the latest version of py4j to ensure proper installation?'],\n",
       " 'd970a0da': [\"What should I do if I encounter an exception stating 'Jupyter command jupyter-notebook not found' even after setting the paths correctly?\",\n",
       "  'Can you provide a brief overview of the steps needed to set up a virtual environment for Jupyter Notebook?',\n",
       "  'What are the necessary commands to install Python and ensure Jupyter Notebook functions correctly on my machine?',\n",
       "  'If I need to create a new Python virtual environment for Jupyter, what are the commands I should use?',\n",
       "  'Where can I find more detailed instructions regarding Jupyter Notebook installation and setup?'],\n",
       " '5fa98bd0': ['What error might occur when executing a PySpark script that attempts to read and write Parquet files?',\n",
       "  \"What is the reason for encountering a java.io.FileNotFoundException when using the 'overwrite' mode in PySpark?\",\n",
       "  \"How does Spark's lazy transformation feature contribute to the FileNotFoundException error?\",\n",
       "  'What is the recommended solution to avoid the FileNotFoundException when writing Parquet files in PySpark?',\n",
       "  'Where should I write the Parquet files to prevent overwriting existing data during a Spark job?'],\n",
       " 'ce508f3c': [\"What do I do if I encounter a FileNotFoundException related to Hadoop's bin directory on Windows?\",\n",
       "  'How can I resolve the issue of Hadoop not being able to find its bin directory when trying to write?',\n",
       "  'Is there a specific directory I need to create for Hadoop installation on Windows?',\n",
       "  'Where should I place the downloaded Hadoop files for proper installation on Windows?',\n",
       "  'Will the Windows installation automatically configure the Hadoop bin directory for me?'],\n",
       " 'b7b9487d': ['What is the primary type of SQL that is utilized in Spark?',\n",
       "  'How does Spark SQL differ from SQL used in databases like Postgres or MySQL?',\n",
       "  'Can you explain the general structure of a SQL query in Spark?',\n",
       "  'What are some examples of how built-in functions vary across different SQL providers?',\n",
       "  'Where can I find more information about Spark SQL and its functionality?'],\n",
       " 'a74de125': ['Why was the spark viewer on localhost:4040 not displaying my current run?',\n",
       "  'What should I do if the port I need is in use by another notebook?',\n",
       "  'How can I find out which port my Spark notebook is using?',\n",
       "  'What is the correct way to clean up after my Spark sessions?',\n",
       "  'Is it normal for Spark to use a port other than 4040 if one is already in use?'],\n",
       " 'e5270303': ['What steps can I take to resolve the java.lang.NoSuchMethodError related to DirectBuffer when calling repartition in a conda pyspark installation?',\n",
       "  'Is there a specific version of the Java Developer Kit that I should use for compatibility with my pyspark setup?',\n",
       "  'What should I do if I encounter a RuntimeError stating that the Java gateway process exited before sending its port number?',\n",
       "  'How can I check if the JAVA_HOME environment variable is correctly set in my notebook setup?',\n",
       "  'Where can I find additional resources or discussions related to the Java gateway process issue in pyspark?'],\n",
       " 'cabe8a5b': ['What specific version of the gcs-connector should I use to resolve Spark issues with BigQuery?',\n",
       "  'How can I authenticate with Google Cloud Storage when using Spark?',\n",
       "  'Can you provide the code snippet for creating the SparkSession with BigQuery configurations?',\n",
       "  'What memory settings should I configure for Spark when reading from BigQuery?',\n",
       "  'Where can I download the necessary authentication files for Google Cloud Platform?'],\n",
       " 'e3c0f777': ['What is the process for configuring the Spark BigQuery connector automatically?',\n",
       "  'How do I create a SparkSession with the necessary BigQuery dependencies?',\n",
       "  'Is there a specific version of the Spark BigQuery connector that I should use?',\n",
       "  'Will the automatic configuration manage dependencies for me?',\n",
       "  'Where can I find more information about the Spark BigQuery connector configuration?'],\n",
       " '50c009ef': ['What is the first step I need to take to connect PySpark with GCP Cloud Storage?',\n",
       "  'Where should I move the .jar file after downloading the Cloud Storage connector?',\n",
       "  'Can you outline the necessary classes I need to import in my Python script for PySpark?',\n",
       "  'What configurations must I set up before building my SparkSession with PySpark?',\n",
       "  'How can I read files directly from Google Cloud Storage once my SparkSession is set up?'],\n",
       " '3fe85b16': ['What library can I use to read a parquet file in PySpark for a limited number of rows?',\n",
       "  'Is there an alternative method to read a small number of rows from a parquet file without using PyArrow?',\n",
       "  'How do I convert a table into a Pandas dataframe after reading from a parquet file?',\n",
       "  \"What is the purpose of the 'limit' function when working with a DataFrame in PySpark?\",\n",
       "  'Can you provide an example of how to obtain a manageable size Pandas dataframe from a parquet file?'],\n",
       " '0fe0c76a': ['What could cause a DataType error when I create a Spark DataFrame using a specific schema?',\n",
       "  'Which video should I refer to if I encounter issues while creating a Spark DataFrame?',\n",
       "  'What is the issue with the PULocation and DOLocationID being defined as IntegerType?',\n",
       "  'What error message will I get if my schema mismatches with the Parquet file format?',\n",
       "  'How can I resolve the DataType error when using a parquet file for my DataFrame schema?'],\n",
       " '18c5bafe': ['How can I eliminate spaces in the names of columns using Pyspark?',\n",
       "  'What is the method to remove whitespace from column names in my dataframe?',\n",
       "  'Can you show me how to use aliases to clean up column names in Pyspark?',\n",
       "  'Is there a way to modify column names in PySpark by removing spaces?',\n",
       "  'What code snippet should I use to adjust column names in a Pyspark dataframe?'],\n",
       " '59e86b40': [\"What does the AttributeError related to 'DataFrame' mean when using PySpark?\",\n",
       "  'Why does this error occur specifically in Spark video 5.3.1?',\n",
       "  'How can I resolve the compatibility issue with pandas version 2.0.0 and Spark 3.3.2?',\n",
       "  'Is there an alternative method to fixing the AttributeError without downgrading pandas?',\n",
       "  'When was this problem with the DataFrame object fixed in Spark versions?'],\n",
       " '1ac3ea8f': [\"What should I do if I encounter an AttributeError related to 'DataFrame' in PySpark?\",\n",
       "  'Is there a recommended version of pandas that works well with PySpark 3.5.1?',\n",
       "  'How can I set up the environment variables for Spark on my system?',\n",
       "  'What specific installation version of pandas is mentioned as compatible with PySpark?',\n",
       "  'Where can I find instructions on configuring my environment for using Spark?'],\n",
       " 'e04529ac': ['What steps should I follow to start Spark in standalone mode on Windows?',\n",
       "  'How can I access the Spark UI after setting up the master and worker nodes?',\n",
       "  'Where can I find the correct homework file for Module 5 instead of the one in the code directory?',\n",
       "  'What command do I need to use to start a master node in Spark on Windows?',\n",
       "  'Is it possible to run the worker node on a different machine, and how would I do that?'],\n",
       " 'a602a7f8': ['How can I make the PYTHONPATH environment variable persistent across sessions?',\n",
       "  'What should I do if I want to avoid typing the export command every time?',\n",
       "  'Is there a way to set the PYTHONPATH for my Jupyter notebooks?',\n",
       "  'What file do I need to modify to add the export command permanently?',\n",
       "  'Can you suggest a command to run at the start of my homework to set up findspark?'],\n",
       " '9336ce2c': ['What should I do if I encounter a compressed file that stops before reaching the end-of-stream marker?',\n",
       "  'How did you manage to fix the problem related to the compressed file not completing?',\n",
       "  'Can you explain the steps to take before generating head.csv for a compressed file?',\n",
       "  'Is there a specific command I need to use to unzip the file correctly?',\n",
       "  'What should I do with the file after unzipping it to prevent issues when creating head.csv?'],\n",
       " 'bac4e0f7': ['What should I do if I encounter gibberish output after using the zcat command on downloaded files?',\n",
       "  'Why does the output appear compressed even after using zcat on certain files?',\n",
       "  'How should I handle the CSV files from the course repo to avoid compression errors?',\n",
       "  'What is the correct way to download the data files for Module 5 without encountering gzipping issues?',\n",
       "  'Can you explain why we should not gzip the files downloaded from the course repo?'],\n",
       " '13dad632': ['What does the PicklingError indicate when running the spark.createDataFrame command?',\n",
       "  'Why does the error occur specifically when I use python version 3.11?',\n",
       "  'How can I create a new conda environment with a supported Python version for PySpark?',\n",
       "  'After creating a new environment, what command do I need to run to start using Python 3.10?',\n",
       "  'What should I do if I want to switch back to my previous environment after activating the new one?'],\n",
       " 'ddc3c75b': ['How can I resolve the issue where my local Spark is unable to find my Google credentials?',\n",
       "  'What should I check if Spark fails to locate my GCP credentials as demonstrated in the tutorial?',\n",
       "  'Where exactly must I place my Google Cloud Platform credentials for Spark to recognize them?',\n",
       "  'Is there a specific directory where my GCP credentials need to be stored in the VM?',\n",
       "  'What steps do I need to follow to ensure my Spark setup can access my Google credentials?'],\n",
       " '095b667f': ['What are the initial steps to set up a Spark environment using Docker?',\n",
       "  'How do I modify the Dockerfile for the Bitnami Spark container?',\n",
       "  'What command should I use to build the Docker image for Spark?',\n",
       "  'Could you provide the contents of the docker-compose.yml file required to run Spark?',\n",
       "  'What command do I need to execute to start the Docker Compose deployment for Spark?'],\n",
       " '56a67c23': ['What is the first step to read data from GCS into pandas on my local machine?',\n",
       "  'After installing gcsfs, what should I do to access my data?',\n",
       "  'Could you explain how to utilize a URI path to read a file in pandas?',\n",
       "  'Is there a specific command to read a CSV file from GCS using pandas?',\n",
       "  'What command would I use in pandas to read data from a file stored in Google Cloud Storage?'],\n",
       " '7fed7813': ['What kind of error may occur when using the spark.createDataFrame function on a pandas DataFrame?',\n",
       "  'What is the reason behind the TypeError related to the Affiliated_base_number when converting a pandas DataFrame to a PySpark DataFrame?',\n",
       "  'How can I ensure the Affiliated_base_number column is correctly interpreted when reading a CSV file into Spark?',\n",
       "  'What should I do if my pandas DataFrame contains null values in the Affiliated_base_number column?',\n",
       "  'How can I filter out rows with null values in the Affiliated_base_number column before converting my pandas DataFrame to PySpark?'],\n",
       " 'a0e7e259': ['What does the error MemoryManager indicate regarding heap memory usage?',\n",
       "  'What is the default memory allocation for the executor in this course?',\n",
       "  'Under what circumstances does the memory allocation error occur?',\n",
       "  'How can I resolve the memory allocation issue while using Spark?',\n",
       "  'What should I do to ensure that my changes to executor memory settings take effect?'],\n",
       " '4ca14331': ['What steps should I follow to change the working directory to the Spark directory on Windows?',\n",
       "  'How do I start the Spark Master in a standalone cluster setup?',\n",
       "  'What command is used to create a local Spark cluster on Windows?',\n",
       "  'How can I start up a cluster using the Spark Worker command?',\n",
       "  'What do I need to set up before running Spark on Windows OS?'],\n",
       " '6fdd09eb': ['Why are the environment variables in ~/.bashrc not recognized in Jupyter when using VS Code?',\n",
       "  'What steps do I need to take after modifying the ~/.bashrc file for changes to take effect?',\n",
       "  'Is there an alternative method to set environment variables instead of using ~/.bashrc?',\n",
       "  'What specific environment variables should I set for working with PySpark?',\n",
       "  \"How can I use PySpark in a Jupyter notebook if it's not being recognized in VS Code?\"],\n",
       " '64bfb2c3': ['What is the method to start port forwarding if I am not utilizing Visual Studio Code?',\n",
       "  'Can you explain the command structure for SSH port forwarding?',\n",
       "  \"What values should I substitute for 'user' and 'IP' in the SSH command?\",\n",
       "  'Is there a specific port number that needs to be used for local and remote in the port forwarding process?',\n",
       "  'How do I connect to the GCP VM using SSH for port forwarding?'],\n",
       " '33dd4516': ['Why does the output of wc -l differ when using the gzip file?',\n",
       "  'What should I do to get the correct line count from the compressed file?',\n",
       "  'Is it necessary to unzip the gzip file before running wc -l on it?',\n",
       "  'What command should I use to obtain the accurate line count after unzipping?',\n",
       "  'Can I run wc -l directly on the compressed file for the right results?'],\n",
       " '504b8570': ['What should I do if I encounter a `WARN Utils: Your hostname resolves to a loopback address` error when using spark-submit?',\n",
       "  \"What might cause the error message stating that 'Master must either be yarn or start with spark, mesos, k8s, or local'?\",\n",
       "  'How can I modify the spark-submit command to resolve issues with the master URL format?',\n",
       "  'What error will I see if I use the wrong syntax for the --master option in spark version 3.4.2?',\n",
       "  'What change is recommended to fix the failure regarding the unrecognized option for --master in spark version 3.4.2?'],\n",
       " '42e933c5': ['What should I do if I encounter a java.lang.UnsatisfiedLinkError related to Hadoop when writing to parquet?',\n",
       "  'How can I fix the error about NativeIO access0 in Hadoop on Windows?',\n",
       "  'What specific environment variable needs to be set to resolve the UnsatisfiedLinkError in Hadoop?',\n",
       "  'Can you tell me how to configure the PATH variable for Hadoop on a Windows machine?',\n",
       "  'Where can I find additional support or information regarding the Hadoop error I am facing?'],\n",
       " 'fe9240b0': ['What can I do if I encounter a Java.io.IOException related to running winutils.exe?',\n",
       "  'Which version of Hadoop should I switch to in order to resolve a compatibility issue with Windows?',\n",
       "  'Where can I find the files I need to replace in the local Hadoop bin folder?',\n",
       "  'What should I do if changing the Hadoop version to 3.0.1 does not resolve my issue?',\n",
       "  'Is there a source for more detailed information about the compatibility problem I am facing?'],\n",
       " 'c0a46e5d': [\"What should I do if I encounter the error that the required property 'project' is not currently set while submitting a Pyspark job with Dataproc?\",\n",
       "  'How can I specify my project ID when running a command to submit a Pyspark job using gcloud?',\n",
       "  'Where can I find my project ID to include it in the gcloud command for submitting a Dataproc job?',\n",
       "  'Can you provide an example of how to properly set the project flag when submitting a Pyspark job to Dataproc?',\n",
       "  'What is the command structure for submitting a Pyspark job to Dataproc that includes specifying the project ID?'],\n",
       " '943c2466': ['What steps must I follow to initiate a local Spark cluster on Windows 10 using CMD?',\n",
       "  'How do I execute the master command for Spark in Windows 10 from the command line?',\n",
       "  'What command do I need to run the worker in Spark after starting the master?',\n",
       "  'How can I create a new Jupyter notebook to connect to my Spark application?',\n",
       "  'Where can I find the Spark UI to monitor the status of the master, worker, and application?'],\n",
       " 'f41ef231': ['What steps should I take if I encounter a 401 Anonymous caller error when accessing Google Cloud Storage?',\n",
       "  'How do I resolve the permission issue related to storage.objects.list access in my Google Cloud Storage bucket?',\n",
       "  'What command do I need to execute to log into my Google Cloud account for accessing storage objects?',\n",
       "  'Can you explain how to set my project ID in the Google Cloud configuration using the terminal?',\n",
       "  'What is the correct command to upload a directory to a Google Cloud Storage Bucket after resolving authentication issues?'],\n",
       " '6b26d73c': ['What should I do if I encounter a py4j.protocol.Py4JJavaError when submitting a job in GCP?',\n",
       "  'Can you explain the process of changing the cluster versioning control in Dataproc?',\n",
       "  'Why did you choose Ubuntu 20.02 for the cluster instead of Debian-Hadoop-Spark?',\n",
       "  'Is it necessary to delete the existing cluster before creating a new one with a different version?',\n",
       "  'Did you find any documentation to support your choice of using Ubuntu for the cluster versioning?'],\n",
       " '830e2936': ['How can I reduce the number of partitions in my DataFrame to 6 instead of 8?',\n",
       "  'What method should I use to ensure that my DataFrame has exactly 6 partitions?',\n",
       "  'Can you explain how to effectively repartition a DataFrame with PySpark?',\n",
       "  'What are the steps to write a DataFrame with 6 partitions to parquet format?',\n",
       "  'Is it necessary to use both repartition and coalesce when setting the number of partitions?'],\n",
       " '02007b7c': [\"What should I do if my Jupyter Notebook or SparkUI won't load after trying to forward a port from VS Code?\",\n",
       "  'How can I properly forward a port using the command line instead of using VS Code?',\n",
       "  'What are the specific SSH commands I need to use to access localhost ports from a GCP VM?',\n",
       "  'Is there a way to ensure that all necessary ports are automatically forwarded when accessing a GCP VM?',\n",
       "  'What happens to my port connection if I log out of the SSH session on the GCP VM?'],\n",
       " '1ebb9a47': ['How can I verify the available Java SDK versions in my codespace?',\n",
       "  'What command should I use to install Java 11 in my environment?',\n",
       "  'What should I do if prompted regarding the default Java version during installation?',\n",
       "  \"After installing Java, how can I confirm that it's working correctly?\",\n",
       "  \"What steps should I follow if Java isn't functioning as expected after installation?\"],\n",
       " '80125745': [\"What does the error message regarding 'SSD_TOTAL_GB' quota mean when creating a dataproc cluster?\",\n",
       "  'What should I do if I encounter an insufficient quota error while working on GCP?',\n",
       "  'Why might there be insufficient resources available in a specific region for my cluster setup?',\n",
       "  'How can changing the boot-disk type in terraform help resolve a quota error?',\n",
       "  'Is it common for resources to become available again shortly after encountering a quota issue?'],\n",
       " 'f01df45b': ['What method does Pyspark use to calculate the difference between two TimestampType values?',\n",
       "  'How can I express the total duration between timestamps in hours using Pyspark?',\n",
       "  'Can you explain how to use the datediff SQL function for calculating time difference?',\n",
       "  'What parameters do I need to provide when using the datediff function in Pyspark?',\n",
       "  'How do I convert the days result from datediff into hours?'],\n",
       " '06014eec': ['What version combinations of PySpark and Pandas should I use to avoid the PicklingError?',\n",
       "  'What could be causing the IndexError related to tuple index out of range in my PySpark project?',\n",
       "  'What should I do if I continue to experience errors after using the recommended version combination?',\n",
       "  'Can you specify the exact versions of PySpark and Pandas that resolved the PicklingError?',\n",
       "  'Is there a specific module in PySpark where this PicklingError commonly occurs?'],\n",
       " '54653ca9': ['What does the error message Py4JJavaError indicate regarding a task failure in Spark?',\n",
       "  'How can I resolve the issue of the Python worker failing to connect back in PySpark?',\n",
       "  'What environment variables should I set before starting my SparkSession to avoid connection issues?',\n",
       "  'In which module do I find the instructions for addressing the PySpark connection error?',\n",
       "  'What action should I take to prevent the Spark job from being aborted due to stage failure?'],\n",
       " 'f95304db': [\"What error might occur if the Python versions in the worker and the driver don't match?\",\n",
       "  'How can I resolve a RuntimeError related to different Python versions in PySpark?',\n",
       "  'What environment variables should I check to ensure compatibility between the driver and worker in PySpark?',\n",
       "  'Can you provide a Python code snippet to set the correct Python environment variables for PySpark?',\n",
       "  'Where can I find pricing information related to Dataproc on GKE?'],\n",
       " '591df4e6': ['Is it possible to run Dataproc jobs without a virtual machine on GCP?',\n",
       "  'What is the first step to submit a Dataproc job from my local machine?',\n",
       "  'Which command should I use to submit a pyspark job to Dataproc from my computer?',\n",
       "  'Where can I find the installation guide for gsutil?',\n",
       "  'What are the parameters needed for the gcloud dataproc jobs submit command?'],\n",
       " '5cb7f597': ['What is the reason behind the error when executing spark.createDataFrame(df_pandas).show()?',\n",
       "  \"How can I resolve the AttributeError related to the 'DataFrame' object in PySpark?\",\n",
       "  'What are the machine type and memory specifications for setting up a Dataproc cluster?',\n",
       "  'I received an insufficient quota error while creating a cluster; what should I do?',\n",
       "  'What is the maximum memory allocation allowed for worker nodes in the Dataproc cluster configuration?'],\n",
       " 'c5de1f96': ['What are the steps to configure JAVA_HOME on an Apple Silicon Mac using Homebrew?',\n",
       "  'Is the provided setup instruction for setting JAVA_HOME applicable to Intel-based Macs only?',\n",
       "  'How can I verify if the JAVA_HOME path has been set correctly on my system?',\n",
       "  'Where should I add the JAVA_HOME environment variable for an Apple Silicon Mac?',\n",
       "  'What output should I expect when I run the command to check the Java installation path?'],\n",
       " '70ac8e80': ['What should I verify in the docker-compose.yaml file to successfully start the control-center service?',\n",
       "  'Are there any specific configurations that need to be checked for the control-center service to launch properly?',\n",
       "  'What steps can I take if I encounter issues starting the Kafka control center on my system?',\n",
       "  'How did the user resolve the problem of starting the Kafka control center if it was not appearing in the docker ps command?',\n",
       "  'What actions did the user take in Docker Desktop to troubleshoot the starting issue of the control center?'],\n",
       " 'f6551ffb': [\"What should I do if I encounter an error indicating that the module 'kafka' cannot be found when executing producer.py?\",\n",
       "  'Can you explain the steps I need to follow to set up a virtual environment for running the requirements.txt file?',\n",
       "  'What command do I need to run to activate the virtual environment after I have created it?',\n",
       "  'Is there a specific command to deactivate the virtual environment when I no longer need it?',\n",
       "  'Are there any differences in the activation process for the virtual environment on Windows compared to MacOS and Linux?'],\n",
       " '0ec021de': ['What should I do if I encounter an ImportError related to cimpl when trying to run Avro examples?',\n",
       "  'How can I check if my Python version is compatible with the Avro library?',\n",
       "  'What do I need to add to my code in order to load the required librdkafka DLL?',\n",
       "  'Is there a specific command I can use in PowerShell to resolve the DLL load error?',\n",
       "  'Where can I find more information about issues related to the cimpl import error from the Avro library?'],\n",
       " '1edd4630': [\"What should I do if I encounter a ModuleNotFoundError indicating that there is no 'avro' module?\",\n",
       "  \"Is there a specific command I need to run in order to resolve the 'avro' module issue related to confluent-kafka?\",\n",
       "  \"Why doesn't Conda include the 'avro' module when I install confluent-kafka using pip?\",\n",
       "  'Where can I find more resources about issues related to Anaconda and confluent-kafka?',\n",
       "  'Are there any online forums or issues pages that provide assistance for resolving confluent-kafka problems?'],\n",
       " '4664ae28': ['What should I do if I encounter an error when executing the command python3 stream.py worker?',\n",
       "  'Can you explain the main benefits of using Redpanda as a streaming data platform?',\n",
       "  'What underlying algorithm is Redpanda built on, and how does it relate to its performance?',\n",
       "  'How does Redpanda maintain compatibility with Kafka while simplifying its use?',\n",
       "  \"What architecture does Redpanda use, and how is it similar to Kafka's architecture?\"],\n",
       " '676e1b76': ['What might cause the Negsignal:SIGKILL error when converting dta files to parquet format?',\n",
       "  'How does the size of the dta file relate to the memory requirements of the Docker container?',\n",
       "  'What solution was implemented to handle the error with the memory exhaustion?',\n",
       "  'How can I effectively process large dta files without encountering memory issues?',\n",
       "  'What tool can I use to load files in chunks before creating parquet files?'],\n",
       " 'a3c84279': ['Where can I find the rides.csv file that is missing in the Python resources?',\n",
       "  \"Is there an alternative source for the rides.csv file in case I can't find it?\",\n",
       "  'Which specific Java example contains the necessary rides.csv file I need?',\n",
       "  'Can I use the rides.csv file from the Java resources for my Python work?',\n",
       "  'What should I do if the rides.csv file is not available in the Python section?'],\n",
       " '119c917d': ['What can I do if the audio of the Kafka Python videos is difficult to hear and follow?',\n",
       "  'Is there a way to enhance the audio quality of the videos on streaming with Kafka?',\n",
       "  'Where can I access the explanation for the rides.csv data used in the producer.py Python program?',\n",
       "  'Can the low audio issue in the Kafka Python videos be fixed with any specific software?',\n",
       "  'Are there any alternatives to improve my understanding of the rides.csv data structure?'],\n",
       " 'f1284c1f': ['What does the error NoBrokersAvailable in Kafka indicate?',\n",
       "  'How can I find out if my Kafka broker is functioning properly?',\n",
       "  'What command should I run to check the status of my Docker containers?',\n",
       "  \"How do I start the Kafka broker if it's not running?\",\n",
       "  'Where can I find the Docker Compose file to launch the Kafka instances?'],\n",
       " '49a7db28': ['What is the primary scaling option we should focus on for Kafka homework Q3?',\n",
       "  'How did Ankush suggest we think about scaling in terms of message consumption?',\n",
       "  'What concept does horizontal scaling relate to in the context of Kafka?',\n",
       "  'Which scaling methods are considered in the Kafka homework Q3 options?',\n",
       "  'Can you clarify what is meant by consuming messages via horizontal scaling?'],\n",
       " '196cb0f2': ['What should I do if I encounter a pull access denied error for spark-3.3.1 while using Docker Compose?',\n",
       "  'What indicates that I have not built my Spark and Jupyter images when running Docker?',\n",
       "  'Where can I find the images for Spark and Jupyter that are mentioned in the error?',\n",
       "  'How can I resolve the access issue when trying to pull the Spark image from Docker Hub?',\n",
       "  'What command should I execute to build the necessary images in the Spark folder before using Docker Compose?'],\n",
       " '1e50eab7': [\"What should I do if I encounter a 'Permission denied' error when running './build.sh' in the Python Kafka module?\",\n",
       "  \"How can I fix the permission issue with the 'build.sh' script?\",\n",
       "  \"What command do I need to change file permissions in the same directory as 'build.sh'?\",\n",
       "  \"In which directory should I run the command to resolve permissions for 'build.sh'?\",\n",
       "  \"How do I enable execution permission for the 'build.sh' file?\"],\n",
       " 'a7a6d0d7': ['What should I do if I encounter a KafkaTimeoutError while using the producer script in Python?',\n",
       "  'Is there a common solution for fixing the metadata update issue in Kafka?',\n",
       "  'How can I resolve the error related to updating metadata that occurs after 60 seconds?',\n",
       "  'What commands do I need to run to restart the services in my Kafka setup?',\n",
       "  'Are there any troubleshooting steps recommended for resolving Kafka connectivity issues?'],\n",
       " '0996213a': ['What error might I encounter when running the streaming.py script using Spark?',\n",
       "  'What information should I verify to resolve the application being killed due to unresponsive masters?',\n",
       "  'What specific version of PySpark should I downgrade to if I encounter connection issues?',\n",
       "  'How can I check the Spark version that is installed on my local machine?',\n",
       "  'What should I do if my Spark version does not match the version specified in the build.sh file?'],\n",
       " '311bf368': ['What steps should I take to troubleshoot a failed connection to the Spark master?',\n",
       "  'How can I view the logs for the Spark master container?',\n",
       "  \"What command do I need to use to enter the Spark master container's bash?\",\n",
       "  'Where can I find the error message related to the Spark master connection issue?',\n",
       "  'Is there a way to search for solutions based on the error message in the logs?'],\n",
       " 'c1551650': ['What action should I take if I encounter a Py4JJavaError while running streaming.py with Python Kafka?',\n",
       "  'How can I verify the version of Java that is currently installed on my system?',\n",
       "  'What command can I use to check all installed Java versions on my machine?',\n",
       "  \"What steps should I follow if I have Java 11 installed but it's not set as the default version?\",\n",
       "  'Is it necessary to have Java version 11 or 8 to avoid errors while using Spark with Kafka?'],\n",
       " 'f9b673cf': ['What should I do if my Java Kafka project shows errors indicating that a package does not exist after running a Gradle build?',\n",
       "  \"How can I ensure that all dependencies are included in my Java Kafka project's JAR file when using Gradle?\",\n",
       "  'Can you explain the steps I need to take to resolve the issues with the <project_name>-1.0-SNAPSHOT.jar in my Kafka setup?',\n",
       "  'What modifications do I need to apply in my build.gradle file to avoid missing package errors?',\n",
       "  'What command should I use to create a correctly packaged JAR file for my Java Kafka project after updating the build configuration?'],\n",
       " '5479dce2': ['What commands should I use to install the required dependencies for the Python Kafka producer example in Module 6?',\n",
       "  'Can I install the Faust library for Module 6 despite the mentioned dependency issues?',\n",
       "  'Is the Faust repository still actively maintained, and where can I find more information about it?',\n",
       "  'If I am not familiar with Java, what resources should I use to follow the Python portion of Module 6?',\n",
       "  'Why is it recommended to watch the Java videos for understanding streaming concepts before jumping to the Python videos?'],\n",
       " '02cf2317': ['How do I execute the Kafka producer and consumer from the terminal?',\n",
       "  'What command should I use to run kstreams in my project directory?',\n",
       "  'Can you tell me how to initiate the JsonProducer using Java in the terminal?',\n",
       "  'What is the proper way to run a Java application with Kafka components from the command line?',\n",
       "  'How can I test my Kafka setup by running a producer in the terminal?'],\n",
       " '947c07a6': [\"What should I check if my Java Kafka producer isn't sending any messages?\",\n",
       "  'Why do I see zero results when I run my JsonConsumer.java script?',\n",
       "  'What could cause a SaslAuthenticationException when using JsonProducer.java?',\n",
       "  'Where can I find the configuration for the server URL in my Kafka scripts?',\n",
       "  'How can I ensure the correct cluster key and secrets are used in my Kafka project?'],\n",
       " 'bea22953': [\"What should I do if I can't see the triangle icon next to my tests in VS Code?\",\n",
       "  'How can I clean the workspace in VS Code to resolve issues with test visibility?',\n",
       "  'Is there a specific order of steps I need to follow to fix the test icon visibility in VS Code?',\n",
       "  'Can I add classes and packages directly in the JAVA PROJECTS section of VS Code?',\n",
       "  'What does the triangle icon next to each test in VS Code signify?'],\n",
       " 'a1603359': ['How do I locate the schema registry URL in Confluent Cloud?',\n",
       "  'What steps should I follow to access the schema registry URL?',\n",
       "  'Where can I find the Endpoint for the Stream Governance API?',\n",
       "  'What do I need to do to create credentials for the schema registry?',\n",
       "  'What is the navigation path to find the schema registry URL in my environment?'],\n",
       " 'a85a6a91': ['What command can I use to verify my local Spark version?',\n",
       "  'How can I ensure that my local Spark and container Spark versions are compatible?',\n",
       "  \"Where should I look to confirm the Spark version in the Python project's build.sh file?\",\n",
       "  'What should I check regarding pyspark installation to maintain version compatibility?',\n",
       "  'Is there a specific command for checking the installed version of Spark?'],\n",
       " '343864f5': [\"What should I do if I encounter the error 'ModuleNotFoundError: No module named 'kafka.vendor.six.moves''?\",\n",
       "  'Is there an alternative to the original kafka-python library that I can use?',\n",
       "  'What resource can I refer to for issues related to the kafka-python module?',\n",
       "  'Which command should I run to install the suggested alternative for kafka-python?',\n",
       "  'Are there any known issues with the current releases of kafka-python?'],\n",
       " '6cb3b4a9': ['What is the process for evaluating my capstone project in this course?',\n",
       "  'How many peers will review my submitted project, and will I be reviewing others?',\n",
       "  'What happens if I do not adhere to the peer review requirements for the capstone project?',\n",
       "  'How will the final grade for my project be determined based on peer evaluations?',\n",
       "  \"Are there specific guidelines I need to follow when reviewing my fellow students' projects?\"],\n",
       " '5959ea3c': ['Is there more than one project to submit for this course?',\n",
       "  'What should I do if I miss the first attempt at the project?',\n",
       "  'Can I submit a project if I have other commitments during the first attempt?',\n",
       "  'How many times can I attempt the project for the course?',\n",
       "  'What happens if I fail the first attempt at the project?'],\n",
       " '202af70b': ['Where can I find a collection of large datasets for my project?',\n",
       "  'Is there a resource that lists nice datasets for data engineering?',\n",
       "  'Can someone share a link to datasets that are suitable for analysis?',\n",
       "  'What is the best source for finding extensive datasets?',\n",
       "  'Does the course provide any references for large datasets?'],\n",
       " 'f2705fe7': ['What is the process for setting up Python as a startup script?',\n",
       "  'How can I configure the environment variable for Python to run at start up?',\n",
       "  'Is there a specific user account requirement for running Python on startup?',\n",
       "  'What steps are needed to change the Python environment variable for my user?',\n",
       "  'Can you explain how to make Python run when my computer starts?'],\n",
       " '74f412c4': ['What is the first step to begin reading from multiple topics in Spark Streaming?',\n",
       "  'How do I initialize a Spark Session for processing streaming data?',\n",
       "  'What method is used to reset terminated streams before starting new queries?',\n",
       "  'Can you explain how to start multiple queries in Spark Streaming?',\n",
       "  'What is the difference between awaitAnyTermination and awaitTermination when managing streams?'],\n",
       " '5214eb93': ['What is the process to transfer transformed data from Databricks to Azure SQL Database?',\n",
       "  'Is it necessary to use Azure Blob Storage when moving data from Databricks?',\n",
       "  'Can transformed data be sent directly to Azure SQL Database from Databricks?',\n",
       "  'What is the recommended method for moving data after transformation?',\n",
       "  'Are there any steps involved in transferring data from Azure Blob Storage to Azure SQL DB?'],\n",
       " '3cfd16a7': ['What are the requirements for orchestrating dbt with Airflow in the trial dbt account?',\n",
       "  'How do I manually add a job when using Airflow to run dbt tasks?',\n",
       "  'What information do I need to provide for Airflow to execute a dbt job successfully?',\n",
       "  'Where can I find a detailed explanation for integrating dbt with Airflow?',\n",
       "  'Is there a source code example available to help me understand how to set up dbt with Airflow?'],\n",
       " 'a7cecdf9': ['What are the necessary roles for the service account to orchestrate DataProc with Airflow?',\n",
       "  'Can you provide links for the documentation on orchestrating DataProc with Airflow?',\n",
       "  'Which operators should I use when working with DataProc in Airflow?',\n",
       "  'Is there anything specific I need to include when using DataprocSubmitPySparkJobOperator?',\n",
       "  'Why do I need to add the BigQuery Connector when using DataProc?'],\n",
       " '2aad1011': ['How can I initiate a dbt job within my Mage pipeline?',\n",
       "  'Where can I locate the dbt cloud API key necessary for integration with Mage?',\n",
       "  'What environment variable should I use to store my dbt API trigger information?',\n",
       "  'Can you provide an example of how to set up the HTTP request in a custom Mage Python block?',\n",
       "  'What content should be included in the body of the POST request to trigger the dbt job?'],\n",
       " 'cb478996': ['What is the link to the relevant Slack thread for project evaluation regarding reproducibility?',\n",
       "  'How does the evaluation process handle situations where a peer reviewer might struggle to follow the documented steps?',\n",
       "  \"What should I do if I'm unable to re-run the entire project as part of the evaluation criterion?\",\n",
       "  'Can you explain what Alex suggests if a reviewer is checking the code instead of re-running it?',\n",
       "  'Is it adequate to merely look for errors and missing instructions without executing the code for reproducibility assessment?'],\n",
       " 'b4ef8ca7': ['What is the purpose of the Key Vault in Azure?',\n",
       "  'How can I securely store passwords in Azure?',\n",
       "  'In what scenarios would I use Key Vault for SQL database credentials?',\n",
       "  'Can Key Vault store secrets from multiple tech stacks?',\n",
       "  'Why should I avoid exposing passwords in my applications?'],\n",
       " '8e74f943': [\"What should I do if I encounter a 'ModuleNotFoundError: No module named 'py4j'' while trying to import pyspark in Spark Docker?\",\n",
       "  'How can I check the version of py4j when using Docker for my Spark project?',\n",
       "  'Is there a command I can use in Docker to find the py4j version for my PySpark setup?',\n",
       "  'What Docker command will help me list the contents of the Spark Python library directory to troubleshoot py4j issues?',\n",
       "  'Could you guide me on how to access the shell in the Docker container to check for py4j?'],\n",
       " 'a73ed357': ['What should I do if psycopg2 is giving me errors related to incompatible architecture?',\n",
       "  'Can I use both conda and pip at the same time for managing my virtual environment?',\n",
       "  \"How can I install psycopg2 if I'm using conda?\",\n",
       "  'Are there specific channels I need to use when installing psycopg2 with conda?',\n",
       "  'What command should I run to install psycopg2 using pip?'],\n",
       " 'd5b6ef5d': ['What is the recommended approach for setting up dbt locally using Docker and Postgres?',\n",
       "  'Can you explain how to create the profiles.yml file for dbt?',\n",
       "  'What steps should I follow to clone the dbt starter project?',\n",
       "  'What configuration line do I need to include in the dbt_project.yml file?',\n",
       "  'How can I troubleshoot issues when running the dbt Docker command?'],\n",
       " 'b406d90e': ['What configuration is needed for Pyspark to integrate with BigQuery?',\n",
       "  'Can you provide an example of initializing a SparkSession for BigQuery?',\n",
       "  'What is the required package for connecting Pyspark to BigQuery?',\n",
       "  'In which section of the Pyspark code should I add the BigQuery configuration?',\n",
       "  'Is there a specific version of the BigQuery connector to use with Spark 3.5?'],\n",
       " '0002ab8b': ['What package do I need to install to run a dbt-core project in Airflow on Google Cloud Composer?',\n",
       "  'Where should I place my dbt-core project in relation to the Google Cloud Composer directory structure?',\n",
       "  'How do I configure the profiles.yml file for authentication with a service account key?',\n",
       "  'What class should I use to create a new DAG for the dbt-core project?',\n",
       "  'How can I ensure my dbt lineage graph is organized as tasks inside a task group?'],\n",
       " '138b55c7': ['How can I change the display name that appears on the leaderboard?',\n",
       "  'What name should I use for the certificate upon course completion?',\n",
       "  \"What does the 'Display on Leaderboard' option allow me to do?\",\n",
       "  'Can I use a nickname instead of my real name for the leaderboard display?',\n",
       "  'Which data sources are supported for creating external tables in BigQuery?'],\n",
       " '154d7705': ['What package do I need to install to execute the code successfully?',\n",
       "  'Is there a specific command I should run for the installation of dependencies?',\n",
       "  'Do I need to install duckdb separately, and if so, when should I do this?',\n",
       "  'Can you clarify the importance of the dlt[duckdb] package for running the code?',\n",
       "  'What should I do if I am running the code locally regarding the duckdb installation?'],\n",
       " 'f96517d9': ['What additional packages are necessary for running the starter Jupyter Notebook?',\n",
       "  \"What should I do if I'm using a new Codespace?\",\n",
       "  \"How can I set up my local machine for the course's Jupyter Notebook?\",\n",
       "  'What command do I need to run to install Jupyter in a new Virtual Environment?',\n",
       "  'Is there any package I need to install before using the Jupyter Notebook provided by the instructor?'],\n",
       " '773587dd': ['What steps should I take to utilize the DuckDB In-Memory database alongside dlt?',\n",
       "  'Is it possible to transition from in-memory to in-file storage while using dlt?',\n",
       "  'What alternatives do I have for storing data with dlt instead of using DuckDB in-memory?',\n",
       "  'How do I configure in-file storage when working with dlt?',\n",
       "  'Can you explain the process for switching to an in-file storage option within dlt?'],\n",
       " '73aff710': ['What should I expect to find in terms of records after completing Exercise 3 in the homework?',\n",
       "  'How can I accurately calculate the total sum of ages for the individuals loaded in the dlt Exercise 3?',\n",
       "  'What should I do if the calculated sum of ages exceeds the available choices?',\n",
       "  'What is the correct way to specify a file path so that the dlt files save to my desired location?',\n",
       "  'How do I check the list of Parquet files generated in my specified folder after running the pipeline?'],\n",
       " '0728ca67': [\"What should I do if I encounter a 'no such file or directory' error for command.sh?\",\n",
       "  'How can I verify if the command.sh file is present in my project?',\n",
       "  'What command can I use to check the contents of the repository?',\n",
       "  'How can I confirm that I cloned the correct repository for the workshop?',\n",
       "  'Where can I find the URL for the correct repository to clone?'],\n",
       " '49a51e24': [\"What should I do if I encounter a 'psql - command not found' error while trying to use PostgreSQL?\",\n",
       "  \"Why do I only have 'pgcli' and not 'psql' when running PostgreSQL?\",\n",
       "  \"What is a suitable alternative to 'psql' for executing SQL scripts if I'm using a container setup?\",\n",
       "  \"How can I install 'usql' on my operating system?\",\n",
       "  \"What is the procedure to run the taxi_trips.sql script using 'usql'?\"],\n",
       " 'f0d552a7': [\"What should I do if I see an error message indicating that 'docker-compose' is not found while trying to set up Workshop 2?\",\n",
       "  'How can I resolve the issue if I have docker compose installed but it is not recognized during the setup?',\n",
       "  'Is there a specific way to edit the command.sh file to fix the docker-compose error?',\n",
       "  \"What change should I make to the command.sh file when I receive 'docker-compose not found' during the setup process?\",\n",
       "  'Can you provide an example of how to modify the command for starting the cluster correctly?'],\n",
       " '9c750080': [\"What does the error message regarding 'Invalid top-level property x-image' indicate in my setup?\",\n",
       "  'What are the acceptable top-level sections in a Docker Compose file according to the FAQ?',\n",
       "  \"How can I resolve the issue if I'm seeing the 'Invalid top-level property x-image' error?\",\n",
       "  'What should I do if I encounter compatibility issues with docker-compose on Ubuntu machines?',\n",
       "  'Is there a resource available for understanding different versions of the Docker Compose file format?'],\n",
       " '6f4998e6': ['Is it normal to see records being ingested in batches of 10 during Workshop 2?',\n",
       "  'Why is it important to observe changes in real-time while working on queries?',\n",
       "  'How does the script modify the date timestamp when ingesting records?',\n",
       "  'What should I do while the stream-kafka script is running in the background?',\n",
       "  'Is it possible to increase the number of records being ingested at once, and if so, how?'],\n",
       " '97170587': ['Do I need to install Kafka for the RisingWave workshop?',\n",
       "  'Is it mandatory to have Kafka installed for Workshop 2?',\n",
       "  'Will the RisingWave workshop require a Kafka setup?',\n",
       "  'Is the installation of Kafka a prerequisite for this workshop?',\n",
       "  'Should I worry about Kafka installation before attending RisingWave?'],\n",
       " '4def6541': ['What is the minimum amount of free disk space required for the setup?',\n",
       "  'How much total disk space should I have available for this workshop?',\n",
       "  'Is 7GB of free space sufficient for running all containers?',\n",
       "  'Do I need additional disk space beyond what is required for the containers?',\n",
       "  'How much free space is needed for psql to run and ingest the data?'],\n",
       " '66e117dd': ['What should I do if I encounter issues with Psycopg2 while running the stream-kafka script?',\n",
       "  'Is there a specific version of Psycopg2 I need to use for this course?',\n",
       "  'Do I need to perform any steps before launching psql in a new terminal session?',\n",
       "  'How do I modify the requirements.txt file for this workshop?',\n",
       "  'What command must I run in each terminal session before executing psql?'],\n",
       " '94fd2476': ['What steps should I follow to resolve the psycopg2 wheel installation issue in a Conda environment?',\n",
       "  'Why is it necessary to install GCC when I encounter an error related to psycopg2 and pyproject.toml?',\n",
       "  'Can you explain the role of GCC in the installation of Python packages like psycopg2?',\n",
       "  'How does the Conda base installation affect the availability of GCC for virtual environments?',\n",
       "  'What command should I execute to activate my RisingWave virtual environment after installing GCC?'],\n",
       " '70d83d78': ['What terminal should I use to run the seed-kafka command on Windows?',\n",
       "  'How do I activate the Python virtual environment using Git Bash?',\n",
       "  'What change should I make to the seed_kafka.py file to resolve the issue?',\n",
       "  'How can I connect to the RisingWave cluster using Powershell?',\n",
       "  'What is the equivalent command for source commands.sh when using Powershell?'],\n",
       " 'accb7285': ['What should I do if the stream-kafka script hangs indefinitely due to a connection issue?',\n",
       "  'How can I check if the message_queue container is having problems in Docker?',\n",
       "  'What adjustments do I need to make to the memory allocation in the docker-compose file if I encounter an insufficient memory error?',\n",
       "  'What error message might indicate that the psql command is not working as expected when running the trip_data.sql file?',\n",
       "  'Why do I need to run the source commands.sh file in each terminal after starting services with default values?'],\n",
       " 'cbca4495': ['Is there a required number of records to process for the homework questions?',\n",
       "  'What method should I use to obtain a static set of results?',\n",
       "  'Can I use stream-kafka for homework or should I stick to seed-kafka?',\n",
       "  'What results can I expect when using seed-kafka for homework?',\n",
       "  'How do I ensure I get a static set of answers for the homework questions?'],\n",
       " '78fce6ad': ['What should I do if I encounter a warning about the materialized view not guaranteeing order?',\n",
       "  'How can I ensure consistent results when using a materialized view in my queries?',\n",
       "  'What steps must I follow if the homework answers do not align with the given options?',\n",
       "  'Which command should I use to clean up my environment before running the homework?',\n",
       "  'Is there a specific volume I should use instead of stream-kafka for the homework task?'],\n",
       " '68842c02': ['What are the specific steps I need to follow to install PostgreSQL on a Linux-like operating system for Workshop 2?',\n",
       "  'Can you provide the commands necessary to set up PostgreSQL if I am following the views from Noel (2024)?',\n",
       "  'Is there a way to check if the PostgreSQL service is running after I have installed it?',\n",
       "  'What should I do if the PostgreSQL service is down after installation?',\n",
       "  'Are there any additional packages required along with PostgreSQL during the installation process?'],\n",
       " '71b1984b': [\"What should I do if I can't open the dashboard because xdg-open isn't launching a browser?\",\n",
       "  'Is there an alternative to using w3m for opening the dashboard?',\n",
       "  \"How can I access the index.html file if my browser isn't working?\",\n",
       "  'Is there a specific method I should follow to open index.html on WSL?',\n",
       "  'Can I use a different browser to view the dashboard, and how?'],\n",
       " 'd452b490': ['What kind of error might occur when running a Python script with a Windows-created shebang line in a Unix-like environment?',\n",
       "  'Can you explain the significance of the \\r character in the context of executing Python scripts?',\n",
       "  'What command should I use to locate the Python 3 interpreter in my environment?',\n",
       "  'How can I modify the shebang line of a Python script to ensure it points to the correct interpreter?',\n",
       "  \"What utility can I use to convert a script's line endings from Windows-style to Unix-style?\"],\n",
       " '707cae8f': ['What is the concept of windowing in streaming SQL?',\n",
       "  'Can you explain how to set boundaries for data processing?',\n",
       "  'How does windowing help with analyzing streaming data?',\n",
       "  'What kind of intervals can be defined for windowing?',\n",
       "  'In what scenarios would windowing be useful in SQL?'],\n",
       " 'ffbf3311': [\"What steps should I take to resolve the 'ModuleNotFoundError: No module named 'kafka.vendor.six.moves'' error when attempting to import KafkaProducer in Jupyter Notebook for Module 6 Homework?\",\n",
       "  'How can I ensure my Mage pipeline runs without failure when some blocks succeed individually?',\n",
       "  'What is the correct way to set the path for profiles.yml in order to avoid issues when executing my dbt pipeline?',\n",
       "  'Can you explain the process of creating triggers in Mage pipelines using the command line interface?',\n",
       "  'Is it possible to perform data partitioning and clustering directly within a dbt model, or do I need to manage this manually in BigQuery?'],\n",
       " '3916f4a9': ['What are the commands to create a Docker image from a base image and how do I list them?',\n",
       "  'How can I attach to a stopped container using the command line?',\n",
       "  'What is the command to create an image from a Dockerfile?',\n",
       "  'How can I delete all containers forcefully using the command line?',\n",
       "  'What steps do I need to follow to install the GCP Cloud SDK on a Docker machine?'],\n",
       " '0227b872': ['What is the process to enroll in the Machine Learning course?',\n",
       "  'Where can I find the frequently asked questions for the course?',\n",
       "  'Is there a specific document for technical inquiries related to the course?',\n",
       "  \"Can you direct me to the course's GitHub repository?\",\n",
       "  'How was the FAQ document structured in the data engineering course?'],\n",
       " '39fda9f0': ['Will the course be conducted live or is it pre-recorded?',\n",
       "  'When can I start watching the course content?',\n",
       "  'Are there any live sessions for asking questions?',\n",
       "  'How can I access the recorded office hours?',\n",
       "  'Where can I find the course videos and office hours on YouTube?'],\n",
       " '5170565b': [\"What happens if I can't attend a session?\",\n",
       "  'Will I have access to the missed content?',\n",
       "  'How can I address my questions if I miss a class?',\n",
       "  'Is there a way to interact during the live stream?',\n",
       "  'Can I use Slack for asking questions after missing a session?'],\n",
       " 'ecca790c': ['What is the main focus of the course in terms of content covered?',\n",
       "  'How in-depth will the theoretical concepts be discussed during the course?',\n",
       "  'Will we focus on practical skills rather than theoretical derivations?',\n",
       "  \"Is there a specific example of a theory we won't delve into deeply?\",\n",
       "  'How will the course help us understand results from practical applications?'],\n",
       " 'c25b3de4': ['Is a math background necessary to enroll in the course?',\n",
       "  'What specific math topics will we learn during the course?',\n",
       "  'Will there be a lot of formulas involved in the course content?',\n",
       "  'Can you recommend any resources to help with linear algebra?',\n",
       "  'How can I get support if I struggle with the course material?'],\n",
       " '6ba259b1': [\"What should I do if I filled out the form but haven't received any confirmation email yet?\",\n",
       "  'Is it expected to not receive a confirmation email after submitting the form?',\n",
       "  \"Where can I check for the confirmation email if it's not in my inbox?\",\n",
       "  'How can I stay updated on course-related information if I unsubscribed from the newsletter?',\n",
       "  'Are there alternative ways to receive course updates besides email?'],\n",
       " '67e2fd13': ['What is the expected duration of the course?',\n",
       "  'Can the course length vary for different students?',\n",
       "  'Is it possible to extend the course duration?',\n",
       "  'How can I extend my time in the course?',\n",
       "  'Will additional projects affect the overall course length?'],\n",
       " 'a6897e8c': ['What is the estimated weekly time commitment for completing this course?',\n",
       "  'How many hours per week should I expect to dedicate to this course?',\n",
       "  'Is there specific research on the time needed for different modules in the course?',\n",
       "  'Who conducted the analysis of time spent by previous students on the course?',\n",
       "  'Where can I find detailed information about the time requirements for this course?'],\n",
       " '2eba08e3': ['Do I need to complete all projects to receive a certificate?',\n",
       "  'What are the requirements for obtaining a certificate in this course?',\n",
       "  'Is there a specific deadline for project completion and peer review?',\n",
       "  \"Can I see examples of the certificate I'll receive upon completion?\",\n",
       "  'Do I need to review any projects to be eligible for the certificate?'],\n",
       " '1d644223': [\"Can I still receive a certificate if I didn't submit the midterm project?\",\n",
       "  'What happens to my certificate if I miss the midterm project?',\n",
       "  'Is it possible to earn a certificate despite not attending the midterm project?',\n",
       "  'Will missing the midterm project affect my eligibility for a certificate?',\n",
       "  'Are there any conditions related to the midterm project for obtaining a certificate?'],\n",
       " '14890cd2': ['What specific Python skills do I need to possess before taking this course?',\n",
       "  'Is there a recommended resource for learning Python basics to prepare for the course?',\n",
       "  'Can you explain why understanding Jupyter notebooks is important for this course?',\n",
       "  'What types of operations related to data analysis should I be familiar with before starting?',\n",
       "  'If I find the recommended article challenging, what should I do next?'],\n",
       " 'a4fad482': ['What are the hardware specifications needed for the Machine Learning part of the course?',\n",
       "  'Is a laptop sufficient for the Deep Learning section, or are additional resources required?',\n",
       "  'Can you clarify if we need to rely on cloud services for the Deep Learning part?',\n",
       "  'Which cloud service is recommended for the Deep Learning section of the course?',\n",
       "  'Is a stable internet connection essential for participating in this course?'],\n",
       " '34b7fd35': ['What steps should I follow to enable GPU support for TensorFlow on Ubuntu?',\n",
       "  'Can you recommend a resource for setting up TensorFlow with GPU on an Ubuntu system?',\n",
       "  'Is there a specific article that details the installation of TensorFlow with GPU on Ubuntu?',\n",
       "  'Where can I find detailed instructions for configuring TensorFlow to use the GPU on Ubuntu?',\n",
       "  'What is the best tutorial to follow for getting TensorFlow to run with GPU capabilities on Ubuntu?'],\n",
       " '4930aa19': [\"How can I find the channel for our course in Slack as I'm unfamiliar with the platform?\",\n",
       "  'What steps do I need to follow to join a specific channel in Slack?',\n",
       "  'Is it necessary to provide a GitHub link for my homework submissions?',\n",
       "  \"What is the process for joining a channel if I can't see the 'All channels' option on Slack?\",\n",
       "  'Where do I go to find public channels in my Slack workspace?'],\n",
       " 'ee58a693': ['Can I still enroll in the course even though it has already begun?',\n",
       "  'What is the impact on homework submissions if I join after the course has started?',\n",
       "  'What are the requirements for obtaining a certificate in this course?',\n",
       "  'If I join late, how many projects do I need to complete for certification?',\n",
       "  'Is it possible to receive a certificate if I start the course towards the end of November?'],\n",
       " '636f55d5': ['When will the next cohort start for the course?',\n",
       "  'Is the course available to take at my own pace?',\n",
       "  'What month will the next iteration of the course occur?',\n",
       "  'Are there future iterations planned beyond September 2024?',\n",
       "  'Can I proceed with the course materials anytime I choose?'],\n",
       " 'c839b764': ['Is it allowed to turn in homework past the deadline?',\n",
       "  'What happens if I miss the homework submission deadline?',\n",
       "  'Will I be penalized for submitting homework late?',\n",
       "  'Is homework submission essential for completing the course?',\n",
       "  \"Can I still pass the course if I don't submit my homework?\"],\n",
       " '0a278fb2': [\"What steps should I take now that I've enrolled in the course?\",\n",
       "  'Where can I find the course materials for my studies?',\n",
       "  'Is there a specific location on the course page where I should begin?',\n",
       "  'How can I access videos from both my current year and previous cohorts?',\n",
       "  'What is the easiest way to view the course syllabus online?'],\n",
       " '8de4fefd': ['What is the deadline information for this course?',\n",
       "  'Where can I find the deadlines for the 2023 cohort?',\n",
       "  'Are the deadlines the same for every cohort?',\n",
       "  'How do I access the deadlines for my course?',\n",
       "  'Can I find deadlines specific to the 2023 cohort online?'],\n",
       " '94e86808': ['How does the 2023 version of the course differ from 2022?',\n",
       "  \"Was there any special module included in the last year's course?\",\n",
       "  'Are the course modules identical between 2022 and 2023?',\n",
       "  \"What changes were made to the homework for this year's course?\",\n",
       "  'Is there a significant difference in content from the previous iteration?'],\n",
       " 'e7ba6b8a': ['Will there be new videos for this course since the current ones are from 2021?',\n",
       "  'Are the existing course videos still relevant for learning this material?',\n",
       "  'If I missed the last iteration, can I still benefit from the current videos?',\n",
       "  'Should I be using Python 3.8 or is there a preferred version for the course?',\n",
       "  'What version of Python do you recommend using while watching the course videos?'],\n",
       " 'f7bc2f65': ['What should I include in my social media posts to get credit for learning in public?',\n",
       "  'How should I format multiple links when submitting my homework?',\n",
       "  'Is there a limit to the number of points I can earn for posting my learning online?',\n",
       "  'Can I use the same link across different social media platforms for the extra score?',\n",
       "  'What happens to the points I earn for midterms or capstone projects compared to regular homework submissions?'],\n",
       " 'ae52a907': ['How can I share my notes for the course with others?',\n",
       "  'What is the process for adding my personal notes to the Community Notes section?',\n",
       "  'Is it possible to create my own repository for course materials?',\n",
       "  'What are the steps to link my notes to the course repository?',\n",
       "  'How do I submit a pull request after adding my notes?'],\n",
       " 'dab5a24a': ['What are the links to access the leaderboard for the years 2023 and 2022?',\n",
       "  'How can I compute the hash of my email using Python?',\n",
       "  'What should I do if I want to generate a SHA-1 hash without writing code?',\n",
       "  'Can you provide an example of how to call the Python function to compute the hash of my email?',\n",
       "  'Is it necessary to use quotes when entering my email in the compute_hash function?'],\n",
       " '49f9bda9': [\"What should I do if I see that 'wget' is not recognized as an internal or external command?\",\n",
       "  'How can I install wget on a Windows system?',\n",
       "  'Is there a way to download files using Python without wget, and what would be the method?',\n",
       "  'Can I read a CSV file directly from a URL using pandas, and if so, how?',\n",
       "  'What should I do if I need to bypass HTTPS checks when downloading a file in Python?'],\n",
       " 'd44de7d1': ['How can I download a CSV file directly within my notebook?',\n",
       "  'What is the purpose of using the exclamation mark in my notebook commands?',\n",
       "  'Can you provide an example of moving a downloaded file to a specific directory?',\n",
       "  'Which shell commands can I use inside my notebooks?',\n",
       "  'How do I create a new directory for storing my data files?'],\n",
       " '314ebe32': ['What steps should I follow to set up WSL on my Windows 11 device?',\n",
       "  'How can I connect my WSL environment to VS Code after installation?',\n",
       "  'Is there a specific extension I need to download for VS Code to work with WSL?',\n",
       "  'Can I access my WSL instance like a virtual machine through VS Code?',\n",
       "  'Where can I find resources or instructions for setting up a WSL development environment?'],\n",
       " '98cff602': ['What should I do if I encounter an error message while trying to push my code to Github for the first time?',\n",
       "  \"Can you explain how to resolve the 'src refspec master does not match any' error when using Git?\",\n",
       "  'Is there a way to upload my homework files to Github without using command line commands?',\n",
       "  'If I write my code in Google Colab, how can I share it directly on my Github account?',\n",
       "  'Where can I find a tutorial for using Github effectively, especially for beginners?'],\n",
       " '54ec0de4': ['What does the singular matrix error mean in the context of matrix inversion?',\n",
       "  'Why am I encountering a singular matrix error while working on my homework?',\n",
       "  'How does the order of multiplication affect the outcome in matrix operations?',\n",
       "  'Can you explain why X.dot(Y) is not the same as Y.dot(X)?',\n",
       "  'What should I consider to avoid the singular matrix error during calculations?'],\n",
       " 'f81f4ecb': [\"What should I do if I receive an error stating that 'Conda is not an internal command' when trying to execute a command in the terminal?\",\n",
       "  'Is there a specific Python version that I should use when creating a new environment with Conda, and does it matter if I use 3.8, 3.9, or 3.10?',\n",
       "  'If I just installed Anaconda on my Windows machine, which terminal should I use to run Conda commands?',\n",
       "  'What steps should I take if I don’t have Anaconda or Miniconda installed on my computer?',\n",
       "  \"Can I run the command 'conda create -n ml-zoomcamp python=3.9' on my terminal if I am using a different operating system?\"],\n",
       " 'be760b92': ['What is the proper way to read a dataset using Pandas on a Windows operating system?',\n",
       "  \"Why doesn't the code I wrote to read the CSV file in Windows work?\",\n",
       "  'What is the significance of using backslashes in file paths on Windows for Python code?',\n",
       "  'How can I avoid conflicts with escape sequences in my file path when using Pandas?',\n",
       "  'What should I do to correctly load a CSV file located in my Downloads folder on Windows?'],\n",
       " 'a2cfa1c9': [\"What should I do if I receive a '403 Forbidden' error when pushing to my GitHub repository?\",\n",
       "  'How can I verify the current remote URL configured for my Git repository?',\n",
       "  'What command do I need to run to check the remote settings for my repository?',\n",
       "  'How do I change my GitHub remote URL to ensure it includes my GitHub username?',\n",
       "  'What format should the remote URL be in after changing it for proper access?'],\n",
       " '7b907071': ['What does the authentication error message indicate when pushing code from Git Bash?',\n",
       "  \"Why did I receive a fatal error stating 'Authentication failed for https://github.com/username'?\",\n",
       "  'What change regarding password authentication occurred on August 13, 2021?',\n",
       "  'What is the recommended solution to resolve the authentication failure when pushing code?',\n",
       "  'Where can I find instructions for creating a personal access token for GitHub authentication?'],\n",
       " 'fc2e0a61': ['What should I do if I encounter an error when trying to wget a dataset from GitHub in Kaggle?',\n",
       "  'How can I resolve the issue of being unable to resolve the host address when using wget in Kaggle notebooks?',\n",
       "  'Is there a specific setting I need to adjust in Kaggle to successfully import data using wget?',\n",
       "  'What steps do I need to follow to enable Internet access for my session in Kaggle?',\n",
       "  'Do I need to verify my phone number when turning on Internet access in Kaggle?'],\n",
       " 'd43e5742': ['What resources are available for setting up a Python environment in VS Code?',\n",
       "  'Does VS Code support using Jupyter Notebooks without opening a browser?',\n",
       "  'How can I execute remote Jupyter Notebooks files in VS Code?',\n",
       "  'Is there GitHub support within VS Code for managing my projects?',\n",
       "  'Where can I find guidance on using Jupyter Notebooks in VS Code?'],\n",
       " '32bc0538': ['Do I need to create a Conda environment every time I start a new project in VS Code?',\n",
       "  'What command should I run to activate my existing Conda environment for the machine learning project?',\n",
       "  'Is there a way to save my current Conda environment configuration to reuse later?',\n",
       "  'Once I create a Conda environment, how do I access it in subsequent sessions?',\n",
       "  'Can you explain how to recreate a Conda environment using a YAML file?'],\n",
       " 'b6730228': ['What issue might I encounter when calculating the inverse of a matrix in Question 7 of Week 1 Homework?',\n",
       "  'Why did my multiplication of the inverse matrix with the original matrix not yield a perfect identity matrix?',\n",
       "  'Can you explain why floating point precision affects the calculations in our machine learning course?',\n",
       "  'Where can I find more information about the limitations of floating point mathematics as mentioned in the FAQ?',\n",
       "  'How can I ensure accurate results when working with matrix inverses in future assignments?'],\n",
       " '3ce9bbb8': ['What is the purpose of using pandas.DataFrame.info() in our analysis?',\n",
       "  'Can you explain what kind of information is retrieved by the df.info() method?',\n",
       "  \"How does the df.info() method help in understanding the dataset's structure?\",\n",
       "  'What specific details about the dataset can I expect to see when using df.info()?',\n",
       "  'Is there any particular format in which the output of df.info() is presented?'],\n",
       " '4e584d06': [\"What should I do if I encounter a NameError related to 'np'?\",\n",
       "  \"Why am I getting a NameError indicating that 'pd' is not defined?\",\n",
       "  'What libraries need to be imported to avoid NameErrors in my code?',\n",
       "  'Can you remind me how to properly import pandas and numpy in my script?',\n",
       "  'What is the common cause of NameErrors when using pandas or numpy?'],\n",
       " 'ff4da2b6': ['What is the method to choose numeric columns from a DataFrame?',\n",
       "  'How can I filter for object data types within a DataFrame?',\n",
       "  'Is there a concise approach to select specific data types in a DataFrame?',\n",
       "  'What should I do if I need to manage hundreds of columns and only want certain types?',\n",
       "  'Can you explain how to retrieve the column names for numeric data using select_dtypes?'],\n",
       " '58c1c168': ['What are some methods to determine the dimensions of a dataset in Pandas?',\n",
       "  'How can I find out the number of rows in a DataFrame using Pandas?',\n",
       "  'What Pandas attribute would I use to assess the shape of my dataset?',\n",
       "  'If I want to know how many columns are in my DataFrame, which command should I use?',\n",
       "  'Can you provide an example of how to use the .shape attribute in Pandas?'],\n",
       " '96076a1a': ['What should I use for matrix multiplication to prevent Value errors in my homework?',\n",
       "  'Why is the order of multiplication important when doing matrix-matrix multiplication?',\n",
       "  'What condition must be met regarding the dimensions of the matrices for multiplication to succeed?',\n",
       "  'How can I rearrange the order of my matrices if I encounter dimension mismatch?',\n",
       "  'Can you clarify what happens if the columns of the first matrix do not match the rows of the second matrix?'],\n",
       " '3218389a': ['What does it mean to impute missing values in a dataset, and why do we need to do it?',\n",
       "  'Can you explain the process to calculate the average of a column and how to use it for replacing NaN values?',\n",
       "  'Why is it important not to remove rows with NaN values when they contain useful information?',\n",
       "  'What steps should I follow in order to replace NaN values with the average in a column?',\n",
       "  'Who added the information regarding the method of imputing NaN values in this course?'],\n",
       " '183a1c90': ['What is the mathematical formula to use for linear regression?',\n",
       "  'How can I calculate the target variable in linear regression?',\n",
       "  'What resources are available for understanding ordinary least squares?',\n",
       "  'Can you explain multiple linear regression in matrix form?',\n",
       "  'What is the pseudoinverse solution to ordinary least squares?'],\n",
       " 'f0bc1c19': ['What might be the reason for having fewer than 5 columns in the final multiplication?',\n",
       "  'How can I correct the issue of having a discrepancy in the number of columns during multiplication?',\n",
       "  'What did I possibly interchange in the initial step of my multiplication?',\n",
       "  'Can you clarify what I might have used incorrectly in my multiplication process?',\n",
       "  'Who added the note about the final multiplication issue?'],\n",
       " '735e6c78': ['What operations can the * operator be used for in matrix multiplication?',\n",
       "  'Which functions or operators should I use for matrix-matrix multiplication according to the numpy documentation?',\n",
       "  'How does the * operator differ from the @ operator in terms of multiplication in numpy?',\n",
       "  'When should I use numpy.multiply() instead of other multiplication operators?',\n",
       "  'Can you explain why the @ operator or np.matmul() is preferred for certain types of multiplication?'],\n",
       " 'b8ca1cd3': ['What should I do if I encounter an ImportError related to Jinja2 when starting Jupyter notebook?',\n",
       "  \"How can I resolve the error regarding 'contextfilter' from Jinja2 when launching a new notebook?\",\n",
       "  'What command do I need to run to fix the ImportError when using a new environment for Jupyter?',\n",
       "  'Can I resolve Jupyter notebook launch issues by switching to the main environment and upgrading nbconvert?',\n",
       "  'What steps should I take if I face an error related to importing Jinja2 while starting a Jupyter notebook?'],\n",
       " 'efdb235f': ['What should I do if wget hangs while downloading the housing dataset?',\n",
       "  'How can I resolve the issue of seeing IPv6 addresses during wget download?',\n",
       "  'Is there a specific setting I need to change in System Settings for the download to work?',\n",
       "  'Where do I find the option to configure IPv6 on my MacOS Ventura M1?',\n",
       "  'What steps should I take to modify my network connection settings for wget?'],\n",
       " '355348f0': ['What should I do if I encounter issues with WGET on macOS?',\n",
       "  'Is there an alternative tool that I can use instead of WGET for downloading files?',\n",
       "  'Can you explain how to use curl for retrieving information from the internet?',\n",
       "  \"What does the '-o' option signify when using curl?\",\n",
       "  'Where can I find more information about curl and its usage?'],\n",
       " '67afabf5': ['What function can I use to round a number to a specific number of decimal places in Python?',\n",
       "  'How can I print a floating-point number with only three decimal places using f-strings?',\n",
       "  'Is there a method to round all the values in a pandas Series at once?',\n",
       "  'What is the syntax for rounding a number to four decimal places using the round function?',\n",
       "  'Where can I find more information about the round method for pandas Series?'],\n",
       " '50d737e7': ['What are the important links I need to access for Week 2 starting on September 18, 2023?',\n",
       "  'Where can I submit my homework for Week 2 of the course?',\n",
       "  'Is there a Google Calendar link available for the weekly meetings?',\n",
       "  'How can I ask questions during the Live Sessions this week?',\n",
       "  'Where can I find all the homework assignments for the course?'],\n",
       " 'bbc0fca3': ['What is the recommended method to examine the long tail of our dataset in this course?',\n",
       "  'Can you provide a code example to create a histogram for analyzing the distribution of median house values?',\n",
       "  \"How can skewness be calculated for the 'median_house_value' variable in our dataset?\",\n",
       "  'What does the skewness value tell us about the distribution of median house values?',\n",
       "  'Is it necessary to use seaborn for plotting the histogram, or can we use another library?'],\n",
       " '6f3bdd20': ['What does it mean if I encounter a Singular Matrix error while following the course videos?',\n",
       "  'Will the reasons behind getting a Singular Matrix error be explained in the course?',\n",
       "  'Is it common to experience a Singular Matrix error while working on the exercises?',\n",
       "  'Could performing the inverse of X multiple times in my code lead to errors?',\n",
       "  'What should I do if I encounter a Singular Matrix error in my implementation?'],\n",
       " '27c2d90a': ['Where can I find more information about the California housing dataset?',\n",
       "  'Is there a specific link for the detailed description of the California housing dataset?',\n",
       "  'What resource provides a thorough explanation of the California housing dataset?',\n",
       "  'Can you direct me to a website that discusses the California housing dataset in detail?',\n",
       "  'Where should I look for the dataset description related to California housing?'],\n",
       " '88e9600a': ['What steps should I follow if I encounter NaN values when calculating the mean using the .mean() function?',\n",
       "  'How did the issue with NaN values in the rmse calculation get resolved in the course example?',\n",
       "  'Why did the NaN values appear in the resulting rmse when using for loops with y_val and y_pred?',\n",
       "  'What was the approach taken to ensure all datasets (train, validation, test) were processed correctly?',\n",
       "  'What method was used to handle missing values in the datasets mentioned in the FAQ record?'],\n",
       " 'd59d8df7': ['What is the reason for transforming the target variable to a logarithm distribution in machine learning projects?',\n",
       "  'Is target variable transformation necessary for every machine learning project?',\n",
       "  'How can I determine if my target variable is highly skewed?',\n",
       "  'What is the best method to assess the skewness of the target variable distribution?',\n",
       "  'Where can I find more information on skewness in data distribution?'],\n",
       " '0b3eaf92': ['How can I import the dataset from GitHub into a pandas dataframe?',\n",
       "  'What is the method to read the dataset directly from the provided GitHub link?',\n",
       "  'Is there a specific code example to read the dataset into pandas?',\n",
       "  'Can you show me how to load the housing dataset from GitHub?',\n",
       "  'What command do I use to read a CSV file from a GitHub URL in pandas?'],\n",
       " '8fe56032': ['How can I load the dataset directly when using Kaggle Notebooks?',\n",
       "  'What command should I use to load the dataset in Kaggle Notebooks?',\n",
       "  'Is there a specific requirement I need to remember when using wget in Kaggle Notebooks?',\n",
       "  'After loading the dataset, how can I read it using Pandas?',\n",
       "  'Can you provide the complete command to download and read the dataset in a Kaggle Notebook?'],\n",
       " 'af833e0a': ['What is the method to filter a dataset based on specific value criteria?',\n",
       "  \"How can I apply the logical 'OR' operator while filtering a DataFrame?\",\n",
       "  'Is there an alternative way to filter a dataset using a list of values?',\n",
       "  \"Can I use both 'AND' and 'OR' operators when filtering data in a DataFrame?\",\n",
       "  'What syntax should I use to check if a value is in a list when filtering?'],\n",
       " '8d209d6d': ['Can you explain how to load the dataset using the requests library instead of directly from GitHub?',\n",
       "  'What is the URL provided for retrieving the housing data for our homework using the requests method?',\n",
       "  'If the download fails when using the requests library, what message will be printed?',\n",
       "  'Could you demonstrate the steps to save the dataset to a file after retrieving it with requests?',\n",
       "  'What status code is checked to confirm that the data was successfully downloaded using requests?'],\n",
       " '0bc4c3da': ['Why is a null column appearing in my dataframe after using .fillna()?',\n",
       "  'What is the difference between a shallow copy and a deep copy in Python?',\n",
       "  'How can I create a deep copy of my dataframe to avoid referencing the original?',\n",
       "  'What is the proper way to assign a new variable to a dataframe without linking it to the original?',\n",
       "  'Can you explain the implications of using X_train = df_train directly?'],\n",
       " 'c0ee2665': [\"Is it permissible to utilize train_test_split from Scikit-Learn during this week's assignments?\",\n",
       "  'Are we expected to implement the train_test_split function ourselves this week?',\n",
       "  \"Can I start using Scikit-Learn's functions early instead of waiting?\",\n",
       "  'Will we continue to work with our own implementation of train_test_split in the future?',\n",
       "  'What is the reasoning behind implementing train_test_split ourselves this week?'],\n",
       " '3f60871d': [\"Is LinearRegression from Scikit-Learn allowed for this week's assignments?\",\n",
       "  'Will we learn how to use LinearRegression next week?',\n",
       "  'Can I rely on using Scikit-Learn for machine learning this week?',\n",
       "  'Should I be concerned about using LinearRegression this week?',\n",
       "  'Is there a plan to cover LinearRegression in future lessons?'],\n",
       " 'f30217a7': ['What Scikit-Learn function should I use for linear regression without regularization?',\n",
       "  'Is there a specific Scikit-Learn function for linear regression with regularization?',\n",
       "  'Where can I find more information about the linear models in Scikit-Learn?',\n",
       "  'Can you clarify which functions correspond to the linear regression models discussed in week 2?',\n",
       "  'What is the function name in Scikit-Learn for the Ridge regression model?'],\n",
       " '91fc573d': ['Can you explain what the `r` parameter represents in the context of regression?',\n",
       "  \"How does the regularization parameter `r` in our lesson compare to the `alpha` parameter in sklearn's Ridge regression?\",\n",
       "  'What mathematical function demonstrates how `alpha` and `r` impact regularization strength?',\n",
       "  'In what way does `r` help with multicollinearity when performing linear regression?',\n",
       "  'Why is adding `r` to the main diagonal necessary for finding the inverse matrix in regression?'],\n",
       " 'fe3139f6': [\"What explains why we don't achieve a perfect fit with linear regression in lesson 2.8?\",\n",
       "  'How does the concept of overfitting relate to the inability of linear regression to fit all data points exactly?',\n",
       "  'Can you elaborate on how using non-linear methods like scipy.optimize.curve_fit could impact predictions on new data?',\n",
       "  'In terms of model simplicity, why might a perfect fit be undesirable in machine learning?',\n",
       "  'What visual representation might help illustrate the fit of a linear model compared to actual data points?'],\n",
       " '48aac030': ['What is the significance of using a random seed in our homework assignment?',\n",
       "  'Why do all my missing values end up in the training dataframe when I use a seed of 42?',\n",
       "  'How does changing the random seed affect the distribution of missing values across dataframes?',\n",
       "  'Can you explain what happens if I use a different random seed like 9 instead of 42?',\n",
       "  'What is the advantage of using the same random seed in machine learning experiments?'],\n",
       " '28321bc2': ['How can I shuffle my dataset using pandas?',\n",
       "  'What command should I use to ensure I get a complete shuffled version of my DataFrame?',\n",
       "  'Is there a way to maintain the same randomization across different runs when shuffling?',\n",
       "  'What does the parameter frac=1 do when using the pandas sample function?',\n",
       "  'How can I reset the index after shuffling the DataFrame?'],\n",
       " 'edb92d22': [\"What should I do if my homework answer doesn't match the provided options?\",\n",
       "  'Is it common for answers to differ from the choices given in the homework?',\n",
       "  'Why might my answer not align with the options available?',\n",
       "  'How do different environments affect the homework solutions I get?',\n",
       "  'If my answer is unique, should I still choose one of the given options?'],\n",
       " 'f488ce85': [\"What does the term 'mean' refer to in the context of Homework 2, specifically in question 3?\",\n",
       "  'Can you clarify what is meant by using only the training data set to compute the mean for question 3 in HW02?',\n",
       "  'How should I calculate the mean based on the instructions in question 3 of Homework 2?',\n",
       "  'What is the significance of not using the validation or test data set when calculating the mean in HW02?',\n",
       "  'Are there alternative methods for computing the mean mentioned in the instructions for question 3 of HW02?'],\n",
       " 'bf395099': ['Under what circumstances is it beneficial to apply a logarithmic transformation to the target variable?',\n",
       "  'What is the appropriate method to use when transforming a target variable with a long tail distribution?',\n",
       "  'Can logarithmic transformation be used if the target variable contains negative values?',\n",
       "  'Why is it important to consider the distribution of the target variable before transformation?',\n",
       "  'In which scenarios are long tail distributions commonly found in target variables?'],\n",
       " '01cd3b35': ['What does the ValueError related to shapes not being aligned mean in the context of machine learning for regression?',\n",
       "  'In what situations might broadcasting fail when performing arithmetic operations on arrays with different shapes?',\n",
       "  'How can I resolve the ValueError that occurs when trying to perform operations on arrays of different dimensions?',\n",
       "  'Is there an alternative method I can use to perform dot product operations when facing alignment issues with array shapes?',\n",
       "  'Can you explain the significance of the * operator in solving the shapes not aligned error during regression analysis?'],\n",
       " '5551c92e': ['What is the correct method to duplicate a dataframe while ensuring the original remains unchanged?',\n",
       "  'Can you explain the difference between a deep copy and a view in the context of dataframes?',\n",
       "  'If I use X_copy = X, what will happen to the original dataframe when I modify X_copy?',\n",
       "  'What is the proper syntax to create a true copy of a dataframe in Python?',\n",
       "  \"What does it mean for a copy of a dataframe to be a 'view' rather than a real copy?\"],\n",
       " '94f928d2': [\"Can you explain the concept of the 'long tail' in relation to statistical distributions?\",\n",
       "  \"How does the 'long tail' affect the relationship between mean, median, and mode in a dataset?\",\n",
       "  'What changes occur in the distribution when there are a few observations with high values?',\n",
       "  \"In a 'long tail' distribution, how does the area under the curve differ on each side?\",\n",
       "  \"Why might the mean become unrepresentative in a distribution characterized by a 'long tail'?\"],\n",
       " '266faa6d': ['Can you explain what standard deviation represents in a set of values?',\n",
       "  'How does a low standard deviation affect the values in relation to the mean?',\n",
       "  'What does a high standard deviation indicate about the spread of values?',\n",
       "  'What is the importance of understanding standard deviation in statistics?',\n",
       "  'Is there a specific formula to compute standard deviation?'],\n",
       " 'c21f99f5': ['Are there specific situations where regularization techniques are particularly important in machine learning?',\n",
       "  'In what scenarios should one consider using regularization when training models?',\n",
       "  'How does the size of the dataset influence the need for regularization techniques?',\n",
       "  'What factors should be evaluated to determine if regularization is necessary for a machine learning model?',\n",
       "  'Can you explain why regularization might be important for complex models in machine learning?'],\n",
       " '13702957': ['What is the benefit of defining functions for faster execution in our regression module?',\n",
       "  'Could you elaborate on how to prepare multiple dataframes and y-vectors using the provided shortcut?',\n",
       "  'Is it possible to use fillna() on the initial_df prior to data splitting, and how would that work?',\n",
       "  'Can you remind me how I might reuse the rmse() and train_linear_regression functions from the class notebook?',\n",
       "  'What are the names of the function and parameters I should use for data preparation in Section 2?'],\n",
       " '7cd652c5': ['What is the process for calculating standard deviation with pandas?',\n",
       "  'Can you provide an example of how to create a series in pandas for standard deviation?',\n",
       "  'How can I directly compute the standard deviation of a data list using pandas?',\n",
       "  'What function do I use in pandas to obtain the standard deviation from a series?',\n",
       "  'Is there a specific format required when passing data to pandas for calculating standard deviation?'],\n",
       " 'e1f93d10': ['What is the primary difference in how Numpy and Pandas calculate standard deviation?',\n",
       "  'Which standard deviation does Numpy calculate by default: population or sample?',\n",
       "  'How does the default calculation of standard deviation in Pandas differ from Numpy?',\n",
       "  'Can I modify the degree of freedom used in Numpy for calculating standard deviation?',\n",
       "  \"What will the result be if I change the degree of freedom in Numpy to match Pandas' default calculation?\"],\n",
       " '36b9d1b7': ['How can I compute the standard deviation of a specific column using Pandas?',\n",
       "  'What function do I use in Pandas to find the standard deviation?',\n",
       "  'Is it possible to calculate the standard deviation for multiple columns in a DataFrame?',\n",
       "  'Can you give me an example of how to use the std() function in Pandas?',\n",
       "  'What is the syntax for using std() to get standard deviation in Pandas?'],\n",
       " '3c8b32a1': ['What function can I use to combine two dataframes in my regression analysis?',\n",
       "  'How can I merge my train and validation datasets effectively?',\n",
       "  'Is there a specific method for combining numpy arrays in this course?',\n",
       "  'What would be the syntax for concatenating train and validation data in pandas?',\n",
       "  'Where can I find the documentation for the pandas.concat function?'],\n",
       " '05fb3a16': ['What is the significance of Root Mean Squared Error (RMSE) in evaluating regression models?',\n",
       "  'Can you explain the process of calculating the RMSE score step by step?',\n",
       "  'Which libraries do I need to import in order to calculate RMSE for my regression model?',\n",
       "  \"How does RMSE provide insight into the model's accuracy in forecasting target variables?\",\n",
       "  'Could you clarify the formula used for computing the RMSE score based on predicted and actual values?'],\n",
       " '225506b9': ['What is the correct operator for using logical OR in Pandas syntax?',\n",
       "  'How can I apply multiple conditions in a Pandas DataFrame?',\n",
       "  'What happens if I use incorrect syntax with multiple conditions in Pandas?',\n",
       "  'Which symbol represents the logical AND operation in Pandas?',\n",
       "  'Can you provide examples of using AND and OR with conditions in Pandas?'],\n",
       " 'bd4a1395': ['Can you explain the concept behind the normal equation in regression?',\n",
       "  'Where can I find a useful resource for understanding the derivation of the normal equation?',\n",
       "  'What is the significance of the normal equation in linear regression analysis?',\n",
       "  'Are there any recommended videos that clarify the normal equation derivation process?',\n",
       "  'How does the normal equation relate to machine learning for regression?'],\n",
       " '81b8e8d0': ['What is a good resource for learning about missing data treatment in regression analysis?',\n",
       "  'Can you recommend a guide for handling missing values using Python?',\n",
       "  'Where can I find information on dealing with missing data in machine learning?',\n",
       "  'Is there a Kaggle notebook that discusses strategies for missing data treatment?',\n",
       "  'Who is the author of the resource for handling missing values in Python?'],\n",
       " 'a7f6a33c': ['What specific instruction is given for log transformation related to the median_house_value variable before Q3 in the Week-2 homework?',\n",
       "  'Why was the log transformation instruction not included in the questions following Q3 in the Week-2 homework?',\n",
       "  'What issue did I encounter while working on Q5, and how does it relate to the application of log transformation?',\n",
       "  'Can you clarify the importance of applying log transformation to the target variable throughout the homework?',\n",
       "  'Is there a specific section in the homework where I can find the guidance on log transformation for the Week-2 cohort?'],\n",
       " '129b4ac0': ['What is the specific sklearn version used by Alexey in his instructional videos?',\n",
       "  'Which version of Python does Alexey utilize in his YouTube videos?',\n",
       "  'Can you tell me the exact versions of sklearn and Python that Alexey references?',\n",
       "  'Is the version of sklearn mentioned in the videos the latest one?',\n",
       "  'What Python version accompanies the sklearn version in the videos?'],\n",
       " 'b8cca8b7': ['Where can I find the homework for Week 3 of the classification section?',\n",
       "  'What is the link to submit my homework for Week 3?',\n",
       "  'Is there a place where I can access all the homework assignments for this course?',\n",
       "  'Where can I view the evaluation matrix for the assignments?',\n",
       "  'What GitHub repository contains the theoretical materials for this part of the course?'],\n",
       " '1091b10f': [\"What does the error message regarding converting 'Nissan' to float indicate about data types in machine learning?\",\n",
       "  'How can I address the issue of string values when my model expects numerical inputs?',\n",
       "  'What is one-hot encoding, and how does it help in converting categorical variables to numerical values?',\n",
       "  'Can you provide an example of how to implement one-hot encoding for a specific column in a pandas DataFrame?',\n",
       "  'What will happen to the original column of car brands after applying the one-hot encoding method?'],\n",
       " '0c7715a1': ['What is the reason for converting the median_house_value target to a binary format in our homework assignment?',\n",
       "  'How does mutual information score determine the relationship between different variable types?',\n",
       "  'What issues arise if we keep the median_house_value in its original continuous format for calculating mutual information score?',\n",
       "  \"Why can't we use continuous variables directly in mutual information score calculations?\",\n",
       "  'What would happen if the algorithm attempted to bin continuous variables during mutual information score computation?'],\n",
       " 'd2043cf5': ['Can you clarify which dataset we are using to create the correlation matrix for the assignment?',\n",
       "  'Is it correct to use df_train exclusively for the correlation analysis instead of df_train_full?',\n",
       "  'Why is it important to avoid using the validation dataset when working on the current task?',\n",
       "  'What is the significance of converting median_house_value from numeric to binary in our analysis?',\n",
       "  'Could you explain the implications of making conclusions based on validation data at this stage?'],\n",
       " '44d22817': ['How can I color the background of a correlation matrix in a pandas DataFrame?',\n",
       "  'What method do I use to apply a background gradient based on numerical values in a DataFrame?',\n",
       "  'Can the background color of any DataFrame be customized, or is it just for the correlation matrix?',\n",
       "  'What is an example of a color map that can be used with the background gradient method?',\n",
       "  'Is it necessary to filter the DataFrame for only numerical values before calculating the correlation?'],\n",
       " '1f76dbeb': ['How can I identify highly correlated feature pairs in my dataset?',\n",
       "  'What code snippet can I use to create a heatmap of correlations using seaborn?',\n",
       "  'Is there a way to plot only a triangle in a heatmap to avoid redundancy?',\n",
       "  'Can you provide an example output from the correlation function using the churn dataset?',\n",
       "  'What options do I have for refining the appearance of my heatmap?'],\n",
       " 'b8071a54': ['What dataset should I primarily use for exploratory data analysis in machine learning?',\n",
       "  'Is it acceptable to include the validation dataset when performing exploratory data analysis?',\n",
       "  'Why is it important to avoid using the test dataset during exploratory data analysis?',\n",
       "  'How should I treat the test dataset while analyzing my data for classification?',\n",
       "  'Can you explain the reasoning behind focusing on the train dataset for EDA?'],\n",
       " 'b8da9037': ['What is the purpose of using a validation dataset in machine learning models?',\n",
       "  'How does the fit method in DictVectorizer determine how to process the input data?',\n",
       "  'Why is it not advisable to fit the validation model after fitting the training model?',\n",
       "  'What should be done with the training set when using DictVectorizer to avoid overwriting learned data?',\n",
       "  'Can you explain the difference between fitting and transforming the training set versus the validation and test sets?'],\n",
       " '467e0cec': ['For homework Q5, should the difference in accuracy be calculated in real or absolute values?',\n",
       "  'What does it mean when a difference in accuracy is negative in the context of feature elimination?',\n",
       "  'When determining the smallest difference in accuracy, should we focus on real values or absolute ones?',\n",
       "  'In Q5, is it correct to say that a smaller negative difference indicates an improvement in the model?',\n",
       "  'What criteria should we use to decide if we are looking for the smallest or lowest difference in accuracy?'],\n",
       " 'b69f32f6': ['What does the FutureWarning regarding get_feature_names indicate?',\n",
       "  'How can I resolve the FutureWarning related to get_feature_names in our course materials?',\n",
       "  'Will I experience any consequences from the deprecation warning concerning get_feature_names?',\n",
       "  'What method should I use instead of get_feature_names according to the FAQ?',\n",
       "  'Is it necessary to address the warning about get_feature_names in our current projects?'],\n",
       " '3b3b1989': ['What should I do if my Jupyter kernel crashes while using logistic regression?',\n",
       "  'Why does fitting logistic regression take so long?',\n",
       "  'What happens when I call predict() after fitting my logistic regression model?',\n",
       "  'Is there a specific type of target variable needed for logistic regression?',\n",
       "  'Who provided the information regarding logistic regression and kernel issues?'],\n",
       " 'eb5771a0': ['What is the purpose of using Ridge regression in predictive modeling?',\n",
       "  'Can you explain what the sag solver stands for and its benefits for large datasets?',\n",
       "  'How does the alpha parameter influence the regularization strength in Ridge regression?',\n",
       "  'What is the relationship between coefficient values and overfitting in Ridge regression?',\n",
       "  'How should I implement Ridge regression using sklearn with specific parameters like alpha and solver?'],\n",
       " 'bca10281': ['What is the difference in the output format between DictVectorizer(sparse=True) and DictVectorizer(sparse=False)?',\n",
       "  'Why might using pandas.get_dummies() be less efficient compared to DictVectorizer(sparse=True) for a large number of classes?',\n",
       "  'How does the use of sparse representation affect memory efficiency during model fitting?',\n",
       "  'What kind of performance issues may arise when using sparse format with a high number of classes?',\n",
       "  'Can you explain the convergence problems that occur with Logistic and Linear/Ridge Regression when using a standard one-hot encoding?'],\n",
       " '34a8edb0': ['What should I do if I encounter a ConvergenceWarning related to max_iter when using the sag solver with Ridge?',\n",
       "  'How can I ensure that my features are properly scaled when working with the Ridge model in W3Q6?',\n",
       "  'Which scalers or encoders are recommended for the numeric and categorical features in this course?',\n",
       "  'Is it necessary to separately handle numeric and categorical features before applying the encoder?',\n",
       "  'Where can I find guidance on scaling features effectively while working on machine learning classification?'],\n",
       " 'f625307b': ['What should I do if I experience convergence errors while training a Ridge regression model in Week 3?',\n",
       "  'How can I ensure my numerical features are properly prepared to prevent convergence issues during model training?',\n",
       "  'What techniques can be used to convert categorical features into a numerical format for Ridge regression?',\n",
       "  'What is the process for creating a single feature matrix after normalizing numerical and encoding categorical features?',\n",
       "  'Why is it important to use an appropriate method like OneHotEncoder for categorical features when training a Ridge model?'],\n",
       " '7fa98526': ['What are the main advantages of using a sparse matrix over a dense matrix in machine learning?',\n",
       "  'How does a sparse matrix handle non-zero values and their positions in memory?',\n",
       "  'Can you explain why sparse matrices are beneficial for large datasets with many missing values?',\n",
       "  'What is the default configuration of DictVectorizer when working with matrices?',\n",
       "  'Why was using a sparse matrix preferred for week3 Q6 in terms of model training performance?'],\n",
       " '0807f0f3': ['What is the method to turn off warnings in Jupyter notebooks?',\n",
       "  'Can you explain how to ignore warnings when using Jupyter notebooks?',\n",
       "  'What comments should I include to suppress warnings in my Jupyter notebook?',\n",
       "  'Is there a way to avoid seeing warnings while working in Jupyter notebooks?',\n",
       "  'What steps need to be taken to disable warnings in a Jupyter notebook environment?'],\n",
       " '6d0fb418': ['How should I approach the issue of selecting the optimal alpha parameter for Q6 in the course materials?',\n",
       "  'What is the process for determining the best RMSE when multiple alpha values yield the same score?',\n",
       "  'Can you explain the reasoning behind choosing the lowest alpha when RMSE scores are equal?',\n",
       "  'In our week two homework discussion, why did some of us end up with incorrect RMSE scores?',\n",
       "  'Is there a specific method recommended for calculating RMSE across different alpha values?'],\n",
       " 'fbda1f40': ['What is the procedure to compute the mutual information score for HW3 Q3?',\n",
       "  'Which training set should I use to calculate the mutual information score?',\n",
       "  'How do I binarize the price variable for the analysis?',\n",
       "  'What is the categorical variable involved in the mutual information calculation?',\n",
       "  'Can you clarify the relationship between the binarized price and the ocean proximity variable?'],\n",
       " '0f88b7ac': ['Do we have to only use the specified features total_rooms, total_bedrooms, population, and households for homework Q5, or should we include all features and then remove them one at a time for comparison?',\n",
       "  \"What is the procedure to evaluate the model's accuracy when working with the features in homework Q5?\",\n",
       "  'When we remove a feature to compare accuracy, should we focus on the smallest difference or the smallest absolute difference in accuracy scores?',\n",
       "  'How do we define the original accuracy score in the context of homework Q5 before removing any features?',\n",
       "  'Is the goal to find out which feature has the least effect on model accuracy by looking at the absolute differences in accuracy scores?'],\n",
       " '9ffcc895': ['Can you explain how OneHotEncoder and DictVectorizer function to convert categorical features into numerical variables?',\n",
       "  'What is the primary input format distinction between OneHotEncoder and DictVectorizer?',\n",
       "  'Do OneHotEncoder and DictVectorizer yield similar outcomes in terms of feature representation?',\n",
       "  'How does the sorting of features differ when using OneHotEncoder compared to DictVectorizer?',\n",
       "  'In what scenarios might I prefer using DictVectorizer over OneHotEncoder for feature transformation?'],\n",
       " '94a3b2fb': ['Can you explain the main differences between pandas get_dummies and sklearn OneHotEncoder?',\n",
       "  'In what scenarios is it more appropriate to use get_dummies rather than OneHotEncoder?',\n",
       "  'How do the input and output types differ between pandas get_dummies and sklearn OneHotEncoder?',\n",
       "  'What advantages does OneHotEncoder offer for a scikit-learn machine learning pipeline?',\n",
       "  'Are the results from using get_dummies and OneHotEncoder exactly the same for one-hot encoding categorical variables?'],\n",
       " 'fb9a45d8': [\"In the third week's homework, should we consistently use 42 as the random_state for both the train and test splits?\",\n",
       "  'Is it required to apply the random seed of 42 to both splits while completing the test_train_split task in HW3?',\n",
       "  'For the assignment pertaining to test_train_split, do we need to set random_state = 42 for the first split only or for both splits?',\n",
       "  'When completing the week 3 homework, is it necessary to use the same random_state value of 42 for both training and testing datasets?',\n",
       "  'In the context of HW3, should we apply the random seed of 42 to the first split and the second split for the test_train_split section?'],\n",
       " 'e31051f7': ['Should I calculate correlation for my data before I split it?',\n",
       "  'When is the right time to compute correlation in my workflow?',\n",
       "  'How can I identify the most correlated features in my dataset?',\n",
       "  'What process should I follow to find the two features with the highest correlation?',\n",
       "  'Is it necessary to use the correlation matrix of the training dataset after data splitting?'],\n",
       " '493b7b59': ['What types of features should I use in a ridge regression model to ensure it functions correctly?',\n",
       "  'Is it possible to include categorical features in my ridge regression model, and if so, how?',\n",
       "  'What steps should I follow to prepare categorical features for a ridge regression model?',\n",
       "  'Why is it important to drop categorical features before training a ridge regression model?',\n",
       "  'What setting should I use to avoid convergence errors when transforming categorical features?'],\n",
       " '4a55c510': ['What features should I include for Homework 3 Question 6?',\n",
       "  'Which variable should I use as the target in my analysis?',\n",
       "  'Is it necessary to incorporate the average variable we previously created?',\n",
       "  'If I utilize DictVectorizer, what setting should I ensure is enabled?',\n",
       "  'Can I run my analysis without using StandardScaler for numerical variables?'],\n",
       " '3ca0b489': ['What methods can I use to convert non-numeric data into numeric format for my model?',\n",
       "  'Are there specific encoders recommended for transforming categorical variables?',\n",
       "  'How can I preprocess my dataset to make it suitable for machine learning algorithms?',\n",
       "  'Which libraries provide tools for encoding and scaling features in my dataset?',\n",
       "  'What is the significance of using encoders like OneHotEncoder and OrdinalEncoder in classification tasks?'],\n",
       " '690d97f1': ['Can you explain the main difference between FeatureHasher and DictVectorizer in terms of memory usage?',\n",
       "  'In what scenarios should I prefer using FeatureHasher over DictVectorizer for categorical features?',\n",
       "  'How does the cardinality of categorical features influence the choice between FeatureHasher and DictVectorizer?',\n",
       "  'What should I consider if I want to preserve feature names when transforming data for machine learning?',\n",
       "  'Where can I find additional resources on the topic of FeatureHasher and DictVectorizer?'],\n",
       " 'eb5a25cb': ['Why is it important to avoid data leakage when working with the test set in machine learning?',\n",
       "  'What does the scikit-learn documentation recommend regarding data splitting and preprocessing?',\n",
       "  'Can you explain the implications of using DictVectorizer before splitting the dataset?',\n",
       "  'How does preprocessing before data splitting affect the validity of the training results?',\n",
       "  'What common practices should be followed to prevent data leakage in machine learning workflows?'],\n",
       " '6d9e0a6f': [\"What should I do if my model's accuracy is 1.0?\",\n",
       "  'How can I address the problem of overfitting in my model?',\n",
       "  'Is it advisable to choose the closest option when accuracy is at its maximum?',\n",
       "  \"Could dropping the column msrp/price improve my model's performance?\",\n",
       "  'What does it mean if my machine learning model is overfitted?'],\n",
       " '618ad97a': ['What are the necessary packages for computing Root Mean Squared Error in this course?',\n",
       "  'Can you provide an example of how to implement the RMSE calculation using Python code?',\n",
       "  'What function should I use to calculate the mean squared error when working with RMSE?',\n",
       "  'Is there a resource where I can find additional information or examples related to RMSE calculation?',\n",
       "  'How do I implement the RMSE function that subtracts predicted values from actual values?'],\n",
       " '683495d2': ['What should I do if I encounter an AttributeError related to the DictVectorizer object?',\n",
       "  'How can I resolve the issue with the get_feature_names function in DictVectorizer?',\n",
       "  'Is there an alternative method to get feature names from the DictVectorizer?',\n",
       "  'Where can I find more information about the DictVectorizer and its methods?',\n",
       "  'What is the correct method to use instead of get_feature_names in DictVectorizer?'],\n",
       " 'dc1897b5': ['How can I calculate the Root Mean Squared Error using sklearn without using math or numpy?',\n",
       "  'What is the purpose of the squared kwarg in the mean_squared_error function from sklearn.metrics?',\n",
       "  'Can you explain how to set the squared parameter to obtain RMSE using sklearn?',\n",
       "  'Is there a library function available for calculating RMSE in Python with sklearn?',\n",
       "  'Where can I find more details about calculating RMSE using sklearn.metrics?'],\n",
       " '826098f2': ['What are the different encoding techniques for categorical variables that I should know about?',\n",
       "  'Where can I find more information regarding encoding techniques for my classification assignment?',\n",
       "  'Could you provide a resource that explains categorical variable encoding in detail?',\n",
       "  'Who is the author of the article that discusses encoding techniques?',\n",
       "  'Is there a specific article that covers all about categorical variable encoding?'],\n",
       " '821dfc08': ['What is the cause of the TypeError when using accuracy_score from sklearn in Jupyter?',\n",
       "  'How did you resolve the issue with accuracy_score returning a TypeError?',\n",
       "  \"What does the code 'accuracy_score(y_val, y_pred >= 0.5)' represent?\",\n",
       "  'Can you explain the correct import statement to use for metrics in sklearn?',\n",
       "  'In which context did you experience the error with accuracy_score in your code?'],\n",
       " '27c8d5da': ['What resources do I need to start working on the homework for Week 4?',\n",
       "  'Where can I find the complete list of homeworks for this course?',\n",
       "  'Is there a spreadsheet available that outlines the evaluation metrics?',\n",
       "  'Can you please share the GitHub repository containing the theoretical material for this week?',\n",
       "  'How can I access the YouTube video related to Week 4 of the course?'],\n",
       " 'a52d4739': ['How can I utilize a variable to score in classification metrics?',\n",
       "  'Where can I find the discussion about scoring with a variable?',\n",
       "  'Can metrics be applied solely to dataframes in this course?',\n",
       "  'What are the options for applying metrics in relation to data types?',\n",
       "  'Who provided the information regarding the use of variables for scoring?'],\n",
       " 'dc55359c': ['What is the purpose of using random_state in our evaluations?',\n",
       "  'Why is random_state necessary for reproducibility when shuffling datasets?',\n",
       "  'In which scenarios should we consider setting both random_state and the shuffle parameters?',\n",
       "  'How does the use of random_state differ between module-04 homework questions?',\n",
       "  'Can you explain the significance of the sklearn documentation regarding random_state?'],\n",
       " '2ab49e43': ['What is the method to obtain all relevant classification metrics at once?',\n",
       "  'Can I calculate precision, recall, f1 score, and accuracy together?',\n",
       "  'Which function from sklearn should I use to get the classification metrics?',\n",
       "  'Is there additional information available on obtaining classification metrics?',\n",
       "  'Who provided the information regarding the evaluation metrics for classification?'],\n",
       " 'b431e7eb': ['If I receive multiple thresholds yielding the same F1 score in my results, should I be concerned about my approach or is there a recommended strategy for selecting one?',\n",
       "  'Is it advisable to always select the lowest threshold when faced with several options that have identical F1 scores, or is there a better method?',\n",
       "  'What tools or libraries can I utilize to confirm the findings from my own code in relation to evaluation metrics like precision, recall, and F1-score?',\n",
       "  \"Can you explain how the 'classification_report' function from scikit-learn can assist in validating my evaluation metrics?\",\n",
       "  'Are there any particular metrics or considerations I should keep in mind when dealing with multiple thresholds that produce the same evaluation results?'],\n",
       " 'c5fdeba9': ['What does the error message about needing samples of at least 2 classes mean in the context of this course?',\n",
       "  \"How can I resolve the issue of having only 0's in my churn column while running my classification model?\",\n",
       "  'Can you clarify what results I should expect if I delete one of the cells mentioned in the solution?',\n",
       "  \"What does it indicate if the churn column only contains one class, like all 0's, when I'm trying to run my analysis?\",\n",
       "  'Why is it important to have at least 2 classes in the data for running a classification model effectively?'],\n",
       " 'b8c9eaf1': ['What is the recommended library for generating attractive classification reports?',\n",
       "  'How does Yellowbrick enhance the functionality of scikit-learn?',\n",
       "  'Can you explain the purpose of Yellowbrick in relation to visualization?',\n",
       "  'What types of visualizations can Yellowbrick produce for model reports?',\n",
       "  'Who is associated with the development or mention of Yellowbrick in this context?'],\n",
       " 'c54058a1': ['Why am I not achieving the precise results for my homework assignments?',\n",
       "  \"What should I do if my answers don't match the exact results?\",\n",
       "  'Is it acceptable to choose an answer that is not exact for my homework?',\n",
       "  'How should I handle discrepancies in my homework results?',\n",
       "  'What is the policy regarding close answers for homework evaluations?'],\n",
       " 'b4b85c4b': ['How can I assess the significance of numerical features using AUC?',\n",
       "  'Where can I find examples related to AUC from previous course iterations?',\n",
       "  'Which score should I apply to evaluate ROC metrics?',\n",
       "  'Is it necessary to refer to prior course materials for feature importance?',\n",
       "  'What is the recommended method for using AUC in feature evaluation?'],\n",
       " '7d40f6f6': ['Can you explain how to use numerical values as scores in the ROC AUC score calculation?',\n",
       "  'What are the parameters required by the sklearn.metrics.roc_auc_score function?',\n",
       "  'How should I pass the target variable when using the roc_auc_score function?',\n",
       "  'Is the dataframe needed for calculating the ROC AUC score?',\n",
       "  \"What do the parameters 'y_true' and 'y_score' represent in the context of ROC AUC?\"],\n",
       " 'f5dc446c': ['Which dataset is necessary for calculating the metrics in Question 3?',\n",
       "  'What dataset should I refer to for the metrics mentioned in Question 3?',\n",
       "  'Is there a specific dataset required to compute the metrics from Question 3?',\n",
       "  'For the calculations in Question 3, which dataset needs to be utilized?',\n",
       "  'Do I need to use the same dataset as in Question 2 for Question 3 metrics?'],\n",
       " 'd30fc29d': ['Can you explain how KFold works and what it means when we set n_splits?',\n",
       "  'What impact does changing the random_state have on the results of KFold?',\n",
       "  'Is there a specific reason to define KFold outside of the loop when processing multiple values of C?',\n",
       "  'Does KFold create separate training and validation datasets on its own, or is that done in a subsequent step?',\n",
       "  'Why might it be more efficient to define KFold before the loop rather than inside it?'],\n",
       " '8eca9f73': [\"What does the error message 'ValueError: multi_class must be in ('ovo', 'ovr')' indicate when using roc_auc_score?\",\n",
       "  'What parameters should I use to avoid the ValueError when evaluating feature importance?',\n",
       "  'How can I correctly call the roc_auc_score function with my training data?',\n",
       "  'What caused the ValueError I encountered when evaluating numerical variables in question 1?',\n",
       "  'Is there a specific order or structure I should follow when passing parameters to roc_auc_score?'],\n",
       " '7b9eb7f7': ['What can I use to monitor the execution progress of my code?',\n",
       "  'Which library provides a terminal progress bar for tracking wait times?',\n",
       "  'How can I visualize the progress of my code execution?',\n",
       "  'What is the command to import the tqdm progress bar?',\n",
       "  'Who provided the information about monitoring wait times in this section?'],\n",
       " 'c4aaeed9': ['Why is it important to invert variables with ROC AUC scores below the threshold?',\n",
       "  'How does negating negatively correlated features contribute to model performance?',\n",
       "  'What benefits does inverting features provide in terms of feature importance?',\n",
       "  'In what scenarios should I consider inverting variables less than the threshold?',\n",
       "  'How does the direction of correlation affect the use of machine learning algorithms?'],\n",
       " '3af31e2a': ['What is the main difference between using predict(X) and predict_proba(X) in classification tasks?',\n",
       "  'Why might the output from predict(X) lead to incorrect evaluation values?',\n",
       "  'How does predict_proba(X) provide a solution to relying solely on predict(X)?',\n",
       "  'What type of predictions do we get when using predict(X) for binary classification?',\n",
       "  'What information does predict_proba(X) give us regarding class membership probabilities?'],\n",
       " '746342ff': ['What does a threshold of 1.0 imply for the classification of churn predictions?',\n",
       "  'Can you explain why both FPR and TPR are zero when the threshold is set at 1.0?',\n",
       "  'How does the nature of the sigmoid function affect the prediction outcomes at a threshold of 1.0?',\n",
       "  'Why can g(x) never reach values of exactly 0 or 1 in this binary classification model?',\n",
       "  'What are the implications of having no predicted positive values when the threshold is at its maximum?'],\n",
       " 'bda2c9b3': ['What methods does Matplotlib offer for graph annotation?',\n",
       "  'Can you explain how to use arrows and text in Matplotlib annotations?',\n",
       "  'What is the purpose of the coordinates in the annotate method?',\n",
       "  'How do you specify different locations for the text and the arrow in an annotation?',\n",
       "  'Could you provide an example of annotating with an optimal threshold and F1 score in Matplotlib?'],\n",
       " '41521c92': ['Is it necessary to grasp the ROC curve thoroughly before proceeding with the course?',\n",
       "  'How important is it to understand the ROC AUC in the context of Binary Classification?',\n",
       "  'What should I do if I find the ROC curve challenging to comprehend?',\n",
       "  'Can I find supplementary materials to help me better understand the ROC curve?',\n",
       "  'What is the significance of the ROC AUC metric in classification models?'],\n",
       " '25481ce5': ['What factors could lead to differing accuracy results compared to the homework options?',\n",
       "  'Can you explain how the method of data splitting affects accuracy values?',\n",
       "  'Which data splitting method is recommended for consistency with the lessons?',\n",
       "  'How does randomness in the train/test split impact the evaluation metrics?',\n",
       "  'Why might two different data splitting approaches result in non-matching datasets?'],\n",
       " '1427d567': ['What are the necessary columns in the dataframe to find the threshold where precision and recall curves intersect?',\n",
       "  'How can I determine the index positions of the intercept between precision and recall using numpy?',\n",
       "  'What functions from numpy are mentioned for finding the intercept between precision and recall curves?',\n",
       "  'Is there a way to print the threshold value where the precision and recall curves intersect?',\n",
       "  'What is the purpose of using np.sign in the process of finding the intercept between the two curves?'],\n",
       " '76c91dfb': ['How can I compute the Recall metric using the Scikit Learn library?',\n",
       "  'What steps should I follow to calculate the Precision score for my classification results?',\n",
       "  'Is there a quick way to obtain the F1 Score without having to define true positives and negatives?',\n",
       "  'Where can I find the demonstration video that shows how to manually calculate precision and recall?',\n",
       "  'What specific functions from sklearn.metrics should I use to calculate these evaluation metrics?'],\n",
       " 'e4dd91cf': ['What is the purpose of using cross-validation in model evaluation?',\n",
       "  'How does cross-validation help in selecting the optimal hyperparameters?',\n",
       "  'Can you explain how the dataset is utilized during cross-validation?',\n",
       "  \"In the context of SVM and logistic regression, what does the 'C' hyperparameter signify?\",\n",
       "  \"How do smaller and larger values of 'C' affect model performance and classification accuracy?\"],\n",
       " 'cc53ae94': ['How can I easily compute model evaluation metrics using a library in Python?',\n",
       "  'Which specific metrics can be utilized from the scikit learn library for evaluating a classification model?',\n",
       "  'What is the advantage of using scikit learn over manually computing metrics with numpy and pandas?',\n",
       "  'Can you provide an example of how to calculate accuracy, precision, recall, F1-Score, and ROC AUC?',\n",
       "  'Where can I find the necessary functions for model evaluation in the scikit learn package?'],\n",
       " '403bbdd8': ['What is an alternative method to calculate Precision, Recall, and F1 score?',\n",
       "  'Can I use Scikit-learn for computing Precision, Recall, and F1 score?',\n",
       "  'How do I utilize precision_recall_fscore_support in Scikit-learn?',\n",
       "  'Is there a way to handle zero division when calculating these metrics?',\n",
       "  'Where can I find an example of using precision_recall_fscore_support?'],\n",
       " '7c68ace0': ['What situations warrant the use of ROC curves instead of Precision-Recall curves when evaluating classifiers?',\n",
       "  \"Why might ROC curves present a misleading assessment of a model's performance on imbalanced datasets?\",\n",
       "  'Can you explain the difference in how ROC curves and Precision-Recall curves handle true negatives?',\n",
       "  'How does the class distribution in a test set impact the performance metrics calculated from a confusion matrix?',\n",
       "  'In what way do ROC graphs differ in their sensitivity to changes in class distribution compared to other evaluation metrics?'],\n",
       " '147577f5': ['What function can I use to assess feature importance for numeric variables using AUC?',\n",
       "  'Which argument should I pass first when using roc_auc_score to evaluate features?',\n",
       "  \"Where can I find the method for calculating AUC in Python's sklearn library?\",\n",
       "  'What type of data do I need to provide to the roc_auc_score function?',\n",
       "  'What will the roc_auc_score function return when evaluating a feature?'],\n",
       " 'd3ffb802': ['How does class imbalance affect the F-score in classification tasks?',\n",
       "  'What is the relationship between the precision-recall curve and class ratios?',\n",
       "  'Why is it problematic to compare F-scores across different classification problems?',\n",
       "  'What can be done to improve the comparison of F-scores with varying class ratios?',\n",
       "  'Who provided the information regarding the dependence of the F-score on class imbalance?'],\n",
       " 'cc04d27a': ['What method can I use to create a Precision-Recall Curve quickly?',\n",
       "  'Which library should I import to access the precision_recall_curve function?',\n",
       "  'What are the parameters needed to compute the precision and recall for my validation data?',\n",
       "  'How do I visualize the Precision and Recall using a plot?',\n",
       "  'What should I include in my plot to differentiate between Precision and Recall?'],\n",
       " '927b5e09': ['What is the purpose of using Stratified k-fold in multiclass classification?',\n",
       "  'How does Stratified k-fold ensure class balance in data partitioning?',\n",
       "  'Can you explain how Stratified k-fold works with respect to sample percentages of each class?',\n",
       "  'Where can I find more information about implementing Stratified k-fold?',\n",
       "  'Why is it important to maintain class balance in dataset splitting for multiclass tasks?'],\n",
       " 'd22efea7': ['What is the link for the homework assignment for Week 5?',\n",
       "  'Where can I find the solutions for Homework 3?',\n",
       "  'Is there a resource that outlines all the homework assignments for this course?',\n",
       "  'Can you provide the link to the evaluation matrix for the machine learning models?',\n",
       "  \"What is the YouTube link for Week 5's content?\"],\n",
       " 'd1409f67': ['What are the common errors I might face related to my default environment during week 5 of the course?',\n",
       "  'Is it necessary to set up a cloud environment for homework in week 5?',\n",
       "  'Can you recommend a specific cloud provider to use for my homework environment setup?',\n",
       "  'Where can I find a guide for setting up an AWS EC2 instance for this course?',\n",
       "  'What should I consider regarding costs when using AWS instances for my homework?'],\n",
       " 'e07759e9': ['What steps do I need to take to create a Kaggle API token for downloading data?',\n",
       "  'Where should I store the kaggle.json file in relation to my Jupyter Notebook?',\n",
       "  'How can I modify the permissions of the kaggle.json file using a command in my Jupyter Notebook?',\n",
       "  'What should I do after importing the os library in my Jupyter Notebook for setting the KAGGLE_CONFIG_DIR?',\n",
       "  \"Once I've downloaded the dataset, what command allows me to extract the CSV file from the zip archive?\"],\n",
       " '620fb76e': ['What command should I use to navigate back one directory in Ubuntu?',\n",
       "  'How can I view the list of current folders in my Ubuntu system?',\n",
       "  'What is the command to change to a specific path in Ubuntu?',\n",
       "  'How do I find out my home directory in the Ubuntu terminal?',\n",
       "  'Which command allows me to edit a text file in Ubuntu?'],\n",
       " '957280d8': ['What terminal command can I use to check the Python version currently installed on my laptop?',\n",
       "  'How can I download the latest version of Python for installation on a Windows machine?',\n",
       "  'What should I make sure to check during the Python installation process?',\n",
       "  'What command do I need to run if I want to upgrade to Python 3 using pip?',\n",
       "  'Where can I find the official website to download Python versions?'],\n",
       " '185096ad': ['What steps do I need to follow to install WSL on my Windows 10 or 11 machine?',\n",
       "  \"How can I ensure that the 'Virtual Machine Platform' feature is activated on my Windows system?\",\n",
       "  'After installing a Linux distribution, how do I verify that I have Python installed in my WSL environment?',\n",
       "  'What command can I use to set my preferred folder as the default directory when opening the Ubuntu terminal?',\n",
       "  'If I encounter an error while installing pipenv, what steps should I take to create a symbolic link for the library?'],\n",
       " 'ec88d101': ['What specific error message might I encounter when building a Docker image on a Mac with M1 silicon?',\n",
       "  'What should I modify in the Dockerfile to resolve the error related to the missing ld-linux-x86-64.so.2 file?',\n",
       "  'How do I change the base image in the Dockerfile for compatibility with Mac M1 chipset?',\n",
       "  'What is the expected build time for the Docker image after making the necessary adjustments?',\n",
       "  'Where can I find the Dockerfile that needs to be edited for deploying machine learning models?'],\n",
       " '7156679d': ['What is the procedure to check the version of installed Python libraries in a Jupyter notebook?',\n",
       "  'Which library needs to be imported to retrieve its version information?',\n",
       "  'How do I print the version of the Waitress library after importing it?',\n",
       "  'Is there a specific command to use after importing the library to display its version?',\n",
       "  'Who should I credit for providing the information on checking library versions?'],\n",
       " '4b2a3181': ['What should I do if I encounter an error related to connecting to the Docker daemon when trying to run a test image?',\n",
       "  'Could you explain how to resolve the issue of not being able to connect to the Docker daemon on WSL?',\n",
       "  'What commands can I use to start the Docker daemon on a Linux system if I experience connection issues?',\n",
       "  'Is there a specific process I need to follow to reinstall Docker on WSL if I face connection errors?',\n",
       "  'What steps should I take if Docker Desktop is not installed on my host machine and I need to resolve a Docker connection error?'],\n",
       " '73bd7fa1': ['What should I do if I encounter a non-zero code error while running the pipenv install command after building the Docker image?',\n",
       "  'How can I determine the correct Python version to use in my Dockerfile for model deployment?',\n",
       "  \"What is the first line I need to change in my Dockerfile to match my system's Python version?\",\n",
       "  'What command do I run to check my current Python version before modifying my Dockerfile?',\n",
       "  'What action should I take in my Dockerfile if my installed Python version differs from the one specified?'],\n",
       " 'a4d3b1e5': [\"What should I do if running 'pipenv install sklearn==1.0.2' results in errors?\",\n",
       "  'Why did the facilitator use sklearn version 0.24.1 during the lectures instead of 1.0.2?',\n",
       "  'How can I successfully install scikit-learn version 1.0.2 in my virtual environment?',\n",
       "  'I need to install scikit-learn version 1.3.1 for my homework. What command should I use?',\n",
       "  'What is the full name I should use to install scikit-learn to avoid errors?'],\n",
       " '1d462fe0': ['What happens to the docker images if we use the --rm flag when running containers?',\n",
       "  'Why is it considered a best practice to avoid abandoning docker images on our system?',\n",
       "  'Can you explain the difference between a docker image and a docker container?',\n",
       "  'What command can I use to view all the images that I have pulled or built so far in Docker?',\n",
       "  'How does the use of --rm benefit our development and testing process with docker containers?'],\n",
       " '366d7563': ['What is the correct name for the Dockerfile when creating it?',\n",
       "  'Why does adding an extension to the Dockerfile cause an error?',\n",
       "  \"What happens if I name my Dockerfile 'Dockerfile.dockerfile'?\",\n",
       "  'How should the Dockerfile be formatted to avoid issues during image build?',\n",
       "  'Can you explain the importance of not having an extension for the Dockerfile?'],\n",
       " 'cef156d1': ['How can I install Docker on my Mac?',\n",
       "  'Is there a specific installation guide for MacOS users?',\n",
       "  'Where can I find instructions for installing Docker on a Mac?',\n",
       "  \"Do I need to know about my Mac's chip type before installing Docker?\",\n",
       "  'What are the system requirements for installing Docker on MacOS?'],\n",
       " 'b632d2ea': ['What should I do if I encounter an error when using the docker pull command for an image?',\n",
       "  \"Why am I getting a 'manifest unknown' error when trying to pull the docker image?\",\n",
       "  \"What is the reason for the 'default tag: latest' message when I attempt to pull the docker image?\",\n",
       "  'Can you explain how to specify the correct tag when pulling a docker image?',\n",
       "  'What is the correct command to pull the svizor/zoomcamp-model image with the proper tag?'],\n",
       " '514e27bb': ['How can I retrieve the size of a specific Docker image instead of all images?',\n",
       "  'Is there a command to show only the size information for a given Docker image?',\n",
       "  'What are the commands to list all local Docker images in Docker?',\n",
       "  'Can I use formatting options to simplify the output for a specific image?',\n",
       "  'What is the alternative command to dump information for a specified image in Docker?'],\n",
       " '5c67e086': ['What is the directory where pipenv creates environments on OSX/Linux systems?',\n",
       "  'How can I find the name of the environment created by pipenv?',\n",
       "  'What is the path format for a pipenv environment on Windows?',\n",
       "  'If I run a pipenv command in a specific project folder, how will this affect the environment name?',\n",
       "  'What do I need to do to activate the environment created by pipenv after it has been set up?'],\n",
       " '63a81b57': ['What command should I use to start a Docker container in interactive mode with bash?',\n",
       "  'How can I find the container ID of a running Docker container?',\n",
       "  'What is the purpose of overriding the entrypoint in a Docker container?',\n",
       "  'If my Docker container is running, how can I execute a bash command inside it?',\n",
       "  'Who provided the information on debugging Docker containers?'],\n",
       " '047f57fb': ['What command should I use to run Docker in interactive mode without encountering the input device not being a TTY error?',\n",
       "  'How can I resolve the issue with the input device not being a TTY when using Mintty for Docker?',\n",
       "  \"What is the purpose of the 'winpty' prefix when executing Docker commands in Git Bash?\",\n",
       "  'Can you explain what a TTY is and why it is relevant when running Docker commands?',\n",
       "  'Where can I find more information about terminal, shell, and console applications?'],\n",
       " '11f7371c': ['What does the error message \\'failed to compute cache key: \"/model2.bin\" not found\\' indicate when deploying models?',\n",
       "  'In what situation did you encounter the error related to model2.bin while using Docker?',\n",
       "  'What was your initial assumption regarding the existence of model2.bin when you faced the error?',\n",
       "  'What temporary solution did you find to resolve the issue with loading model2.bin?',\n",
       "  'How does using \\'COPY [\"*\", \"./\"]\\' differ from specifically copying model2.bin and dv.bin?'],\n",
       " '45f39b76': ['How can I resolve the issue of not being able to write dependencies to the pipfile and piplock file?',\n",
       "  'What command should I use to create a virtual environment for deploying my machine learning models?',\n",
       "  'Is there a way to write the required packages to a text file easily?',\n",
       "  'What command will I need to run after creating a virtual environment to manage my project dependencies?',\n",
       "  'Can you clarify the steps necessary to handle dependency management in my project?'],\n",
       " '94e17563': ['What could be the reason for the error I receive after importing pickle when using f-strings?',\n",
       "  'How should I correctly format my f-string to avoid errors related to variable C?',\n",
       "  'What is the correct syntax for the pickle.dump function when saving a model?',\n",
       "  'Why did I encounter an error when my f-string used parentheses instead of curly braces?',\n",
       "  'What should I remember about parentheses when using pickle to avoid syntax errors?'],\n",
       " '9dd8efd2': [\"What does it mean if I see an error stating that 'pipenv' is not recognized when I try to use it?\",\n",
       "  'Why might I encounter an error indicating that pipenv cannot be accessed from my path?',\n",
       "  'What steps should I follow to resolve the issue of pipenv not being recognized on my Windows system?',\n",
       "  'Is the solution to my pipenv issue different if I am using Anaconda instead of a standard installation?',\n",
       "  \"What path locations need to be checked or added to fix the 'pipenv' command error on my computer?\"],\n",
       " '9531dc92': ['What is the error message related to the collections module that I might encounter during deployment?',\n",
       "  'According to the video in week 5.6, what should I ensure about my Python version to avoid installation issues?',\n",
       "  'What Python version was recommended in the very first lesson of the zoomcamp to prevent the AttributeError?',\n",
       "  'What should I use instead of python==3.10 to resolve the installation error when using pipenv?',\n",
       "  'Who contributed the solution regarding the Python version for the deployment error?'],\n",
       " '14e0e697': [\"What should I do after I enter the command 'pipenv shell' to avoid errors when trying to install packages?\",\n",
       "  'How can I check if I am currently in the pipenv shell on a Windows system?',\n",
       "  'What terminal command can I use to fix the PATH issue related to a missing VIRTUAL_ENV on Windows?',\n",
       "  'Is there a way to manually restore a removed virtual environment folder if it is missing?',\n",
       "  'What specific location should I check to find the removed environment name causing the ValueError?'],\n",
       " '6189375f': ['What should I do if I encounter a ConnectionError when deploying my model?',\n",
       "  'How can I resolve a RemoteDisconnected error during deployment?',\n",
       "  'What host setting is recommended for the Flask app when using Docker?',\n",
       "  'Is it necessary to run the URL on localhost after making changes to the Flask app?',\n",
       "  'Who provided the solution for the deployment connection issue?'],\n",
       " '3419ee27': ['What is the reason for the docker build error related to COPY?',\n",
       "  'How can I fix the docker build error when using single quotes?',\n",
       "  'What type of quotes should I use around filenames to avoid the error?',\n",
       "  'Are there specific tips for resolving docker COPY errors during model deployment?',\n",
       "  'What common mistakes should I avoid when deploying machine learning models with Docker?'],\n",
       " '8b8c1603': ['What should I do if I encounter an error while installing the Pipfile in my Docker container?',\n",
       "  'Is there a specific command I can use to update the Pipfile.lock when using Pipenv?',\n",
       "  \"What alternative method can I try if updating the Pipfile.lock doesn't solve the installation issue?\",\n",
       "  'Can you provide a recommended command to use for Pipenv installation within a Docker container?',\n",
       "  'How can I bypass the Pipfile when deploying with Pipenv in a Docker setup?'],\n",
       " 'e54d5411': ['What should I do if I encounter an error after executing the Docker run command?',\n",
       "  'Why was there an issue when trying to remove the orphan container?',\n",
       "  'What specific commands need to be run to list Docker containers and images?',\n",
       "  'How can I stop and remove a Docker container that is causing issues?',\n",
       "  'What steps did the individual take to successfully rebuild and run the Docker image?'],\n",
       " 'f7b38587': [\"What does the error message 'Bind for 0.0.0.0:9696 failed: port is already allocated' indicate when deploying a model?\",\n",
       "  \"Why did I encounter the 'port is already allocated' error after rebuilding my Docker image if the port seemed available?\",\n",
       "  'How can I resolve the issue of Docker failing to allocate the specified port during the deployment of a machine learning model?',\n",
       "  'What command can I execute to potentially fix the error related to port allocation in Docker?',\n",
       "  'Where can I find more information if I continue to experience port allocation issues with Docker?'],\n",
       " 'be86b333': ['What error might I encounter when binding to 127.0.0.1:5000?',\n",
       "  'What kind of error is thrown on the client side in case of a connection issue?',\n",
       "  'How does the gunicorn server respond when there is a binding problem?',\n",
       "  'What works well on the server side when gunicorn shows an error?',\n",
       "  'What IP addresses should I use to avoid binding errors in most cases?'],\n",
       " '4ea80460': ['How can I install md5sum on my MacOS system?',\n",
       "  'What command should I use to verify the hash of a file?',\n",
       "  'Is there a specific package manager required to install md5sum on MacOS?',\n",
       "  'What command do I run to compare the hash values of two files?',\n",
       "  'Who provided the information about installing md5sum?'],\n",
       " '8006b496': ['What steps should I follow to run a script while my web server is active?',\n",
       "  'In what environment can I initiate a web server for my project?',\n",
       "  'Is it possible to execute another Python script while the server is running?',\n",
       "  'Do I need to open a new terminal to run a script that communicates with the server?',\n",
       "  'Who can I contact for further questions about deploying machine learning models?'],\n",
       " '704f95d8': ['What warning do I receive when running pipenv shell and gunicorn in video 5.5?',\n",
       "  'What might happen if I try to unpickle the DictVectorizer using different versions?',\n",
       "  'What version of Scikit-Learn should I use for creating a virtual environment?',\n",
       "  'Why is it important to match the version of Scikit-Learn with the version used for training?',\n",
       "  'What should I do to avoid version conflicts in my model and DV files during deployment?'],\n",
       " 'a5b3296b': ['What should I do if I encounter a ValidationError related to python_version and python_full_version after running pipenv install?',\n",
       "  \"How can I resolve the error that states 'python_full_version must not be present with python_version' during package installation?\",\n",
       "  'What steps do I need to follow to fix issues related to conflicting Python version specifications in my Pipfile?',\n",
       "  'After making changes to the Pipfile regarding python_version and python_full_version, what command should I run next?',\n",
       "  'If I successfully edit my Pipfile to correct the Python version error, what should I do to resume my work?'],\n",
       " 'a23b276a': ['What should I do if I encounter an error indicating that my Pipfile.lock is out of date during the Docker build process?',\n",
       "  \"Can you provide a solution for updating my Pipfile.lock file when it's not in sync?\",\n",
       "  'What commands do I need to run to remove my pipenv environment and start fresh if the docker build command still fails?',\n",
       "  'If my Pipfile.lock is out of date, is there a way to quickly rebuild it before attempting to build my Docker image again?',\n",
       "  'What specific steps should I take to resolve the error message that mentions an expected but out-of-date Pipfile.lock during deployment?'],\n",
       " '3537eeee': ['What should I do if the mlflow server stops running after using waitress in my Windows conda environment?',\n",
       "  'Is it necessary to uninstall waitress if I encounter issues with the mlflow server?',\n",
       "  'After uninstalling waitress, what do I need to reinstall to fix the mlflow server issue?',\n",
       "  \"If I've already built my docker image, do I need to reinstall waitress after fixing mlflow?\",\n",
       "  'What are the steps to ensure that my mlflow server runs successfully after encountering issues?'],\n",
       " '1d6d5b51': [\"What should I check if I can't find my created environment on AWS?\",\n",
       "  'Is there a specific AWS region I need to be in for my environment?',\n",
       "  \"What do I do if I'm in a different region than eu-west-1?\",\n",
       "  'How can I verify the location of my environment in the console?',\n",
       "  'Why is my environment not visible outside of the eu-west-1 region?'],\n",
       " '3a98b6b7': [\"What should I do if the 'waitress-serve' command is not found in GitBash after installation?\",\n",
       "  'How can I properly install waitress on Windows when using GitBash?',\n",
       "  \"What steps should I take to ensure the 'waitress-serve.exe' file is downloaded successfully?\",\n",
       "  'What warning might I encounter when installing waitress through a Jupyter notebook?',\n",
       "  \"How do I add the directory of 'waitress-serve.exe' to my GitBash PATH?\"],\n",
       " 'd42eb923': ['What does the warning about the environment variable LANG indicate when deploying machine learning models?',\n",
       "  'Is the warning regarding the LANG variable critical, or can I ignore it while working in the conda environment?',\n",
       "  'What specific version of Scikit-Learn should I install using Pipenv for this course?',\n",
       "  'Where can I find a quick solution for the LANG variable warning that appears during model deployment?',\n",
       "  'Can I continue with my work in the ml-zoomcamp conda environment despite the LANG variable warning?'],\n",
       " '42aebe10': ['What resources are included in the image for question 6 of the homework?',\n",
       "  'Which specific files should I utilize for the model and dictvectorizer in this task?',\n",
       "  'Can you clarify the source of the image mentioned in the homework?',\n",
       "  'Who provided the information regarding the files needed for this assignment?',\n",
       "  'What version of the image should I refer to for question 6?'],\n",
       " 'e4f62713': ['What terminal software is shown in the videos for Week 5?',\n",
       "  'Can you provide a link to the terminal used in the Week 5 instructional content?',\n",
       "  'What tool is recommended for deployment in the Week 5 videos?',\n",
       "  'Is there a specific terminal featured in the videos from Week 5 of the course?',\n",
       "  'Where can I find the Windows terminal discussed in the Week 5 resources?'],\n",
       " 'c13d811f': [\"What does the error message 'Malformed application' indicate when using waitress-serve?\",\n",
       "  'What command triggers the ValueError related to the app import?',\n",
       "  \"Why doesn't Waitress accept a dash in the filename for the machine learning model?\",\n",
       "  'What is the suggested method to correct the error when importing the module?',\n",
       "  'Can you give an example of how to rename the file to resolve the issue?'],\n",
       " 'dfb41f7e': ['How can I quickly verify if my HTTP POST requests are functioning properly from the command line?',\n",
       "  'Is there a specific tool I can use to test HTTP POST requests without additional software?',\n",
       "  'What operating systems support running curl for checking HTTP POST requests?',\n",
       "  'Can you give an example of how to use curl with JSON data in a POST request?',\n",
       "  'What are some alternative methods to send JSON data in HTTP POST requests from the command line?'],\n",
       " 'd04e77f8': ['What does the NotSupportedError indicate when trying to run eb local?',\n",
       "  'How can I resolve the NotSupportedError when using eb local?',\n",
       "  'What command should I use to re-initialize and select the docker platform options?',\n",
       "  'What file do I need to edit to change the default platform to Amazon Linux 2023?',\n",
       "  'What is the potential downside of directly editing the config.yml file?'],\n",
       " '451c067f': [\"What should I do if I encounter a 'No connection adapters were found' error while trying to make a request to my machine learning model?\",\n",
       "  'Could you explain why requests require a protocol scheme when connecting to a server?',\n",
       "  'Is it possible to use uppercase letters in the protocol scheme when forming a request URL?',\n",
       "  \"What exactly does the error message indicate about my request to 'localhost:9696/predict'?\",\n",
       "  'How can I ensure that my request URL is correctly formatted for successful connections?'],\n",
       " '9fbfcd61': [\"What should I check if I'm getting the same results while using the docker image?\",\n",
       "  'How can I ensure that I am using the correct model during my prediction test?',\n",
       "  'Is there anything specific about the model and Python version that I need to remember?',\n",
       "  'What should I do if I want to change the model in my file?',\n",
       "  'Who provided the information related to deploying machine learning models?'],\n",
       " '1ed8cfde': ['What steps should I follow to run my Docker image successfully?',\n",
       "  'How can I confirm that all necessary modules are installed for my container?',\n",
       "  'Is there a specific tool I need to use for module installation in my project?',\n",
       "  'What is the importance of using pipenv when working with Docker images?',\n",
       "  'Could you explain how to utilize pipenv shell for my Docker setup?'],\n",
       " '3f97f50f': ['What command should I use to transfer files from my local machine to a Docker container?',\n",
       "  'Can you explain the syntax for copying files into a running Docker container?',\n",
       "  \"Is there a specific command like 'docker cp' to move directories as well as files to a container?\",\n",
       "  'What is the proper format for specifying the container ID when using the docker cp command?',\n",
       "  'Are there any restrictions or specifics I should be aware of when using the docker cp command?'],\n",
       " 'a24a874a': ['What command should I use to transfer files from my local machine to a Docker container?',\n",
       "  'How can I specify the source folder when copying files into a Docker container?',\n",
       "  'What is the syntax for copying multiple files at once into a Docker container?',\n",
       "  'Is there a way to define the destination path when using the Dockerfile for copying files?',\n",
       "  'Can I copy specific files into the working directory of a Docker container directly?'],\n",
       " 'bf563b1f': ['What command should I use to initialize my AWS Elastic Beanstalk environment for a Docker application?',\n",
       "  \"What error message might I encounter when running the command 'eb local run' on AWS Elastic Beanstalk?\",\n",
       "  \"Why might I be unable to use the 'eb local' command with the original Docker platform configuration?\",\n",
       "  'What specific Docker platform configuration worked for successfully recognizing the Dockerfile?',\n",
       "  'In which AWS region should I set up my tumor-diagnosis-serving application according to the FAQ?'],\n",
       " '21e9facf': ['What should I do if I encounter an error regarding missing Dockerfile when creating an AWS ElasticBean environment?',\n",
       "  \"How do I resolve the issue of both 'Dockerfile' and 'Dockerrun.aws.json' being absent during deployment?\",\n",
       "  'What steps did you take after getting the docker error with the eb create command?',\n",
       "  'Why did the deployment fail when I tried to create the tumor-diagnosis-env?',\n",
       "  'What files need to be committed before running the eb create command successfully?'],\n",
       " 'aef786aa': ['What resources do I need to begin Week 6 assignments?',\n",
       "  'Where can I find all the homework assignments for this course?',\n",
       "  'Is there a specific GitHub link for the solution of Homework 4?',\n",
       "  'How can I access the evaluation matrix for my assignments?',\n",
       "  'Where can I find the YouTube link for the Week 6 lecture?'],\n",
       " '68858294': ['What method can I use to retrieve training and validation metrics from XGBoost without complex steps?',\n",
       "  'Is there a simpler way to obtain the auc values during the XGBoost lesson?',\n",
       "  'How can I store the training and validation results for easier visualization while using XGBoost?',\n",
       "  'What parameters do I need to utilize in XGBoost for capturing the evaluation results?',\n",
       "  'Can you explain the process of using a dataframe for plotting metrics obtained from XGBoost?'],\n",
       " '85ac722e': ['What object should I create in scikit-learn to address regression issues using random forest?',\n",
       "  'How is the RandomForestRegressor different from the RandomForestClassifier in scikit-learn?',\n",
       "  'Where can I find additional details on using RandomForestRegressor for regression tasks?',\n",
       "  'Is the approach for solving regression problems with random forest similar to that of classification problems?',\n",
       "  'What library do I need to import for using RandomForestRegressor in Python?'],\n",
       " 'b61d2e92': ['What specific error did you encounter when creating DMatrix for the train and validation datasets?',\n",
       "  'Can you explain why the feature names in DMatrix need to be strings and what special characters should be avoided?',\n",
       "  'What was the method employed to resolve the ValueError related to feature names?',\n",
       "  'Is there an alternative solution to fix the issue with feature names that contain special characters?',\n",
       "  'How did Peter Ernicke address the feature name issue differently than Asia Saeed?'],\n",
       " '8d7392cb': [\"What does the error mean when I see 'TypeError: Expecting a sequence of strings for feature names, got: <class 'numpy.ndarray'>' while training my xgboost model?\",\n",
       "  'How can I fix the issue of feature names being a numpy.ndarray instead of a list in my xgboost model?',\n",
       "  'Is there a specific method I should use to convert the feature names to a list when training an xgboost model?',\n",
       "  'What data type should my feature names be in order to avoid the TypeError related to the xgboost model?',\n",
       "  'Could you explain the steps to properly format feature names for use in an xgboost model?'],\n",
       " 'c920eef3': ['What should I do if I encounter a TypeError related to feature names when using xgb.DMatrix?',\n",
       "  'How can I convert the output from dv.get_feature_names_out() to a compatible format for xgb.DMatrix?',\n",
       "  'What does it mean if I receive a ValueError indicating that feature_names must be strings and contain invalid symbols?',\n",
       "  'What steps can I take to resolve issues with feature names when they include symbols like [] or <?',\n",
       "  \"Is there a way to avoid specifying 'feature_names=' when creating an xgb.DMatrix to prevent errors?\"],\n",
       " '5017c9a4': ['What is the required version of pip to install Xgboost?',\n",
       "  'Can you provide the installation command for Xgboost in Jupyter Notebook?',\n",
       "  'How can I update my pip to the latest version?',\n",
       "  'Where can I find more information about Xgboost installation?',\n",
       "  'Is there a specific platform or environment in which Xgboost should be installed?'],\n",
       " '6ffe101d': ['What role does the learning rate play in XGBoost models?',\n",
       "  'How does gradient descent relate to the hyperparameters in XGBoost?',\n",
       "  'Why is it important to tune the learning rate when training the model?',\n",
       "  'Can you explain how eta influences the optimization of weights in XGBoost?',\n",
       "  'What happens when you adjust the learning rate in the training process?'],\n",
       " 'a55b29ff': ['Can you explain how bagging works and what its main advantages are?',\n",
       "  'What is the primary difference in the training process between Random Forest and XGBoost?',\n",
       "  'How does boosting address the mistakes made by previous models in the sequence?',\n",
       "  'What are the implications of using bagging regarding variance and overfitting?',\n",
       "  'Why might boosting be considered more accurate than bagging, and what is the potential downside?'],\n",
       " 'eac70ce3': ['How can I capture stdout for each iteration of a loop separately without running the cell multiple times?',\n",
       "  \"What is the purpose of using the magic command '%%capture output' when trying to capture output?\",\n",
       "  'Is there a specific code sample that illustrates how to capture the output from multiple runs in a dictionary?',\n",
       "  \"Can you explain how the 'capture_output' function is used within a loop for output capture?\",\n",
       "  'What would the final structure of the dictionary look like after capturing outputs for different iterations?'],\n",
       " '5f91f8ca': ['What error might I encounter when using roc_auc_score() for AUC calculation?',\n",
       "  'How should I correctly organize the arguments when calling roc_auc_score()?',\n",
       "  'What are the required parameters to pass into the roc_auc_score() function?',\n",
       "  'In what order do I need to provide the actual and predicted values to avoid errors?',\n",
       "  'Who provided the solution to the ValueError related to continuous format in roc_auc_score()?'],\n",
       " 'a3be507a': ['In the context of homework 6, if I notice that the RMSE increases after a specific number of n_estimators but decreases again afterwards, which value should I report?',\n",
       "  'When analyzing the RMSE behavior, does it indicate that I should stop looking for improvements when it no longer decreases significantly?',\n",
       "  'For Question 3 of homework 6, should I focus on the first point of RMSE increase or the lowest overall value when deciding on n_estimators?',\n",
       "  'Can you clarify what it means for RMSE to stop improving and how that affects my choice of n_estimators?',\n",
       "  'In relation to the homework, does the overall trend of RMSE changes dictate the optimal number of n_estimators I should select?'],\n",
       " '9a8faa50': ['How can I effectively visualize decision trees using Python?',\n",
       "  'What are some methods to export decision tree data for visualization?',\n",
       "  'Can you explain how to use Graphviz for rendering decision trees?',\n",
       "  'In which format can the output of the decision tree visualization be generated?',\n",
       "  'What Python libraries are recommended for working with decision trees?'],\n",
       " 'a6e384fe': [\"What should I do if I encounter a ValueError related to 'unknown label type: continuous'?\",\n",
       "  'How do I know whether to use DecisionTreeClassifier or DecisionTreeRegressor?',\n",
       "  'What could be the reason for my model throwing a ValueError during training?',\n",
       "  'Are there specific scenarios where I should choose classification over regression for decision trees?',\n",
       "  'What is the main difference between using a DecisionTreeClassifier and a DecisionTreeRegressor?'],\n",
       " 'ddc14ada': ['Why do I see varying AUC values every time I execute the DecisionTreeClassifier code on my laptop?',\n",
       "  'What could be the reason behind the AUC results changing with each kernel restart in Jupyter?',\n",
       "  'Can you explain how using a random seed might affect the results of the DecisionTreeClassifier?',\n",
       "  'What specific values did the AUC take during my multiple runs of the model in the provided example?',\n",
       "  'Where can I find more information on setting the random seed for consistent results in machine learning models?'],\n",
       " '593f7569': ['Is there a difference between creating the server in the Python file and running gunicorn directly?',\n",
       "  \"Will using one method over the other affect the server's performance?\",\n",
       "  'Is there a recommended approach for server creation in our course?',\n",
       "  'How does the typing in the script change based on the method used?',\n",
       "  'Is there a preference between the two methods for handling server creation?'],\n",
       " '6cb56405': [\"What should I do if I encounter a 'No module named ping' error while running an example from the video?\",\n",
       "  \"How can I successfully import the 'ping' function if the standard import statement does not work?\",\n",
       "  \"Can you explain the steps I need to take to resolve the issue with importing the 'ping' function?\",\n",
       "  \"What is the correct way to import a function named 'ping' from my file if the direct import fails?\",\n",
       "  \"Is there a specific statement I should use to import 'ping' if my initial attempt is unsuccessful?\"],\n",
       " 'a22a93f1': ['What function does DictVectorizer provide to obtain feature names?',\n",
       "  'How can I analyze feature importance using the DictVectorizer?',\n",
       "  'What is the return type of the get_feature_names_out() function?',\n",
       "  'Do I need to convert the output of get_feature_names_out() for certain uses?',\n",
       "  'Is it necessary to fit the predictor and response arrays before accessing feature names?'],\n",
       " 'b6259dea': ['What causes the ValueError regarding feature names in decision trees?',\n",
       "  'How can I resolve the issue with unsupported characters in feature names?',\n",
       "  'Is there a specific method to create a list of features without special characters?',\n",
       "  'What characters should I avoid including in my feature names for ensemble learning?',\n",
       "  'Can you provide an example of how to replace problematic characters in feature names?'],\n",
       " 'bcfdc6f4': ['How can I visualize the importance of features in my model using a chart?',\n",
       "  'What steps do I need to follow to extract and sort feature importances?',\n",
       "  'What libraries or functions are suggested for creating a horizontal bar chart to display feature importance?',\n",
       "  'Can you explain the process of creating a DataFrame from feature importances?',\n",
       "  'What do I need to include in my chart to effectively show feature significance?'],\n",
       " 'a7e7cdd2': ['How can I calculate RMSE without using np.sqrt()?',\n",
       "  'Is there an alternative method to get RMSE in this course?',\n",
       "  'What function can I use to directly obtain RMSE from predictions?',\n",
       "  'Can you explain how to extract RMSE without a square root step?',\n",
       "  'Who provided the information on calculating RMSE in our course?'],\n",
       " '55477da8': ['Can you recommend a resource for visualizing feature importance in decision trees?',\n",
       "  'How does the features importance graph contribute to model explainability?',\n",
       "  'Where can I find an example of feature importance implementation in scikit-learn?',\n",
       "  'What additional information does the features importance graph provide about stability?',\n",
       "  'Why is tracing the stability of features important for a model?'],\n",
       " '6a245a05': ['What does the XGBoostError message indicate about the required dependencies?',\n",
       "  'How can I resolve the xgboost.core.XGBoostError I encountered?',\n",
       "  'Is there a specific library I need to install for using XGBoost?',\n",
       "  'What must be included in the requirements to avoid the XGBoost error?',\n",
       "  'Who provided the information regarding the XGBoost error and its resolution?'],\n",
       " '4405bfca': ['What is the meaning of information gain in relation to variables X and Y?',\n",
       "  'How does one measure the mutual information between Y and X?',\n",
       "  'What does it imply if X does not provide any information about Y?',\n",
       "  'What does it mean if X is fully informative about Y?',\n",
       "  'Can you explain the concept of entropy in the context of information gain?'],\n",
       " '3e0acc25': ['What issues arise from filling in missing values before dataset splitting?',\n",
       "  'Why is it problematic to use the entire dataset for imputation prior to division?',\n",
       "  'How does data leakage occur in the context of missing value treatment?',\n",
       "  'Can you explain the risks associated with pre-splitting data imputation?',\n",
       "  'What is the consequence of addressing missing values using the whole dataset first?'],\n",
       " 'abaecdf8': ['What is the recommended method for saving a model in Xgboost?',\n",
       "  'How can I load a saved model in the context of Xgboost?',\n",
       "  'Who is mentioned in the section regarding the loading of models?',\n",
       "  'Where can I find information related to the models after they have been saved?',\n",
       "  'Is there any specific function I should use to save the model in Xgboost?'],\n",
       " 'ff40f83b': ['What steps should I follow to begin with Week 8 of the course?',\n",
       "  'Is there any specific material we need to review before starting Week 8?',\n",
       "  'When will additional resources be available for Week 8?',\n",
       "  'How can I prepare for the content covered in Week 8?',\n",
       "  'Are there any prerequisites I need to complete before tackling Week 8?'],\n",
       " '95a16746': ['What steps are necessary to utilize Kaggle for Deep Learning projects?',\n",
       "  'How can I import my notebook into Kaggle for use?',\n",
       "  'What should I do after accessing my notebook in Kaggle?',\n",
       "  'Which type of GPU should I select for optimal deep learning performance?',\n",
       "  'Who provided the guidelines for using Kaggle for Deep Learning?'],\n",
       " '46acdd18': ['What are the initial steps to get started with Google Colab for Deep Learning projects?',\n",
       "  'How can I select the appropriate hardware settings in Google Colab?',\n",
       "  'Which GPU type should I choose for optimal performance in Deep Learning?',\n",
       "  'What is the process for importing an existing notebook into Google Colab?',\n",
       "  'Is there a specific location in the Colab interface where I can change runtime settings?'],\n",
       " 'f721d54b': ['What are the steps to connect my GPU on Saturn Cloud to a GitHub repository if I prefer automation?',\n",
       "  'Is it necessary to connect my Saturn Cloud account to GitHub to work on my projects?',\n",
       "  'Can you explain how to use the default public keys provided by Saturn Cloud for GitHub authentication?',\n",
       "  'Where can I find the Git SSH keys section to manage my keys in Saturn Cloud?',\n",
       "  'What command should I run in the terminal on Saturn Cloud to check my GitHub authentication status?'],\n",
       " '69cd4897': ['What is the current location of the Python TensorFlow template on Saturn Cloud?',\n",
       "  'How can I find the Python Deep Learning tutorials on Saturn Cloud?',\n",
       "  'Is the location of the TensorFlow template in video 8.1b still accurate?',\n",
       "  'Where should I look on the Saturn Cloud home page for deep learning resources?',\n",
       "  \"Who provided the information regarding the template's new location for TensorFlow?\"],\n",
       " '346e799a': [\"What should I do if I encounter an error indicating that the module scipy is not found during model training in Saturn Cloud's tensorflow image?\",\n",
       "  'How can I ensure that the scipy package is installed when creating a Jupyter server resource in Saturn Cloud?',\n",
       "  'Is there a way to automatically install additional Python packages when setting up a Jupyter server on Saturn Cloud?',\n",
       "  'Where can I find the section to add extra packages while creating a Jupyter server resource in Saturn Cloud?',\n",
       "  'What command should I expect to see below the textbox for adding extra packages during Jupyter server creation?'],\n",
       " '551461b2': ['What steps should I follow to upload Kaggle datasets to Saturn Cloud efficiently?',\n",
       "  'How do I set up my Kaggle API token for use in Saturn Cloud?',\n",
       "  'What command do I need to run after uploading the kaggle.json file?',\n",
       "  'How can I download a specific dataset from Kaggle using a command in my notebook?',\n",
       "  'What should I do with the downloaded zip file after retrieving a dataset from Kaggle?'],\n",
       " 'c3ba4459': ['What is the requirement for running TensorFlow with GPU on my local machine?',\n",
       "  'Can you provide a simplified guide for setting up CUDA and cuDNN?',\n",
       "  'Is it necessary to install CUDA and cuDNN for TensorFlow on Ubuntu 22.04?',\n",
       "  'Who can I refer to for help with installing CUDA and cuDNN?',\n",
       "  'What specific versions of CUDA and cuDNN do I need for TensorFlow?'],\n",
       " 'a114ad55': ['What should I do if I encounter a ValueError when trying to load weights in HDF5 format into my subclassed Model?',\n",
       "  'Why am I getting an error indicating that the Model has not created its variables yet when attempting to load weights?',\n",
       "  'Can you explain the necessary step I must take before I can successfully load weights into my subclassed Model?',\n",
       "  'What does the error message suggest I do before loading the model to avoid the ValueError?',\n",
       "  'Is there a specific function I need to call on my model before loading weights saved in HDF5 format?'],\n",
       " 'dd3c8000': [\"What should I do if I encounter a 'permission denied' error while connecting git on Saturn Cloud?\",\n",
       "  \"How can I fix the issue when running 'ssh -T git@github.com' leads to an error?\",\n",
       "  'Is there an alternative method to set up git in the Saturn Cloud environment?',\n",
       "  'What steps should I follow to generate an SSH key in Saturn Cloud for git access?',\n",
       "  'Where can I find detailed instructions for managing git through Saturn’s Jupyter server?'],\n",
       " '34b0ebfc': ['What should I do if I encounter a host key verification error when trying to clone a GitHub repository?',\n",
       "  'Is there a specific command I should use to successfully clone the clothing dataset repository?',\n",
       "  'What does the error message indicate about my access rights to the repository?',\n",
       "  'Why does the host key verification failure occur when cloning a repository with SSH?',\n",
       "  'Can I use an alternative method to clone the repository if I have issues with SSH?'],\n",
       " '7d11d5ce': ['What does it mean if accuracy remains unchanged during training epochs?',\n",
       "  'How can I resolve the issue of constant accuracy and loss while training?',\n",
       "  'What specific setting should I use for class_mode when reading data for my homework?',\n",
       "  'Why might the choice of optimizer, batch size, or learning rate affect training outcomes?',\n",
       "  'What should I do if my training results in unchanged accuracy and loss?'],\n",
       " 'e4e45f15': ['What should I do if my model experiences high loss and low accuracy after augmentation?',\n",
       "  'Why does my model show a loss of over 1000 when I resume training?',\n",
       "  \"How can I improve my model's performance after using augmented data?\",\n",
       "  'What settings should I verify in ImageDataGenerator to address model issues post-augmentation?',\n",
       "  'Is there a specific option I need to check in the ImageDataGenerator for proper rescaling?'],\n",
       " 'b3997e6f': [\"What should I do if I encounter a 'Missing channel value' error when loading my model with TensorFlow?\",\n",
       "  'Why am I getting a ValueError related to the channel dimension when executing the load_model function?',\n",
       "  'What happens if the number of channels is not defined in the Input layer of my model?',\n",
       "  'How can I ensure that the model architecture retains the channel dimension information when saving?',\n",
       "  'What changes do I need to make in the model architecture code to avoid issues with undefined channel dimensions?'],\n",
       " 'e414df91': ['What is the issue encountered when unzipping a dataset in a Jupyter notebook using the unzip command?',\n",
       "  'How can I suppress the output messages generated during the unzipping process in a Jupyter notebook?',\n",
       "  'What command should I use in a Jupyter notebook to unzip a folder while avoiding excess output?',\n",
       "  'Can you explain the steps to extract files from a zipped folder using the zipfile module in Jupyter?',\n",
       "  'What are the commands needed to unzip a dataset and store it in a specified destination folder?'],\n",
       " 'f20a3479': ['How does keras flow_from_directory determine the class names of images when processing directories?',\n",
       "  'Is the class name derived from the folder name in which the images are stored?',\n",
       "  \"What happens if I create a folder with a random name like 'xyz' for my images?\",\n",
       "  'Can you explain how flow_from_directory assigns class labels based on folder names?',\n",
       "  'Is there any additional mechanism at play when using flow_from_directory with multiple classes?'],\n",
       " 'e7af4968': ['What should I do if I encounter an error related to a missing scipy module while using SaturnCloud?',\n",
       "  'I created a new environment in SaturnCloud and am getting an error about scipy. How can I resolve this issue?',\n",
       "  'If I select the Tensorflow image in SaturnCloud but face a module error, what steps should I take?',\n",
       "  'Could you provide a solution for addressing the scipy missing module error when fitting my model?',\n",
       "  'After installing scipy in SaturnCloud, what is the next step to ensure my model fits correctly?'],\n",
       " '9fad096e': ['How does the alphabetical order of folders affect numeric class labels when using flow_from_directory in binary class mode?',\n",
       "  'What does the single probability output from a binary Keras model represent when predicting labels?',\n",
       "  'In a scenario with two folders named dino and dragon, what class label does each folder correspond to?',\n",
       "  \"How can I determine the probability of class 0 given the model's prediction for class 1?\",\n",
       "  'What are the implications of using from_logits in terms of the output values for label predictions?'],\n",
       " 'bcdf7407': ['Do the predicted values from a neural network need to be precise, or is some variation acceptable?',\n",
       "  'When using a neural network, how important is the accuracy of the predicted values?',\n",
       "  'Should we consider minor discrepancies in predictions as normal when working with neural networks?',\n",
       "  'Is it the case that after predicting with a neural network, slight changes in values are to be expected?',\n",
       "  'Can we treat neural network predictions more like probabilities rather than exact outcomes?'],\n",
       " '8d1e7e20': ['What should I do if the accuracy and standard deviation of my training loss differ from the homework results?',\n",
       "  'Could the optimizer be the reason for discrepancies in accuracy and training loss when running the model?',\n",
       "  'Is there a recommended platform for running the model if I am getting unexpected results on my laptop?',\n",
       "  'What runtime configuration should I use in Google Colab to improve model performance?',\n",
       "  'Did you notice any differences in results when you used different versions of the SGD optimizer?'],\n",
       " '2023a9dc': ['What parameter can I specify to use multi-threading during data generation in model.fit()?',\n",
       "  \"What is the default setting for the 'workers' parameter in model.fit()?\",\n",
       "  'How can I determine the optimal worker count for my data loading when using model.fit()?',\n",
       "  'Where can I find more information about the model.fit() method in TensorFlow?',\n",
       "  'Who added the information regarding multi-threading in the FAQ record?'],\n",
       " '468f69ff': ['How can I ensure reproducibility in my training runs with TensorFlow?',\n",
       "  'What instructions do I need to follow for reproducibility using TensorFlow?',\n",
       "  'Is there a specific seed value I need to set for reproducibility in TensorFlow?',\n",
       "  'Can you explain how to execute a script multiple times while maintaining reproducibility?',\n",
       "  'Where can I find the official TensorFlow documentation related to reproducibility and enabling operation determinism?'],\n",
       " 'c4ff26e5': ['Is it possible to use PyTorch for the upcoming lessons and homework assignments?',\n",
       "  'Are there resources available for creating a CNN in PyTorch?',\n",
       "  'Will the functions in PyTorch serve the same purpose as those in Keras?',\n",
       "  'Can I submit a pull request for my PyTorch projects related to the lessons?',\n",
       "  'What framework will be primarily used for the course assignments?'],\n",
       " '62722d72': ['What error might occur during Keras model training related to data adapters?',\n",
       "  'What could cause the error about failing to find a data adapter when training a Keras model?',\n",
       "  'How should I correctly use ImageDataGenerator while training my Keras model?',\n",
       "  'What are the correct variables to use for training and validation data in model.fit?',\n",
       "  'What is the suggested fix for the error encountered during Keras model training?'],\n",
       " 'd1419be1': [\"How can I run the command 'nvidia-smi' repeatedly without employing the 'watch' function?\",\n",
       "  \"Is there a specific command for executing 'nvidia-smi' at regular intervals?\",\n",
       "  \"What does the '-l' option do when used with 'nvidia-smi'?\",\n",
       "  \"How can I set 'nvidia-smi' to refresh its output every 2 seconds?\",\n",
       "  \"What command should I use to stop 'nvidia-smi' from running in a loop?\"],\n",
       " 'a5f6f439': ['What tool can I use to monitor both GPU and CPU usage interactively?',\n",
       "  \"How does 'nvitop' compare to traditional CPU monitoring tools?\",\n",
       "  \"Where can I find more information about the 'nvitop' package?\",\n",
       "  \"Is 'nvitop' a Python package or an application for monitoring resources?\",\n",
       "  \"Who contributed the information about using 'nvitop' in our course materials?\"],\n",
       " '879c1ec0': ['What parameters are involved in defining the Conv2D layer, specifically regarding the input shape and filter count?',\n",
       "  'How is the number of parameters for the Conv2D layer calculated, and what does each component of the calculation represent?',\n",
       "  'Can you explain how the output shape of the MaxPooling2D layer and the Flatten layer relates to the number of features?',\n",
       "  'What is the formula used to determine the number of features after applying the Flatten layer in the model?',\n",
       "  'What does the output shape of (None, 6272) indicate after the Flatten layer in terms of the data processed?'],\n",
       " '3ac604c3': ['What is the main difference between Sequential Model API and Functional Model API in Keras?',\n",
       "  'Can you explain how to build a model in Keras using the Sequential Model API?',\n",
       "  'Why is it recommended to perform a fresh run when correcting errors in neural network architecture?',\n",
       "  'In what scenarios might the Functional Model API be preferred over the Sequential Model API?',\n",
       "  'Where can I find a useful example of a Sequential model in Keras for reference?'],\n",
       " '0315aa96': ['What can I do to resolve out of memory errors when using TensorFlow on my Nvidia GPU?',\n",
       "  'Is there a specific code snippet that can help with OOM issues in TensorFlow?',\n",
       "  'Are the solutions for OOM errors on Nvidia GPUs applicable to CPU usage as well?',\n",
       "  'What is the purpose of setting memory growth in TensorFlow, and how can I implement it?',\n",
       "  'What error might I encounter if I try to modify virtual devices once they are initialized?'],\n",
       " 'daf84bc3': ['What can I do to improve the model training speed on the T4 GPU in Google Colab?',\n",
       "  'How many workers or threads should I set to optimize training performance in Google Colab?',\n",
       "  'Is the default value for the number of workers in Google Colab sufficient for efficient training?',\n",
       "  'Where can I find additional information or discussions about optimizing training on Google Colab?',\n",
       "  'What changes did you make to the workers variable to mitigate slow training on the T4 GPU?'],\n",
       " '1e956ca7': ['What is the recommended method for loading images in new code according to the Keras documentation?',\n",
       "  'Why is tf.keras.preprocessing.image.ImageDataGenerator not recommended?',\n",
       "  'What should I use instead of ImageDataGenerator for handling image data?',\n",
       "  'Where can I find tutorials related to loading and augmenting images?',\n",
       "  'What guides are available for understanding preprocessing layers in image loading?'],\n",
       " '3ee083ab': ['What steps should I follow to begin Week 9?',\n",
       "  'Are there specific resources I need for Week 9?',\n",
       "  'Can you provide guidance on what to focus on in Week 9?',\n",
       "  'Is there a checklist for getting started with Week 9?',\n",
       "  'When will the materials for Week 9 be available?'],\n",
       " 'f826cba4': ['How can I access the model required for week 9 of the course?',\n",
       "  'What is the new location for the week 9 model?',\n",
       "  'Is there a specific link to fetch the models for week 9?',\n",
       "  'Where should I go to find the GitHub link for the week 9 model?',\n",
       "  'Can you tell me the URL to retrieve the models for week 9?'],\n",
       " '60fa95ed': ['What should I do if the command echo ${REMOTE_URI} does not display any output?',\n",
       "  'How can I set the REMOTE_URI variable to a specific URI address in the terminal?',\n",
       "  'Will I still have access to the REMOTE_URI variable after I close my terminal session?',\n",
       "  'What commands did you run to successfully display the REMOTE_URI value?',\n",
       "  'Is the use of curly brackets necessary when echoing the REMOTE_URI variable?'],\n",
       " '53f3ee10': ['What command should I use to avoid the invalid choice error while fetching the password from aws-cli?',\n",
       "  'How can I simplify the login process for AWS ECR using the command line?',\n",
       "  'What do I need to replace in the login command for it to work correctly?',\n",
       "  'Is there a specific syntax for exporting the password from the AWS command?',\n",
       "  'What error do I get if I use aws ecr get-login instead of the recommended command?'],\n",
       " '93aa4278': ['How can I pass multiple parameters to the model simultaneously?',\n",
       "  'What function should I use to send various cnn parameters at once?',\n",
       "  'Is there a recommended method for passing several parameters in a deep learning model?',\n",
       "  'Can I use Sequential to handle many parameters in my model configuration?',\n",
       "  'What is the easiest way to define multiple parameters for a cnn in my project?'],\n",
       " '0edeb016': ['What does the error message ERROR [internal] load metadata for public.ecr.aws/lambda/python:3.8 indicate when building a Docker image?',\n",
       "  'What should I do if I encounter an issue while using the Amazon python base image for Docker?',\n",
       "  'Are there any specific steps I can take to resolve the ERROR [internal] load metadata issue?',\n",
       "  'How can I ensure that my Docker desktop is up to date to prevent errors while building images?',\n",
       "  'What command can I run as a last resort if the previous solutions do not work while building my Docker image?'],\n",
       " 'ba186de6': [\"What error message do I encounter when running the 'ls' command in Windows Jupyter Notebook?\",\n",
       "  \"What alternative command can I use in a Windows Jupyter Notebook to get similar output to '!ls -lh'?\",\n",
       "  \"Can you explain why the 'ls' command is not recognized in a Windows environment?\",\n",
       "  \"What is the command I should use instead of '!ls -lh' when working on a Windows system?\",\n",
       "  \"Who provided the solution for the issue with the 'ls' command in the FAQ record?\"],\n",
       " 'da2f1cf4': ['What should I do if I encounter the error \\'ImportError: generic_type: type \"InterpreterWrapper\" is already registered!\\' when trying to use tflite_runtime?',\n",
       "  'How can I resolve the issue of conflicting imports in my notebook related to TensorFlow and tflite_runtime?',\n",
       "  'Is there a specific order or method I should follow when importing tflite_runtime to avoid import errors?',\n",
       "  'What steps can I take to fix the ImportError I see with tflite_runtime when I also import TensorFlow?',\n",
       "  \"If I receive an error regarding 'InterpreterWrapper' when using tflite_runtime, how can I ensure my notebook runs smoothly?\"],\n",
       " '7fd648ca': ['What error message might I encounter when trying to build a Docker image on Windows?',\n",
       "  'How do I know if my Windows version may not be up-to-date when using Docker?',\n",
       "  'What should I check if the Docker daemon is not running on my system?',\n",
       "  'What command do I use to build a Docker image for dino_dragon?',\n",
       "  'What can prevent Docker from running correctly on my Windows system?'],\n",
       " '42c09143': ['What is the warning I receive when running the command to build the Docker image for the model?',\n",
       "  \"How does the version of the Python wheel affect the Docker build process in this week's section?\",\n",
       "  'What specific version of Python do I need to be using for compatibility with the wheel?',\n",
       "  'What is a common mistake that leads to the error when attempting to download the required file?',\n",
       "  'Can you provide the correct link format to download the wheel needed for this project?'],\n",
       " 'd6d534fc': ['What specific steps should I follow for configuring AWS after I have installed awscli?',\n",
       "  'During the configuration process with aws configure, what information is required, particularly regarding Access Key ID and Secret Access Key?',\n",
       "  'Is it acceptable to leave the Default output format blank when configuring awscli, and what default settings do you recommend?',\n",
       "  'Can I use the default values for most of the configuration options in aws configure, and are there any exceptions I should be aware of?',\n",
       "  'What should I do if I am uncertain about the Default Region Name during the awscli configuration process?'],\n",
       " 'b2c0c554': ['Why does my lambda function work locally but produce a float32 serialization error when using Docker?',\n",
       "  'What specific error message appears when encountering an issue with JSON serialization in my serverless model?',\n",
       "  'How can I convert numpy float32 values to a format that is JSON serializable for my lambda function?',\n",
       "  'What changes should I make in the predict function to resolve the serialization issue with float32 outputs?',\n",
       "  'Which chapters should I refer to for additional guidance on troubleshooting the float32 serialization problem in serverless deep learning?'],\n",
       " '819afebc': ['What could cause the ValueError when using interpreter.set_tensor with the input X?',\n",
       "  'How can I convert my input data to the correct type to resolve the error encountered in the video?',\n",
       "  'Is there any specific version of TensorFlow that might relate to this issue I am facing with tensor types?',\n",
       "  'Where can I find additional information or solutions regarding the ValueError I encountered?',\n",
       "  'What is the correct data type that should be used for input when working with interpreter.set_tensor?'],\n",
       " '74551c54': ['What command can I use in PowerShell to retrieve file size?',\n",
       "  'How do I assign a file item to a variable in a PowerShell script?',\n",
       "  'What is the command to display the file size in megabytes using PowerShell?',\n",
       "  'Can you provide an example of checking file size in the PowerShell terminal?',\n",
       "  'What is the PowerShell command to get the length of a file?'],\n",
       " '4d98cd09': ['Can you explain the functionality of lambda container images in detail?',\n",
       "  'What resources did you find helpful for understanding the initialization of lambda functions?',\n",
       "  'Where can I access documentation regarding lambda container images?',\n",
       "  'Is there any specific guide for using lambda images effectively?',\n",
       "  'What are some key aspects of the runtimes API related to lambda functions?'],\n",
       " '59a81fd5': ['What steps are involved in deploying a Docker image on AWS Lambda using the AWS Serverless Framework?',\n",
       "  'How can I expose my Lambda function as a REST API via APIGatewayService after deployment?',\n",
       "  'Is there any detailed guide available for creating and pushing Docker images to AWS ECR?',\n",
       "  'Can I find a comprehensive tutorial for deploying containerized applications to AWS Lambda?',\n",
       "  'What resources are recommended for learning about the AWS Serverless Framework integration with AWS services?'],\n",
       " '35dbd6e2': ['What should I do if I encounter an error when trying to build the Docker image on my M1 Mac during the process described in Section 9.5?',\n",
       "  'Is there a specific command I can use to resolve the pip install error for the tflite runtime when building the Docker image?',\n",
       "  'If the provided link for the tflite runtime wheel does not work, what are my alternatives for building the Docker image?',\n",
       "  'What adjustments do I need to make to the Docker build command to accommodate the arm architecture of my M1 Mac?',\n",
       "  'How can I run the Docker image once it has been successfully built on my machine?'],\n",
       " 'e5fe9efe': ['What error might I encounter when attempting to invoke the API Gateway while testing it locally in section 9.7?',\n",
       "  'What specific error message indicates a problem when I try to expose the Lambda Function using the API Gateway?',\n",
       "  \"What do I need to do if I receive a 'Missing Authentication Token' error while testing my API?\",\n",
       "  'How can I find the correct URL to use when invoking a deployed API in AWS?',\n",
       "  'Can you provide an example of what the API URL should look like when I perform a prediction request?'],\n",
       " '5c043c62': ['What error message appears when I attempt to install tflite_runtime using the provided command?',\n",
       "  'Where can I find the specific OS and Python version combinations for tflite_runtime availability?',\n",
       "  'How can I determine if a compatible version of tflite_runtime is available for my system?',\n",
       "  'What are the steps to install a compatible tflite_runtime version using pip from GitHub?',\n",
       "  'What alternative methods can I use to run my code if tflite_runtime cannot be installed directly?'],\n",
       " 'af0739da': ['What should I do if I encounter a Docker run error related to a read-only file system?',\n",
       "  'How can I resolve the issue with mkdir in Docker when it shows an error response from the daemon?',\n",
       "  'Is there a specific command I need to run to fix the Docker error involving overlay2?',\n",
       "  'What steps do I take to address the Docker services error mentioned in the FAQ?',\n",
       "  'Who can I contact if restarting the Docker services does not fix my issue?'],\n",
       " '451bc25d': ['How can I save a Docker image to my local machine?',\n",
       "  'What command should I use to export a Docker image in tar format?',\n",
       "  'How do I view the contents of a Docker image after saving it?',\n",
       "  'What should I extract to see the individual layers of a Docker image?',\n",
       "  'Is there a specific file I need to look for after extracting the Docker image tar?'],\n",
       " 'ea2e7458': [\"What should I do if my Jupyter notebook doesn't recognize a package after installation?\",\n",
       "  \"Why is my notebook failing to recognize imports after I've installed a package?\",\n",
       "  'How can I fix issues with Jupyter notebook not seeing a package I installed?',\n",
       "  'What steps should I take if my Jupyter notebook still does not work with my imports?',\n",
       "  'Is there a need to restart the Jupyter notebook after installing a package for it to work?'],\n",
       " '6ce8e875': ['What should I do if I run out of space on my AWS instance?',\n",
       "  \"Why doesn't deleting docker images free up space on my instance?\",\n",
       "  'Is there a specific command I need to run after deleting images to reclaim disk space?',\n",
       "  'How much storage does my AWS instance have?',\n",
       "  'What is the process for cleaning up space in a Docker environment?'],\n",
       " 'b50e9e2b': ['Is Tensorflow 2.15 compatible for our AWS deployment?',\n",
       "  'What version of Tensorflow should I use if 2.15 does not work?',\n",
       "  'Can I use Python 3.11 with Tensorflow 2.14?',\n",
       "  'What is the recommended Python version for Tensorflow 2.4.4?',\n",
       "  'What issues might arise if I use an unsupported Python version with Tensorflow?'],\n",
       " '29311ef5': ['Why does running the command aws ecr get-login --no-include-email lead to an error regarding an invalid operation choice?',\n",
       "  'What should I do if I receive an error message when using the aws ecr get-login command?',\n",
       "  'Is there a resource available to help me understand the invalid choice error from aws ecr get-login?',\n",
       "  'Could you explain why the aws ecr get-login command might fail and give an invalid choice error?',\n",
       "  'Where can I find more information about the error that occurs with the aws ecr get-login command?'],\n",
       " '1e0dc11c': ['What steps should I follow after signing into the AWS Console to get to the IAM service?',\n",
       "  'How can I create a new IAM policy for Week 9: Serverless?',\n",
       "  'What actions are included in the JSON policy for ECR that I need to create?',\n",
       "  'What should I do after reviewing my IAM policy before creating it?',\n",
       "  'What error message might I encounter related to credentials, and how can I fix it?'],\n",
       " '1078aeb7': ['What should I do if I encounter a Docker temporary failure in name resolution?',\n",
       "  'How can I configure DNS settings in Docker to resolve name issues?',\n",
       "  'What changes need to be made in the daemon.json file for Docker DNS?',\n",
       "  'After modifying the DNS settings in Docker, what is the next step?',\n",
       "  'Who provided the instructions for resolving Docker name resolution errors?'],\n",
       " '7daaca73': ['What should I do if my Keras model fails to load with a weight_decay error?',\n",
       "  'How can I resolve the issue with loading a Keras model due to a kwargs problem?',\n",
       "  'What code modification is needed to successfully load a Keras model that throws an error?',\n",
       "  'Is there a specific function argument I need to set when loading a model to avoid errors?',\n",
       "  'Can you tell me the correct syntax to use when loading a Keras model that has compatibility issues?'],\n",
       " '0cfbe2e2': ['What is the role of AWS RIE in local testing of serverless applications?',\n",
       "  'What command should I use to run my Docker image for testing locally?',\n",
       "  'How can I test the endpoint after running the Docker container?',\n",
       "  'What are the differences in curl commands for Windows and Unix testing?',\n",
       "  'How should I handle the error related to marshaling response in testing?'],\n",
       " '1460fb65': [\"What should I check if I encounter the error related to importing 'lambda_function' in my Python script?\",\n",
       "  \"How can I resolve the 'No module named tensorflow' error when running my test script?\",\n",
       "  'Is there any specific library I need to avoid importing in my test.py to prevent this error?',\n",
       "  'What is the correct way to import tflite to avoid compatibility issues in serverless deep learning?',\n",
       "  'Why is it important to change the import statement from tensorflow.lite to tflite_runtime.interpreter?'],\n",
       " 'd4f9efdc': ['How can I install Docker (udocker) while using Google Colab?',\n",
       "  'What steps should I follow to run Docker commands in Google Colab?',\n",
       "  'What should I do if I encounter errors related to the Authorization header while using the Lambda API Gateway?',\n",
       "  \"How can I test my API method in Amazon's API Gateway using boto3?\",\n",
       "  'What is the solution for running pip install tflite_runtime from a GitHub wheel link if it fails?'],\n",
       " '6a417bfe': ['What steps should I follow to begin Week 10 of the course?',\n",
       "  'Is there any specific preparation needed for Week 10 activities?',\n",
       "  'Are there any resources recommended for the Kubernetes and TensorFlow Serving section?',\n",
       "  'When will the Week 10 materials be available for review?',\n",
       "  'Will there be any assignments associated with Week 10 topics?'],\n",
       " 'ed8b300d': ['What are the benefits of using TensorFlow with CUDA support on my local machine compared to running a CNN on the CPU?',\n",
       "  'Can you provide resources or links for installing TensorFlow in an Ubuntu WSL2 setup?',\n",
       "  'What specific version of CUDA should I choose when installing TensorFlow with pip for optimal performance?',\n",
       "  'How do I ensure that my hardware is compatible with CUDA support before installing TensorFlow?',\n",
       "  'Is there any additional information or resources I should consider when setting up PyTorch alongside TensorFlow?'],\n",
       " 'a64aed6b': [\"What should I do if I encounter 'Allocator ran out of memory' errors while using TensorFlow on my machine?\",\n",
       "  'Can you explain how to potentially improve performance when running TensorFlow with memory constraints?',\n",
       "  'Is there a specific code snippet I should add to my notebook to address memory allocation issues in TensorFlow?',\n",
       "  'What should I expect after implementing the code fix for memory errors in TensorFlow?',\n",
       "  'Has anyone experienced the memory allocation error again after applying the suggested solution, and what was the outcome?'],\n",
       " '727238ee': ['What error might occur when running the script gateway.py in session 10.3, and what does it indicate?',\n",
       "  'If I encounter the TypeError related to descriptors, what should I do to resolve the issue with protobuf?',\n",
       "  'What version of protoc do I need to regenerate my generated code if it is out of date?',\n",
       "  'What are some alternative solutions if I cannot regenerate my protobufs right away?',\n",
       "  'Could you provide the specific pipenv install command that helps avoid the recent version of protobuf issue?'],\n",
       " '85d4901d': ['What error message might I encounter when trying to run a docker command in WSL?',\n",
       "  'What needs to be checked if Docker Desktop is not connecting to the WSL Linux distro?',\n",
       "  'Where can I find the WSL Integration settings in Docker Desktop to resolve connectivity issues?',\n",
       "  'What is the solution for fixing connection problems with the Docker daemon in WSL?',\n",
       "  'Do I need to enable the same default WSL distro when using additional distros in Docker Desktop?'],\n",
       " 'df023a13': ['What should I do if my HPA instance is not functioning as expected despite updating the Metrics Server?',\n",
       "  'How can I fix the issue where the targets for my HPA instance show up as <unknown>?',\n",
       "  'What specific command do I need to use to edit the metrics-server deployment in the kube-system namespace?',\n",
       "  'What line do I need to add to the metrics-server args to resolve the HPA instance problem?',\n",
       "  'After making changes to the metrics-server deployment, what command should I run to check the status of the HPA?'],\n",
       " '48e92d65': ['What should I do if my HPA instance is not functioning correctly despite having the latest Metrics Server installed?',\n",
       "  'How can I check if the targets are displaying as <unknown> for my HPA instance?',\n",
       "  \"Is there a specific command to fix issues with the HPA instance if the default installation doesn't work?\",\n",
       "  'What option is included in the metrics server deployment file provided for fixing HPA instances?',\n",
       "  'Who added the suggestion to use the metrics server deployment file with the --kubelet-insecure-tls option?'],\n",
       " '1685cae4': ['What should I do if I encounter an OSError when trying to install packages on my Windows machine?',\n",
       "  'Is there a specific error message I might see when the installation fails due to access issues?',\n",
       "  'What command did you use to successfully install the libraries after encountering the access denied error?',\n",
       "  'Could you explain the significance of using the `--user` option for the pip install command?',\n",
       "  'What steps can I take to fix permission issues when installing Python packages on Windows?'],\n",
       " '4fb7b21e': ['What error message did you encounter when you modified the code and created a virtual environment in the course?',\n",
       "  'Which command resolved the issue related to the TypeError in your TensorFlow Serving code?',\n",
       "  'What version of the protobuf package did you downgrade to in order to fix the error?',\n",
       "  'What are two potential workarounds if you cannot regenerate your protos immediately?',\n",
       "  'What is the implication of setting PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION to python?'],\n",
       " '8bd3bfc2': ['What steps did you take to install kubectl on Windows using the terminal?',\n",
       "  'Can you share a tutorial link that explains the installation of kubectl on Windows?',\n",
       "  'Which command did you use to download kubectl on Windows?',\n",
       "  'What do you need to do after copying the exe file to the specific folder on your C drive?',\n",
       "  'Is there a similar installation process for kind on Windows as is for kubectl?'],\n",
       " '03b5fc59': ['What is the first step to install kind using the choco library?',\n",
       "  'How do I open a powershell terminal with the necessary permissions?',\n",
       "  'What command do I need to run in powershell to install the choco library?',\n",
       "  'What PowerShell command allows me to change the execution policy temporarily?',\n",
       "  'Where can I find the installation script for the choco library?'],\n",
       " '7c31bc9a': ['What should I do if I encounter issues while installing Kind using Windows Powershell?',\n",
       "  'Can you guide me on how to verify that Go is installed correctly on my system?',\n",
       "  'What command is required to install Kind through Go?',\n",
       "  'Is there a specific version of Kind that I should install using the Go command?',\n",
       "  'How can I check if Kind has been successfully installed on my machine?'],\n",
       " '605efc12': ['What was the error message I encountered when trying to use kubectl?',\n",
       "  'What did I find when I searched for a solution to the kubectl issue?',\n",
       "  'What did the online discussions suggest I should create to fix the problem?',\n",
       "  'What steps did I follow to resolve the connection issue with kubectl?',\n",
       "  'What was the result after I recreated the cluster and tried the command again?'],\n",
       " 'c5cde96c': ['What problem might I encounter if I experiment with Docker images without monitoring storage usage?',\n",
       "  'What solution should I consider if I find that I am running out of storage on my AWS instance?',\n",
       "  'What command can I use to check how much storage my Docker images are using?',\n",
       "  'Why does deleting Docker images not seem to free up space as expected?',\n",
       "  'What additional command should be executed after removing Docker images to reclaim storage?'],\n",
       " 'd45d2da6': ['What is the significance of specifying CPU and memory in HW10 Q6?',\n",
       "  'Can you clarify if the CPU and memory values are actually arbitrary in context?',\n",
       "  'Why does the question specifically mention a correct value for the port?',\n",
       "  'What should I instead focus on regarding the CPU and memory setup in the yaml file?',\n",
       "  'Could you explain how the port value is determined for this particular homework?'],\n",
       " '59823c72': [\"Can you explain the significance of the 'm' in the CPU values found in the Kubernetes deployment.yaml file?\",\n",
       "  \"What does a value of '100m' indicate for a container in terms of CPU resource requests?\",\n",
       "  \"How much CPU power does '500m' represent for the container's limit in Kubernetes?\",\n",
       "  'Why does Kubernetes utilize milliCPU units for defining resource specifications?',\n",
       "  'In what scenarios would specifying CPU requirements in milliCPUs be beneficial for an application?'],\n",
       " '665f7b27': ['What should I do if Kind fails to load a Docker image due to an error message about nodes not being found for the cluster?',\n",
       "  'How can I successfully load a Docker image to my Kubernetes cluster when I have named my cluster using Kind?',\n",
       "  'What is the command to load the Docker image if I run into issues with no nodes being found?',\n",
       "  'Is there a specific flag I need to use in the Kind command to target my named cluster when loading a Docker image?',\n",
       "  'What is the correct syntax for loading a Docker image into a specified cluster using Kind?'],\n",
       " '0a406fe0': [\"What error message do I get if 'kind' is not recognized in Windows?\",\n",
       "  'How do I download kind for Windows using curl?',\n",
       "  'What should I rename the downloaded kind executable file to?',\n",
       "  'After renaming the file to kind.exe, where should I place it?',\n",
       "  'What do I need to do to ensure that kind.exe is recognized in the command line?'],\n",
       " '64b209b0': ['What modifications are necessary to use kind with Rootless Docker on Linux?',\n",
       "  'Are there any specific configurations needed for Rootless Podman to work with kind?',\n",
       "  'Can you explain how Rootless Docker impacts running kind?',\n",
       "  'What is the link to the kind documentation for Rootless configurations?',\n",
       "  'Is there any troubleshooting advice for using kind with Rootless setups on Linux?'],\n",
       " '518c4cb8': ['How can I deploy the Kubernetes dashboard in our course project?',\n",
       "  'Is there a specific method to access the Kubernetes dashboard?',\n",
       "  'What should I do to set up the Kubernetes dashboard for visualization?',\n",
       "  'Can you detail the steps for deploying the Kubernetes dashboard?',\n",
       "  'Where can I find information on accessing the Kubernetes dashboard after deployment?'],\n",
       " '00882c83': ['What version of the AWS CLI do I need to use eksctl?',\n",
       "  'How can I verify the version of my AWS CLI?',\n",
       "  'Is there a specific version requirement for the AWS CLI in this course?',\n",
       "  'Where can I find information on upgrading to AWS CLI v2?',\n",
       "  'Why is it important to use AWS CLI v2 for eksctl?'],\n",
       " 'd6d483ce': ['What error did I encounter when testing a Flask service in video 10.3?',\n",
       "  'What command did I run in one terminal before encountering the error while running gateway.py?',\n",
       "  'What specific versions of Flask and Werkzeug did I find using pip freeze?',\n",
       "  'What is the underlying cause of the TypeError related to Flask and Werkzeug versions?',\n",
       "  'How did I resolve the version conflict that caused the error when importing Flask?'],\n",
       " 'f9711723': ['What should I do if the command aws ecr get-login --no-include-email gives me an error regarding an invalid choice?',\n",
       "  'Can you provide the proper command for logging into AWS ECR using Docker?',\n",
       "  'Is there a way to run the login command without modifying any fields if I have a default region set?',\n",
       "  'Where can I find the official AWS documentation that relates to pushing images to ECR?',\n",
       "  'What specific parts of the command do I need to change when using aws ecr get-login-password?'],\n",
       " '5bda3b94': ['What should I do if I encounter an error when trying to download tensorflow/serving:2.7.0 on my Apple M1 Mac?',\n",
       "  'Can you explain the error message I might see when running the Docker code for TensorFlow Serving on an M1 Mac?',\n",
       "  'What is a possible solution to resolve the issue with TensorFlow Serving on the Apple M1 Mac?',\n",
       "  'How can I run TensorFlow Serving properly on my M1 Mac without facing errors?',\n",
       "  'Is there an alternative Docker image that I can use for TensorFlow Serving on Apple M1 Macs?'],\n",
       " 'cccd31cf': ['What type of error do I encounter when using the tensorflow/serving image on a Mac M2 with Apple Silicon?',\n",
       "  \"Can you explain why I might be getting an 'Illegal instruction' error when running my docker command?\",\n",
       "  'What is the reason behind the recommendations for using a different base image for TensorFlow Serving?',\n",
       "  'How can I successfully run TensorFlow Serving on my Mac M2 without encountering the illegal instruction error?',\n",
       "  'What are the necessary steps to set up TensorFlow Serving using bitnami/tensorflow-serving image in Docker?'],\n",
       " '57f49999': [\"What could be the reason for the HPA showing 'Unknown' for CPU metrics?\",\n",
       "  'What steps should I take if my HPA fails to get CPU utilization?',\n",
       "  'How do I delete the existing HPA if it is not fetching metrics correctly?',\n",
       "  'What file do I need to apply to resolve the CPU metrics issue with HPA?',\n",
       "  'After applying the metrics file, what should I do next to recreate the HPA?'],\n",
       " '5cb58698': ['What should I do if I encounter errors with Istio during the KServe installation process?',\n",
       "  'How can I verify the version of kubectl I have installed before attempting to install KServe?',\n",
       "  \"What changes do I need to make to the 'quick_install.bash' file before running it?\",\n",
       "  'Where can I find the version matrix for Istio and Knative to ensure compatibility with KServe?',\n",
       "  \"What is the command to download and edit the 'quick_install.bash' file without executing it?\"],\n",
       " 'de650b41': ['What should I include in the problem title for my project?',\n",
       "  'Can you clarify what needs to be covered in the problem description?',\n",
       "  'Is there a specific format for the solution description section?',\n",
       "  'Are there guidelines on who can add information to the project?',\n",
       "  'What information is optional for the project submissions?'],\n",
       " '9ffacaac': ['What are the specific deadlines for the projects in this course?',\n",
       "  \"Where can I find the deadlines for my cohort's projects?\",\n",
       "  'Are the deadlines for the midterm and capstone projects the same for all cohorts?',\n",
       "  'Is there a specific link to view the project deadlines for my group?',\n",
       "  \"How do I access the cohort folder to find my project's deadlines?\"],\n",
       " '4dfb5d4f': ['Do I need to work alone on my midterm project?',\n",
       "  'Are the capstone projects assigned as group activities or individual efforts?',\n",
       "  'Is collaboration allowed for midterm and capstone assignments?',\n",
       "  'Can I team up with classmates for my midterm project?',\n",
       "  'Are midterm and capstone projects designed for individual completion?'],\n",
       " '0b8739b7': ['What is the recommended scope of modules for the midterm and capstone projects in this course?',\n",
       "  'Are there any specific topics or problem sets that I should focus on for my midterm project?',\n",
       "  'Can I incorporate additional content not covered in the syllabus into my capstone project?',\n",
       "  'Where can I find past office hours from earlier cohorts for additional guidance?',\n",
       "  'How do I access the DTC YouTube channel to look for resources regarding the course?'],\n",
       " '9eb52679': ['Are there specific links that I should refer to for my Midterm and Capstone projects, and do these links vary by cohort?',\n",
       "  'If I want to submit my Midterm Project, where can I find the submission form?',\n",
       "  'What is the first step I should take when starting on my project regarding problem selection?',\n",
       "  'Can you clarify what I need to do after preparing my data and performing exploratory data analysis?',\n",
       "  'Where can I find datasets to use for my project, and are there multiple sources available?'],\n",
       " '7a1fcfd9': ['What are the steps to perform peer reviews for the projects in this course?',\n",
       "  'Where can I find the instructions for conducting peer reviews for my projects?',\n",
       "  'Is there a specific format or platform we will use to submit our peer reviews?',\n",
       "  'When will the links to the submitted projects be available for review?',\n",
       "  'Who is responsible for compiling the list of projects for peer review in this course?'],\n",
       " '1cfa62c5': ['What should I refer to for guidance on computing the hash for my project review?',\n",
       "  'Where can I find information about the hash computation for my project?',\n",
       "  'Is there a specific resource that explains how to compute the hash for the project review?',\n",
       "  'Can you direct me to the answer regarding hash computation for projects?',\n",
       "  'What is the procedure for calculating the hash needed for project review?'],\n",
       " '2a78f52e': ['What is the total value assigned to the learning in public for the midterm project?',\n",
       "  'How many posts are required for the learning in public component for the midterm project?',\n",
       "  'Do we need to create seven posts for each module, or is there a different requirement?',\n",
       "  'Is the expectation for the learning in public to be fulfilled in a single post worth 14, or is it separate entries?',\n",
       "  'Are we supposed to make a post for each day during the project period?'],\n",
       " '68aeab64': [\"What should I do if my dataset exceeds GitHub's size limits?\",\n",
       "  'Is there a method to handle large files for my project on GitHub?',\n",
       "  'How can I upload a large dataset to GitHub without issues?',\n",
       "  'Can anyone suggest a solution for managing oversized files in my repository?',\n",
       "  'What tool can I use to upload large datasets to my GitHub project?'],\n",
       " '9a7c26e0': [\"What happens if I only submit two projects and don't submit the third one?\",\n",
       "  'Do I still get the course certificate if I submit two projects?',\n",
       "  'Is it necessary to submit three projects to receive the certificate?',\n",
       "  'What are the submission requirements for obtaining the course certificate?',\n",
       "  'Who should I contact for questions regarding project submissions?'],\n",
       " '1fd83eb9': ['Do I need to complete all projects to avoid peer reviews in the capstone?',\n",
       "  'Is it true that I only need to submit my project to be assigned a peer review?',\n",
       "  'If I skip the last project, will I still have to review peers for my submission?',\n",
       "  'How does submitting my project relate to the requirement for peer reviews?',\n",
       "  'Who confirmed the information about peer reviews and project submissions?'],\n",
       " 'fbaa5b20': ['What is the minimum number of models I need to train for my midterm project?',\n",
       "  'Can you clarify how many models are considered multiple for the midterm requirements?',\n",
       "  'Is there a recommended limit to the number of models I should train for my project?',\n",
       "  'Could you explain the importance of training multiple models for the midterm deliverables?',\n",
       "  'What does training multiple models involve in the context of my midterm assignment?'],\n",
       " '37eab341': ['What steps do I need to follow to find my assigned peer projects for evaluation?',\n",
       "  'Can I choose any capstone project to review, or is there a specific assignment I need to follow?',\n",
       "  'How do I calculate the hash value of my email address for the project evaluation?',\n",
       "  'Where can I access the list of all submitted projects that I need to evaluate as a peer reviewer?',\n",
       "  'What is the process for locating my peer project based on the hashed email value after generating it?'],\n",
       " '57754faf': ['Is the project grading based on individual scores or average scores of the class?',\n",
       "  'How is the passing criteria determined for the project?',\n",
       "  'Does everyone’s scores influence my project passing status?',\n",
       "  'Will my project score be evaluated in relation to my classmates’ scores?',\n",
       "  'Who provided the explanation about the project grading system?'],\n",
       " '6979c5d1': ['What is the purpose of submitting a train.py file if I have already shared a notebook file?',\n",
       "  'How will my peers utilize the train.py file during the project review?',\n",
       "  'Why is it necessary for the train.py file to function on a different system?',\n",
       "  'In what way should the train.py file be integrated with my project environment?',\n",
       "  'Can you explain the importance of including the train.py file alongside my notebook?'],\n",
       " 'a1bd8c34': ['How do I install the PILLOW library for my project?',\n",
       "  'What is the process to load an image using PILLOW?',\n",
       "  'Which module do I need to import to convert an image to a numpy array?',\n",
       "  'Can you provide a sample code for converting an image to a numpy array?',\n",
       "  'Who provided the information in the FAQ record?'],\n",
       " 'b2ab0fc1': [\"Do I need to include a train.py file if there's already a train.ipynb file in my midterm project?\",\n",
       "  'Why is a train.py file preferred over a train.ipynb for model training?',\n",
       "  'What is the advantage of using a python script for training instead of a notebook?',\n",
       "  'How do real-life training jobs typically operate regarding scripts and notebooks?',\n",
       "  'Is it common practice to run training jobs with python files instead of notebooks?'],\n",
       " '80c439a9': ['What options do I have for users to input data into the model?',\n",
       "  'Can I create an app specifically for form management?',\n",
       "  'Is it important to validate data on the backend as well?',\n",
       "  'Where can I find resources related to building a frontend for data entry?',\n",
       "  'Does the course recommend any specific tools for creating user interfaces?'],\n",
       " 'ff93b86e': ['What method should I use to obtain feature importance from an XGBoost model?',\n",
       "  'What error might occur when using feature_importances_ with an XGBoost model?',\n",
       "  'How should I train my model to avoid the feature_importances_ error?',\n",
       "  'What is the correct method to retrieve scores if I trained my model using xgb.train?',\n",
       "  'Can you explain the difference between feature_importances_ and get_score() in XGBoost?'],\n",
       " 'fcd86c8f': [\"What does the error message '[Errno 12] Cannot allocate memory' mean in AWS Elastic Container Service tasks?\",\n",
       "  'How can I resolve the memory allocation issue in Elastic Container Service?',\n",
       "  \"Is there a specific solution for the '[Errno 12]' error in AWS ECS?\",\n",
       "  'What adjustments should I make to my task definition in AWS ECS to fix memory issues?',\n",
       "  'Who provided the advice regarding increasing RAM and CPU for AWS Elastic Container Service tasks?'],\n",
       " '236864c2': [\"What causes the pickle error saying it can't get attribute XXX on module __main__ when using waitress?\",\n",
       "  'Why does the pickle error not occur when running the app directly with Flask instead of through waitress?',\n",
       "  'How does the custom column transformer class impact the pickle loading process when using waitress?',\n",
       "  'What is the recommended solution to avoid the pickle error related to module __main__?',\n",
       "  'Where can I find detailed information regarding issues with loading files using pickle and multiple modules?'],\n",
       " 'efc4a04f': ['What are some techniques to deal with outliers in my dataset?',\n",
       "  'Can you explain the method of log transformation for outlier handling?',\n",
       "  'Is it acceptable to drop observations when managing outliers?',\n",
       "  'What does clipping high values mean in the context of outliers?',\n",
       "  'Are there common practices used to transform datasets with outliers?'],\n",
       " '15f361b7': ['What was the error message I encountered when trying to create a Docker image using BentoML?',\n",
       "  'What specific module was not found that caused the failed loading of the Bento?',\n",
       "  'Which package was incorrectly listed in the bentofile.yaml that led to the issue?',\n",
       "  'How was the problem with the module import resolved in the bentofile.yaml?',\n",
       "  'What are the correct package names to include in the packages list for the service?'],\n",
       " 'dbbce78b': ['What error might I encounter when using BentoML with the --production flag and how does it manifest in the swagger UI?',\n",
       "  'What is a potential cause for the error related to sparse matrices when running bentoml serve?',\n",
       "  'How does the setting of DictVectorizer or OHE to sparse during training affect the model when it is called in service.py?',\n",
       "  'Why does inconsistent length of sparse matrices prevent batching in my BentoML model when it is served?',\n",
       "  \"What should I set the batchable parameter to in the bentoml model signatures for production if I'm using sparse matrices?\"],\n",
       " 'f3a00e15': ['Is it necessary for us to execute every file provided in the course materials?',\n",
       "  \"What should I do if I'm unable to run all the provided files, particularly the neural networks?\",\n",
       "  'How can I ensure that I have everything needed for reproducibility?',\n",
       "  'What steps can I take to verify that there are no obvious errors in the provided materials?',\n",
       "  'Where can I find the related Slack conversation for further clarification on reproducibility?'],\n",
       " '9102b3c0': ['What should I do if my model exceeds the size limit for GitHub?',\n",
       "  'How can I compress my model to fit it on GitHub?',\n",
       "  'Is there a specific library or method recommended for compressing large models?',\n",
       "  'What happens when I use joblib for compression?',\n",
       "  'How long does it usually take to compress a model with joblib?'],\n",
       " '70d89fdf': ['What should I do if I encounter an unauthorized error when pushing an image to Google Container Registry?',\n",
       "  'How can I configure my Docker to push to Google Container Registry?',\n",
       "  'What installation is required before using gcloud in the console?',\n",
       "  'What command do I need to run to resolve permission issues with Google Container Registry?',\n",
       "  'Who provided the instructions for resolving the push permission issue?'],\n",
       " 'c5d6a804': ['What error message did I receive while trying to install tflite_runtime in my pipenv environment?',\n",
       "  \"Why can't I find a version of tflite_runtime that works with Python 3.10?\",\n",
       "  'What version of Python do I need to install in order to successfully install tflite_runtime?',\n",
       "  'Where can I check for all available versions of tflite_runtime?',\n",
       "  'What should I do if I cannot find a suitable tflite_runtime version for my setup?'],\n",
       " '8c7f089f': ['What could cause an error when using ImageDataGenerator.flow_from_dataframe?',\n",
       "  \"How can I resolve the 'name 'scipy' is not defined' error?\",\n",
       "  'Is there a specific library I need to have installed for ImageDataGenerator?',\n",
       "  'What steps should I take if I encounter an error related to scipy?',\n",
       "  'What should I do after installing scipy regarding the Jupyter kernel?'],\n",
       " '739bcccf': ['What resources are available for deploying BentoML content on Amazon Lambda?',\n",
       "  'Is there a specific tutorial for using Docker containers with Amazon Lambda?',\n",
       "  'Who created the video on passing BentoML content to Amazon Lambda?',\n",
       "  'Can I find detailed instructions for deploying Docker containers in AWS Lambda?',\n",
       "  'Where can I watch the dedicated video tutorial for this use case?'],\n",
       " '4603e4e5': ['What do I do if I encounter an UnidentifiedImageError when working on my model?',\n",
       "  'Can you explain what causes the UnidentifiedImageError related to image files?',\n",
       "  'How can I modify my image URL to avoid the IdentifiedImageError when testing locally?',\n",
       "  'What is the proper format for a URL when accessing images from GitHub for my model?',\n",
       "  'Is there any specific adjustment I need to make to the URL when retrieving test images?'],\n",
       " '0a7c328e': ['What does it mean when I see a resolution failure warning during pipenv install?',\n",
       "  'How can I resolve dependency issues if pipenv install fails?',\n",
       "  'What actions can I take if there is a mismatch in sub-dependencies?',\n",
       "  'Is there a command I can run to fix problems with Pipfile and Pipfile.lock?',\n",
       "  'Who provided the information about resolving pipenv dependency issues?'],\n",
       " '77efd069': [\"What should I do if I encounter an error stating that 'get_feature_names()' is not found in my code?\",\n",
       "  \"Why does the function 'dv.get_feature_names()' work in the course but not on my local setup?\",\n",
       "  \"Is there a chance that the 'get_feature_names()' function may be removed in future library updates?\",\n",
       "  'What changes do I need to make to my code regarding the feature extraction method to avoid errors?',\n",
       "  \"Where can I find more information about the deprecation of the 'get_feature_names()' function?\"],\n",
       " 'cc60f7bc': ['What causes the error related to decoding JSON responses during prediction tests?',\n",
       "  'Can you explain what the correct format for input data should be before sending it to the server?',\n",
       "  'Why is it necessary to convert input data to numpy arrays instead of using JSON format?',\n",
       "  'What happens if the data sent to the server is not in the expected shape?',\n",
       "  'Who provided the information about the JSON decoding error and its solution?'],\n",
       " 'aa13dd66': ['What are some free cloud alternatives for deploying my projects that offer more resources than Render?',\n",
       "  'Can you explain the benefits of using AWS and GCP for free instances compared to other services?',\n",
       "  'Is there a cloud service that provides free GPU instances specifically for ML Zoomcamp students?',\n",
       "  'How long can I expect to use the free microinstances offered by AWS and GCP?',\n",
       "  'What should I do to get additional GPU hours on Saturn when signing up as a student from ML Zoomcamp?'],\n",
       " 'c41e479c': ['What is the process to convert the day_of_the_month column from integer to string format in order to prepare for further calculations?',\n",
       "  \"How can I transform the month_of_the_year values in my DataFrame from string representations like 'jan' and 'feb' to their corresponding numeric values?\",\n",
       "  'What method do I use in pandas to create a datetime object after I have converted the day and month columns?',\n",
       "  'Can you explain how to derive the day of the year from the newly created date_formatted column using pandas?',\n",
       "  'In the provided solution, what specific year is used for creating the datetime object and why is this year chosen?'],\n",
       " '2f28dcf1': ['How can I visualize the predictions for different classes after training my neural network?',\n",
       "  'What is the procedure to create a bar chart displaying predictions per class?',\n",
       "  'Can you explain the steps for plotting the output classifications of my model?',\n",
       "  'What is the best way to represent predictions for each class graphically?',\n",
       "  'How do I use matplotlib to visualize class predictions from my trained model?'],\n",
       " '7a69cccf': ['How can I transform dictionary values into a DataFrame structure?',\n",
       "  'What is the method to create a DataFrame from dictionary output values?',\n",
       "  \"Which function allows me to convert a dictionary's values to a table format in DataFrame?\",\n",
       "  'Can you explain how to use the pandas library to turn a dictionary into a DataFrame?',\n",
       "  'What parameters do I need to use when creating a DataFrame from a dictionary?'],\n",
       " '20174c95': ['What is the purpose of the Kitchenware Classification Competition Dataset Generator?',\n",
       "  'How does the generated image dataset differ from the one used in the dino vs dragon lesson?',\n",
       "  'Why did you create a script for generating the dataset?',\n",
       "  'Where can I find the Kitchenware dataset generator?',\n",
       "  'Who is responsible for the Kitchenware dataset generator on Kaggle?'],\n",
       " 'f2cd48b6': ['What are the initial steps for installing the CUDA toolkit and cuDNN for TensorFlow on Windows?',\n",
       "  'Can you explain the options available for installing TensorFlow on Windows using Anaconda?',\n",
       "  'What are the instructions for setting up CUDA on WSL or Linux for TensorFlow?',\n",
       "  'How do I ensure CUDA is properly configured after installation for TensorFlow?',\n",
       "  'If I want to share my progress on social media, do I need to include a link to my LinkedIn profile or post about my assignment completion?'],\n",
       " '59b4324f': ['Why is the order of multiplication significant in matrix operations?',\n",
       "  'What are the dimensions of the resulting matrices when multiplying A and B?',\n",
       "  'Can you provide an example of how changing the multiplication order affects results?',\n",
       "  'What happens if I multiply two matrices in the opposite order?',\n",
       "  'Are the results of matrix multiplication always the same regardless of the order?'],\n",
       " 'e1dc1ed9': ['Are there any specific installation instructions for Mac users with an M1 chip?',\n",
       "  'Where can I find guidance on setting up the environment for Mac?',\n",
       "  'Is there a resource available for installing the course environment on Mac?',\n",
       "  'Can someone share the steps for environment installation on Mac?',\n",
       "  'What link should I check for environment setup instructions for Mac with M1?'],\n",
       " 'fc60bf3b': ['Will my late assignment be graded if I submit it?',\n",
       "  'What determines if the assignment form is still open?',\n",
       "  'How can I check if the submission form is accessible?',\n",
       "  'What happens if I miss the deadline for the assignment?',\n",
       "  'Is there a chance to submit past the due date?'],\n",
       " '1e60e888': ['Is it necessary for the GitHub repository to be publicly accessible?',\n",
       "  'What steps should I follow to install Conda on my local system?',\n",
       "  'Which integrated development environment is best suited for machine learning tasks?',\n",
       "  'Who will be able to view the homework repository?',\n",
       "  'What are the implications of having a private repository for my assignments?'],\n",
       " '44552c2e': ['What are the steps to install wget in Google Colab?',\n",
       "  'Can you explain how to download files using wget in Colab?',\n",
       "  'What directory should I specify for downloading files with wget in Google Colab?',\n",
       "  'Is there a command to check if wget is installed in my Google Colab environment?',\n",
       "  'How can I download data from a specific URL using wget in Google Colab?'],\n",
       " '7116b3be': ['What format must features be in to work with scikit-learn?',\n",
       "  'How can I convert a 1D array into a 2D array for scikit-learn?',\n",
       "  'In what context is reshaping mentioned for arrays in scikit-learn?',\n",
       "  \"Could you give an example of filtering a DataFrame based on 'ocean_proximity'?\",\n",
       "  'What are some key columns I should consider when selecting data for housing analysis?'],\n",
       " '5d4d206e': ['What should I do to resolve the FutureWarning I encountered while plotting with Matplotlib?',\n",
       "  'Is there an alternative method recommended to avoid the deprecation warning regarding is_categorical_dtype?',\n",
       "  'How can I bypass the warning that says is_categorical_dtype will be removed in future Matplotlib versions?',\n",
       "  'What is the correct way to check for categorical data types to prevent the FutureWarning?',\n",
       "  'Can you explain why is_categorical_dtype is being deprecated and what I should use instead?'],\n",
       " '387093cc': ['What error might I encounter when rerunning the Docker file in Windows compared to WSL/Linux?',\n",
       "  'How can I resolve the issue of Python 3.11 not being found on my system when using Docker?',\n",
       "  \"What should I do if neither 'pipenv' nor 'asdf' is available to install Python on my Windows setup?\",\n",
       "  'Is there a specific procedure I need to follow to add the Python311 installation folder to my PATH?',\n",
       "  'What steps should I take after modifying the PATH to ensure my Docker file runs successfully again?'],\n",
       " 'd12a2657': ['What are the steps involved in deploying a project to DigitalOcean App Cloud?',\n",
       "  'How much does it cost to deploy a project on DigitalOcean each month?',\n",
       "  'What should I do if my project is not located in the root of the repository when deploying?',\n",
       "  'Is there anything important I need to remember about the Dockerfile during the deployment process?',\n",
       "  'Do I need to manually add model files during the container build process, or are they added automatically?'],\n",
       " 'eb7a57a6': ['What do the lessons in week 3 tell us about feature importance for categorical values?',\n",
       "  'In lesson 3.10, which model is trained using all categorical variables?',\n",
       "  'Why might it not be sufficient to train a model only on the most important features?',\n",
       "  'What should you do if excluding a feature leads to a drop in model performance?',\n",
       "  'Which method among those learned in the course performs implicit feature selection?'],\n",
       " 'd6f0c6ea': ['What are some effective strategies for analyzing large datasets like the New York Yellow Taxi dataset that contains over a million rows?',\n",
       "  'How can I handle memory limitations when working with extensive data collections during data processing?',\n",
       "  'What is the significance of using sampling during the exploratory phase of data analysis?',\n",
       "  'Can you explain how optimizing data types can help in reducing memory usage when dealing with large datasets?',\n",
       "  'What is Dask and how does it assist in working with large datasets in Python?'],\n",
       " '9f261648': ['Is it possible to take the course using programming languages other than Python, such as R or Scala?',\n",
       "  'What are the main reasons for not recommending the use of languages other than Python for the course?',\n",
       "  'How might using a different programming language affect my homework submissions?',\n",
       "  'Will my fellow students be able to review my work effectively if I use a language other than Python?',\n",
       "  'Can I create a separate repository for personal practice if I write the course materials in another language?'],\n",
       " 'aa7ff0f7': ['Are libraries such as fast.ai or huggingface permitted for use in the capstone project?',\n",
       "  'Is it acceptable to use tools like fast.ai and huggingface during the competition?',\n",
       "  'What is the stance on using fast.ai or huggingface in our final project?',\n",
       "  'Are there any restrictions on using libraries like fast.ai and huggingface for the capstone?',\n",
       "  'Can I utilize libraries such as fast.ai or huggingface in the competition without issues?'],\n",
       " '387bdc5f': ['What should I check if my TensorFlow Serving image fails to test successfully?',\n",
       "  'How can I ensure that my TF versions are compatible for serving?',\n",
       "  'Is there a specific version for TF Serving that I should be aware of?',\n",
       "  \"Why was the Flask image tested successfully while TensorFlow Serving wasn't?\",\n",
       "  'Where can I find more information about matching TF and TF Serving versions?'],\n",
       " 'c6a22665': ['What are some suggested titles to use when listing my Machine Learning Zoomcamp experience on LinkedIn?',\n",
       "  'Can I categorize my experience with DataTalksClub as an official job or internship?',\n",
       "  'Which LinkedIn sections are suitable for showcasing my DataTalksClub experience?',\n",
       "  'How can I highlight my Machine Learning project on my CV?',\n",
       "  'What additional tips are there for sharing my progress on LinkedIn?'],\n",
       " '0560e827': ['What is the purpose of the MLOps Zoomcamp FAQ document?',\n",
       "  'How was the FAQ document structured for the data engineering course?',\n",
       "  'Are there specific formats recommended for posing questions in the FAQ?',\n",
       "  'What kind of information can I find in the FAQ?',\n",
       "  'Is it possible to see examples of questions and answers in the document?'],\n",
       " '59812e77': ['How long does the course typically take to complete in total?',\n",
       "  'What is the time frame for each individual module in the course?',\n",
       "  'Are there any options for extending deadlines for the modules?',\n",
       "  'What is the duration allocated for working on the final capstone project?',\n",
       "  'How much time is set aside for the peer review process at the end of the course?'],\n",
       " 'dce0bb09': ['What modules are new in the 2023 course compared to 2022?',\n",
       "  'Will the videos for the Orchestration and Monitoring modules be updated?',\n",
       "  'Are the homeworks for the 2023 cohort different from the previous year?',\n",
       "  'Can you explain the changes made between the 2022 and 2023 versions of the course?',\n",
       "  'Is the overall content of the course mostly unchanged from 2022 to 2023?'],\n",
       " '4920d4e9': ['Is a new cohort scheduled for 2024?',\n",
       "  'When is the beginning date for the 2024 cohort?',\n",
       "  'Can you confirm if there will be a cohort next year?',\n",
       "  'What month will the 2024 cohort launch?',\n",
       "  'Are we expecting a cohort to be available in May 2024?'],\n",
       " '0f1d2765': ['How should I handle my answer if it differs slightly from the options given?',\n",
       "  \"What steps should I take if my response doesn't match the provided choices?\",\n",
       "  \"Am I allowed to share my answer in the course's slack channel if it isn't a perfect match?\",\n",
       "  'What should I do if I feel that none of the choices accurately reflect my answer?',\n",
       "  'Is there a specific way to select the best option if my answer is not an exact match?'],\n",
       " '4eef2f81': ['Can students select their own subjects for the final project?',\n",
       "  'Are there recommended sources for datasets for our final project?',\n",
       "  'Is it acceptable to work on a problem of personal interest for the final assignment?',\n",
       "  'Where can I find datasets to use for the final project?',\n",
       "  'Do we have the freedom to choose the issue we want to address in our final project?'],\n",
       " '7f93c032': ['Is completing weekly homework essential for graduation?',\n",
       "  'What happens if I miss homework for week x?',\n",
       "  'Do I need to finish all homework to get my certificate?',\n",
       "  'How does optional homework affect my course ranking?',\n",
       "  'Is the final capstone project the only requirement for graduation?'],\n",
       " 'ee6f7c89': ['For my final project, do I have to deploy it on the cloud?',\n",
       "  'Is using Kubernetes necessary for cloud points in the final project?',\n",
       "  'Can I receive cloud points for a local deployment of my project?',\n",
       "  'Is it acceptable to simulate AWS for the project without using the cloud?',\n",
       "  'What options do I have for cloud points if I choose not to use a cloud deployment?'],\n",
       " 'b63b12e0': [\"How can I set up port-forwarding for Jupyter Notebook if I'm not using Visual Studio Code?\",\n",
       "  'What specific line do I need to add to my ~/.ssh/config file for automating port-forwarding?',\n",
       "  'Which command should I use to launch Jupyter Notebook on port 8899 without opening a browser?',\n",
       "  'After setting up port-forwarding, how do I access my Jupyter Notebook in a web browser?',\n",
       "  'Where should I add the LocalForward line in my SSH configuration for it to work correctly?'],\n",
       " '892c22c1': ['How can I open Jupyter notebooks in Visual Studio Code?',\n",
       "  'What do I need to install to use Jupyter in VSCode?',\n",
       "  'Is there a specific extension for Jupyter in Visual Studio Code?',\n",
       "  'Can I use Jupyter notebooks within VSCode?',\n",
       "  'What steps are necessary to access Jupyter in VSCode?'],\n",
       " '13d38e8d': ['What steps should I follow to configure GitHub for use with the remote virtual machine?',\n",
       "  'Are there any recommended tutorials for setting up a GitHub repository for homework assignments?',\n",
       "  'How can I set up GitHub on an AWS instance effectively?',\n",
       "  'Is there a specific guide for configuring keys on an AWS instance?',\n",
       "  'Once set up, will I be able to push my changes to the repository without issues?'],\n",
       " '7d64e9e0': ['What steps should I follow to open Jupyter Notebook in AWS?',\n",
       "  'What issue did I encounter when trying to access Jupyter from my desktop?',\n",
       "  'What command do I need to run to generate the Jupyter Notebook configuration file?',\n",
       "  'Which file do I need to edit to change the Jupyter Notebook settings?',\n",
       "  'What specific line should I add to the jupyter_notebook_config.py file to resolve the access issue?'],\n",
       " '645f0a55': ['What are the steps to set up WSL on my Windows machine for this course?',\n",
       "  \"How can I download Anaconda once I've installed WSL?\",\n",
       "  'Is there a command I need to run to get Docker Desktop working with WSL?',\n",
       "  'What is the command for cloning a GitHub repository for our study materials?',\n",
       "  'How do I install Jupyter within the WSL environment for the course assignments?'],\n",
       " '7297b7fc': ['What steps should I follow to effectively create a .gitignore file for my project?',\n",
       "  'How can I exclude all files in a specific folder from being pushed to my remote repository?',\n",
       "  'Is there a way to ignore multiple file types with a single rule in the .gitignore file?',\n",
       "  'Where can I find more detailed information about using .gitignore rules and patterns?',\n",
       "  'What file extension will I need to specify in my .gitignore file to ignore all parquet files?'],\n",
       " '68154f64': ['What visual indicators can I look for to confirm the status of my EC2 instance when I stop it?',\n",
       "  'Are there any additional charges I should expect even after stopping my EC2 instance?',\n",
       "  'What happens to data that is uploaded to an EC2 instance once it is stopped?',\n",
       "  'Is there a method to receive notifications or alerts regarding my billing on AWS services?',\n",
       "  'Can you provide guidance on how to set up billing alerts for my AWS account?'],\n",
       " 'dc7b6f51': ['How can I obtain an invitation code for IBM Cloud?',\n",
       "  'What is the process to verify my account on IBM Cloud?',\n",
       "  'Are there any significant differences between IBM Cloud and AWS?',\n",
       "  'Is there a resource where I can learn more about IBM Cloud features?',\n",
       "  'Can you share your personal experience with IBM Cloud?'],\n",
       " 'b25c6ca3': ['What strategies can I use to minimize costs while running an AWS instance during this course?',\n",
       "  'If I run my AWS instance for around 5 hours each day, what would my estimated monthly cost be?',\n",
       "  'How will using the AWS instance affect my public IP address when I restart it?',\n",
       "  'Is it possible to receive alerts if I exceed my budget for AWS expenses?',\n",
       "  'Where can I find a tutorial to help me set up budget alerts in AWS?'],\n",
       " '9f69ca26': ['Can I complete the course using only the AWS free tier?',\n",
       "  'Are there any AWS services that are not included in the free tier?',\n",
       "  'Will I need to use localstack for certain tasks in this course?',\n",
       "  'Is it necessary to pay for AWS services while taking this course?',\n",
       "  'Which specific AWS services should I be aware of that are not part of the free tier?'],\n",
       " '0f1ddc9e': [\"What should I do if I encounter the error message 'This site can’t be reached' when trying to access an AWS EC2 instance using its IP address?\",\n",
       "  'Is it necessary to open the IP address of my AWS EC2 instance in a browser for it to work?',\n",
       "  'How can I connect to my running AWS EC2 instance from my local machine?',\n",
       "  'What command should I use to connect to an EC2 instance with a specific IP address and key file?',\n",
       "  'What is the proper location for storing the downloaded key file when connecting to an AWS EC2 instance?'],\n",
       " '01f61154': [\"What does the error message 'unprotected private key file' indicate when using SSH?\",\n",
       "  \"Can you explain how to resolve the 'unprotected private key file' error when connecting to an EC2 instance?\",\n",
       "  'What command is needed to fix the file permissions of my private key file?',\n",
       "  'Where can I find a resource that provides guidance on fixing SSH permission errors?',\n",
       "  'What permission level should I set for my private key file to avoid security issues?'],\n",
       " 'd43c32ba': ['What could be causing my AWS EC2 instance to drop my SSH connection intermittently?',\n",
       "  'How can I troubleshoot recurring SSH connection issues with my AWS EC2 instance?',\n",
       "  \"Is there a reason why my SSH connection drops only after running specific code like 'import mlflow'?\",\n",
       "  'What steps can I take to reconnect to my EC2 instance after losing the SSH connection?',\n",
       "  'How can I prevent my instance from running out of memory and causing SSH disconnections?'],\n",
       " 'a044d267': [\"What happens to my EC2 instance's IP address when I restart it?\",\n",
       "  \"How can I avoid manually updating the config file for my EC2 instance's IP?\",\n",
       "  'Is there a solution for automatically updating the IP address on my EC2 instance?',\n",
       "  'Where can I find a script to help with IP address updates for EC2?',\n",
       "  'Does the IP address change every time I restart my EC2 instance?'],\n",
       " 'abf8ccdc': ['What should I do if I experience crashes in VS Code while trying to connect to Jupyter?',\n",
       "  'How can I ensure that my instance has sufficient compute resources for running Jupyter with VS Code?',\n",
       "  'Is there a specific instance type recommended for using Jupyter in VS Code without crashes?',\n",
       "  'Where can I monitor the performance of my EC2 instance while running Jupyter?',\n",
       "  'What steps can I take to prevent VS Code from crashing during Jupyter usage?'],\n",
       " '26918af3': ['What should I do if I encounter a ValueError stating that X has 526 features while expecting 525 features in my Linear Regression Model?',\n",
       "  'How can I fix the problem of having a mismatch in the number of features when running my validation dataset?',\n",
       "  'What is the purpose of using transform instead of fit_transform when working with DictVectorizer on my validation dataset?',\n",
       "  'What steps do I need to take to ensure that my validation dataset has the correct feature mapping after training?',\n",
       "  'Why does the DictVectorizer throw an error regarding the number of features during my Linear Regression Model execution?'],\n",
       " 'a5234ac0': ['What should I do if I encounter missing dependencies while working on Module 1?',\n",
       "  'Which packages do I need to install to resolve the missing dependencies issue?',\n",
       "  'How can I specifically fix the error related to pandas.read_parquet()?',\n",
       "  'Is there a difference between using pip and Conda for installing the necessary packages?',\n",
       "  'What package is recommended for installation if I am using Conda instead of pip?'],\n",
       " 'af22c52a': ['What should I do if the RMSE I calculate does not match the options provided?',\n",
       "  'How can I filter outliers when evaluating the model on the February data?',\n",
       "  'Is there a specific method to round my RMSE result to two decimal points?',\n",
       "  'What is the warning about deprecated Python modules, and how can I address it?',\n",
       "  'How can I handle null values in my dataset to improve RMSE calculations?'],\n",
       " '2aaac94c': ['What is the method for substituting distplot with histplot in my code?',\n",
       "  'Can you provide an example of how to implement histplot in place of distplot?',\n",
       "  'What additional parameters should I consider when using histplot instead of distplot?',\n",
       "  'How do I ensure that the output of histplot closely matches that of distplot?',\n",
       "  'Is it necessary to adjust any settings when transitioning from distplot to histplot?'],\n",
       " '9d15c9e9': [\"What should I do if I encounter a KeyError related to 'PULocationID' or 'DOLocationID'?\",\n",
       "  \"Can you explain how to fix the error involving 'PULocationID' or 'DOLocationID'?\",\n",
       "  'What is the recommended way to resolve a KeyError for those specific identifiers?',\n",
       "  \"How can I address a KeyError that mentions 'PULocationID' or 'DOLocationID' in my work?\",\n",
       "  'What adjustment is needed to fix the KeyError associated with those location IDs?'],\n",
       " '79b88d0b': ['What issue did you encounter when attempting to read large parquet files?',\n",
       "  'What error message did you receive while trying to read the parquet file in Jupyter?',\n",
       "  'How did you resolve the problem with the large parquet file?',\n",
       "  'What suggestion was given regarding using a different library for reading large parquet files?',\n",
       "  'Who reported the initial problem with reading large parquet files?'],\n",
       " '45485322': ['What should I do to improve the speed of my distplot?',\n",
       "  'Are there any specific data points I need to consider before plotting?',\n",
       "  'How can I identify trips with unusual duration?',\n",
       "  'What steps can I take to handle outliers in my dataset?',\n",
       "  'Is it necessary to remove outliers prior to creating a distplot?'],\n",
       " 'd5eab395': ['What could be the reason for experiencing a high RMSE on the test set during the model evaluation?',\n",
       "  \"How does the usage of OneHotEncoder with handle_unknown set to 'ignore' affect the test set RMSE?\",\n",
       "  'Are there alternative transformers that can be used instead of OneHotEncoder to avoid high RMSE issues?',\n",
       "  'In what way do OneHotEncoder and DictVectorizer differ when processing categorical features for the homework?',\n",
       "  'How are unknown categories represented in the hot-encoded matrix to ensure proper RMSE results?'],\n",
       " '282957fb': ['What are the differences in handling missing data between OneHotEncoder and DictVectorizer as discussed in the module?',\n",
       "  'How might using OneHotEncoder affect the consistency of columns in training and validation datasets?',\n",
       "  'Can you explain why DictVectorizer ignores missing data during training according to the FAQ record?',\n",
       "  'Are there any video resources available that address the use of OneHotEncoder instead of DictVectorizer?',\n",
       "  'Where can I find additional sources for understanding when to use OneHotEncoder versus DictVectorizer?'],\n",
       " '39ad14fd': ['What are the advantages of using DictVectorizer over OneHotEncoder in our module?',\n",
       "  'Can you explain why we opted for DictVectorizer instead of get_dummies from pandas for one-hot encoding?',\n",
       "  'Is OneHotEncoder from scikit-learn considered less useful compared to DictVectorizer in this context?',\n",
       "  'Are there alternative methods for one-hot encoding besides DictVectorizer and OneHotEncoder that we should be aware of?',\n",
       "  'What specific matrix outputs does DictVectorizer support that might differ from OneHotEncoder?'],\n",
       " 'e34df2a5': ['What method can I use to confirm that outliers have been successfully removed from the dataset?',\n",
       "  'How can I utilize pandas to gain insights into the data distribution after outlier removal?',\n",
       "  \"Which pandas function offers a summary report of the data's statistical characteristics?\",\n",
       "  'Can I check the minimum and maximum values of a specific column after applying a boolean expression for clipping?',\n",
       "  'What kind of statistics will determine the status of outliers in my data analysis?'],\n",
       " 'c91b6b57': ['What method can I use to create one-hot encoding for pickup and drop-off locations?',\n",
       "  'How do I handle NaN values in the PUlocationID and DOlocationID columns when encoding?',\n",
       "  'Why is it necessary to convert PUlocationID and DOlocationID values to string?',\n",
       "  \"Does using 'nan' as a string representation for NaN values affect RMSE when using DictVectorizer?\",\n",
       "  \"Can I choose a different string representation instead of '-1' for NaN values in my dataset?\"],\n",
       " '4aa8eafc': ['Is it common for the RSME from LinearRegression to be very close to the actual value but not exactly the same?',\n",
       "  'What should I do if my LinearRegression model is yielding slightly different RSME values on different runs?',\n",
       "  'How can I ensure that my outliers are treated correctly in both the training and validation sets?',\n",
       "  'What is the significance of checking the shape of the one hot encoded feature matrix?',\n",
       "  'How do I properly encode the drop off and pick up codes for my LinearRegression model?'],\n",
       " 'a9daaab0': ['What steps should I take if I encounter an extremely low RMSE score while training my model?',\n",
       "  'How can I verify that my model is actually learning the target variable instead of just predicting it?',\n",
       "  'What are the potential issues if my target variable is included as a parameter during model fitting?',\n",
       "  'How can I ensure that my training data does not inadvertently include the target values?',\n",
       "  'What should I do to confirm that my validation set is set up correctly in relation to my training data?'],\n",
       " '931f9626': ['What is the issue with enabling auto-completion in Jupyter Notebook?',\n",
       "  'How can I resolve the problem with the Tab key not functioning correctly?',\n",
       "  'What specific package needs to be upgraded to enable auto-completion?',\n",
       "  'Who provided the solution for enabling auto-completion in Jupyter Notebook?',\n",
       "  'What version of the jedi package should I install to fix the auto-completion issue?'],\n",
       " '782e1723': ['What should I do if I encounter a 403 Forbidden error while trying to download the NY Taxis datasets?',\n",
       "  'Can you explain the reason behind the 403 Forbidden error when using wget to download the files?',\n",
       "  'Is there a recommended approach to download the datasets without facing the access issues mentioned?',\n",
       "  'Where can I find the official NYC trip record page to download the dataset directly?',\n",
       "  'How can I modify the dataset link to avoid the forbidden access error while downloading?'],\n",
       " '4e08c86a': ['What should I do if PyCharm does not recognize the conda environment path during remote development?',\n",
       "  'How can I activate my conda environment on a remote server to ensure it works with PyCharm?',\n",
       "  'What command do I need to use in the command line to find the Python execution path for my conda environment?',\n",
       "  'Can you explain the steps to add a new interpreter in PyCharm after obtaining the Python path?',\n",
       "  'Is it necessary to use a specific command to activate the conda environment before using it in PyCharm on a remote server?'],\n",
       " '34bcad27': ['What memory issues might I encounter when using DictVectorizer?',\n",
       "  'Why did my linear regression model fail to run on my 16 GB machine?',\n",
       "  'How can I reduce memory usage when using DictVectorizer?',\n",
       "  \"What happens if I set the 'sparse' parameter to False in DictVectorizer?\",\n",
       "  \"What is the default setting for the 'sparse' parameter in DictVectorizer?\"],\n",
       " '96144e66': [\"What should I do if Anaconda didn't update my .bashrc after installation?\",\n",
       "  'How can I add Anaconda entries to my .bashrc if they are missing?',\n",
       "  'What commands do I need to run to initialize the conda environment in bash?',\n",
       "  'Is there a way to automatically edit my .bashrc for Anaconda configuration?',\n",
       "  'What command do I use to reload my .bashrc after making changes?'],\n",
       " '840f739d': ['Why are the feature sizes different for the training and validation data sets?',\n",
       "  'What specific operation should I use on the dictionary vectorizer during HW1?',\n",
       "  \"Is it necessary to perform 'fit' on the premade dictionary vectorizer provided?\",\n",
       "  'What should I do instead of executing the fit pipeline on my model?',\n",
       "  'Who can I reach out to if I have more questions about the module?'],\n",
       " 'bf006ff9': [\"What should I do if I encounter a 'Permission denied (publickey)' error after removing my public key on an AWS machine?\",\n",
       "  'Can you provide a guide for regaining access to my instance after losing my public key?',\n",
       "  'Which command do I need to use to retrieve my old public key after removing it?',\n",
       "  'Is there a link that can help me log in to my instance via Session Manager to recreate my public key?',\n",
       "  'Where can I find additional information about retrieving a public key on AWS EC2?'],\n",
       " 'f178d4a0': ['What is the reason behind getting an excessively high RMSE for the validation dataset?',\n",
       "  'Why is it important to ensure that the validation dataset is treated similarly to the training dataset?',\n",
       "  'Can you explain what steps were taken to remove outliers from the February dataset?',\n",
       "  'What issues arise from converting the sparsematrix result from DictVectorizer into an ndarray?',\n",
       "  'How did you resolve the problem with obtaining the correct RMSE results?'],\n",
       " 'b80401a2': [\"What should I do if I'm unable to import sklearn in my project?\",\n",
       "  'How can I resolve the issue with importing DictVectorizer from sklearn.feature_extraction?',\n",
       "  'Is there a specific command I need to run to fix sklearn import issues?',\n",
       "  'What error signal indicates trouble with sklearn imports in my code?',\n",
       "  'Who experienced a similar issue with sklearn and how did they fix it?'],\n",
       " '88002d35': ['Why am I unable to access Localhost:5000?',\n",
       "  'What should I do if I encounter an authorization issue on Localhost?',\n",
       "  'How can I resolve the problem with Localhost Denied messages?',\n",
       "  'Is there a specific solution for Chrome users facing access issues?',\n",
       "  'What does flushing socket pools do in resolving this authorization problem?'],\n",
       " 'fe61aa5b': ['What should I do if I encounter a message indicating that port 5000 is already in use?',\n",
       "  'How can I identify the process that is currently using port 5000 on my Mac terminal?',\n",
       "  'What command can I execute to terminate the process using port 5000 after finding its process ID?',\n",
       "  'Is there a command available that can forcibly kill all processes using port 5000 at once?',\n",
       "  'If I want to avoid the conflict with port 5000, what alternative port can I use when launching the MLflow UI?'],\n",
       " 'b9adeb39': [\"What does the error 'ValueError: could not convert string to float' indicate when I run register_model.py?\",\n",
       "  \"Can you explain the significance of the 'with' statement in the objective function for logging parameters?\",\n",
       "  'What modifications should I make to prevent the parameters from being logged in a group?',\n",
       "  'Where should I place the mlflow.log_params function in my hyper-parameter tuning code?',\n",
       "  'What effect does the order of parameter logging have on the execution of register_model.py?'],\n",
       " 'ebc13686': [\"What should I do if I can't see my experiment in the MLflow UI?\",\n",
       "  'How can I ensure that MLflow UI launches from the correct directory?',\n",
       "  'What is the correct format for specifying the tracking URI if my database is located in a subdirectory?',\n",
       "  'Is there a way to use an absolute path for the mlflow.db instead of a relative one?',\n",
       "  'Can I launch the MLflow UI directly from my notebook, and if so, how?'],\n",
       " '939f9c33': ['What specific error message might I encounter when trying to install MLFlow with pip on Windows?',\n",
       "  'What could cause the hash mismatch error while installing the Numpy package through MLFlow?',\n",
       "  'What steps can I take to resolve the issue of package hashes not matching during installation?',\n",
       "  'If I experience the hash mismatch error, what alternative approach might help in successfully installing MLFlow?',\n",
       "  'Is there a possibility that the hash mismatch issue could be related to tampering with the package contents?'],\n",
       " 'b5c3e6af': ['What are the steps required to ensure an experiment is completely removed from the MLFlow database?',\n",
       "  \"Is it true that an experiment remains in the database even after it's deleted from the UI?\",\n",
       "  'Can you explain how to install the necessary package for using SQL in Jupyter notebooks?',\n",
       "  'Which command should I use to load the SQLite database in my notebook?',\n",
       "  'What SQL command do I need to execute to permanently delete an experiment from the database?'],\n",
       " '80554fc2': ['What should I do to avoid losing my changes when trying to update from a public repository?',\n",
       "  'Is it necessary to fork a repo instead of cloning it if I want to keep my changes?',\n",
       "  'Can you explain how to fetch and merge updates from the upstream repository?',\n",
       "  'What are the steps to configure my Git settings to work with my own repository?',\n",
       "  'Where can I find the option to fetch and merge updates on GitHub?'],\n",
       " '943df153': ['What is the maximum allowable image size for the module?',\n",
       "  'How can I resolve the issue of image size exceeding the limit?',\n",
       "  'Which specific version of xgboost causes the large image size issue?',\n",
       "  'What command do I need to run to downgrade to xgboost version 1.6.0?',\n",
       "  'Is there an alternative way to change the xgboost version in my project?'],\n",
       " 'b8d3c55e': ['What should I use instead of the deprecated list_experiments method?',\n",
       "  'What happened to the list_experiments method in version 1.29?',\n",
       "  'Is the list_experiments method still available in the latest version?',\n",
       "  'Who provided the information regarding the change in the MlflowClient object?',\n",
       "  'What is the recommended method to track experiments now?'],\n",
       " '67bf60c6': ['What should I check if MLflow Autolog is not functioning as expected?',\n",
       "  'Where should I place the mlflow.autolog() function in my code?',\n",
       "  'Are there specific packages I need to install for the autologger to work properly?',\n",
       "  'What happens if I forget to install the required dependencies for autologging?',\n",
       "  'Will I receive any notifications if some dependencies for autologging are missing?'],\n",
       " '336f5e36': [\"What should I do if the MLflow URL doesn't open when I try to access it?\",\n",
       "  \"How can I forward the port for MLflow if I'm using a remote virtual machine?\",\n",
       "  'Is there a different URL I can try if 127.0.0.1:5000 displays a blank page?',\n",
       "  'What steps should I take to connect my server to VS Code for MLflow?',\n",
       "  'Do I need to add a specific port number when accessing MLflow in VS Code?'],\n",
       " 'fd2b9972': ['What should I do if I encounter a warning message when using mlflow.xgboost.autolog()?',\n",
       "  'How can I verify if my model has been tracked in MLflow after using autolog?',\n",
       "  'Is the warning message I received regarding mlflow.xgboost.autolog() something I need to worry about?',\n",
       "  \"What steps should I take to ensure that there are no 'tag' filters applied in the MLflow UI?\",\n",
       "  'Who can I contact if I experience issues with experiment tracking in MLflow?'],\n",
       " '75cd9b7a': ['What should I do if I encounter an MlflowException while trying to set a deleted experiment as active?',\n",
       "  'Is it possible to restore a deleted experiment in MLflow, and how would I do that?',\n",
       "  'Can I permanently delete an experiment in MLflow if I no longer need it?',\n",
       "  'What are my options for resolving an MlflowException related to a deleted experiment?',\n",
       "  'Where can I find more information on deleting experiments in MLflow?'],\n",
       " '51c99586': ['What should I do if I encounter an OSError with Errno 28 while trying to install requirements?',\n",
       "  \"How can I increase the disk space on my instance if I'm running out of storage?\",\n",
       "  'What steps do I need to take to configure conda installation on an external disk?',\n",
       "  'Is there a specific command I can use to confirm that my disk is properly mounted on the VM?',\n",
       "  'What alternatives can I use instead of Anaconda if I need more disk space for installations?'],\n",
       " '089c8c18': ['What caused the parameters mismatch in Homework Question 3?',\n",
       "  'Which version of sklearn led to the incorrect number of parameters?',\n",
       "  'What specific function was deprecated in the latest version of sklearn?',\n",
       "  'What action did I take to resolve the parameters mismatch issue?',\n",
       "  'How did upgrading sklearn help in fixing my homework problem?'],\n",
       " 'f4b82056': ['What should I do if I encounter a Protobuf error when trying to install MLflow?',\n",
       "  'How can I resolve the issue with MLflow if I have a version conflict with the Protobuf module?',\n",
       "  'What is the recommended version of the Protobuf library to use with MLflow?',\n",
       "  'What command do I need to execute to downgrade the Protobuf module to make MLflow work?',\n",
       "  \"I installed all the libraries as per the requirements.txt, but I'm facing an error. What steps can I take to fix it?\"],\n",
       " 'dd2e7dc9': [\"How can I ensure I'm in the correct directory when using the mlflow ui command?\",\n",
       "  'What should I verify about my current directory before running mlflow ui?',\n",
       "  'Is there a specific directory I need to be in for mlflow server commands?',\n",
       "  'What command do I need to run after checking my current directory?',\n",
       "  'How do I correctly set up Artifacts folders while using mlflow?'],\n",
       " '3fcbd80e': ['How can I resolve issues with setting up MLflow for experiment tracking on Google Cloud Platform?',\n",
       "  'Are there any helpful links for configuring MLflow on GCP that I can refer to?',\n",
       "  'What resources are available for troubleshooting MLflow experiment tracking setup on GCP?',\n",
       "  'Can you provide specific URLs to guide me through the MLflow setup process on GCP?',\n",
       "  'Where can I find detailed instructions for using MLflow with Google Cloud Platform?'],\n",
       " '924fcf47': ['What should I do if I encounter a warning related to MLflow autologging?',\n",
       "  'Is there a recommended version of setuptools to avoid issues?',\n",
       "  'How can I resolve the warning caused by Distutils in my module?',\n",
       "  'What steps can I take to downgrade setuptools effectively?',\n",
       "  'Which specific version of setuptools is suggested in the solution to the MLflow issue?'],\n",
       " '58240887': ['How can I sort my runs in the MLflow interface?',\n",
       "  'What view should I be in to sort runs in MLflow?',\n",
       "  'Is there a specific view I need to use for sorting in MLflow?',\n",
       "  'Can I sort my runs in the list view of MLflow?',\n",
       "  'Who provided the information about sorting runs in MLflow?'],\n",
       " '67d343f2': ['What issue might I encounter when launching the MLflow UI on a remote server?',\n",
       "  'Why does the MLflow UI not load in my local browser after executing the command?',\n",
       "  'What steps can I take to resolve the TypeError I encountered with send_file()?',\n",
       "  'How can I fix the compatibility issue with Flask when using a conda environment?',\n",
       "  'What specific commands should I run to uninstall the old Flask version and install the updated one?'],\n",
       " '6de95c2a': ['What should I do if I encounter a FileNotFoundError when running mlflow ui on Windows?',\n",
       "  'Why does the mlflow ui command produce an error after installing mlflow with pip?',\n",
       "  'What specific error message might I see when trying to use mlflow ui on a Windows system?',\n",
       "  'How can I resolve the issue related to mlflow ui not being found on my Windows machine?',\n",
       "  'What directory do I need to add to my PATH to fix the mlflow ui error on Windows?'],\n",
       " '2ff28e5b': ['What error occurs when I run the command for the homework using hpo.py?',\n",
       "  'Can you explain the cause of the TypeError related to unsupported operand types in hpo.py?',\n",
       "  'How should I define the max_evals argument to avoid the TypeError in hpo.py?',\n",
       "  'What is the appropriate datatype for the --max_evals argument when using hpo.py?',\n",
       "  'What change do I need to implement to ensure the script runs correctly without errors?'],\n",
       " '29c6bbf1': ['What should I do if I receive a warning about using an unsupported Scikit-Learn version while running mlflow.sklearn?',\n",
       "  'How can I resolve errors that arise during autologging in MLflow due to Scikit-Learn version issues?',\n",
       "  'Is there a specific range of Scikit-Learn versions that I should be using with MLflow to avoid compatibility problems?',\n",
       "  'What steps can I take if upgrading my Scikit-Learn version does not fix the warnings related to MLflow?',\n",
       "  'Where can I find more detailed information about the Scikit-Learn compatibility requirements for MLflow?'],\n",
       " 'bd09df94': [\"Why aren't my experiments showing up when using Mlflow CLI commands?\",\n",
       "  'What command do I use to list experiments in Mlflow?',\n",
       "  'What should I do if the CLI fails to return any experiments?',\n",
       "  'Is there an environment variable that needs to be set for tracking URI?',\n",
       "  'How do I set the MLFLOW_TRACKING_URI correctly?'],\n",
       " 'af887c59': ['What should I do if I cannot view my MLflow experiments after starting the tracking server using the MLflow CLI?',\n",
       "  'How do I set the environment variable for the MLflow tracking URI to access my sqlite database?',\n",
       "  'What is the correct format to export the MLFLOW_TRACKING_URI variable for viewing experiments?',\n",
       "  'Why do some MLflow CLI commands fail to locate the experiments when using the tracking server?',\n",
       "  \"Do I need to specify the tracking URI every time when running certain MLflow commands, such as 'mlflow gc'?\"],\n",
       " 'ee7c59ea': ['How can I view the raw data stored in the SQLite database for my experiments?',\n",
       "  'Is it possible to delete experiments manually from the SQLite database?',\n",
       "  'What type of database does mlflow use for experiment tracking information?',\n",
       "  'How can I inspect the tables within the SQLite database using PyCharm?',\n",
       "  'Can I use other SQL databases like Postgres for experiment tracking with mlflow?'],\n",
       " 'a2531c75': ['Can you explain what it means to launch the tracking server locally in the context of our course?',\n",
       "  'Why would we choose to run the mlflow server on a remote host instead of on an individual laptop?',\n",
       "  'What is the benefit of having multiple colleagues connect to the same mlflow server?',\n",
       "  'In what scenarios would launching the tracking server locally be most useful?',\n",
       "  'How does remote hosting of an mlflow server support collaboration among team members?'],\n",
       " 'bc4b2320': ['What should I do if a parameter like max_depth is not recognized during model registration?',\n",
       "  'How can I ensure parameters are accepted before the model registry process?',\n",
       "  'Is there a specific function to add parameters to the model before registry?',\n",
       "  'How can I append parameters to data.run.params appropriately?',\n",
       "  'Who provided the solution for the parameter recognition issue in Module 2?'],\n",
       " 'f69fb077': ['Why is the max_depth parameter not recognized when using mlflow.log_params in my script?',\n",
       "  'What should I do if mlflow.log_params is not logging the max_depth parameter correctly?',\n",
       "  'How do I modify my hpo.py script to properly log the parameters with mlflow?',\n",
       "  'What happens if I run my experiment again after adding mlflow.log_params for max_depth?',\n",
       "  'Should I delete the previous experiment or how can I change it to fix the max_depth logging issue?'],\n",
       " 'e223524c': ['What error message do I encounter when running the register_model.py script in a Jupyter notebook?',\n",
       "  \"What is the suggested solution for fixing the error related to 'tuple' when using register_model.py?\",\n",
       "  'What specific decorators need to be removed to resolve the AttributeError in my homework?',\n",
       "  \"Can you explain what causes the AttributeError: 'tuple' object has no attribute 'tb_frame' in the context of this course?\",\n",
       "  'Is there any documentation or guidance on handling errors when copying scripts into Jupyter notebooks?'],\n",
       " '0f08bec7': ['What kind of error might I encounter while running the preprocess_data.py file related to WandB?',\n",
       "  'How can I resolve the WandB API error that mentions the API key not being configured?',\n",
       "  'Where can I find my API key to fix the WandB login issue?',\n",
       "  'What steps should I follow to add my WandB API key before running the preprocess_data.py script?',\n",
       "  \"Who can I contact for assistance if I'm still having issues with the WandB API after following the instructions?\"],\n",
       " '8b4b1685': ['What should I check if I receive a warning about failing to infer model signature in mlflow.xgboost?',\n",
       "  'Is there a specific order I need to follow when enabling autologging for my XGBoost model?',\n",
       "  'What is the correct method to enable MLflow autologging for XGBoost?',\n",
       "  'Could the format of my dataset affect the ability to enable autologging in MLflow?',\n",
       "  'What steps should I take after enabling autologging to successfully train my XGBoost model?'],\n",
       " 'ecfc5c07': ['What should I do if wget command fails to work for downloading files?',\n",
       "  'How can I solve the issue of pip not being recognized in Windows?',\n",
       "  'Is there an alternative way to use pip with Python virtual environments?',\n",
       "  \"What command should I use instead of wget if it doesn't function properly?\",\n",
       "  'Who provided the solution for the wget issue in the course?'],\n",
       " 'a1b68c52': ['How can I open a GitHub notebook directly in Google Colab?',\n",
       "  'What is the process to change the URL for opening a GitHub notebook in Colab?',\n",
       "  'Is it possible to open notebooks from private repositories in Google Colab?',\n",
       "  'What should I do if I find using the Wandb UI challenging?',\n",
       "  'Where can I find official documentation for navigating Wandb UI?'],\n",
       " '483e7d61': ['What are the key reasons for using a time-based data split instead of a random one during model training, testing, and validation?',\n",
       "  'How do we determine whether our time-based validation approach reveals seasonality in our data?',\n",
       "  'Can you explain what the potential risks are when using a random sample for train and test sets in model development?',\n",
       "  'What are the implications of using out-of-time validations for reporting model performance to stakeholders?',\n",
       "  'What specific steps do I need to take if I encounter an error related to urllib3 while running the mlflow server on AWS?'],\n",
       " 'e5c33f50': ['What information is included in the problem title section of Module 3?',\n",
       "  'Can you explain what the problem description entails?',\n",
       "  'What details are provided in the solution description for each problem?',\n",
       "  'How can I identify who added a problem in Module 3?',\n",
       "  'Is it necessary to include a solution description when submitting a problem?'],\n",
       " 'cbf13b19': ['Can you tell me where I can find answers for Prefect-related inquiries?',\n",
       "  'Is there a specific location for the FAQ regarding Prefect questions?',\n",
       "  'Where can I look up frequently asked questions about Prefect?',\n",
       "  'Could you guide me to the Prefect FAQ section?',\n",
       "  'What is the reference point for questions concerning Prefect?'],\n",
       " '39861d6e': [\"What should I do if I encounter an 'Invalid choice' error when trying to login to ECR using Docker?\",\n",
       "  'How can I properly login to ECR with Docker on Windows?',\n",
       "  'Is there a specific version of AWS CLI required to avoid errors when using Docker with ECR?',\n",
       "  'Can you provide a reference for the correct command to login to ECR using Docker?',\n",
       "  \"What command should I use instead of 'aws ecr get-login' to authenticate Docker with ECR?\"],\n",
       " '3dac15ff': ['How do I structure multiline commands in Windows Powershell correctly?',\n",
       "  'What is the purpose of using the backtick (`) at the end of each line in a Powershell command?',\n",
       "  'How can I create non-persistent environment variables in Powershell?',\n",
       "  'What is the correct syntax for escaping double quotes in a multiline string?',\n",
       "  'Can you provide an example of using the aws kinesis command with environment variables?'],\n",
       " '32686722': ['What common issue might arise when trying to install Pipenv using the system Python version 3.10?',\n",
       "  \"How can I resolve the AttributeError related to 'MutableMapping' when using Pipenv?\",\n",
       "  'What command should I use to remove Pipenv if it was initially installed via apt-get?',\n",
       "  'What is the recommended way to have a non-system Python environment for Pipenv?',\n",
       "  'Can you explain the steps to reinstall Pipenv after setting up a non-system Python?'],\n",
       " '22521751': ['What should I do if I cannot access the module due to an HTTPS URL issue?',\n",
       "  'How can I verify if the SSL module is configured correctly?',\n",
       "  'What command do I need to use to check the SSL configuration?',\n",
       "  'What steps should I take if the SSL output is empty?',\n",
       "  'How do I upgrade the pipenv package in my environment to fix the module issue?'],\n",
       " '81ad4784': ['What error is displayed when trying to install scikit-learn version 1.0.2 using pipenv?',\n",
       "  \"What should I do if I encounter a 'No module named pip._vendor.six' error during installation?\",\n",
       "  \"Which command do I need to run to resolve the 'ModuleNotFoundError' while installing scikit-learn?\",\n",
       "  'Is there a specific package I need to install before attempting to reinstall scikit-learn?',\n",
       "  'What is the command to remove the existing pipenv environment before reinstalling scikit-learn?'],\n",
       " '29b5651e': ['How can I integrate Jupyter notebooks with my Pipenv environment effectively?',\n",
       "  'What steps should I take to register a kernel for Jupyter when using Pipenv?',\n",
       "  'Is there a specific command I need to run to install jupyter and ipykernel in Pipenv?',\n",
       "  'Will adding the virtual environment in VS Code allow me to use it easily with Jupyter notebooks?',\n",
       "  'Where can I find additional guidance on using Jupyter with Pipenv if I need further help?'],\n",
       " 'ca79bbe8': ['What should I do if I encounter no output when running a Jupyter notebook in a Pipenv environment?',\n",
       "  'Which version of Tornado caused issues with output on prints in my Jupyter notebook?',\n",
       "  'How did downgrading Tornado resolve the issue with my Jupyter notebook?',\n",
       "  'Is there a specific version of scikit-learn that I should use to avoid this problem?',\n",
       "  'Where can I find more information about the bug related to Tornado and Jupyter notebooks?'],\n",
       " '668f1ad9': [\"What should I do if I encounter an 'Invalid base64' error when executing the aws kinesis put-record command?\",\n",
       "  \"Why might the 'Invalid base64' error occur when using aws kinesis put-record on my local machine?\",\n",
       "  \"How does the AWS CLI version affect the occurrence of the 'Invalid base64' error?\",\n",
       "  \"What is the recommended method to resolve the 'Invalid base64' error in the AWS CLI?\",\n",
       "  'Where can I find a reference for the AWS CLI version mentioned with a warning in the course video?'],\n",
       " '7a6f23eb': [\"What error might I encounter when executing the starter.ipynb for homework's Q1?\",\n",
       "  'What does the error message index 311297 indicate when dealing with a parquet file?',\n",
       "  'How can I resolve the issue related to the error mentioned in Module 4?',\n",
       "  'Is it necessary to update pandas even if the version is the latest when facing this error?',\n",
       "  'Who provided the solution for the out of bounds error in the module record?'],\n",
       " '232e5557': ['What should I do if I notice that Pipfile.lock is missing after generating Pipfile?',\n",
       "  'How can I ensure that Pipfile.lock gets created when I have a Pipfile?',\n",
       "  'Is there a specific command I need to run to generate Pipfile.lock?',\n",
       "  'What command do I use with Pipenv to create a Pipfile.lock file?',\n",
       "  \"If my Pipfile.lock wasn't generated, is there a way to force its creation?\"],\n",
       " 'e44ec04a': ['What causes the Permission Denied error when using Pipenv?',\n",
       "  'How can I fix the Permission Denied issue with Pipenv?',\n",
       "  'Which module is typically responsible for the Permission Denied error in Pipenv?',\n",
       "  'Is there a specific method for resolving the Python Finder issue in Pipenv?',\n",
       "  'Who provided the solution for the Permission Denied error related to Pipenv?'],\n",
       " '55fdb8b9': ['What should I do if I encounter a ValueError regarding unknown format codes while using the command line interface?',\n",
       "  'Why am I getting an error related to argument parsing when trying to convert command line inputs to integers?',\n",
       "  'How can I properly pass a year as an argument to a script to avoid formatting errors?',\n",
       "  'What is the cause of the error that appears when attempting to format a year using f-strings in Python?',\n",
       "  'How can I utilize the click library to correctly handle year inputs for my function?'],\n",
       " 'bf9082a2': ['What is the importance of using the correct image when Dockerizing a project?',\n",
       "  'How do I properly copy data into my Docker image during the build process?',\n",
       "  'Why should I avoid using absolute paths in my Docker image?',\n",
       "  'What is the recommended working directory to set before executing code in a Docker container?',\n",
       "  'Can you explain the commands needed to build and run a Docker container for my project?'],\n",
       " 'e7906e44': ['How can I run both Flask and MLFlow server in a single Docker container?',\n",
       "  'What should be included in the Dockerfile to ensure both services can run?',\n",
       "  'Is there a script arrangement needed for running multiple services inside a container?',\n",
       "  'How do I make sure that all necessary scripts have executable permissions?',\n",
       "  'What is the functionality of the wrapper script in managing multiple processes?'],\n",
       " '76d8892e': ['What should I do if I encounter an InstallationError related to pipfile.lock during deployment?',\n",
       "  \"How can I resolve the issue where the command 'python setup.py egg_info' fails with error code 1?\",\n",
       "  'Is there a specific command I need to run to fix issues with pipenv and wheel during deployment?',\n",
       "  \"What does the error message 'Cannot generate pipfile.lock' indicate in Module 4?\",\n",
       "  'Why is it necessary to force an upgrade of pipenv and wheel when facing InstallationError?'],\n",
       " 'c5c2c82a': ['What is the recommended method for connecting an S3 bucket to MLFLOW?',\n",
       "  'Why are access keys necessary when using boto3 to connect to AWS servers?',\n",
       "  \"What could happen if I don't have the correct access keys for my S3 bucket?\",\n",
       "  'Is it possible to configure my S3 bucket to be publicly accessible without using access keys?',\n",
       "  'Where can I find more information about using boto3 and AWS access keys?'],\n",
       " '82b6c143': ['What should I do if I receive an InvalidAccessKeyId error when uploading to S3?',\n",
       "  'Why does the upload succeed with aws cli and boto3 in Jupyter notebook but fail otherwise?',\n",
       "  'How can I resolve the issue with my AWS Access Key Id when using S3?',\n",
       "  'What environment variable needs to be set to fix the S3 upload error?',\n",
       "  'Is there a specific default profile I should be using for AWS uploads?'],\n",
       " '77d9a742': ['What is the problem related to lib_lightgbm.so in Module 4?',\n",
       "  'Why is the image not found when using lightgbm?',\n",
       "  'What should I add to my Dockerfile to resolve the lightgbm issue?',\n",
       "  'How do I change the installer command based on my operating system?',\n",
       "  'Who provided the solution for dockerizing lightgbm?'],\n",
       " '1667e95d': [\"What kind of error might occur when using mlflow's pyfunc.load_model in a lambda function?\",\n",
       "  'What does the warning message from mlflow indicate when an error is raised?',\n",
       "  'How can I view the complete traceback of the error encountered in the lambda function?',\n",
       "  'What specific adjustment can I make to the lambda function to resolve the memory issue?',\n",
       "  \"Who contributed the solution regarding the lambda function's memory increase?\"],\n",
       " '624a3525': ['What is the final outcome of the video in Module 4?',\n",
       "  'Can you explain the relationship between the notebook and the video in this module?',\n",
       "  'Is the FYI Notebook related to mlflow pipelines as mentioned in the video?',\n",
       "  'What should I do if I experience issues while following the video?',\n",
       "  'Who provided the information about the notebook and video in Module 4?'],\n",
       " '1db86601': ['How can I ensure that my Docker image reads AWS credentials correctly?',\n",
       "  'What command format should I use to pass environment variables while running my Docker container?',\n",
       "  'Is it possible to use AWS configuration files in Docker, and if so, how?',\n",
       "  \"What should I do if my Python script can't access AWS credentials from environment variables?\",\n",
       "  'Can I pass multiple environment variables to my Docker container, and how would I do that?'],\n",
       " '047baefe': ['What steps do I need to follow to view the contents of the model in the docker container located in the app directory?',\n",
       "  'Can you explain the purpose of the Dockerfile in the context of troubleshooting the model image?',\n",
       "  'How do I ensure that my files are included when I build the Docker image for the model?',\n",
       "  'What is the role of the CMD command in the Dockerfile, and how does it differ from the RUN commands?',\n",
       "  'Is there a way to have a script run automatically when starting the docker container, and how can I implement that?'],\n",
       " '4f240372': ['How can I fix the platform mismatch warning when deploying my image?',\n",
       "  'What command should I use to build a docker image with a specific platform?',\n",
       "  'Is there a way to specify the platform when building my docker image?',\n",
       "  \"What happens if the requested image's platform does not match the host platform?\",\n",
       "  'Can you provide an example of how to include the platform tag in a docker build command?'],\n",
       " '7aef625b': ['What should I do if I encounter an HTTP 403 error when using apply_model() in score.ipynb?',\n",
       "  'Is there an alternative URL for the input file in case of a forbidden error?',\n",
       "  'What format should the input_file variable follow to avoid an HTTP error?',\n",
       "  'Can you clarify the correct structure for the input_file when accessing trip data?',\n",
       "  'What is the updated link to access the NYC taxi trip data instead of the previous one?'],\n",
       " 'a3aa3a7d': [\"What does the error message 'ModuleNotFoundError: No module named 'pipenv.patched.pip._vendor.urllib3.response'' indicate?\",\n",
       "  'How can I resolve the error related to missing modules in pipenv?',\n",
       "  'What command can I use to reinstall pipenv to fix the module not found error?',\n",
       "  'Is there a specific command to update pip that might help with this issue?',\n",
       "  'What should I do if I encounter an error in the connection pool related to urllib3?'],\n",
       " 'd2719204': ['What should I do if I encounter a login prompt in Grafana after following the video instructions?',\n",
       "  'What are the default credentials for Grafana when accessing localhost:3000?',\n",
       "  'How can I change my password after logging in to Grafana?',\n",
       "  'Where can I find additional information regarding the login issue in Grafana?',\n",
       "  'What steps are involved if I run into problems with Docker Compose while accessing Grafana?'],\n",
       " '30b8e8e6': ['What should I do if I encounter an error when starting monitoring services in Linux?',\n",
       "  \"Why does the command 'docker compose up --build' not work for me?\",\n",
       "  \"How can I resolve the 'unknown flag: --build' message in the command prompt?\",\n",
       "  \"Is there a difference between 'docker compose' and 'docker-compose' in Linux?\",\n",
       "  'What command should I use to successfully start services using Docker Compose?'],\n",
       " 'f33fc6e9': [\"What should I do if I encounter a KeyError 'content-length' when executing prepare.py?\",\n",
       "  'Is there a specific reason why I am receiving a KeyError while running the script?',\n",
       "  'What changes did Emeli Dral make to the prepare.py file to resolve the issue?',\n",
       "  'Can you provide the updated URL that should be used in prepare.py to download the taxi data?',\n",
       "  'Is the original URL mentioned in prepare.py no longer functional for accessing the taxi data?'],\n",
       " 'd828de2a': [\"What problem occurs when I execute the command 'docker-compose up --build' for the real-time prediction service?\",\n",
       "  'Why does my evidently service exit with code 2 and what specific error message do I receive?',\n",
       "  'What are the recommended solutions if my service fails to run due to the inability to import the pyarrow module?',\n",
       "  'What should I do if installing the pyarrow module and restarting my machine does not resolve the issue?',\n",
       "  'How did commenting out the pyarrow import in the app.py file of the evidently service help solve the problem?'],\n",
       " '03f20ec1': ['What should I do if I encounter a ValueError related to metrics in Module 5?',\n",
       "  'Can you explain the cause of a ValueError in Evidently while working on Report?',\n",
       "  'What steps should I follow to resolve an error involving incorrect items in Module 5?',\n",
       "  'How can I fix a ValueError that mentions metrics or metric presets?',\n",
       "  'Is there any specific syntax I should check if I receive a ValueError in this module?'],\n",
       " '249726fe': ['What error might occur when using RegressionQualityMetric()?',\n",
       "  'What do I need to specify when using RegressionQualityMetric()?',\n",
       "  \"Is it necessary to include target='duration_min' when calling RegressionQualityMetric()?\",\n",
       "  'How should I modify current_data to use RegressionQualityMetric()?',\n",
       "  'Who provided the information about the RegressionQualityMetric() error?'],\n",
       " '4e492af0': ['What does the error message about finding an array with 0 samples mean in the context of LinearRegression?',\n",
       "  'Why does the training dataset become empty when using an early date for generating data?',\n",
       "  'How can I modify the starting date to avoid the issue of an empty training dataset?',\n",
       "  'What minimum data requirement does LinearRegression need to function correctly?',\n",
       "  'Can you explain how adjusting the beginning date impacts the training dataset generation process?'],\n",
       " '10011dc1': ['What should I do if I encounter errors related to target or prediction columns after including a new metric?',\n",
       "  'Where can I find detailed guidelines on requirements for adding a new metric?',\n",
       "  'Can you give an example of a metric that doesn’t require any parameters?',\n",
       "  'Is there a specific metric recommended for evaluating feature correlations?',\n",
       "  'Who can I contact for further assistance regarding issues with metrics in Module 5?'],\n",
       " '92fb909a': ['What should I do if I encounter an error when logging into Grafana with the default credentials?',\n",
       "  'How can I resolve the issue of not being able to log in to Grafana?',\n",
       "  'Is there a specific command to reset the admin password in the Grafana container?',\n",
       "  'What steps do I need to take if the standard login credentials for Grafana do not work?',\n",
       "  'Who contributed the solution for the login issue in Grafana?'],\n",
       " '2b8cb640': ['Why are the charts in Grafana not refreshing like I expected?',\n",
       "  'What steps should I take to ensure my Grafana charts display updated data?',\n",
       "  'How often should I set the refresh interval for Grafana to get timely updates?',\n",
       "  'What timezone settings do I need to change for Grafana to update correctly?',\n",
       "  'Is there a specific example of a timezone that caused issues in Grafana updates?'],\n",
       " 'd4ceab0b': [\"What should I do if the Prefect server doesn't run on my local machine?\",\n",
       "  'How can I resolve the issue of the Prefect server stopping immediately after starting it?',\n",
       "  \"Is there a way to run my script if the Prefect server isn't operational locally?\",\n",
       "  'Did anyone else encounter issues with the Prefect server not running locally?',\n",
       "  'What steps can I take if I need to report problems regarding the Prefect server on GitHub?'],\n",
       " '482e575f': [\"What should I do when I encounter a 'no disk space left' error during the 'docker compose up' command?\",\n",
       "  'How can I remove unused items in Docker to free up space?',\n",
       "  'Is there a way to check what is consuming disk space in Docker before I delete anything?',\n",
       "  \"What command can I use to clean up Docker's build cache, containers, and images?\",\n",
       "  \"Who provided the solution for the 'no disk space left' issue in the FAQ record?\"],\n",
       " '33e775eb': [\"What error might I encounter when I run 'docker-compose up --build'?\",\n",
       "  \"How can I resolve the issue related to 'php_network_getaddresses' when using Docker?\",\n",
       "  'What should I add to the adminer block in the yml file to fix the address family error?',\n",
       "  'Can you provide the command that needs to be added in the yml file to resolve the mentioned problem?',\n",
       "  'Which image is referenced in the example provided to fix the issue during deployment?'],\n",
       " '19a3d34a': ['What is the main issue when trying to create Evidently charts in Grafana?',\n",
       "  'What kind of panels can we use in Grafana to approximate Evidently chart features?',\n",
       "  'Is there a quick way to replicate the entire Evidently dashboard in Grafana?',\n",
       "  'How can I export Evidently output for use in external visualizations?',\n",
       "  'Why might it be more beneficial to use Evidently for certain plots during debugging?'],\n",
       " '55c68f23': [\"What should I do if I encounter the error 'Unable to locate credentials' while using localstack with kinesis?\",\n",
       "  'Which additional environment variables need to be added in the docker-compose.yaml file to resolve credential errors?',\n",
       "  'Can you explain how to configure AWS credentials using the AWS CLI to avoid issues with localstack?',\n",
       "  'Is it necessary to provide real values for AWS Access Key ID and Secret Access Key when fixing the credentials error?',\n",
       "  \"What are some common solutions for resolving the 'Unable to locate credentials' error in localstack?\"],\n",
       " '54020f0a': [\"What does the error 'unspecified location constraint is incompatible' mean when creating a bucket?\",\n",
       "  \"How can I resolve the 'IllegalLocationConstraintException' error while using localstack?\",\n",
       "  'What is the correct syntax for creating a bucket with the LocationConstraint in boto3?',\n",
       "  'Why do I encounter a location constraint error when trying to create a bucket in a specific region?',\n",
       "  'Can you explain the parameters needed for the create_bucket function to avoid this error?'],\n",
       " 'b6249d2c': [\"What should I do if I encounter an error message that includes '<botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>' after running an AWS CLI command?\",\n",
       "  \"Is there a specific AWS CLI command that might trigger the error message '<botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>'?\",\n",
       "  'What environment variables do I need to set to resolve the error I received after executing an AWS CLI command?',\n",
       "  'Do the values I set for AWS environment variables need to be correct to fix the AWS CLI error?',\n",
       "  'Who provided the instructions on how to fix the error message related to the AWS CLI command?'],\n",
       " '31543d95': ['What error occurs at every commit when using pre-commit hooks?',\n",
       "  'Why are pre-commit hooks not running during commits?',\n",
       "  'What should I check in the .pre-commit-config.yaml file if I encounter an error?',\n",
       "  'Is there a specific indentation requirement for the repo statements in the configuration file?',\n",
       "  'Who provided the information regarding the pre-commit error and its solution?'],\n",
       " 'e147bbb6': ['What should I do if I cannot reconfigure pytest after using a previous folder?',\n",
       "  'Is there a way to completely remove pytest test from a folder?',\n",
       "  'Where can I find the .vscode folder that needs to be deleted?',\n",
       "  'What folder was used as an example for testing in Module 6?',\n",
       "  'Whose input was added regarding pytest and the .vscode folder?'],\n",
       " 'dc55657f': ['What issue can occur when using Kinesis Get Records in LocalStack as demonstrated in video 6.3?',\n",
       "  'At what time in video 6.3 does the problem with empty records happen?',\n",
       "  'What specific command modification is needed to resolve the issue with empty records in Kinesis?',\n",
       "  'What endpoint URL must be used for the Kinesis get records command when working with LocalStack?',\n",
       "  'Is there any additional option required in the Kinesis command to avoid signing issues during the get records call?'],\n",
       " 'f6979915': ['What issue might occur when attempting to commit changes using Powershell with a pre-commit yaml file?',\n",
       "  'Can you explain the error message related to utf-8 encoding when running git commit?',\n",
       "  'What command should I use to set utf-8 encoding for the pre-commit yaml file?',\n",
       "  'Who provided the solution for the utf-8 encoding error in the pre-commit yaml file?',\n",
       "  'What does the error InvalidConfigError indicate when trying to commit in Git?'],\n",
       " '1076a121': ['What error might occur when performing a Git commit with a pre-commit hook?',\n",
       "  \"What is the error message related to 'PythonInfo' when trying to commit?\",\n",
       "  'How do I resolve the issue with the pre-commit hook error?',\n",
       "  'What command must be run to clear app-data of the virtual environment?',\n",
       "  'Who provided the solution to the pre-commit hook error?'],\n",
       " 'aa203ca7': [\"What causes the 'module not found' error when using Pytest with custom packages?\",\n",
       "  'Can you explain the correct project structure that should be followed to avoid errors in Pytest?',\n",
       "  \"Why does running 'python test_model_service.py' work while 'pytest ./test/unit_tests' fails?\",\n",
       "  'What is the recommended solution for resolving the module not found error in this context?',\n",
       "  \"What does the command 'python -m pytest' do differently compared to running pytest directly?\"],\n",
       " '8b04605d': ['What is the issue encountered when using pre-commit hooks with pytest and custom packages?',\n",
       "  \"Can you explain the specific project structure that leads to the 'No module named production' error?\",\n",
       "  'What adjustments should be made to the pre-commit hook configuration to resolve the pytest error?',\n",
       "  'How should the run.sh script be configured to ensure pytest runs correctly in this context?',\n",
       "  'What commands are necessary within the run.sh script to set the correct directory and run pytest?'],\n",
       " 'a3b9af04': ['What do I do if I encounter a permission denied error while running a script in GitHub Actions?',\n",
       "  'Can you provide an example of a step in the CI YAML file that might cause a permission error?',\n",
       "  'What does error code 126 indicate when using GitHub CI action?',\n",
       "  'How can I solve a permission issue with a script file in my project?',\n",
       "  'What command should I use to add execution permission to a script before committing?'],\n",
       " 'b16aae74': ['What does it mean when a docker-compose file has too many containers and how does it affect resource usage?',\n",
       "  'How can I select a specific group of containers in a docker-compose setup during testing?',\n",
       "  'What is the method to add profiles in the service definition of a docker-compose file?',\n",
       "  'What command should I use when starting a service with a specific profile in docker-compose?',\n",
       "  'Who contributed to the solution of managing multiple Docker containers with profiles?'],\n",
       " '66326a87': ['What should I check if I am experiencing issues with integration tests and Kinesis?',\n",
       "  'How can I ensure that my AWS regions are correctly aligned in my docker-compose setup?',\n",
       "  'What specific configuration should I use for the AWS region in both my local setup and docker-compose?',\n",
       "  'If my AWS regions do not match, what could potentially go wrong when creating a stream?',\n",
       "  'Can you provide an example of how to set the AWS region in the config file and docker-compose.yaml?'],\n",
       " 'fb3c4150': ['What issue should I be aware of regarding the pre-commit command and the isort repository?',\n",
       "  'What version should I set for isort to resolve the pre-commit command failure?',\n",
       "  'Who contributed the solution for the isort pre-commit command issue?',\n",
       "  'Is there a specific version number I need to adjust to fix the problem with isort?',\n",
       "  'Can you explain the problem related to the pre-commit command when using isort?'],\n",
       " '886d1617': ['What steps are necessary to dismantle infrastructure using GitHub Actions?',\n",
       "  'How can I initiate the destruction of AWS infrastructure created by CD-Deploy Action?',\n",
       "  'What command do I use to initialize Terraform before destroying infrastructure?',\n",
       "  'What does the backend configuration key look like for my project?',\n",
       "  'What file should I specify when executing the terraform destroy command?']}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "530f7463-e0e9-42b8-9779-4fc8b4a663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05c58595-54e4-4673-b37f-1b2bd34988d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c02e79ef': {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp', 'id': 'c02e79ef'}, '1f6520ca': {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites', 'section': 'General course-related questions', 'question': 'Course - What are the prerequisites for this course?', 'course': 'data-engineering-zoomcamp', 'id': '1f6520ca'}, '7842b56a': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp', 'id': '7842b56a'}, '0bbf41ec': {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp', 'id': '0bbf41ec'}, '63394d91': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.', 'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp', 'id': '63394d91'}, '2ed9b986': {'text': \"There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\\nData-Engineering (Jan - Apr)\\nMLOps (May - Aug)\\nMachine Learning (Sep - Jan)\\nThere's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\\nThey follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\", 'section': 'General course-related questions', 'question': 'Course - how many Zoomcamps in a year?', 'course': 'data-engineering-zoomcamp', 'id': '2ed9b986'}, '93e2c8ed': {'text': 'Yes. For the 2024 edition we are using Mage AI instead of Prefect and re-recorded the terraform videos, For 2023, we used Prefect instead of Airflow..', 'section': 'General course-related questions', 'question': 'Course - Is the current cohort going to be different from the previous cohort?', 'course': 'data-engineering-zoomcamp', 'id': '93e2c8ed'}, 'a482086d': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp', 'id': 'a482086d'}, 'eb56ae98': {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp', 'id': 'eb56ae98'}, '4292531b': {'text': 'All the main videos are stored in the Main “DATA ENGINEERING” playlist (no year specified). The Github repository has also been updated to show each video with a thumbnail, that would bring you directly to the same playlist below.\\nBelow is the MAIN PLAYLIST’. And then you refer to the year specific playlist for additional videos for that year like for office hours videos etc. Also find this playlist pinned to the slack channel.\\nh\\nttps://youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&si=NspQhtZhZQs1B9F-', 'section': 'General course-related questions', 'question': 'Course - Which playlist on YouTube should I refer to?', 'course': 'data-engineering-zoomcamp', 'id': '4292531b'}, 'ea739c65': {'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.', 'section': 'General course-related questions', 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?', 'course': 'data-engineering-zoomcamp', 'id': 'ea739c65'}, 'cb257ee5': {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\", 'section': 'General course-related questions', 'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?', 'course': 'data-engineering-zoomcamp', 'id': 'cb257ee5'}, '04aa4897': {'text': 'The zoom link is only published to instructors/presenters/TAs.\\nStudents participate via Youtube Live and submit questions to Slido (link would be pinned in the chat when Alexey goes Live). The video URL should be posted in the announcements channel on Telegram & Slack before it begins. Also, you will see it live on the DataTalksClub YouTube Channel.\\nDon’t post your questions in chat as it would be off-screen before the instructors/moderators have a chance to answer it if the room is very active.', 'section': 'General course-related questions', 'question': 'Office Hours - What is the video/zoom link to the stream for the “Office Hour” or workshop sessions?', 'course': 'data-engineering-zoomcamp', 'id': '04aa4897'}, '9681be3b': {'text': 'Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.', 'section': 'General course-related questions', 'question': 'Office Hours - I can’t attend the “Office hours” / workshop, will it be recorded?', 'course': 'data-engineering-zoomcamp', 'id': '9681be3b'}, 'a1daf537': {'text': 'You can find the latest and up-to-date deadlines here: https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\\nAlso, take note of Announcements from @Au-Tomator for any extensions or other news. Or, the form may also show the updated deadline, if Instructor(s) has updated it.', 'section': 'General course-related questions', 'question': 'Homework - What are homework and project deadlines?', 'course': 'data-engineering-zoomcamp', 'id': 'a1daf537'}, 'be5bfee4': {'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]', 'section': 'General course-related questions', 'question': 'Homework - Are late submissions of homework allowed?', 'course': 'data-engineering-zoomcamp', 'id': 'be5bfee4'}, '0e424a44': {'text': 'Answer: In short, it’s your repository on github, gitlab, bitbucket, etc\\nIn long, your repository or any other location you have your code where a reasonable person would look at it and think yes, you went through the week and exercises.', 'section': 'General course-related questions', 'question': 'Homework - What is the homework URL in the homework link?', 'course': 'data-engineering-zoomcamp', 'id': '0e424a44'}, '29865466': {'text': 'After you submit your homework it will be graded based on the amount of questions in a particular homework. You can see how many points you have right on the page of the homework up top. Additionally in the leaderboard you will find the sum of all points you’ve earned - points for Homeworks, FAQs and Learning in Public. If homework is clear, others work as follows: if you submit something to FAQ, you get one point, for each learning in a public link you get one point.\\n(https://datatalks-club.slack.com/archives/C01FABYF2RG/p1706846846359379?thread_ts=1706825019.546229&cid=C01FABYF2RG)', 'section': 'General course-related questions', 'question': 'Homework and Leaderboard - what is the system for points in the course management platform?', 'course': 'data-engineering-zoomcamp', 'id': '29865466'}, '016d46a1': {'text': 'When you set up your account you are automatically assigned a random name such as “Lucid Elbakyan” for example. If you want to see what your Display name is.\\nGo to the Homework submission link →  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‘Data Engineering Zoom Camp 2024’ > click on ‘Edit Course Profile’ - your display name is here, you can also change it should you wish:', 'section': 'General course-related questions', 'question': 'Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?', 'course': 'data-engineering-zoomcamp', 'id': '016d46a1'}, '47972cb1': {'text': 'Yes, for simplicity (of troubleshooting against the recorded videos) and stability. [source]\\nBut Python 3.10 and 3.11 should work fine.', 'section': 'General course-related questions', 'question': 'Environment - Is Python 3.9 still the recommended version to use in 2024?', 'course': 'data-engineering-zoomcamp', 'id': '47972cb1'}, 'ddf6c1b3': {'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.', 'section': 'General course-related questions', 'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?', 'course': 'data-engineering-zoomcamp', 'id': 'ddf6c1b3'}, 'ac25d3af': {'text': 'GitHub Codespaces offers you computing Linux resources with many pre-installed tools (Docker, Docker Compose, Python).\\nYou can also open any GitHub repository in a GitHub Codespace.', 'section': 'General course-related questions', 'question': 'Environment - Is GitHub codespaces an alternative to using cli/git bash to ingest the data and create a docker file?', 'course': 'data-engineering-zoomcamp', 'id': 'ac25d3af'}, '251218fc': {'text': \"It's up to you which platform and environment you use for the course.\\nGithub codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\", 'section': 'General course-related questions', 'question': 'Environment - Do we really have to use GitHub codespaces? I already have PostgreSQL & Docker installed.', 'course': 'data-engineering-zoomcamp', 'id': '251218fc'}, '3c0114ce': {'text': 'Choose the approach that aligns the most with your idea for the end project\\nOne of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.', 'section': 'General course-related questions', 'question': 'Environment - Do I need both GitHub Codespaces and GCP?', 'course': 'data-engineering-zoomcamp', 'id': '3c0114ce'}, 'f43f5fe7': {'text': '1. To open Run command window, you can either:\\n(1-1) Use the shortcut keys: \\'Windows + R\\', or\\n(1-2) Right Click \"Start\", and click \"Run\" to open.\\n2. Registry Values Located in Registry Editor, to open it: Type \\'regedit\\' in the Run command window, and then press Enter.\\' 3. Now you can change the registry values \"Autorun\" in \"HKEY_CURRENT_USER\\\\Software\\\\Microsoft\\\\Command Processor\" from \"if exists\" to a blank.\\nAlternatively, You can simplify the solution by deleting the fingerprint saved within the known_hosts file. In Windows, this file is placed at  C:\\\\Users\\\\<your_user_name>\\\\.ssh\\\\known_host', 'section': 'General course-related questions', 'question': 'This happens when attempting to connect to a GCP VM using VSCode on a Windows machine. Changing registry value in registry editor', 'course': 'data-engineering-zoomcamp', 'id': 'f43f5fe7'}, 'd061525d': {'text': 'For uniformity at least, but you’re not restricted to GCP, you can use other cloud platforms like AWS if you’re comfortable with other cloud platforms, since you get every service that’s been provided by GCP in Azure and AWS or others..\\nBecause everyone has a google account, GCP has a free trial period and gives $300 in credits  to new users. Also, we are working with BigQuery, which is a part of GCP.\\nNote that to sign up for a free GCP account, you must have a valid credit card.', 'section': 'General course-related questions', 'question': 'Environment - Why are we using GCP and not other cloud providers?', 'course': 'data-engineering-zoomcamp', 'id': 'd061525d'}, '1cd01b2c': {'text': 'No, if you use GCP and take advantage of their free trial.', 'section': 'General course-related questions', 'question': 'Should I pay for cloud services?', 'course': 'data-engineering-zoomcamp', 'id': '1cd01b2c'}, 'e4a7c3b0': {'text': 'You can do most of the course without a cloud. Almost everything we use (excluding BigQuery) can be run locally. We won’t be able to provide guidelines for some things, but most of the materials are runnable without GCP.\\nFor everything in the course, there’s a local alternative. You could even do the whole course locally.', 'section': 'General course-related questions', 'question': 'Environment - The GCP and other cloud providers are unavailable in some countries. Is it possible to provide a guide to installing a home lab?', 'course': 'data-engineering-zoomcamp', 'id': 'e4a7c3b0'}, '7cd1912e': {'text': 'Yes, you can. Just remember to adapt all the information on the videos to AWS. Besides, the final capstone will be evaluated based on the task: Create a data pipeline! Develop a visualisation!\\nThe problem would be when you need help. You’d need to rely on  fellow coursemates who also use AWS (or have experience using it before), which might be in smaller numbers than those learning the course with GCP.\\nAlso see Is it possible to use x tool instead of the one tool you use?', 'section': 'General course-related questions', 'question': 'Environment - I want to use AWS. May I do that?', 'course': 'data-engineering-zoomcamp', 'id': '7cd1912e'}, '52393fb3': {'text': 'We will probably have some calls during the Capstone period to clear some questions but it will be announced in advance if that happens.', 'section': 'General course-related questions', 'question': 'Besides the “Office Hour” which are the live zoom calls?', 'course': 'data-engineering-zoomcamp', 'id': '52393fb3'}, '10515af5': {'text': 'We will use the same data, as the project will essentially remain the same as last year’s. The data is available here', 'section': 'General course-related questions', 'question': 'Are we still using the NYC Trip data for January 2021? Or are we using the 2022 data?', 'course': 'data-engineering-zoomcamp', 'id': '10515af5'}, 'cdb86a97': {'text': 'No, but we moved the 2022 stuff here', 'section': 'General course-related questions', 'question': 'Is the 2022 repo deleted?', 'course': 'data-engineering-zoomcamp', 'id': 'cdb86a97'}, '3e0114ad': {'text': 'Yes, you can use any tool you want for your project.', 'section': 'General course-related questions', 'question': 'Can I use Airflow instead for my final project?', 'course': 'data-engineering-zoomcamp', 'id': '3e0114ad'}, 'b2799574': {'text': 'Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\\nThe course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\\nShould you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.', 'section': 'General course-related questions', 'question': 'Is it possible to use tool “X” instead of the one tool you use in the course?', 'course': 'data-engineering-zoomcamp', 'id': 'b2799574'}, '2f19301f': {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.', 'section': 'General course-related questions', 'question': 'How can we contribute to the course?', 'course': 'data-engineering-zoomcamp', 'id': '2f19301f'}, '7c700adb': {'text': 'Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully', 'section': 'General course-related questions', 'question': 'Environment - Is the course [Windows/mac/Linux/...] friendly?', 'course': 'data-engineering-zoomcamp', 'id': '7c700adb'}, '44b14808': {'text': \"Have no idea how past cohorts got past this as I haven't read old slack messages, and no FAQ entries that I can find.\\nLater modules (module-05 & RisingWave workshop) use shell scripts in *.sh files and most Windows users not using WSL would hit a wall and cannot continue, even in git bash or MINGW64. This is why WSL environment setup is recommended from the start.\", 'section': 'General course-related questions', 'question': 'Environment - Roadblock for Windows users in modules with *.sh (shell scripts).', 'course': 'data-engineering-zoomcamp', 'id': '44b14808'}, '76e4baf6': {'text': 'Yes to both! check out this document: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md', 'section': 'General course-related questions', 'question': 'Any books or additional resources you recommend?', 'course': 'data-engineering-zoomcamp', 'id': '76e4baf6'}, '48b533a8': {'text': 'You will have two attempts for a project. If the first project deadline is over and you’re late or you submit the project and fail the first attempt, you have another chance to submit the project with the second attempt.', 'section': 'General course-related questions', 'question': 'Project - What is Project Attemp #1 and Project Attempt #2 exactly?', 'course': 'data-engineering-zoomcamp', 'id': '48b533a8'}, '954044d1': {'text': \"The first step is to try to solve the issue on your own. Get used to solving problems and reading documentation. This will be a real life skill you need when employed. [ctrl+f] is your friend, use it! It is a universal shortcut and works in all apps/browsers.\\nWhat does the error say? There will often be a description of the error or instructions on what is needed or even how to fix it. I have even seen a link to the solution. Does it reference a specific line of your code?\\nRestart app or server/pc.\\nGoogle it, use ChatGPT, Bing AI etc.\\nIt is going to be rare that you are the first to have the problem, someone out there has posted the fly issue and likely the solution.\\nSearch using: <technology> <problem statement>. Example: pgcli error column c.relhasoids does not exist.\\nThere are often different solutions for the same problem due to variation in environments.\\nCheck the tech’s documentation. Use its search if available or use the browsers search function.\\nTry uninstall (this may remove the bad actor) and reinstall of application or reimplementation of action. Remember to restart the server/pc for reinstalls.\\nSometimes reinstalling fails to resolve the issue but works if you uninstall first.\\nPost your question to Stackoverflow. Read the Stackoverflow guide on posting good questions.\\nhttps://stackoverflow.com/help/how-to-ask\\nThis will be your real life. Ask an expert in the future (in addition to coworkers).\\nAsk in Slack\\nBefore asking a question,\\nCheck Pins (where the shortcut to the repo and this FAQ is located)\\nUse the slack app’s search function\\nUse the bot @ZoomcampQABot to do the search for you\\ncheck the FAQ (this document), use search [ctrl+f]\\nWhen asking a question, include as much information as possible:\\nWhat are you coding on? What OS?\\nWhat command did you run, which video did you follow? Etc etc\\nWhat error did you get? Does it have a line number to the “offending” code and have you check it for typos?\\nWhat have you tried that did not work? This answer is crucial as without it, helpers would ask you to do the suggestions in the error log first. Or just read this FAQ document.\\nDO NOT use screenshots, especially don’t take pictures from a phone.\\nDO NOT tag instructors, it may discourage others from helping you. Copy and paste errors; if it’s long, just post it in a reply to your thread.\\nUse ``` for formatting your code.\\nUse the same thread for the conversation (that means reply to your own thread).\\nDO NOT create multiple posts to discuss the issue.\\nlearYou may create a new post if the issue reemerges down the road. Describe what has changed in the environment.\\nProvide additional information in the same thread of the steps you have taken for resolution.\\nTake a break and come back later. You will be amazed at how often you figure out the solution after letting your brain rest. Get some fresh air, workout, play a video game, watch a tv show, whatever allows your brain to not think about it for a little while or even until the next day.\\nRemember technology issues in real life sometimes take days or even weeks to resolve.\\nIf somebody helped you with your problem and it's not in the FAQ, please add it there. It will help other students.\", 'section': 'General course-related questions', 'question': 'How to troubleshoot issues', 'course': 'data-engineering-zoomcamp', 'id': '954044d1'}, 'a820b9b3': {'text': 'When the troubleshooting guide above does not help resolve it and you need another pair of eyeballs to spot mistakes. When asking a question, include as much information as possible:\\nWhat are you coding on? What OS?\\nWhat command did you run, which video did you follow? Etc etc\\nWhat error did you get? Does it have a line number to the “offending” code and have you check it for typos?\\nWhat have you tried that did not work? This answer is crucial as without it, helpers would ask you to do the suggestions in the error log first. Or just read this FAQ document.', 'section': 'General course-related questions', 'question': 'How to ask questions', 'course': 'data-engineering-zoomcamp', 'id': 'a820b9b3'}, 'f2945cd2': {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/', 'section': 'General course-related questions', 'question': 'How do I use Git / GitHub for this course?', 'course': 'data-engineering-zoomcamp', 'id': 'f2945cd2'}, 'eb9d376f': {'text': 'Error: Makefile:2: *** missing separator.  Stop.\\nSolution: Tabs in document should be converted to Tab instead of spaces. Follow this stack.', 'section': 'General course-related questions', 'question': 'VS Code: Tab using spaces', 'course': 'data-engineering-zoomcamp', 'id': 'eb9d376f'}, '72f25f6d': {'text': \"If you’re running Linux on Windows Subsystem for Linux (WSL) 2, you can open HTML files from the guest (Linux) with whatever Internet Browser you have installed on the host (Windows). Just install wslu and open the page with wslview <file>, for example:\\nwslview index.html\\nYou can customise which browser to use by setting the BROWSER environment variable first. For example:\\nexport BROWSER='/mnt/c/Program Files/Firefox/firefox.exe'\", 'section': 'General course-related questions', 'question': 'Opening an HTML file with a Windows browser from Linux running on WSL', 'course': 'data-engineering-zoomcamp', 'id': '72f25f6d'}, 'a1e59afc': {'text': 'This tutorial shows you how to set up the Chrome Remote Desktop service on a Debian Linux virtual machine (VM) instance on Compute Engine. Chrome Remote Desktop allows you to remotely access applications with a graphical user interface.\\nTaxi Data - Yellow Taxi Trip Records downloading error, Error no or XML error webpage\\nWhen you try to download the 2021 data from TLC website, you get this error:\\nIf you click on the link, and ERROR 403: Forbidden on the terminal.\\nWe have a backup, so use it instead: https://github.com/DataTalksClub/nyc-tlc-data\\nSo the link should be https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\\nNote: Make sure to unzip the “gz” file (no, the “unzip” command won’t work for this.)\\n“gzip -d file.gz”g', 'section': 'Module 1: Docker and Terraform', 'question': 'Set up Chrome Remote Desktop for Linux on Compute Engine', 'course': 'data-engineering-zoomcamp', 'id': 'a1e59afc'}, '71c10610': {'text': 'In this video, we store the data file as “output.csv”. The data file won’t store correctly if the file extension is csv.gz instead of csv. One alternative is to replace csv_name = “output.cs -v” with the file name given at the end of the URL. Notice that the URL for the yellow taxi data is: https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz where the highlighted part is the name of the file. We can parse this file name from the URL and use it as csv_name. That is, we can replace csv_name = “output.csv” with\\ncsv_name = url.split(“/”)[-1] . Then when we use csv_name to using pd.read_csv, there won’t be an issue even though the file name really has the extension csv.gz instead of csv since the pandas read_csv function can read csv.gz files directly.', 'section': 'Module 1: Docker and Terraform', 'question': 'Taxi Data - How to handle taxi data files, now that the files are available as *.csv.gz?', 'course': 'data-engineering-zoomcamp', 'id': '71c10610'}, '17a5aea1': {'text': 'Yellow Trips: https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\\nGreen Trips: https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf', 'section': 'Module 1: Docker and Terraform', 'question': 'Taxi Data - Data Dictionary for NY Taxi data?', 'course': 'data-engineering-zoomcamp', 'id': '17a5aea1'}, '5a275db7': {'text': 'You can unzip this downloaded parquet file, in the command line. The result is a csv file which can be imported with pandas using the pd.read_csv() shown in the videos.\\n‘’’gunzip green_tripdata_2019-09.csv.gz’’’\\nSOLUTION TO USING PARQUET FILES DIRECTLY IN PYTHON SCRIPT ingest_data.py\\nIn the def main(params) add this line\\nparquet_name= \\'output.parquet\\'\\nThen edit the code which downloads the files\\nos.system(f\"wget {url} -O {parquet_name}\")\\nConvert the download .parquet file to csv and rename as csv_name to keep it relevant to the rest of the code\\ndf = pd.read_parquet(parquet_name)\\ndf.to_csv(csv_name, index=False)', 'section': 'Module 1: Docker and Terraform', 'question': 'Taxi Data - Unzip Parquet file', 'course': 'data-engineering-zoomcamp', 'id': '5a275db7'}, '7ec0f9b0': {'text': '“wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run:\\n$ sudo apt-get install wget\\nOn MacOS, the easiest way to install wget is to use Brew:\\n$ brew install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\n$ choco install wget\\nOr you can download a binary (https://gnuwin32.sourceforge.net/packages/wget.htm) and put it to any location in your PATH (e.g. C:/tools/)\\nAlso, you can following this step to install Wget on MS Windows\\n* Download the latest wget binary for windows from [eternallybored] (https://eternallybored.org/misc/wget/) (they are available as a zip with documentation, or just an exe)\\n* If you downloaded the zip, extract all (if windows built in zip utility gives an error, use [7-zip] (https://7-zip.org/)).\\n* Rename the file `wget64.exe` to `wget.exe` if necessary.\\n* Move wget.exe to your `Git\\\\mingw64\\\\bin\\\\`.\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need to use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAlternatively, you can just paste the file URL into your web browser and download the file normally that way. You’ll want to move the resulting file into your working directory.\\nAlso recommended a look at the python library requests for the loading gz file  https://pypi.org/project/requests', 'section': 'Module 1: Docker and Terraform', 'question': 'lwget is not recognized as an internal or external command', 'course': 'data-engineering-zoomcamp', 'id': '7ec0f9b0'}, 'bb1ba786': {'text': 'Firstly, make sure that you add “!” before wget if you’re running your command in a Jupyter Notebook or CLI. Then, you can check one of this 2 things (from CLI):\\nUsing the Python library wget you installed with pip, try python -m wget <url>\\nWrite the usual command and add --no-check-certificate at the end. So it should be:\\n!wget <website_url> --no-check-certificate', 'section': 'Module 1: Docker and Terraform', 'question': 'wget - ERROR: cannot verify <website> certificate  (MacOS)', 'course': 'data-engineering-zoomcamp', 'id': 'bb1ba786'}, '2f83dbe7': {'text': 'For those who wish to use the backslash as an escape character in Git Bash for Windows (as Alexey normally does), type in the terminal: bash.escapeChar=\\\\ (no need to include in .bashrc)', 'section': 'Module 1: Docker and Terraform', 'question': 'Git Bash - Backslash as an escape character in Git Bash for Windows', 'course': 'data-engineering-zoomcamp', 'id': '2f83dbe7'}, '543ff080': {'text': 'Instruction on how to store secrets that will be avialable in GitHub  Codespaces.\\nManaging your account-specific secrets for GitHub Codespaces - GitHub Docs', 'section': 'Module 1: Docker and Terraform', 'question': 'GitHub Codespaces - How to store secrets', 'course': 'data-engineering-zoomcamp', 'id': '543ff080'}, 'd407d65b': {'text': \"Make sure you're able to start the Docker daemon, and check the issue immediately down below:\\nAnd don’t forget to update the wsl in powershell the  command is wsl –update\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Cannot connect to Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?', 'course': 'data-engineering-zoomcamp', 'id': 'd407d65b'}, 'c9375c56': {'text': \"As the official Docker for Windows documentation says, the Docker engine can either use the\\nHyper-V or WSL2 as its backend. However, a few constraints might apply\\nWindows 10 Pro / 11 Pro Users: \\nIn order to use Hyper-V as its back-end, you MUST have it enabled first, which you can do by following the tutorial: Enable Hyper-V Option on Windows 10 / 11\\nWindows 10 Home / 11 Home Users: \\nOn the other hand, Users of the 'Home' version do NOT have the option Hyper-V option enabled, which means, you can only get Docker up and running using the WSL2 credentials(Windows Subsystem for Linux). Url\\nYou can find the detailed instructions to do so here: rt ghttps://pureinfotech.com/install-wsl-windows-11/\\nIn case, you run into another issue while trying to install WSL2 (WslRegisterDistribution failed with error: 0x800701bc), Make sure you update the WSL2 Linux Kernel, following the guidelines here: \\n\\nhttps://github.com/microsoft/WSL/issues/5393\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Error during connect: In the default daemon configuration on Windows, the docker client must be run with elevated privileges to connect.: Post: \"http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/create\" : open //./pipe/docker_engine: The system cannot find the file specified', 'course': 'data-engineering-zoomcamp', 'id': 'c9375c56'}, 'e866156b': {'text': 'Whenever a `docker pull is performed (either manually or by `docker-compose up`), it attempts to fetch the given image name (pgadmin4, for the example above) from a repository (dbpage).\\nIF the repository is public, the fetch and download happens without any issue whatsoever.\\nFor instance:\\ndocker pull postgres:13\\ndocker pull dpage/pgadmin4\\nBE ADVISED:\\n\\nThe Docker Images we\\'ll be using throughout the Data Engineering Zoomcamp are all public (except when or if explicitly said otherwise by the instructors or co-instructors).\\n\\nMeaning: you are NOT required to perform a docker login to fetch them. \\n\\nSo if you get the message above saying \"docker login\\': denied: requested access to the resource is denied. That is most likely due to a typo in your image name:\\n\\nFor instance:\\n$ docker pull dbpage/pgadmin4\\nWill throw that exception telling you \"repository does not exist or may require \\'docker login\\'\\nError response from daemon: pull access denied for dbpage/pgadmin4, repository does not exist or \\nmay require \\'docker login\\': denied: requested access to the resource is denied\\nBut that actually happened because the actual image is dpage/pgadmin4 and NOT dbpage/pgadmin4\\nHow to fix it:\\n$ docker pull dpage/pgadmin4\\nEXTRA NOTES:\\nIn the real world, occasionally, when you\\'re working for a company or closed organisation, the Docker image you\\'re trying to fetch might be under a private repo that your DockerHub Username was granted access to.\\nFor which cases, you must first execute:\\n$ docker login\\nFill in the details of your username and password.\\nAnd only then perform the `docker pull` against that private repository\\nWhy am I encountering a \"permission denied\" error when creating a PostgreSQL Docker container for the New York Taxi Database with a mounted volume on macOS M1?\\nIssue Description:\\nWhen attempting to run a Docker command similar to the one below:\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\mount\\npostgres:13\\nYou encounter the error message:\\ndocker: Error response from daemon: error while creating mount source path \\'/path/to/ny_taxi_postgres_data\\': chown /path/to/ny_taxi_postgres_data: permission denied.\\nSolution:\\n1- Stop Rancher Desktop:\\nIf you are using Rancher Desktop and face this issue, stop Rancher Desktop to resolve compatibility problems.\\n2- Install Docker Desktop:\\nInstall Docker Desktop, ensuring that it is properly configured and has the required permissions.\\n2-Retry Docker Command:\\nRun the Docker command again after switching to Docker Desktop. This step resolves compatibility issues on some systems.\\nNote: The issue occurred because Rancher Desktop was in use. Switching to Docker Desktop resolves compatibility problems and allows for the successful creation of PostgreSQL containers with mounted volumes for the New York Taxi Database on macOS M1.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - docker pull dbpage', 'course': 'data-engineering-zoomcamp', 'id': 'e866156b'}, '16370470': {'text': 'When I runned command to create postgre in docker container it created folder on my local machine to mount it to volume inside container. It has write and read protection and owned by user 999, so I could not delete it by simply drag to trash.  My obsidian could not started due to access error, so I had to change placement of this folder and delete old folder by this command:\\nsudo rm -r -f docker_test/\\n- where `rm` - remove, `-r` - recursively, `-f` - force, `docker_test/` - folder.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - can’t delete local folder that mounted to docker volume', 'course': 'data-engineering-zoomcamp', 'id': '16370470'}, '316df755': {'text': 'First off, make sure you\\'re running the latest version of Docker for Windows, which you can download from here. Sometimes using the menu to \"Upgrade\" doesn\\'t work (which is another clear indicator for you to uninstall, and reinstall with the latest version)\\nIf docker is stuck on starting, first try to switch containers by right clicking the docker symbol from the running programs and switch the containers from windows to linux or vice versa\\n[Windows 10 / 11 Pro Edition] The Pro Edition of Windows can run Docker either by using Hyper-V or WSL2 as its backend (Docker Engine)\\nIn order to use Hyper-V as its back-end, you MUST have it enabled first, which you can do by following the tutorial: Enable Hyper-V Option on Windows 10 / 11\\nIf you opt-in for WSL2, you can follow the same steps as detailed in the tutorial here', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - Docker won't start or is stuck in settings (Windows 10 / 11)\", 'course': 'data-engineering-zoomcamp', 'id': '316df755'}, 'f3aa9252': {'text': \"It is recommended by the Docker do\\n[Windows 10 / 11 Home Edition] If you're running a Home Edition, you can still make it work with WSL2 (Windows Subsystem for Linux) by following the tutorial here\\nIf even after making sure your WSL2 (or Hyper-V) is set up accordingly, Docker remains stuck, you can try the option to Reset to Factory Defaults or do a fresh install.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Should I run docker commands from the windows file system or a file system of a Linux distribution in WSL?', 'course': 'data-engineering-zoomcamp', 'id': 'f3aa9252'}, 'a4abe7a5': {'text': 'More info in the Docker Docs on Best Practises', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).', 'course': 'data-engineering-zoomcamp', 'id': 'a4abe7a5'}, 'fb930700': {'text': 'You may have this error:\\n$ docker run -it ubuntu bash\\nthe input device is not a TTY. If you are using mintty, try prefixing the command with \\'winpty\\'\\nerror:\\nSolution:\\nUse winpty before docker command (source)\\n$ winpty docker run -it ubuntu bash\\nYou also can make an alias:\\necho \"alias docker=\\'winpty docker\\'\" >> ~/.bashrc\\nOR\\necho \"alias docker=\\'winpty docker\\'\" >> ~/.bash_profile', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - The input device is not a TTY (Docker run for Windows)', 'course': 'data-engineering-zoomcamp', 'id': 'fb930700'}, 'aa187680': {'text': \"You may have this error:\\nRetrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.u\\nrllib3.connection.HTTPSConnection object at 0x7efe331cf790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')':\\n/simple/pandas/\\nPossible solution might be:\\n$ winpty docker run -it --dns=8.8.8.8 --entrypoint=bash python:3.9\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Cannot pip install on Docker container (Windows)', 'course': 'data-engineering-zoomcamp', 'id': 'aa187680'}, 'b000e899': {'text': 'Even after properly running the docker script the folder is empty in the vs code  then try this (For Windows)\\nwinpty docker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v \"C:\\\\Users\\\\abhin\\\\dataengg\\\\DE_Project_git_connected\\\\DE_OLD\\\\week1_set_up\\\\docker_sql/ny_taxi_postgres_data:/var/lib/postgresql/data\" \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nHere quoting the absolute path in  the -v parameter is solving the issue and all the files are visible in the Vs-code ny_taxi folder as shown in the video', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - ny_taxi_postgres_data is empty', 'course': 'data-engineering-zoomcamp', 'id': 'b000e899'}, '9c66759f': {'text': 'Check this article for details - Setting up docker in macOS\\nFrom researching it seems this method might be out of date, it seems that since docker changed their licensing model, the above is a bit hit and miss. What worked for me was to just go to the docker website and download their dmg. Haven’t had an issue with that method.', 'section': 'Module 1: Docker and Terraform', 'question': 'dasDocker - Setting up Docker on Mac', 'course': 'data-engineering-zoomcamp', 'id': '9c66759f'}, 'e3106e07': {'text': '$ docker run -it\\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"admin\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v \"/mnt/path/to/ny_taxi_postgres_data\":\"/var/lib/postgresql/data\" \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nCCW\\nThe files belonging to this database system will be owned by user \"postgres\".\\nThis use The database cluster will be initialized with locale \"en_US.utf8\".\\nThe default databerrorase encoding has accordingly been set to \"UTF8\".\\nxt search configuration will be set to \"english\".\\nData page checksums are disabled.\\nfixing permissions on existing directory /var/lib/postgresql/data ... initdb: f\\nerror: could not change permissions of directory \"/var/lib/postgresql/data\": Operation not permitted  volume\\nOne way to solve this issue is to create a local docker volume and map it to postgres data directory /var/lib/postgresql/data\\nThe input dtc_postgres_volume_local must match in both commands below\\n$ docker volume create --name dtc_postgres_volume_local -d local\\n$ docker run -it\\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v dtc_postgres_volume_local:/var/lib/postgresql/data \\\\\\n-p 5432:5432\\\\\\npostgres:13\\nTo verify the above command works in (WSL2 Ubuntu 22.04, verified 2024-Jan), go to the Docker Desktop app and look under Volumes - dtc_postgres_volume_local would be listed there. The folder ny_taxi_postgres_data would however be empty, since we used an alternative config.\\nAn alternate error could be:\\ninitdb: error: directory \"/var/lib/postgresql/data\" exists but is not empty\\nIf you want to create a new database system, either remove or empthe directory \"/var/lib/postgresql/data\" or run initdb\\nwitls', 'section': 'Module 1: Docker and Terraform', 'question': '1Docker - Could not change permissions of directory \"/var/lib/postgresql/data\": Operation not permitted', 'course': 'data-engineering-zoomcamp', 'id': 'e3106e07'}, '72229da5': {'text': 'Mapping volumes on Windows could be tricky. The way it was done in the course video doesn’t work for everyone.\\nFirst, if yo\\nmove your data to some folder without spaces. E.g. if your code is in “C:/Users/Alexey Grigorev/git/…”, move it to “C:/git/…”\\nTry replacing the “-v” part with one of the following options:\\n-v /c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\\n-v //c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\\n-v /c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\\n-v //c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\\n--volume //driveletter/path/ny_taxi_postgres_data/:/var/lib/postgresql/data\\nwinpty docker run -it\\n-e POSTGRES_USER=\"root\"\\n-e POSTGRES_PASSWORD=\"root\"\\n-e POSTGRES_DB=\"ny_taxi\"\\n-v /c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\\n-p 5432:5432\\npostgres:1\\nTry adding winpty before the whole command\\n3\\nwin\\nTry adding quotes:\\n-v \"/c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"\\n-v \"//c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"\\n-v “/c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"\\n-v \"//c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"\\n-v \"c:\\\\some\\\\path\\\\ny_taxi_postgres_data\":/var/lib/postgresql/data\\nNote:  (Window) if it automatically creates a folder called “ny_taxi_postgres_data;C” suggests you have problems with volume mapping, try deleting both folders and replacing “-v” part with other options. For me “//c/” works instead of “/c/”. And it will work by automatically creating a correct folder called “ny_taxi_postgres_data”.\\nA possible solution to this error would be to use /”$(pwd)”/ny_taxi_postgres_data:/var/lib/postgresql/data (with quotes’ position varying as in the above list).\\nYes for windows use the command it works perfectly fine\\n-v /”$(pwd)”/ny_taxi_postgres_data:/var/lib/postgresql/data\\nImportant: note how the quotes are placed.\\nIf none of these options work, you can use a volume name instead of the path:\\n-v ny_taxi_postgres_data:/var/lib/postgresql/data\\nFor Mac: You can wrap $(pwd) with quotes like the highlighted.\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v \"$(pwd)\"/ny_taxi_postgres_data:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\\\nPostgres:13\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v \"$(pwd)\"/ny_taxi_postgres_data:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nSource:https://stackoverflow.com/questions/48522615/docker-error-invalid-reference-format-repository-name-must-be-lowercase', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - invalid reference format: repository name must be lowercase (Mounting volumes with Docker on Windows)', 'course': 'data-engineering-zoomcamp', 'id': '72229da5'}, '58c9f99f': {'text': 'Change the mounting path. Replace it with one of following:\\n-v /e/zoomcamp/...:/var/lib/postgresql/data\\n-v /c:/.../ny_taxi_postgres_data:/var/lib/postgresql/data\\\\ (leading slash in front of c:)', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Error response from daemon: invalid mode: \\\\Program Files\\\\Git\\\\var\\\\lib\\\\postgresql\\\\data.', 'course': 'data-engineering-zoomcamp', 'id': '58c9f99f'}, 'bc42139a': {'text': 'When you run this command second time\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v <your path>:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nThe error message above could happen. That means you should not mount on the second run. This command helped me:\\nWhen you run this command second time\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-p 5432:5432 \\\\\\npostgres:13', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - Error response from daemon: error while creating buildmount source path '/run/desktop/mnt/host/c/<your path>': mkdir /run/desktop/mnt/host/c: file exists\", 'course': 'data-engineering-zoomcamp', 'id': 'bc42139a'}, 'a146e3ee': {'text': 'This error appeared when running the command: docker build -t taxi_ingest:v001 .\\nWhen feeding the database with the data the user id of the directory ny_taxi_postgres_data was changed to 999, so my user couldn’t access it when running the above command. Even though this is not the problem here it helped to raise the error due to the permission issue.\\nSince at this point we only need the files Dockerfile and ingest_data.py, to fix this error one can run the docker build command on a different directory (having only these two files).\\nA more complete explanation can be found here: https://stackoverflow.com/questions/41286028/docker-build-error-checking-context-cant-stat-c-users-username-appdata\\nYou can fix the problem by changing the permission of the directory on ubuntu with following command:\\nsudo chown -R $USER dir_path\\nOn windows follow the link: https://thegeekpage.com/take-ownership-of-a-file-folder-through-command-prompt-in-windows-10/ \\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAdded by\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKenan Arslanbay', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - build error: error checking context: 'can't stat '/home/user/repos/data-engineering/week_1_basics_n_setup/2_docker_sql/ny_taxi_postgres_data''.\", 'course': 'data-engineering-zoomcamp', 'id': 'a146e3ee'}, '593a85ba': {'text': 'You might have installed docker via snap. Run “sudo snap status docker” to verify.\\nIf you have “error: unknown command \"status\", see \\'snap help\\'.” as a response than deinstall docker and install via the official website\\nBind for 0.0.0.0:5432 failed: port is a', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - ERRO[0000] error waiting for container: context canceled', 'course': 'data-engineering-zoomcamp', 'id': '593a85ba'}, '50bd1a71': {'text': 'Found the issue in the PopOS linux. It happened because our user didn’t have authorization rights to the host folder ( which also caused folder seems empty, but it didn’t!).\\n✅Solution:\\nJust add permission for everyone to the corresponding folder\\nsudo chmod -R 777 <path_to_folder>\\nExample:\\nsudo chmod -R 777 ny_taxi_postgres_data/', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - build error checking context: can’t stat ‘/home/fhrzn/Projects/…./ny_taxi_postgres_data’', 'course': 'data-engineering-zoomcamp', 'id': '50bd1a71'}, 'f409f751': {'text': 'This happens on Ubuntu/Linux systems when trying to run the command to build the Docker container again.\\n$ docker build -t taxi_ingest:v001 .\\nA folder is created to host the Docker files. When the build command is executed again to rebuild the pipeline or create a new one the error is raised as there are no permissions on this new folder. Grant permissions by running this comtionmand;\\n$ sudo chmod -R 755 ny_taxi_postgres_data\\nOr use 777 if you still see problems. 755 grants write access to only the owner.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - failed to solve with frontend dockerfile.v0: failed to read dockerfile: error from sender: open ny_taxi_postgres_data: permission denied.', 'course': 'data-engineering-zoomcamp', 'id': 'f409f751'}, '7d217da3': {'text': 'Get the network name via: $ docker network ls.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Docker network name', 'course': 'data-engineering-zoomcamp', 'id': '7d217da3'}, '09081824': {'text': 'Sometimes, when you try to restart a docker image configured with a network name, the above message appears. In this case, use the following command with the appropriate container name:\\n>>> If the container is running state, use docker stop <container_name>\\n>>> then, docker rm pg-database\\nOr use docker start instead of docker run in order to restart the docker image without removing it.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Error response from daemon: Conflict. The container name \"pg-database\" is already in use by container “xxx”.  You have to remove (or rename) that container to be able to reuse that name.', 'course': 'data-engineering-zoomcamp', 'id': '09081824'}, '4df80c55': {'text': 'Typical error: sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name \"pgdatabase\" to address: Name or service not known\\nWhen running docker-compose up -d see which network is created and use this for the ingestions script instead of pg-network and see the name of the database to use instead of pgdatabase\\nE.g.:\\npg-network becomes 2docker_default\\nPgdatabase becomes 2docker-pgdatabase-1', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - ingestion when using docker-compose could not translate host name', 'course': 'data-engineering-zoomcamp', 'id': '4df80c55'}, '3aee7261': {'text': 'terraformRun this command before starting your VM:\\nOn Intel CPU:\\nmodprobe -r kvm_intel\\nmodprobe kvm_intel nested=1\\nOn AMD CPU:\\nmodprobe -r kvm_amd\\nmodprobe kvm_amd nested=1', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Cannot install docker on MacOS/Windows 11 VM running on top of Linux (due to Nested virtualization).', 'course': 'data-engineering-zoomcamp', 'id': '3aee7261'}, '6497b659': {'text': 'It’s very easy to manage your docker container, images, network and compose projects from VS Code.\\nJust install the official extension and launch it from the left side icon.\\nIt will work even if your Docker runs on WSL2, as VS Code can easily connect with your Linux.\\nDocker - How to stop a container?\\nUse the following command:\\n$ docker stop <container_id>', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Connecting from VS Code', 'course': 'data-engineering-zoomcamp', 'id': '6497b659'}, 'a02f2039': {'text': \"When you see this in logs, your container with postgres is not accepting any requests, so if you attempt to connect, you'll get this error:\\nconnection failed: server closed the connection unexpectedly\\nThis probably means the server terminated abnormally before or while processing the request.\\nIn this case, you need to delete the directory with data (the one you map to the container with the -v flag) and restart the container.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - PostgreSQL Database directory appears to contain a database. Database system is shut down', 'course': 'data-engineering-zoomcamp', 'id': 'a02f2039'}, 'c6db65aa': {'text': 'On few versions of Ubuntu, snap command can be used to install Docker.\\nsudo snap install docker', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker not installable on Ubuntu', 'course': 'data-engineering-zoomcamp', 'id': 'c6db65aa'}, 'f476a606': {'text': 'error: could not change permissions of directory \"/var/lib/postgresql/data\": Operation not permitted  volume\\nif you have used the prev answer (just before this) and have created a local docker volume, then you need to tell the compose file about the named volume:\\nvolumes:\\ndtc_postgres_volume_local:  # Define the named volume here\\n# services mentioned in the compose file auto become part of the same network!\\nservices:\\nyour remaining code here . . .\\nnow use docker volume inspect dtc_postgres_volume_local to see the location by checking the value of Mountpoint\\nIn my case, after i ran docker compose up the mounting dir created was named ‘docker_sql_dtc_postgres_volume_local’ whereas it should have used the already existing ‘dtc_postgres_volume_local’\\nAll i did to fix this is that I renamed the existing ‘dtc_postgres_volume_local’ to ‘docker_sql_dtc_postgres_volume_local’ and removed the newly created one (just be careful when doing this)\\nrun docker compose up again and check if the table is there or not!', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - mounting error', 'course': 'data-engineering-zoomcamp', 'id': 'f476a606'}, 'e41b100c': {'text': 'Couldn’t translate host name to address\\nMake sure postgres database is running.\\n\\n\\u200b\\u200bUse the command to start containers in detached mode: docker-compose up -d\\n(data-engineering-zoomcamp) hw % docker compose up -d\\n[+] Running 2/2\\n⠿ Container pg-admin     Started                                                                                                                                                                      0.6s\\n⠿ Container pg-database  Started\\nTo view the containers use: docker ps.\\n(data-engineering-zoomcamp) hw % docker ps\\nCONTAINER ID   IMAGE            COMMAND                  CREATED          STATUS          PORTS                           NAMES\\nfaf05090972e   postgres:13      \"docker-entrypoint.s…\"   39 seconds ago   Up 37 seconds   0.0.0.0:5432->5432/tcp          pg-database\\n6344dcecd58f   dpage/pgadmin4   \"/entrypoint.sh\"         39 seconds ago   Up 37 seconds   443/tcp, 0.0.0.0:8080->80/tcp   pg-admin\\nhw\\nTo view logs for a container: docker logs <containerid>\\n(data-engineering-zoomcamp) hw % docker logs faf05090972e\\nPostgreSQL Database directory appears to contain a database; Skipping initialization\\n2022-01-25 05:58:45.948 UTC [1] LOG:  starting PostgreSQL 13.5 (Debian 13.5-1.pgdg110+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit\\n2022-01-25 05:58:45.948 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\\n2022-01-25 05:58:45.948 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\\n2022-01-25 05:58:45.954 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\\n2022-01-25 05:58:45.984 UTC [28] LOG:  database system was interrupted; last known up at 2022-01-24 17:48:35 UTC\\n2022-01-25 05:58:48.581 UTC [28] LOG:  database system was not properly shut down; automatic recovery in\\nprogress\\n2022-01-25 05:58:48.602 UTC [28] LOG:  redo starts at 0/872A5910\\n2022-01-25 05:59:33.726 UTC [28] LOG:  invalid record length at 0/98A3C160: wanted 24, got 0\\n2022-01-25 05:59:33.726 UTC [28\\n] LOG:  redo done at 0/98A3C128\\n2022-01-25 05:59:48.051 UTC [1] LOG:  database system is ready to accept connections\\nIf docker ps doesn’t show pgdatabase running, run: docker ps -a\\nThis should show all containers, either running or stopped.\\nGet the container id for pgdatabase-1, and run', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Error translating host name to address', 'course': 'data-engineering-zoomcamp', 'id': 'e41b100c'}, 'cd0f9300': {'text': 'After executing `docker-compose up` - if you lose database data and are unable to successfully execute your Ingestion script (to re-populate your database) but receive the following error:\\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name /data_pgadmin:/var/lib/pgadmin\"pg-database\" to address: Name or service not known\\nDocker compose is creating its own default network since it is no longer specified in a docker execution command or file. Docker Compose will emit to logs the new network name. See the logs after executing `docker compose up` to find the network name and change the network name argument in your Ingestion script.\\nIf problems persist with pgcli, we can use HeidiSQL,usql\\nKrishna Anand', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose -  Data retention (could not translate host name \"pg-database\" to address: Name or service not known)', 'course': 'data-engineering-zoomcamp', 'id': 'cd0f9300'}, '7f845a1c': {'text': 'It returns --> Error response from daemon: network 66ae65944d643fdebbc89bd0329f1409dec2c9e12248052f5f4c4be7d1bdc6a3 not found\\nTry:\\ndocker ps -a to see all the stopped & running containers\\nd to nuke all the containers\\nTry: docker-compose up -d again ports\\nOn localhost:8080 server → Unable to connect to server: could not translate host name \\'pg-database\\' to address: Name does not resolve\\nTry: new host name, best without “ - ” e.g. pgdatabase\\nAnd on docker-compose.yml, should specify docker network & specify the same network in both  containers\\nservices:\\npgdatabase:\\nimage: postgres:13\\nenvironment:\\n- POSTGRES_USER=root\\n- POSTGRES_PASSWORD=root\\n- POSTGRES_DB=ny_taxi\\nvolumes:\\n- \"./ny_taxi_postgres_data:/var/lib/postgresql/data:rw\"\\nports:\\n- \"5431:5432\"\\nnetworks:\\n- pg-network\\npgadmin:\\nimage: dpage/pgadmin4\\nenvironment:\\n- PGADMIN_DEFAULT_EMAIL=admin@admin.com\\n- PGADMIN_DEFAULT_PASSWORD=root\\nports:\\n- \"8080:80\"\\nnetworks:\\n- pg-network\\nnetworks:\\npg-network:\\nname: pg-network', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Hostname does not resolve', 'course': 'data-engineering-zoomcamp', 'id': '7f845a1c'}, '36e54439': {'text': 'So one common issue is when you run docker-compose on GCP, postgres won’t persist it’s data to mentioned path for example:\\nservices:\\n…\\n…\\npgadmin:\\n…\\n…\\nVolumes:\\n“./pgadmin”:/var/lib/pgadmin:wr”\\nMight not work so in this use you can use Docker Volume to make it persist, by simply changing\\nservices:\\n…\\n….\\npgadmin:\\n…\\n…\\nVolumes:\\npgadmin:/var/lib/pgadmin\\nvolumes:\\nPgadmin:', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Persist PGAdmin docker contents on GCP', 'course': 'data-engineering-zoomcamp', 'id': '36e54439'}, '32e8450c': {'text': 'The docker will keep on crashing continuously\\nNot working after restart\\ndocker engine stopped\\nAnd failed to fetch extensions pop ups will on screen non-stop\\nSolution :\\nTry checking if latest version of docker is installed / Try updating the docker\\nIf Problem still persist then final solution is to reinstall docker\\n(Just have to fetch images again else no issues)', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker engine stopped_failed to fetch extensions', 'course': 'data-engineering-zoomcamp', 'id': '32e8450c'}, '96606db2': {'text': 'As per the lessons,\\nPersisting pgAdmin configuration (i.e. server name) is done by adding a “volumes” section:\\nservices:\\npgdatabase:\\n[...]\\npgadmin:\\nimage: dpage/pgadmin4\\nenvironment:\\n- PGADMIN_DEFAULT_EMAIL=admin@admin.com\\n- PGADMIN_DEFAULT_PASSWORD=root\\nvolumes:\\n- \"./pgAdmin_data:/var/lib/pgadmin/sessions:rw\"\\nports:\\n- \"8080:80\"\\nIn the example above, ”pgAdmin_data” is a folder on the host machine, and “/var/lib/pgadmin/sessions” is the session settings folder in the pgAdmin container.\\nBefore running docker-compose up on the YAML file, we also need to give the pgAdmin container access to write to the “pgAdmin_data” folder. The container runs with a username called “5050” and user group “5050”. The bash command to give access over the mounted volume is:\\nsudo chown -R 5050:5050 pgAdmin_data', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Persist PGAdmin configuration', 'course': 'data-engineering-zoomcamp', 'id': '96606db2'}, '0882bfac': {'text': 'This happens if you did not create the docker group and added your user. Follow these steps from the link:\\nguides/docker-without-sudo.md at main · sindresorhus/guides · GitHub\\nAnd then press ctrl+D to log-out and log-in again. pgAdmin: Maintain state so that it remembers your previous connection\\nIf you are tired of having to setup your database connection each time that you fire up the containers, all you have to do is create a volume for pgAdmin:\\nIn your docker-compose.yaml file, enter the following into your pgAdmin declaration:\\nvolumes:\\n- type: volume\\nsource: pgadmin_data\\ntarget: /var/lib/pgadmin\\nAlso add the following to the end of the file:ls\\nvolumes:\\nPgadmin_data:', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - dial unix /var/run/docker.sock: connect: permission denied', 'course': 'data-engineering-zoomcamp', 'id': '0882bfac'}, '7d067f5c': {'text': 'This is happen to me after following 1.4.1 video where we are installing docker compose in our Google Cloud VM. In my case, the docker-compose file downloaded from github named docker-compose-linux-x86_64 while it is more convenient to use docker-compose command instead. So just change the docker-compose-linux-x86_64 into docker-compose.', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - docker-compose still not available after changing .bashrc', 'course': 'data-engineering-zoomcamp', 'id': '7d067f5c'}, 'ff352621': {'text': 'Installing pass via ‘sudo apt install pass’ helped to solve the issue. More about this can be found here: https://github.com/moby/buildkit/issues/1078', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Error getting credentials after running docker-compose up -d', 'course': 'data-engineering-zoomcamp', 'id': 'ff352621'}, '2d653208': {'text': \"For everyone who's having problem with Docker compose, getting the data in postgres and similar issues, please take care of the following:\\ncreate a new volume on docker (either using the command line or docker desktop app)\\nmake the following changes to your docker-compose.yml file (see attachment)\\nset low_memory=false when importing the csv file (df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=1000, low_memory=False))\\nuse the below function (in the upload-data.ipynb) for better tracking of your ingestion process (see attachment)\\nOrder of execution:\\n(1) open terminal in 2_docker_sql folder and run docker compose up\\n(2) ensure no other containers are running except the one you just executed (pgadmin and pgdatabase)\\n(3) open jupyter notebook and begin the data ingestion\\n(4) open pgadmin and set up a server (make sure you use the same configurations as your docker-compose.yml file like the same name (pgdatabase), port, databasename (ny_taxi) etc.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Errors pertaining to docker-compose.yml and pgadmin setup', 'course': 'data-engineering-zoomcamp', 'id': '2d653208'}, 'f09ea61e': {'text': 'Locate config.json file for docker (check your home directory; Users/username/.docker).\\nModify credsStore to credStore\\nSave and re-run', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker Compose up -d error getting credentials - err: exec: \"docker-credential-desktop\": executable file not found in %PATH%, out: ``', 'course': 'data-engineering-zoomcamp', 'id': 'f09ea61e'}, 'fbd3d2bb': {'text': 'To figure out which docker-compose you need to download from https://github.com/docker/compose/releases you can check your system with these commands:\\nuname -s  -> return Linux most likely\\nuname -m -> return \"flavor\"\\nOr try this command -\\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Which docker-compose binary to use for WSL?', 'course': 'data-engineering-zoomcamp', 'id': 'fbd3d2bb'}, '0b014d0c': {'text': 'If you wrote the docker-compose.yaml file exactly like the video, you might run into an error like this:dev\\nservice \"pgdatabase\" refers to undefined volume dtc_postgres_volume_local: invalid compose project\\nIn order to make it work, you need to include the volume in your docker-compose file. Just add the following:\\nvolumes:\\ndtc_postgres_volume_local:\\n(Make sure volumes are at the same level as services.)', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - Error undefined volume in Windows/WSL', 'course': 'data-engineering-zoomcamp', 'id': '0b014d0c'}, 'd21bff1d': {'text': 'Error:  initdb: error: could not change permissions of directory\\nIssue: WSL and Windows do not manage permissions in the same way causing conflict if using the Windows file system rather than the WSL file system.\\nSolution: Use Docker volumes.\\nWhy: Volume is used for storage of persistent data and not for use of transferring files. A local volume is unnecessary.\\nBenefit: This resolves permission issues and allows for better management of volumes.\\nNOTE: the ‘user:’ is not necessary if using docker volumes, but is if using local drive.\\n</>  docker-compose.yaml\\nservices:\\npostgres:\\nimage: postgres:15-alpine\\ncontainer_name: postgres\\nuser: \"0:0\"\\nenvironment:\\n- POSTGRES_USER=postgres\\n- POSTGRES_PASSWORD=postgres\\n- POSTGRES_DB=ny_taxi\\nvolumes:\\n- \"pg-data:/var/lib/postgresql/data\"\\nports:\\n- \"5432:5432\"\\nnetworks:\\n- pg-network\\npgadmin:\\nimage: dpage/pgadmin4\\ncontainer_name: pgadmin\\nuser: \"${UID}:${GID}\"\\nenvironment:\\n- PGADMIN_DEFAULT_EMAIL=email@some-site.com\\n- PGADMIN_DEFAULT_PASSWORD=pgadmin\\nvolumes:\\n- \"pg-admin:/var/lib/pgadmin\"\\nports:\\n- \"8080:80\"\\nnetworks:\\n- pg-network\\nnetworks:\\npg-network:\\nname: pg-network\\nvolumes:\\npg-data:\\nname: ingest_pgdata\\npg-admin:\\nname: ingest_pgadmin', 'section': 'Module 1: Docker and Terraform', 'question': 'WSL Docker directory permissions error', 'course': 'data-engineering-zoomcamp', 'id': 'd21bff1d'}, '6afb7b55': {'text': 'Cause : If Running on git bash or vm in windows pgadmin doesnt work easily LIbraries like psycopg2 and libpq ar required still the error persists.\\nSolution- I use psql instead of pgadmin totally same\\nPip install psycopg2\\ndock', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - If pgadmin is not working for Querying in Postgres Use PSQL', 'course': 'data-engineering-zoomcamp', 'id': '6afb7b55'}, 'b51c3b82': {'text': 'Cause:\\nIt happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\\nSolution\\nfor updating Windows terminal which worked for me:\\nGo to Microsoft Store.\\nGo to the library of apps installed in your system.\\nSearch for Windows terminal.\\nUpdate the app and restart your system to  see the changes.\\nFor updating the Windows security updates:\\nGo to Windows updates and check if there are any pending updates from Windows, especially security updates.\\nDo restart your system once the updates are downloaded and installed successfully.', 'section': 'Module 1: Docker and Terraform', 'question': 'WSL - Insufficient system resources exist to complete the requested service.', 'course': 'data-engineering-zoomcamp', 'id': 'b51c3b82'}, '326af690': {'text': 'Up restardoting the same issue appears. Happens out of the blue on windows.\\nSolution 1: Fixing DNS Issue (credit: reddit) this worked for me personally\\nreg add \"HKLM\\\\System\\\\CurrentControlSet\\\\Services\\\\Dnscache\" /v \"Start\" /t REG_DWORD /d \"4\" /f\\nRestart your computer and then enable it with the following\\nreg add \"HKLM\\\\System\\\\CurrentControlSet\\\\Services\\\\Dnscache\" /v \"Start\" /t REG_DWORD /d \"2\" /f\\nRestart your OS again. It should work.\\nSolution 2: right click on running Docker icon (next to clock) and chose \"Switch to Linux containers\"\\nbash: conda: command not found\\nDatabase is uninitialized and superuser password is not specified.\\nDatabase is uninitialized and superuser password is not specified.', 'section': 'Module 1: Docker and Terraform', 'question': 'WSL - WSL integration with distro Ubuntu unexpectedly stopped with exit code 1.', 'course': 'data-engineering-zoomcamp', 'id': '326af690'}, 'c2ec9047': {'text': 'Issue when trying to run the GPC VM through SSH through WSL2,  probably because WSL2 isn’t looking for .ssh keys in the correct folder. My case I was trying to run this command in the terminal and getting an error\\nPC:/mnt/c/Users/User/.ssh$ ssh -i gpc [username]@[my external IP]\\nYou can try to use sudo before the command\\nSudo .ssh$ ssh -i gpc [username]@[my external IP]\\nYou can also try to cd to your folder and change the permissions for the private key SSH file.\\nchmod 600 gpc\\nIf that doesn’t work, create a .ssh folder in the home diretory of WSL2 and copy the content of windows .ssh folder to that new folder.\\ncd ~\\nmkdir .ssh\\ncp -r /mnt/c/Users/YourUsername/.ssh/* ~/.ssh/\\nYou might need to adjust the permissions of the files and folders in the .ssh directory.', 'section': 'Module 1: Docker and Terraform', 'question': 'WSL - Permissions too open at Windows', 'course': 'data-engineering-zoomcamp', 'id': 'c2ec9047'}, '3b711e73': {'text': 'Such as the issue above, WSL2 may not be referencing the correct .ssh/config path from Windows. You can create a config file at the home directory of WSL2.\\ncd ~\\nmkdir .ssh\\nCreate a config file in this new .ssh/ folder referencing this folder:\\nHostName [GPC VM external IP]\\nUser [username]\\nIdentityFile ~/.ssh/[private key]', 'section': 'Module 1: Docker and Terraform', 'question': 'WSL - Could not resolve host name', 'course': 'data-engineering-zoomcamp', 'id': '3b711e73'}, 'cfe07c9d': {'text': 'Change TO Socket\\npgcli -h 127.0.0.1 -p 5432 -u root -d ny_taxi\\npgcli -h 127.0.0.1 -p 5432 -u root -d ny_taxi', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - connection failed: :1), port 5432 failed: could not receive data from server: Connection refused could not send SSL negotiation packet: Connection refused', 'course': 'data-engineering-zoomcamp', 'id': 'cfe07c9d'}, 'acf42bb8': {'text': 'probably some installation error, check out sy', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI --help error', 'course': 'data-engineering-zoomcamp', 'id': 'acf42bb8'}, '176ce516': {'text': 'In this section of the course, the 5432 port of pgsql is mapped to your computer’s 5432 port. Which means you can access the postgres database via pgcli directly from your computer.\\nSo No, you don’t need to run it inside another container. Your local system will do.', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - INKhould we run pgcli inside another docker container?', 'course': 'data-engineering-zoomcamp', 'id': '176ce516'}, '3e5d1e9b': {'text': 'FATAL:  password authentication failed for user \"root\"\\nobservations: Below in bold do not forget the folder that was created ny_taxi_postgres_data\\nThis happens if you have a local Postgres installation in your computer. To mitigate this, use a different port, like 5431, when creating the docker container, as in: -p 5431: 5432\\nThen, we need to use this port when connecting to pgcli, as shown below:\\npgcli -h localhost -p 5431 -u root -d ny_taxi\\nThis will connect you to your postgres docker container, which is mapped to your host’s 5431 port (though you might choose any port of your liking as long as it is not occupied).\\nFor a more visual and detailed explanation, feel free to check the video 1.4.2 - Port Mapping and Networks in Docker\\nIf you want to debug: the following can help (on a MacOS)\\nTo find out if something is blocking your port (on a MacOS):\\nYou can use the lsof command to find out which application is using a specific port on your local machine. `lsof -i :5432`wi\\nOr list the running postgres services on your local machine with launchctl\\nTo unload the running service on your local machine (on a MacOS):\\nunload the launch agent for the PostgreSQL service, which will stop the service and free up the port  \\n`launchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist`\\nthis one to start it again\\n`launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist`\\nChanging port from 5432:5432 to 5431:5432 helped me to avoid this error.', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - FATAL: password authentication failed for user \"root\" (You already have Postgres)', 'course': 'data-engineering-zoomcamp', 'id': '3e5d1e9b'}, '78833f32': {'text': 'I get this error\\npgcli -h localhost -p 5432 -U root -d ny_taxi\\nTraceback (most recent call last):\\nFile \"/opt/anaconda3/bin/pgcli\", line 8, in <module>\\nsys.exit(cli())\\nFile \"/opt/anaconda3/lib/python3.9/site-packages/click/core.py\", line 1128, in __call__\\nreturn self.main(*args, **kwargs)\\nFile \"/opt/anaconda3/lib/python3.9/sitYe-packages/click/core.py\", line\\n1053, in main\\nrv = self.invoke(ctx)\\nFile \"/opt/anaconda3/lib/python3.9/site-packages/click/core.py\", line 1395, in invoke\\nreturn ctx.invoke(self.callback, **ctx.params)\\nFile \"/opt/anaconda3/lib/python3.9/site-packages/click/core.py\", line 754, in invoke\\nreturn __callback(*args, **kwargs)\\nFile \"/opt/anaconda3/lib/python3.9/site-packages/pgcli/main.py\", line 880, in cli\\nos.makedirs(config_dir)\\nFile \"/opt/anaconda3/lib/python3.9/os.py\", line 225, in makedirspython\\nmkdir(name, mode)PermissionError: [Errno 13] Permission denied: \\'/Users/vray/.config/pgcli\\'\\nMake sure you install pgcli without sudo.\\nThe recommended approach is to use conda/anaconda to make sure your system python is not affected.\\nIf conda install gets stuck at \"Solving environment\" try these alternatives: https://stackoverflow.com/questions/63734508/stuck-at-solving-environment-on-anaconda', 'section': 'Module 1: Docker and Terraform', 'question': \"PGCLI - PermissionError: [Errno 13] Permission denied: '/some/path/.config/pgcli'\", 'course': 'data-engineering-zoomcamp', 'id': '78833f32'}, '63823f21': {'text': 'ImportError: no pq wrapper available.\\nAttempts made:\\n- couldn\\'t import \\\\dt\\nopg \\'c\\' implementation: No module named \\'psycopg_c\\'\\n- couldn\\'t import psycopg \\'binary\\' implementation: No module named \\'psycopg_binary\\'\\n- couldn\\'t import psycopg \\'python\\' implementation: libpq library not found\\nSolution:\\nFirst, make sure your Python is set to 3.9, at least.\\nAnd the reason for that is we have had cases of \\'psycopg2-binary\\' failing to install because of an old version of Python (3.7.3). \\n\\n0. You can check your current python version with: \\n$ python -V(the V must be capital)\\n1. Based on the previous output, if you\\'ve got a 3.9, skip to Step #2\\n   Otherwispye better off with a new environment with 3.9\\n$ conda create –name de-zoomcamp python=3.9\\n$ conda activate de-zoomcamp\\n2. Next, you should be able to install the lib for postgres like this:\\n```\\n$ e\\n$ pip install psycopg2_binary\\n```\\n3. Finally, make sure you\\'re also installing pgcli, but use conda for that:\\n```\\n$ pgcli -h localhost -U root -d ny_taxisudo\\n```\\nThere, you should be good to go now!\\nAnother solution:\\nRun this\\npip install \"psycopg[binary,pool]\"', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - no pq wrapper available.', 'course': 'data-engineering-zoomcamp', 'id': '63823f21'}, 'b36ea564': {'text': 'If your Bash prompt is stuck on the password command for postgres\\nUse winpty:\\nwinpty pgcli -h localhost -p 5432 -u root -d ny_taxi\\nAlternatively, try using Windows terminal or terminal in VS code.\\nEditPGCLI -connection failed: FATAL:  password authentication failed for user \"root\"\\nThe error above was faced continually despite inputting the correct password\\nSolution\\nOption 1: Stop the PostgreSQL service on Windows\\nOption 2 (using WSL): Completely uninstall Protgres 12 from Windows and install postgresql-client on WSL (sudo apt install postgresql-client-common postgresql-client libpq-dev)\\nOption 3: Change the port of the docker container\\nNEW SOLUTION: 27/01/2024\\nPGCLI -connection failed: FATAL:  password authentication failed for user \"root\"\\nIf you’ve got the error above, it’s probably because you were just like me, closed the connection to the Postgres:13 image in the previous step of the tutorial, which is\\n\\ndocker run -it \\\\\\n-e POSTGRES_USER=root \\\\\\n-e POSTGRES_PASSWORD=root \\\\\\n-e POSTGRES_DB=ny_taxi \\\\\\n-v d:/git/data-engineering-zoomcamp/week_1/docker_sql/ny_taxi_postgres_data:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nSo keep the database connected and you will be able to implement all the next steps of the tutorial.', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI -  stuck on password prompt', 'course': 'data-engineering-zoomcamp', 'id': 'b36ea564'}, 'e2a46ce5': {'text': 'Problem: If you have already installed pgcli but bash doesn\\'t recognize pgcli\\nOn Git bash: bash: pgcli: command not found\\nOn Windows Terminal: pgcli: The term \\'pgcli\\' is not recognized…\\nSolution: Try adding a Python path C:\\\\Users\\\\...\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts to Windows PATH\\nFor details:\\nGet the location: pip list -v\\nCopy C:\\\\Users\\\\...\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\n3. Replace site-packages with Scripts: C:\\\\Users\\\\...\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts\\nIt can also be that you have Python installed elsewhere.\\nFor me it was under c:\\\\python310\\\\lib\\\\site-packages\\nSo I had to add c:\\\\python310\\\\lib\\\\Scripts to PATH, as shown below.\\nPut the above path in \"Path\" (or \"PATH\") in System Variables\\nReference: https://stackoverflow.com/a/68233660', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - pgcli: command not found', 'course': 'data-engineering-zoomcamp', 'id': 'e2a46ce5'}, '27bdbc3f': {'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - running in a Docker container', 'course': 'data-engineering-zoomcamp', 'id': '27bdbc3f'}, 'f7c5d8da': {'text': 'PULocationID will not be recognized but “PULocationID” will be. This is because unquoted \"Localidentifiers are case insensitive. See docs.', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - case sensitive use “Quotations” around columns with capital letters', 'course': 'data-engineering-zoomcamp', 'id': 'f7c5d8da'}, 'c91ad8f2': {'text': 'When using the command `\\\\d <database name>` you get the error column `c.relhasoids does not exist`.\\nResolution:\\nUninstall pgcli\\nReinstall pgclidatabase \"ny_taxi\" does not exist\\nRestart pc', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - error column c.relhasoids does not exist', 'course': 'data-engineering-zoomcamp', 'id': 'c91ad8f2'}, '88bf31a0': {'text': \"This happens while uploading data via the connection in jupyter notebook\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\\nThe port 5432 was taken by another postgres. We are not connecting to the port in docker, but to the port on our machine. Substitute 5431 or whatever port you mapped to for port 5432.\\nAlso if this error is still persistent , kindly check if you have a service in windows running postgres , Stopping that service will resolve the issue\", 'section': 'Module 1: Docker and Terraform', 'question': 'Postgres - OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  password authentication failed for user \"root\"', 'course': 'data-engineering-zoomcamp', 'id': '88bf31a0'}, '23524e6d': {'text': 'Can happen when connecting via pgcli\\npgcli -h localhost -p 5432 -U root -d ny_taxi\\nOr while uploading data via the connection in jupyter notebook\\nengine = create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')\\nThis can happen when Postgres is already installed on your computer. Changing the port can resolve that (e.g. from 5432 to 5431).\\nTo check whether there even is a root user with the ability to login:\\nTry: docker exec -it <your_container_name> /bin/bash\\nAnd then run\\n???\\nAlso, you could change port from 5432:5432 to 5431:5432\\nOther solution that worked:\\nChanging `POSTGRES_USER=juroot` to `PGUSER=postgres`\\nBased on this: postgres with docker compose gives FATAL: role \"root\" does not exist error - Stack Overflow\\nAlso `docker compose down`, removing folder that had postgres volume, running `docker compose up` again.', 'section': 'Module 1: Docker and Terraform', 'question': 'Postgres - OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  role \"root\" does not exist', 'course': 'data-engineering-zoomcamp', 'id': '23524e6d'}, '9211bbd6': {'text': '~\\\\anaconda3\\\\lib\\\\site-packages\\\\psycopg2\\\\__init__.py in connect(dsn, connection_factory, cursor_factory, **kwargs)\\n120\\n121     dsn = _ext.make_dsn(dsn, **kwargs)\\n--> 122     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\\n123     if cursor_factory is not None:\\n124         conn.cursor_factory = cursor_factory\\nOperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"ny_taxi\" does not exist\\nMake sure postgres is running. You can check that by running `docker ps`\\n✅Solution: If you have postgres software installed on your computer before now, build your instance on a different port like 8080 instead of 5432', 'section': 'Module 1: Docker and Terraform', 'question': 'Postgres - OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  dodatabase \"ny_taxi\" does not exist', 'course': 'data-engineering-zoomcamp', 'id': '9211bbd6'}, '5db86809': {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', 'id': '5db86809'}, '20c604dd': {'text': 'In the join queries, if we mention the column name directly or enclosed in single quotes it’ll throw an error says “column does not exist”.\\n✅Solution: But if we enclose the column names in double quotes then it will work', 'section': 'Module 1: Docker and Terraform', 'question': 'Postgres - \"Column does not exist\" but it actually does (Pyscopg2 error in MacBook Pro M2)', 'course': 'data-engineering-zoomcamp', 'id': '20c604dd'}, 'b11b8c15': {'text': 'pgAdmin has a new version. Create server dialog may not appear. Try using register-> server instead.', 'section': 'Module 1: Docker and Terraform', 'question': 'pgAdmin - Create server dialog does not appear', 'course': 'data-engineering-zoomcamp', 'id': 'b11b8c15'}, 'a6475348': {'text': 'Using GitHub Codespaces in the browser resulted in a blank screen after the login to pgAdmin (running in a Docker container). The terminal of the pgAdmin container was showing the following error message:\\nCSRFError: 400 Bad Request: The referrer does not match the host.\\nSolution #1:\\nAs recommended in the following issue  https://github.com/pgadmin-org/pgadmin4/issues/5432 setting the following environment variable solved it.\\nPGADMIN_CONFIG_WTF_CSRF_ENABLED=\"False\"\\nModified “docker run” command\\ndocker run --rm -it \\\\\\n-e PGADMIN_DEFAULT_EMAIL=\"admin@admin.com\" \\\\\\n-e PGADMIN_DEFAULT_PASSWORD=\"root\" \\\\\\n-e PGADMIN_CONFIG_WTF_CSRF_ENABLED=\"False\" \\\\\\n-p \"8080:80\" \\\\\\n--name pgadmin \\\\\\n--network=pg-network \\\\\\ndpage/pgadmin4:8.2\\nSolution #2:\\nUsing the local installed VSCode to display GitHub Codespaces.\\nWhen using GitHub Codespaces in the locally installed VSCode (opening a Codespace or creating/starting one) this issue did not occur.', 'section': 'Module 1: Docker and Terraform', 'question': 'pgAdmin - Blank/white screen after login (browser)', 'course': 'data-engineering-zoomcamp', 'id': 'a6475348'}, '1ea7680e': {'text': 'I am using a Mac Pro device and connect to the GCP Compute Engine via Remote SSH - VSCode. But when I trying to run the PgAdmin container via docker run or docker compose command, I am failed to access the pgAdmin address via my browser. I have switched to another browser, but still can not access the pgAdmin address. So I modified a little bit the configuration from the previous DE Zoomcamp repository like below and can access the pgAdmin address:\\nSolution #1:\\nModified “docker run” command\\ndocker run --rm -it \\\\\\n-e PGADMIN_DEFAULT_EMAIL=\"admin@admin.com\" \\\\\\n-e PGADMIN_DEFAULT_PASSWORD=\"pgadmin\" \\\\\\n-e PGADMIN_CONFIG_WTF_CSRF_ENABLED=\"False\" \\\\\\n-e PGADMIN_LISTEN_ADDRESS=0.0.0.0 \\\\\\n-e PGADMIN_LISTEN_PORT=5050 \\\\\\n-p 5050:5050 \\\\\\n--network=de-zoomcamp-network \\\\\\n--name pgadmin-container \\\\\\n--link postgres-container \\\\\\n-t dpage/pgadmin4\\nSolution #2:\\nModified docker-compose.yaml configuration (via “docker compose up” command)\\npgadmin:\\nimage: dpage/pgadmin4\\ncontainer_name: pgadmin-conntainer\\nenvironment:\\n- PGADMIN_DEFAULT_EMAIL=admin@admin.com\\n- PGADMIN_DEFAULT_PASSWORD=pgadmin\\n- PGADMIN_CONFIG_WTF_CSRF_ENABLED=False\\n- PGADMIN_LISTEN_ADDRESS=0.0.0.0\\n- PGADMIN_LISTEN_PORT=5050\\nvolumes:\\n- \"./pgadmin_data:/var/lib/pgadmin/data\"\\nports:\\n- \"5050:5050\"\\nnetworks:\\n- de-zoomcamp-network\\ndepends_on:\\n- postgres-conntainer\\nPython - ModuleNotFoundError: No module named \\'pysqlite2\\'\\nImportError: DLL load failed while importing _sqlite3: The specified module could not be found. ModuleNotFoundError: No module named \\'pysqlite2\\'\\nThe issue seems to arise from the missing of sqlite3.dll in path \".\\\\Anaconda\\\\Dlls\\\\\".\\n✅I solved it by simply copying that .dll file from \\\\Anaconda3\\\\Library\\\\bin and put it under the path mentioned above. (if you are using anaconda)', 'section': 'Module 1: Docker and Terraform', 'question': 'pgAdmin - Can not access/open the PgAdmin address via browser', 'course': 'data-engineering-zoomcamp', 'id': '1ea7680e'}, '10acd478': {'text': 'If you follow the video 1.2.2 - Ingesting NY Taxi Data to Postgres and you execute all the same\\nsteps as Alexey does, you will ingest all the data (~1.3 million rows) into the table yellow_taxi_data as expected.\\nHowever, if you try to run the whole script in the Jupyter notebook for a second time from top to bottom, you will be missing the first chunk of 100000 records. This is because there is a call to the iterator before the while loop that puts the data in the table. The while loop therefore starts by ingesting the second chunk, not the first.\\n✅Solution: remove the cell “df=next(df_iter)” that appears higher up in the notebook than the while loop. The first time w(df_iter) is called should be within the while loop.\\n📔Note: As this notebook is just used as a way to test the code, it was not intended to be run top to bottom, and the logic is tidied up in a later step when it is instead inserted into a .py file for the pipeline', 'section': 'Module 1: Docker and Terraform', 'question': 'Python - Ingestion with Jupyter notebook - missing 100000 records', 'course': 'data-engineering-zoomcamp', 'id': '10acd478'}, '752e8452': {'text': '{t_end - t_start} seconds\")\\nimport pandas as pd\\ndf = pd.read_csv(\\'path/to/file.csv.gz\\', /app/ingest_data.py:1: DeprecationWarning:)\\nIf you prefer to keep the uncompressed csv (easier preview in vscode and similar), gzip files can be unzipped using gunzip (but not unzip). On a Ubuntu local or virtual machine, you may need to apt-get install gunzip first.', 'section': 'Module 1: Docker and Terraform', 'question': 'Python - Iteration csv without error', 'course': 'data-engineering-zoomcamp', 'id': '752e8452'}, 'aa6f52b8': {'text': \"Pandas can interpret “string” column values as “datetime” directly when reading the CSV file using “pd.read_csv” using the parameter “parse_dates”, which for example can contain a list of column names or column indices. Then the conversion afterwards is not required anymore.\\npandas.read_csv — pandas 2.1.4 documentation (pydata.org)\\nExample from week 1\\nimport pandas as pd\\ndf = pd.read_csv(\\n'yellow_tripdata_2021-01.csv',\\nnrows=100,\\nparse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'])\\ndf.info()\\nwhich will output\\n<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 100 entries, 0 to 99\\nData columns (total 18 columns):\\n#   Column                 Non-Null Count  Dtype\\n---  ------                 --------------  -----\\n0   VendorID               100 non-null    int64\\n1   tpep_pickup_datetime   100 non-null    datetime64[ns]\\n2   tpep_dropoff_datetime  100 non-null    datetime64[ns]\\n3   passenger_count        100 non-null    int64\\n4   trip_distance          100 non-null    float64\\n5   RatecodeID             100 non-null    int64\\n6   store_and_fwd_flag     100 non-null    object\\n7   PULocationID           100 non-null    int64\\n8   DOLocationID           100 non-null    int64\\n9   payment_type           100 non-null    int64\\n10  fare_amount            100 non-null    float64\\n11  extra                  100 non-null    float64\\n12  mta_tax                100 non-null    float64\\n13  tip_amount             100 non-null    float64\\n14  tolls_amount           100 non-null    float64\\n15  improvement_surcharge  100 non-null    float64\\n16  total_amount           100 non-null    float64\\n17  congestion_surcharge   100 non-null    float64\\ndtypes: datetime64[ns](2), float64(9), int64(6), object(1)\\nmemory usage: 14.2+ KB\", 'section': 'Module 1: Docker and Terraform', 'question': 'iPython - Pandas parsing dates with ‘read_csv’', 'course': 'data-engineering-zoomcamp', 'id': 'aa6f52b8'}, '3dacbb98': {'text': 'os.system(f\"curl -LO {url} -o {csv_name}\")', 'section': 'Module 1: Docker and Terraform', 'question': 'Python - Python cant ingest data from the github link provided using curl', 'course': 'data-engineering-zoomcamp', 'id': '3dacbb98'}, '8b71a398': {'text': 'When a CSV file is compressed using Gzip, it is saved with a \".csv.gz\" file extension. This file type is also known as a Gzip compressed CSV file. When you want to read a Gzip compressed CSV file using Pandas, you can use the read_csv() function, which is specifically designed to read CSV files. The read_csv() function accepts several parameters, including a file path or a file-like object. To read a Gzip compressed CSV file, you can pass the file path of the \".csv.gz\" file as an argument to the read_csv() function.\\nHere is an example of how to read a Gzip compressed CSV file using Pandas:\\ndf = pd.read_csv(\\'file.csv.gz\\'\\n, compression=\\'gzip\\'\\n, low_memory=False\\n)', 'section': 'Module 1: Docker and Terraform', 'question': 'Python - Pandas can read *.csv.gzip', 'course': 'data-engineering-zoomcamp', 'id': '8b71a398'}, 'aa244fa0': {'text': \"Contrary to panda’s read_csv method there’s no such easy way to iterate through and set chunksize for parquet files. We can use PyArrow (Apache Arrow Python bindings) to resolve that.\\nimport pyarrow.parquet as pq\\noutput_name = “https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet”\\nparquet_file = pq.ParquetFile(output_name)\\nparquet_size = parquet_file.metadata.num_rows\\nengine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{db}')\\ntable_name=”yellow_taxi_schema”\\n# Clear table if exists\\npq.read_table(output_name).to_pandas().head(n=0).to_sql(name=table_name, con=engine, if_exists='replace')\\n# default (and max) batch size\\nindex = 65536\\nfor i in parquet_file.iter_batches(use_threads=True):\\nt_start = time()\\nprint(f'Ingesting {index} out of {parquet_size} rows ({index / parquet_size:.0%})')\\ni.to_pandas().to_sql(name=table_name, con=engine, if_exists='append')\\nindex += 65536\\nt_end = time()\\nprint(f'\\\\t- it took %.1f seconds' % (t_end - t_start))\", 'section': 'Module 1: Docker and Terraform', 'question': 'Python - How to iterate through and ingest parquet file', 'course': 'data-engineering-zoomcamp', 'id': 'aa244fa0'}, 'eac816d7': {'text': 'Error raised during the jupyter notebook’s cell execution:\\nfrom sqlalchemy import create_engine.\\nSolution: Version of Python module “typing_extensions” >= 4.6.0. Can be updated by Conda or pip.', 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLAlchemy - ImportError: cannot import name 'TypeAliasType' from 'typing_extensions'.\", 'course': 'data-engineering-zoomcamp', 'id': 'eac816d7'}, 'd44d1c77': {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)', 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\", 'course': 'data-engineering-zoomcamp', 'id': 'd44d1c77'}, 'ed34766a': {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\", 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", 'course': 'data-engineering-zoomcamp', 'id': 'ed34766a'}, 'fd714677': {'text': 'Unable to add Google Cloud SDK PATH to Windows\\nWindows error: The installer is unable to automatically update your system PATH. Please add  C:\\\\tools\\\\google-cloud-sdk\\\\bin\\nif you are constantly getting this feedback. Might be that you needed to add Gitbash to your Windows path:\\nOne way of doing that is to use conda: ‘If you are not already using it\\nDownload the Anaconda Navigator\\nMake sure to check the box (add conda to the path when installing navigator: although not recommended do it anyway)\\nYou might also need to install git bash if you are not already using it(or you might need to uninstall it to reinstall it properly)\\nMake sure to check the following boxes while you install Gitbash\\nAdd a GitBash to Windows Terminal\\nUse Git and optional Unix tools from the command prompt\\nNow open up git bash and type conda init bash This should modify your bash profile\\nAdditionally, you might want to use Gitbash as your default terminal.\\nOpen your Windows terminal and go to settings, on the default profile change Windows power shell to git bash', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - Unable to add Google Cloud SDK PATH to Windows', 'course': 'data-engineering-zoomcamp', 'id': 'fd714677'}, '9de2c3e9': {'text': 'It asked me to create a project. This should be done from the cloud console. So maybe we don’t need this FAQ.\\nWARNING: Project creation failed: HttpError accessing <https://cloudresourcemanager.googleapis.com/v1/projects?alt=json>: response: <{\\'vtpep_pickup_datetimeary\\': \\'Origin, X-Origin, Referer\\', \\'content-type\\': \\'application/json; charset=UTF-8\\', \\'content-encoding\\': \\'gzip\\', \\'date\\': \\'Mon, 24 Jan 2022 19:29:12 GMT\\', \\'server\\': \\'ESF\\', \\'cache-control\\': \\'private\\', \\'x-xss-protection\\': \\'0\\', \\'x-frame-options\\': \\'SAMEORIGIN\\', \\'x-content-type-options\\': \\'nosniff\\', \\'server-timing\\': \\'gfet4t7; dur=189\\', \\'alt-svc\\': \\'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000,h3-Q050=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000,quic=\":443\"; ma=2592000; v=\"46,43\"\\', \\'transfer-encoding\\': \\'chunked\\', \\'status\\': 409}>, content <{\\n\"error\": {\\n\"code\": 409,\\n\"message\": \"Requested entity alreadytpep_pickup_datetime exists\",\\n\"status\": \"ALREADY_EXISTS\"\\n}\\n}\\nFrom Stackoverflow: https://stackoverflow.com/questions/52561383/gcloud-cli-cannot-create-project-the-project-id-you-specified-is-already-in-us?rq=1\\nProject IDs are unique across all projects. That means if any user ever had a project with that ID, you cannot use it. testproject is pretty common, so it\\'s not surprising it\\'s already taken.', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - Project creation failed: HttpError accessing … Requested entity alreadytpep_pickup_datetime exists', 'course': 'data-engineering-zoomcamp', 'id': '9de2c3e9'}, '827dd4af': {'text': 'If you receive the error: “Error 403: The project to be billed is associated with an absent billing account., accountDisabled” It is most likely because you did not enter YOUR project ID. The snip below is from video 1.3.2\\nThe value you enter here will be unique to each student. You can find this value on your GCP Dashboard when you login.\\nAshish Agrawal\\nAnother possibility is that you have not linked your billing account to your current project', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - The project to be billed is associated with an absent billing account', 'course': 'data-engineering-zoomcamp', 'id': '827dd4af'}, 'a42a7e8c': {'text': 'GCP Account Suspension Inquiry\\nIf Google refuses your credit/debit card, try another - I’ve got an issue with Kaspi (Kazakhstan) but it worked with TBC (Georgia).\\nUnfortunately, there’s small hope that support will help.\\nIt seems that Pyypl web-card should work too.', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - OR-CBAT-15 ERROR Google cloud free trial account', 'course': 'data-engineering-zoomcamp', 'id': 'a42a7e8c'}, '4eefdd01': {'text': 'The ny-rides.json is your private file in Google Cloud Platform (GCP). \\n\\nAnd here’s the way to find it:\\nGCP -> Select project with your  instance -> IAM & Admin -> Service Accounts Keys tab -> add key, JSON as key type, then click create\\nNote: Once you go into Service Accounts Keys tab, click the email, then you can see the “KEYS” tab where you can add key as a JSON as its key type', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - Where can I find the “ny-rides.json” file?', 'course': 'data-engineering-zoomcamp', 'id': '4eefdd01'}, '0282578d': {'text': 'In this lecture, Alexey deleted his instance in Google Cloud. Do I have to do it?\\nNope. Do not delete your instance in Google Cloud platform. Otherwise, you have to do this twice for the week 1 readings.', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - Do I need to delete my instance in Google Cloud?', 'course': 'data-engineering-zoomcamp', 'id': '0282578d'}, 'bd3e60fd': {'text': 'System Resource Usage:\\ntop or htop: Shows real-time information about system resource usage, including CPU, memory, and processes.\\nfree -h: Displays information about system memory usage and availability.\\ndf -h: Shows disk space usage of file systems.\\ndu -h <directory>: Displays disk usage of a specific directory.\\nRunning Processes:\\nps aux: Lists all running processes along with detailed information.\\nNetwork:\\nifconfig or ip addr show: Shows network interface configuration.\\nnetstat -tuln: Displays active network connections and listening ports.\\nHardware Information:\\nlscpu: Displays CPU information.\\nlsblk: Lists block devices (disks and partitions).\\nlshw: Lists hardware configuration.\\nUser and Permissions:\\nwho: Shows who is logged on and their activities.\\nw: Displays information about currently logged-in users and their processes.\\nPackage Management:\\napt list --installed: Lists installed packages (for Ubuntu and Debian-based systems)', 'section': 'Module 1: Docker and Terraform', 'question': 'Commands to inspect the health of your VM:', 'course': 'data-engineering-zoomcamp', 'id': 'bd3e60fd'}, 'c4e9bc60': {'text': 'if you’ve got the error\\n│ Error: Error updating Dataset \"projects/<your-project-id>/datasets/demo_dataset\": googleapi: Error 403: Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. The default table expiration time must be less than 60 days, billingNotEnabled\\nbut you’ve set your billing account indeed, then try to disable billing for the project and enable it again. It worked for ME!', 'section': 'Module 1: Docker and Terraform', 'question': 'Billing account has not been enabled for this project. But you’ve done it indeed!', 'course': 'data-engineering-zoomcamp', 'id': 'c4e9bc60'}, 'f10b49be': {'text': 'for windows if you having trouble install SDK try follow these steps on the link, if you getting this error:\\nThese credentials will be used by any library that requests Application Default Credentials (ADC).\\nWARNING:\\nCannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\\nFor me:\\nI reinstalled the sdk using unzip file “install.bat”,\\nafter successfully checking gcloud version,\\nrun gcloud init to set up project before\\nyou run gcloud auth application-default login\\nhttps://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_1_basics_n_setup/1_terraform_gcp/windows.md\\nGCP VM - I cannot get my Virtual Machine to start because GCP has no resources.\\nClick on your VM\\nCreate an image of your VM\\nOn the page of the image, tell GCP to create a new VM instance via the image\\nOn the settings page, change the location', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP - Windows Google Cloud SDK install issue:gcp', 'course': 'data-engineering-zoomcamp', 'id': 'f10b49be'}, '3184bd8b': {'text': 'The reason this video about the GCP VM exists is that many students had problems configuring their env. You can use your own env if it works for you.\\nAnd the advantage of using your own environment is that if you are working in a Github repo where you can commit, you will be able to commit the changes that you do. In the VM the repo is cloned via HTTPS so it is not possible to directly commit, even if you are the owner of the repo.', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP VM - Is it necessary to use a GCP VM? When is it useful?', 'course': 'data-engineering-zoomcamp', 'id': '3184bd8b'}, '8bea4d53': {'text': \"I am trying to create a directory but it won't let me do it\\nUser1@DESKTOP-PD6UM8A MINGW64 /\\n$ mkdir .ssh\\nmkdir: cannot create directory ‘.ssh’: Permission denied\\nYou should do it in your home directory. Should be your home (~)\\nLocal. But it seems you're trying to do it in the root folder (/). Should be your home (~)\\nLink to Video 1.4.1\", 'section': 'Module 1: Docker and Terraform', 'question': 'GCP VM - mkdir: cannot create directory ‘.ssh’: Permission denied', 'course': 'data-engineering-zoomcamp', 'id': '8bea4d53'}, '86d11cc0': {'text': \"Failed to save '<file>': Unable to write file 'vscode-remote://ssh-remote+de-zoomcamp/home/<user>/data_engineering_course/week_2/airflow/dags/<file>' (NoPermissions (FileSystemError): Error: EACCES: permission denied, open '/home/<user>/data_engineering_course/week_2/airflow/dags/<file>')\\nYou need to change the owner of the files you are trying to edit via VS Code. You can run the following command to change the ownership.\\nssh\\nsudo chown -R <user> <path to your directory>\", 'section': 'Module 1: Docker and Terraform', 'question': 'GCP VM - Error while saving the file in VM via VS Code', 'course': 'data-engineering-zoomcamp', 'id': '86d11cc0'}, '2cb48591': {'text': 'Question: I connected to my VM perfectly fine last week (ssh) but when I tried again this week, the connection request keeps timing out.\\n✅Answer: Start your VM. Once the VM is running, copy its External IP and paste that into your config file within the ~/.ssh folder.\\ncd ~/.ssh\\ncode config ← this opens the config file in VSCode', 'section': 'Module 1: Docker and Terraform', 'question': '. GCP VM - VM connection request timeout', 'course': 'data-engineering-zoomcamp', 'id': '2cb48591'}, '9523c813': {'text': '(reference: https://serverfault.com/questions/953290/google-compute-engine-ssh-connect-to-host-ip-port-22-operation-timed-out)Go to edit your VM.\\nGo to section Automation\\nAdd Startup script\\n```\\n#!/bin/bash\\nsudo ufw allow ssh\\n```\\nStop and Start VM.', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP VM -  connect to host port 22 no route to host', 'course': 'data-engineering-zoomcamp', 'id': '9523c813'}, '4f8d9174': {'text': 'You can easily forward the ports of pgAdmin, postgres and Jupyter Notebook using the built-in tools in Ubuntu and without any additional client:\\nFirst, in the VM machine, launch docker-compose up -d and jupyter notebook in the correct folder.\\nFrom the local machine, execute: ssh -i ~/.ssh/gcp -L 5432:localhost:5432 username@external_ip_of_vm\\nExecute the same command but with ports 8080 and 8888.\\nNow you can access pgAdmin on local machine in browser typing localhost:8080\\nFor Jupyter Notebook, type localhost:8888 in the browser of your local machine. If you have problems with the credentials, it is possible that you have to copy the link with the access token provided in the logs of the terminal of the VM machine when you launched the jupyter notebook command.\\nTo forward both pgAdmin and postgres use, ssh -i ~/.ssh/gcp -L 5432:localhost:5432 -L 8080:localhost:8080 modito@35.197.218.128', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP VM - Port forwarding from GCP without using VS Code', 'course': 'data-engineering-zoomcamp', 'id': '4f8d9174'}, '29f84a82': {'text': 'If you are using MS VS Code and running gcloud in WSL2, when you first try to login to gcp via the gcloud cli gcloud auth application-default login, you will see a message like this, and nothing will happen\\nAnd there might be a prompt to ask if you want to open it via browser, if you click on it, it will open up a page with error message\\nSolution : you should instead hover on the long link, and ctrl + click the long link\\n\\nClick configure Trusted Domains here\\n\\nPopup will appear, pick first or second entry\\nNext time you gcloud auth, the login page should popup via default browser without issues', 'section': 'Module 1: Docker and Terraform', 'question': 'GCP gcloud + MS VS Code - gcloud auth hangs', 'course': 'data-engineering-zoomcamp', 'id': '29f84a82'}, '20a01fd0': {'text': 'It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later', 'course': 'data-engineering-zoomcamp', 'id': '20a01fd0'}, '5a712a20': {'text': \"The issue was with the network. Google is not accessible in my country, I am using a VPN. And The terminal program does not automatically follow the system proxy and requires separate proxy configuration settings.I opened a Enhanced Mode in Clash, which is a VPN app, and 'terraform apply' works! So if you encounter the same issue, you can ask help for your vpn provider.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error:Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=coherent-ascent-379901\": oauth2: cannot fetch token: Post \"https://oauth2.googleapis.com/token\": dial tcp 172.217.163.42:443: i/o timeout', 'course': 'data-engineering-zoomcamp', 'id': '5a712a20'}, '06021091': {'text': 'https://techcommunity.microsoft.com/t5/azure-developer-community-blog/configuring-terraform-on-windows-10-linux-sub-system/ba-p/393845', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Install for WSL', 'course': 'data-engineering-zoomcamp', 'id': '06021091'}, 'df8ea7e8': {'text': 'https://github.com/hashicorp/terraform/issues/14513', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error acquiring the state lock', 'course': 'data-engineering-zoomcamp', 'id': 'df8ea7e8'}, '1093daf5': {'text': 'When running\\nterraform apply\\non wsl2 I\\'ve got this error:\\n│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\\n│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\\nIT happens because there may be time desync on your machine which affects computing JWT\\nTo fix this, run the command\\nsudo hwclock -s\\nwhich fixes your system time.\\nReference', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.', 'course': 'data-engineering-zoomcamp', 'id': '1093daf5'}, '947213b1': {'text': '│ Error: googleapi: Error 403: Access denied., forbidden\\nYour $GOOGLE_APPLICATION_CREDENTIALS might not be pointing to the correct file \\nrun = export GOOGLE_APPLICATION_CREDENTIALS=~/.gc/YOUR_JSON.json\\nAnd then = gcloud auth activate-service-account --key-file $GOOGLE_APPLICATION_CREDENTIALS', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error 403 : Access denied', 'course': 'data-engineering-zoomcamp', 'id': '947213b1'}, '002d4943': {'text': \"One service account is enough for all the services/resources you'll use in this course. After you get the file with your credentials and set your environment variable, you should be good to go.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Do I need to make another service account for terraform before I get the keys (.json file)?', 'course': 'data-engineering-zoomcamp', 'id': '002d4943'}, '8dc77677': {'text': 'Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?', 'course': 'data-engineering-zoomcamp', 'id': '8dc77677'}, '29d3d343': {'text': 'You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g', 'course': 'data-engineering-zoomcamp', 'id': '29d3d343'}, 'e2095203': {'text': 'The error:\\nError: googleapi: Error 403: Access denied., forbidden\\n│\\nand\\n│ Error: Error creating Dataset: googleapi: Error 403: Request had insufficient authentication scopes.\\nFor this solution make sure to run:\\necho $GOOGLE_APPLICATION_CREDENTIALS\\necho $?\\nSolution:\\nYou have to set again the GOOGLE_APPLICATION_CREDENTIALS as Alexey did in the environment set-up video in week1:\\nexport GOOGLE_APPLICATION_CREDENTIALS=\"<path/to/your/service-account-authkeys>.json', 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error creating Dataset: googleapi: Error 403: Request had insufficient authentication scopes', 'course': 'data-engineering-zoomcamp', 'id': 'e2095203'}, '22a2b9f2': {'text': \"The error:\\nError: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\\nThe solution:\\nYou have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access ‘storage.buckets.create’', 'course': 'data-engineering-zoomcamp', 'id': '22a2b9f2'}, '5d7588f0': {'text': 'provider \"google\" {\\nproject     = var.projectId\\ncredentials = file(\"${var.gcpkey}\")\\n#region      = var.region\\nzone = var.zone\\n}', 'section': 'Module 1: Docker and Terraform', 'question': 'To ensure the sensitivity of the credentials file, I had to spend lot of time to input that as a file.', 'course': 'data-engineering-zoomcamp', 'id': '5d7588f0'}, '5276a695': {'text': 'For the HW1 I encountered this issue. The solution is\\nSELECT * FROM zones AS z WHERE z.\"Zone\" = \\'Astoria Zone\\';\\nI think columns which start with uppercase need to go between “Column”. I ran into a lot of issues like this and “ ” made it work out.\\nAddition to the above point, for me, there is no ‘Astoria Zone’, only ‘Astoria’ is existing in the dataset.\\nSELECT * FROM zones AS z WHERE z.\"Zone\" = \\'Astoria’;', 'section': 'Module 1: Docker and Terraform', 'question': \"SQL - SELECT * FROM zones_taxi WHERE Zone='Astoria Zone'; Error Column Zone doesn't exist\", 'course': 'data-engineering-zoomcamp', 'id': '5276a695'}, '70c159df': {'text': 'It is inconvenient to use quotation marks all the time, so it is better to put the data to the database all in lowercase, so in Pandas after\\ndf = pd.read_csv(‘taxi+_zone_lookup.csv’)\\nAdd the row:\\ndf.columns = df.columns.str.lower()', 'section': 'Module 1: Docker and Terraform', 'question': \"SQL - SELECT Zone FROM taxi_zones Error Column Zone doesn't exist\", 'course': 'data-engineering-zoomcamp', 'id': '70c159df'}, 'f55efcf0': {'text': 'Solution (for mac users): os.system(f\"curl {url} --output {csv_name}\")', 'section': 'Module 1: Docker and Terraform', 'question': 'CURL - curl: (6) Could not resolve host: output.csv', 'course': 'data-engineering-zoomcamp', 'id': 'f55efcf0'}, '2b7a8512': {'text': 'To resolve this, ensure that your config file is in C/User/Username/.ssh/config', 'section': 'Module 1: Docker and Terraform', 'question': 'SSH Error: ssh: Could not resolve hostname linux: Name or service not known', 'course': 'data-engineering-zoomcamp', 'id': '2b7a8512'}, '1cd746c4': {'text': 'If you use Anaconda (recommended for the course), it comes with pip, so the issues is probably that the anaconda’s Python is not on the PATH.\\nAdding it to the PATH is different for each operation system.\\nFor Linux and MacOS:\\nOpen a terminal.\\nFind the path to your Anaconda installation. This is typically `~/anaconda3` or `~/opt/anaconda3`.\\nAdd Anaconda to your PATH with the command: `export PATH=\"/path/to/anaconda3/bin:$PATH\"`.\\nTo make this change permanent, add the command to your `.bashrc` (Linux) or `.bash_profile` (MacOS) file.\\nOn Windows, python and pip are in different locations (python is in the anaconda root, and pip is in Scripts). With GitBash:\\nLocate your Anaconda installation. The default path is usually `C:\\\\Users\\\\[YourUsername]\\\\Anaconda3`.\\nDetermine the correct path format for Git Bash. Paths in Git Bash follow the Unix-style, so convert the Windows path to a Unix-style path. For example, `C:\\\\Users\\\\[YourUsername]\\\\Anaconda3` becomes `/c/Users/[YourUsername]/Anaconda3`.\\nAdd Anaconda to your PATH with the command: `export PATH=\"/c/Users/[YourUsername]/Anaconda3/:/c/Users/[YourUsername]/Anaconda3/Scripts/$PATH\"`.\\nTo make this change permanent, add the command to your `.bashrc` file in your home directory.\\nRefresh your environment with the command: `source ~/.bashrc`.\\nFor Windows (without Git Bash):\\nRight-click on \\'This PC\\' or \\'My Computer\\' and select \\'Properties\\'.\\nClick on \\'Advanced system settings\\'.\\nIn the System Properties window, click on \\'Environment Variables\\'.\\nIn the Environment Variables window, select the \\'Path\\' variable in the \\'System variables\\' section and click \\'Edit\\'.\\nIn the Edit Environment Variable window, click \\'New\\' and add the path to your Anaconda installation (typically `C:\\\\Users\\\\[YourUsername]\\\\Anaconda3` and C:\\\\Users\\\\[YourUsername]\\\\Anaconda3\\\\Scripts`).\\nClick \\'OK\\' in all windows to apply the changes.\\nAfter adding Anaconda to the PATH, you should be able to use `pip` from the command line. Remember to restart your terminal (or command prompt in Windows) to apply these changes.', 'section': 'Module 1: Docker and Terraform', 'question': \"'pip' is not recognized as an internal or external command, operable program or batch file.\", 'course': 'data-engineering-zoomcamp', 'id': '1cd746c4'}, '6d367222': {'text': \"Resolution: You need to stop the services which is using the port.\\nRun the following:\\n```\\nsudo kill -9 `sudo lsof -t -i:<port>`\\n```\\n<port> being 8080 in this case. This will free up the port for use.\\n~ Abhijit Chakraborty\\nError: error response from daemon: cannot stop container: 1afaf8f7d52277318b71eef8f7a7f238c777045e769dd832426219d6c4b8dfb4: permission denied\\nResolution: In my case, I had to stop docker and restart the service to get it running properly\\nUse the following command:\\n```\\nsudo systemctl restart docker.socket docker.service\\n```\\n~ Abhijit Chakraborty\\nError: cannot import module psycopg2\\nResolution: Run the following command in linux:\\n```\\nsudo apt-get install libpq-dev\\npip install psycopg2\\n```\\n~ Abhijit Chakraborty\\nError: docker build Error checking context: 'can't stat '<path-to-file>'\\nResolution: This happens due to insufficient permission for docker to access a certain file within the directory which hosts the Dockerfile.\\n1. You can create a .dockerignore file and add the directory/file which you want Dockerfile to ignore while build.\\n2. If the above does not work, then put the dockerfile and corresponding script, `\\t1.py` in our case to a subfolder. and run `docker build ...`\\nfrom inside the new folder.\\n~ Abhijit Chakraborty\", 'section': 'Module 1: Docker and Terraform', 'question': 'Error: error starting userland proxy: listen tcp4 0.0.0.0:8080: bind: address already in use', 'course': 'data-engineering-zoomcamp', 'id': '6d367222'}, '84e601e1': {'text': 'To get a pip-friendly requirements.txt file file from Anaconda use\\nconda install pip then `pip list –format=freeze > requirements.txt`.\\n`conda list -d > requirements.txt` will not work and `pip freeze > requirements.txt` may give odd pathing.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Anaconda to PIP', 'course': 'data-engineering-zoomcamp', 'id': '84e601e1'}, '4cf83cc2': {'text': 'Prefect: https://docs.google.com/document/d/1K_LJ9RhAORQk3z4Qf_tfGQCDbu8wUWzru62IUscgiGU/edit?usp=sharing\\nAirflow: https://docs.google.com/document/d/1-BwPAsyDH_mAsn8HH5z_eNYVyBMAtawJRjHHsjEKHyY/edit?usp=sharing', 'section': 'Module 2: Workflow Orchestration', 'question': 'Where are the FAQ questions from the previous cohorts for the orchestration module?', 'course': 'data-engineering-zoomcamp', 'id': '4cf83cc2'}, '5adc5188': {'text': 'Issue : Docker containers exit instantly with code 132, upon docker compose up\\nMage documentation has it listing the cause as \"older architecture\" .\\nThis might be a hardware issue, so unless you have another computer, you can\\'t solve it without purchasing a new one, so the next best solution is a VM.\\nThis is from a student running on a VirtualBox VM, Ubuntu 22.04.3 LTS, Docker version 25.0.2. So not having the context on how the vbox was spin up with (CPU, RAM, network, etc), it’s really inconclusive at this time.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Docker - 2.2.2 Configure Mage', 'course': 'data-engineering-zoomcamp', 'id': '5adc5188'}, '3ef0bb96': {'text': 'This issue was occurring with Windows WSL 2\\nFor me this was because WSL 2 was not dedicating enough cpu cores to Docker.The load seems to take up at least one cpu core so I recommend dedicating at least two.\\nOpen Bash and run the following code:\\n$ cd ~\\n$ ls -la\\nLook for the .wsl config file:\\n-rw-r--r-- 1 ~1049089       31 Jan 25 12:54  .wslconfig\\nUsing a text editing tool of your choice edit or create your .wslconfig file:\\n$ nano .wslconfig\\nPaste the following into the new file/ edit the existing file in this format and save:\\n*** Note - for memory– this is the RAM on your machine you can dedicate to Docker, your situation may be different than mine ***\\n[wsl2]\\nprocessors=<Number of Processors - at least 2!> example: 4\\nmemory=<memory> example:4GB\\nExample:\\nOnce you do that run:\\n$ wsl --shutdown\\nThis shuts down WSL\\nThen Restart Docker Desktop - You should now be able to load the .csv.gz file without the error into a pandas dataframe', 'section': 'Module 2: Workflow Orchestration', 'question': 'WSL - 2.2.3 Mage - Unexpected Kernel Restarts; Kernel Running out of memory:', 'course': 'data-engineering-zoomcamp', 'id': '3ef0bb96'}, 'a41ce360': {'text': 'The issue and solution on the link:\\nhttps://datatalks-club.slack.com/archives/C01FABYF2RG/p1706817366764269?thread_ts=1706815324.993529&cid=C01FABYF2RG', 'section': 'Module 2: Workflow Orchestration', 'question': '2.2.3 Configuring Postgres', 'course': 'data-engineering-zoomcamp', 'id': 'a41ce360'}, 'b1cf59e5': {'text': 'Check that the POSTGRES_PORT variable in the io_config.yml  file is set to port 5432, which is the default postgres port. The POSTGRES_PORT variable is the mage container port, not the host port. Hence, there’s no need to set the POSTGRES_PORT to 5431 just because you already have a conflicting postgres installation in your host machine.', 'section': 'Module 2: Workflow Orchestration', 'question': 'MAGE - 2.2.3 OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5431 failed: Connection refused', 'course': 'data-engineering-zoomcamp', 'id': 'b1cf59e5'}, 'f9d6f8bd': {'text': 'You forgot to select ‘dev’ profile in the dropdown menu next to where you select ‘PostgreSQL’ in the connection drop down.', 'section': 'Module 2: Workflow Orchestration', 'question': 'MAGE - 2.2.4 executing SELECT 1; results in KeyError', 'course': 'data-engineering-zoomcamp', 'id': 'f9d6f8bd'}, 'f3adb937': {'text': 'If you are getting this error. Update your mage io_config.yaml file, and specify a timeout value set to 600 like this.\\nMake sure to save your changes.\\nMAGE - 2.2.4 Testing BigQuery connection using SQL 404 error:\\nNotFound: 404 Not found: Dataset ny-rides-diegogutierrez:None was not found in location northamerica-northeast1\\nIf you get this error even with all roles/permissions given to the service account check if you have ticked the box where it says “Use raw SQL”, just like the image below.', 'section': 'Module 2: Workflow Orchestration', 'question': \"MAGE -2.2.4 ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\", 'course': 'data-engineering-zoomcamp', 'id': 'f3adb937'}, 'eb3d6d36': {'text': 'Solution: https://stackoverflow.com/questions/48056381/google-client-invalid-jwt-token-must-be-a-short-lived-token', 'section': 'Module 2: Workflow Orchestration', 'question': \"Problem: RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})\", 'course': 'data-engineering-zoomcamp', 'id': 'eb3d6d36'}, 'a76e1f4d': {'text': \"Origin of Solution (Mage Slack-Channel): https://mageai.slack.com/archives/C03HTTWFEKE/p1706543947795599\\nProblem: This error can often be seen after solving the error mentioned in 2.2.4. The error can be found in Mage version 0.9.61 and is a side-effect of the update of the code for data-loader blocks.\\nNote: Mage 0.9.62 has been released, as of Feb 5 2024. Please recheck. Solution below may be obsolete\\nSolution: Using a “fixed” version of the docker container\\nPull updated docker image from docker-hub\\nmageai/mageaidocker pull:alpha\\nUpdate docker-compose.yaml\\nversion: '3'\\nservices:\\nmagic:\\nimage: mageai/mageai:alpha  <--- instead of “latest”-tag\\ndocker-compose up\\nThe original Error is still present, but the SQL-query will return the desired result:\\n--------------------------------------------------------------------------------------\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage - 2.2.4 IndexError: list index out of range', 'course': 'data-engineering-zoomcamp', 'id': 'a76e1f4d'}, '934facf8': {'text': 'Add\\nif not path.parent.is_dir():\\npath.parent.mkdir(parents=True)\\npath = Path(path).as_posix()\\nsee:\\nhttps://datatalks-club.slack.com/archives/C01FABYF2RG/p1675774214591809?thread_ts=1675768839.028879&cid=C01FABYF2RG', 'section': 'Module 2: Workflow Orchestration', 'question': '2.2.6 OSError: Cannot save file into a non-existent directory: \\'..\\\\\\\\..\\\\\\\\data\\\\\\\\yellow\\'\\\\n\")', 'course': 'data-engineering-zoomcamp', 'id': '934facf8'}, 'a2c7b59f': {'text': 'The video DE Zoomcamp 2.2.7 is missing  the actual deployment of Mage using Terraform to GCP. The steps for the deployment were not covered in the video.\\nI successfully deployed it and wanted to share some key points:\\nIn variables.tf, set the project_id default value to your GCP project ID.\\nEnable the Cloud Filestore API:\\nVisit the Google Cloud Console.to\\nNavigate to \"APIs & Services\" > \"Library.\"\\nSearch for \"Cloud Filestore API.\"\\nClick on the API and enable it.\\nTo perform the deployment:\\nterraform init\\nterraform apply\\nPlease note that during the terraform apply step, Terraform will prompt you to enter the PostgreSQL password. After that, it will ask for confirmation to proceed with the deployment. Review the changes, type \\'yes\\' when prompted, and press Enter.', 'section': 'Module 2: Workflow Orchestration', 'question': 'GCP - 2.2.7d Deploying Mage to GCP', 'course': 'data-engineering-zoomcamp', 'id': 'a2c7b59f'}, '997d4aaa': {'text': 'If you want to rune multiple docker containers from different directories. Then make sure to change the port mappings in the docker-compose.yml file.\\nports:\\n- 8088:6789\\nThe 8088 port in above case is hostport, where mage will run on your local machine. You can customize this as long as the port is available. If you are running on VM, make sure to forward the port too. You need to keep the container port to 6789 as this is the port where mage is running.\\nGCP - 2.2.7d Deploying Mage to Google Cloud\\nWhile terraforming all the resources inside a VM created in GCS the following error is shown.\\nError log:\\nmodule.lb-http.google_compute_backend_service.default[\"default\"]: Creating...\\n╷\\n│ Error: Error creating GlobalAddress: googleapi: Error 403: Request had insufficient authentication scopes.\\n│ Details:\\n│ [\\n│   {\\n│     \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\\n│     \"domain\": \"googleapis.com\",\\n│     \"metadatas\": {\\n│       \"method\": \"compute.beta.GlobalAddressesService.Insert\",\\n│       \"service\": \"compute.googleapis.com\"\\n│     },\\n│     \"reason\": \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\\n│   }\\n│ ]\\n│\\n│ More details:\\n│ Reason: insufficientPermissions, Message: Insufficient Permission\\nThis error might happen when you are using a VM inside GCS. To use the Google APIs from a GCP virtual machine you need to add the cloud platform scope (\"https://www.googleapis.com/auth/cloud-platform\") to your VM when it is created.\\nSince ours is already created you can just stop it and change the permissions. You can do it in the console, just go to \"EDIT\", g99o all the way down until you find \"Cloud API access scopes\". There you can \"Allow full access to all Cloud APIs\". I did this and all went smoothly generating all the resources needed. Hope it helps if you encounter this same error.\\nResources: https://stackoverflow.com/questions/35928534/403-request-had-insufficient-authentication-scopes-during-gcloud-container-clu', 'section': 'Module 2: Workflow Orchestration', 'question': 'Ruuning Multiple Mage instances in Docker from different directories', 'course': 'data-engineering-zoomcamp', 'id': '997d4aaa'}, 'bc269b95': {'text': 'If you are on the free trial account on GCP you will face this issue when trying to deploy the infrastructures with terraform. This service is not available for this kind of account.\\nThe solution I found was to delete the load_balancer.tf file and to comment or delete the rows that differentiate it on the main.tf file. After this just do terraform destroy to delete any infrastructure created on the fail attempts and re-run the terraform apply.\\nCode on main.tf to comment/delete:\\nLine 166, 167, 168', 'section': 'Module 2: Workflow Orchestration', 'question': 'GCP - 2.2.7d Load Balancer Problem (Security Policies quota)', 'course': 'data-engineering-zoomcamp', 'id': 'bc269b95'}, '10ea342e': {'text': \"If you get the following error\\nYou have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\\nYou can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\\nDeploying MAGE to GCP  with Terraform via the VM (2.2.7)\\nFYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\\n`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\\nWhy are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\\nI checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\", 'section': 'Module 2: Workflow Orchestration', 'question': 'GCP - 2.2.7d Part 2 - Getting error when you run terraform apply', 'course': 'data-engineering-zoomcamp', 'id': '10ea342e'}, '4bd23594': {'text': '```\\n│ Error: Error creating Connector: googleapi: Error 403: Permission \\'vpcaccess.connectors.create\\' denied on resource \\'//vpcaccess.googleapis.com/projects/<ommit>/locations/us-west1\\' (or it may not exist).\\n│ Details:\\n│ [\\n│   {\\n│     \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\\n│     \"domain\": \"vpcaccess.googleapis.com\",\\n│     \"metadata\": {\\n│       \"permission\": \"vpcaccess.connectors.create\",\\n│       \"resource\": \"projects/<ommit>/locations/us-west1\"\\n│     },\\n│     \"reason\": \"IAM_PERMISSION_DENIED\"\\n│   }\\n│ ]\\n│\\n│   with google_vpc_access_connector.connector,\\n│   on fs.tf line 19, in resource \"google_vpc_access_connector\" \"connector\":\\n│   19: resource \"google_vpc_access_connector\" \"connector\" {\\n│\\n```\\nSolution: Add Serverless VPC Access Admin to Service Account.\\nLine 148', 'section': 'Module 2: Workflow Orchestration', 'question': \"Question: Permission 'vpcaccess.connectors.create'\", 'course': 'data-engineering-zoomcamp', 'id': '4bd23594'}, 'b0d48cd7': {'text': 'Git won’t push an empty folder to GitHub, so if you put a file in that folder and then push, then you should be good to go.\\nOr - in your code- make the folder if it doesn’t exist using Pathlib as shown here: https://stackoverflow.com/a/273227/4590385.\\nFor some reason, when using github storage, the relative path for writing locally no longer works. Try using two separate paths, one full path for the local write, and the original relative path for GCS bucket upload.', 'section': 'Module 2: Workflow Orchestration', 'question': \"File Path: Cannot save file into a non-existent directory: 'data/green'\", 'course': 'data-engineering-zoomcamp', 'id': 'b0d48cd7'}, '70a37f2c': {'text': 'The green dataset contains lpep_pickup_datetime while the yellow contains tpep_pickup_datetime. Modify the script(s) depending on  the dataset as required.', 'section': 'Module 2: Workflow Orchestration', 'question': 'No column name lpep_pickup_datetime / tpep_pickup_datetime', 'course': 'data-engineering-zoomcamp', 'id': '70a37f2c'}, '8ab78bee': {'text': 'pd.read_csv\\ndf_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\\nThe data needs to be appended to the parquet file using the fastparquet engine\\ndf.to_parquet(path, compression=\"gzip\", engine=\\'fastparquet\\', append=True)', 'section': 'Module 2: Workflow Orchestration', 'question': 'Process to download the VSC using Pandas is killed right away', 'course': 'data-engineering-zoomcamp', 'id': '8ab78bee'}, '54c6db2f': {'text': 'denied: requested access to the resource is denied\\nThis can happen when you\\nHaven\\'t logged in properly to Docker Desktop (use docker login -u \"myusername\")\\nHave used the wrong username when pushing to docker images. Use the same one as your username and as the one you build on\\ndocker image build -t <myusername>/<imagename>:<tag>\\ndocker image push <myusername>/<imagename>:<tag>', 'section': 'Module 2: Workflow Orchestration', 'question': 'Push to docker image failure', 'course': 'data-engineering-zoomcamp', 'id': '54c6db2f'}, 'c5b998f3': {'text': \"16:21:35.607 | INFO    | Flow run 'singing-malkoha' - Executing 'write_bq-b366772c-0' immediately...\\nKilled\\nSolution:  You probably are running out of memory on your VM and need to add more.  For example, if you have 8 gigs of RAM on your VM, you may want to expand that to 16 gigs.\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Flow script fails with “killed” message:', 'course': 'data-engineering-zoomcamp', 'id': 'c5b998f3'}, 'eec29536': {'text': 'After playing around with prefect for a while this can happen.\\nSsh to your VM and run sudo du -h --block-size=G | sort -n -r | head -n 30 to see which directory needs the most space.\\nMost likely it will be …/.prefect/storage, where your cached flows are stored. You can delete older flows from there. You also have to delete the corresponding flow in the UI, otherwise it will throw you an error, when you try to run your next flow.\\nSSL Certificate Verify: (I got it when trying to run flows on MAC): urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]\\npip install certifi\\n/Applications/Python\\\\ {ver}/Install\\\\ Certificates.command\\nor\\nrunning the “Install Certificate.command” inside of the python{ver} folder', 'section': 'Module 2: Workflow Orchestration', 'question': 'GCP VM: Disk Space is full', 'course': 'data-engineering-zoomcamp', 'id': 'eec29536'}, '727e5a69': {'text': 'It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\\nI would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Docker: container crashed with status code 137.', 'course': 'data-engineering-zoomcamp', 'id': '727e5a69'}, 'da899638': {'text': 'In Q3 there was a task to run the etl script from web to GCS. The problem was, it wasn’t really an ETL straight from web to GCS, but it was actually a web to local storage to local memory to GCS over network ETL. Yellow data is about 100 MB each per month compressed and ~700 MB after uncompressed on memory\\nThis leads to a problem where i either got a network type error because my not so good 3rd world internet or i got my WSL2 crashed/hanged because out of memory error and/or 100% resource usage hang.\\nSolution:\\nif you have a lot of time at hand, try compressing it to parquet and writing it to GCS with the timeout argument set to a really high number (the default os 60 seconds)\\nthe yellow taxi data for feb 2019 is about 100MB as parquet file\\ngcp_cloud_storage_bucket_block.upload_from_path(\\nfrom_path=f\"{path}\",\\nto_path=path,\\ntimeout=600\\n)', 'section': 'Module 2: Workflow Orchestration', 'question': 'Timeout due to slow upload internet', 'course': 'data-engineering-zoomcamp', 'id': 'da899638'}, 'dde58c8f': {'text': 'This error occurs when you try to re-run the export block, of the transformed green_taxi data to PostgreSQL.\\nWhat you’ll need to do is to drop the table using SQL in Mage (screenshot below).\\nYou should be able to re-run the block successfully after dropping the table.', 'section': 'Module 2: Workflow Orchestration', 'question': 'UndefinedColumn: column \"ratecode_id\", \"rate_code_id\" “vendor_id”, “pu_location_id”, “do_location_id” of relation \"green_taxi\" does not exist - Export transformed green_taxi data to PostgreSQL', 'course': 'data-engineering-zoomcamp', 'id': 'dde58c8f'}, '207be93b': {'text': 'SettingWithCopyWarning:\\nA value is trying to be set on a copy of a slice from a DataFrame.\\nUse the data.loc[] = value syntax instead of df[] = value to ensure that the new column is being assigned to the original dataframe instead of a copy of a dataframe or a series.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Homework - Q3 SettingWithCopyWarning Error:', 'course': 'data-engineering-zoomcamp', 'id': '207be93b'}, 'f0617e65': {'text': 'CSV Files are very big in nyc data, so we instead of using Pandas/Python kernel , we can try Pyspark Kernel\\nDocumentation of Mage for using pyspark kernel: https://docs.mage.ai/integrations/spark-pyspark\\n?', 'section': 'Module 2: Workflow Orchestration', 'question': 'Since I was using slow laptop, and we have so big csv files, I used pyspark kernel in mage instead of python, How to do it?', 'course': 'data-engineering-zoomcamp', 'id': 'f0617e65'}, '6290a1a6': {'text': 'So we will first delete the connection between blocks then we can remove the connection.', 'section': 'Module 2: Workflow Orchestration', 'question': 'I got an error when I was deleting  BLOCK IN A PIPELINE', 'course': 'data-engineering-zoomcamp', 'id': '6290a1a6'}, '5a06248c': {'text': 'While Editing the Pipeline Name It throws permission denied error.\\n(Work around)In that case proceed with the work and save later on revisit it will let you edit.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage UI won’t let you edit the Pipeline name?', 'course': 'data-engineering-zoomcamp', 'id': '5a06248c'}, 'c46a2e9e': {'text': 'Solution n°1 if you want to download everything :\\n```\\nimport pyarrow as pa\\nimport pyarrow.parquet as pq\\nfrom pyarrow.fs import GcsFileSystem\\n…\\n@data_loader\\ndef load_data(*args, **kwargs):\\n    bucket_name = YOUR_BUCKET_NAME_HERE\\'\\n    blob_prefix = \\'PATH / TO / WHERE / THE / PARTITIONS / ARE\\'\\n    root_path = f\"{bucket_name}/{blob_prefix}\"\\npa_table = pq.read_table(\\n        source=root_path,\\n        filesystem=GcsFileSystem(),        \\n    )\\n\\n    return pa_table.to_pandas()\\nSolution n°2 if you want to download only some dates :\\n@data_loader\\ndef load_data(*args, **kwargs):\\ngcs = pa.fs.GcsFileSystem()\\nbucket_name = \\'YOUR_BUCKET_NAME_HERE\\'\\nblob_prefix = \\'\\'PATH / TO / WHERE / THE / PARTITIONS / ARE\\'\\'\\nroot_path = f\"{bucket_name}/{blob_prefix}\"\\npa_dataset = pq.ParquetDataset(\\npath_or_paths=root_path,\\nfilesystem=gcs,\\nfilters=[(\\'lpep_pickup_date\\', \\'>=\\', \\'2020-10-01\\'), (\\'lpep_pickup_date\\', \\'<=\\', \\'2020-10-31\\')]\\n)\\nreturn pa_dataset.read().to_pandas()\\n# More information about the pq.Parquet.Dataset : Encapsulates details of reading a complete Parquet dataset possibly consisting of multiple files and partitions in subdirectories. Documentation here :\\nhttps://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html#pyarrow.parquet.ParquetDataset\\nERROR: UndefinedColumn: column \"vendor_id\" of relation \"green_taxi\" does not exist\\nTwo possible solutions both of them work in the same way.\\nOpen up a Data Loader connect using SQL - RUN the command \\n`DROP TABLE mage.green_taxi`\\nElse, Open up a Data Extractor of SQL  - increase the rows to above the number of rows in the dataframe (you can find that in the bottom of the transformer block) change the Write Policy to `Replace` and run the SELECT statement', 'section': 'Module 2: Workflow Orchestration', 'question': 'How do I make Mage load the partitioned files that we created on 2.2.4, to load them into BigQuery ?', 'course': 'data-engineering-zoomcamp', 'id': 'c46a2e9e'}, '0513ab8a': {'text': \"All mage files are in your /home/src/folder where you saved your credentials.json so you should be able to access them locally. You will see a folder for ‘Pipelines’,  'data loaders', 'data transformers' & 'data exporters' - inside these will be the .py or .sql files for the blocks you created in your pipeline.\\nRight click & ‘download’ the pipeline itself to your local machine (which gives you metadata, pycache and other files)\\nAs above, download each .py/.sql file that corresponds to each block you created for the pipeline. You'll find these under 'data loaders', 'data transformers' 'data exporters'\\nMove the downloaded files to your GitHub repo folder & commit your changes.\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - What Files Should I Submit for Homework 2 & How do I get them out of MAGE:', 'course': 'data-engineering-zoomcamp', 'id': '0513ab8a'}, 'a9385356': {'text': 'Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\\nMove the contents of the .gitignore file in your main .gitignore.\\nUse the terminal to cd into the Mage folder and:\\nrun “git remote remove origin” to de-couple the Mage repo,\\nrun “rm -rf .git” to delete local git files,\\nrun “git add .” to add the current folder as changes to stage, commit and push.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?', 'course': 'data-engineering-zoomcamp', 'id': 'a9385356'}, 'c30468c0': {'text': \"When try to add three assertions:\\nvendor_id is one of the existing values in the column (currently)\\npassenger_count is greater than 0\\ntrip_distance is greater than 0\\nto test_output, I got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). Below is my code:\\ndata_filter = (data['passenger_count'] > 0) and (data['trip_distance'] > 0)\\nAfter looking for solutions at Stackoverflow, I found great discussion about it. So I changed my code into:\\ndata_filter = (data['passenger_count'] > 0) & (data['trip_distance'] > 0)\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()', 'course': 'data-engineering-zoomcamp', 'id': 'c30468c0'}, '305aead7': {'text': 'This happened when I just booted up my PC, continuing from the progress I was doing from yesterday.\\nAfter cd-ing into your directory, and running docker compose up , the web interface for the Mage shows, but the files that I had yesterday was gone.\\nIf your files are gone, go ahead and close the web interface, and properly shutting down the mage docker compose by doing Ctrl + C once. Try running it again. This worked for me more than once (yes the issue persisted with my PC twice)\\nAlso, you should check if you’re in the correct repository before doing docker compose up . This was discussed in the Slack #course-data-engineering channel', 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage AI Files are Gone/disappearing', 'course': 'data-engineering-zoomcamp', 'id': '305aead7'}, '77410975': {'text': 'The above errors due to “ at the trailing side and it need to be modified with ‘ quotes at both ends\\nKrishna Anand', 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage - Errors in io.config.yaml file', 'course': 'data-engineering-zoomcamp', 'id': '77410975'}, '0952abde': {'text': \"Problem: The following error occurs when attempting to export data from Mage to a GCS bucket using pyarrow suggesting Mage doesn’t have the necessary permissions to access the specified GCP credentials .json file.\\nArrowException: Unknown error: google::cloud::Status(UNKNOWN: Permanent error GetBucketMetadata: Could not create a OAuth2 access token to authenticate the request. The request was not sent, as such an access token is required to complete the request successfully. Learn more about Google Cloud authentication at https://cloud.google.com/docs/authentication. The underlying error message was: Cannot open credentials file /home/src/...\\nSolution: Inside the Mage app:\\nCreate a credentials folder (e.g. gcp-creds) within the magic-zoomcamp folder\\nIn the credentials folder create a .json key file (e.g. mage-gcp-creds.json)\\nCopy/paste GCP service account credentials into the .json key file and save\\nUpdate code to point to this file. E.g.\\nenviron['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/src/magic-zoomcamp/gcp-creds/mage-gcp-creds.json'\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage - ArrowException Cannot open credentials file', 'course': 'data-engineering-zoomcamp', 'id': '0952abde'}, '7c4326eb': {'text': \"Oserror: google::cloud::status(unavailable: retry policy exhausted getbucketmetadata: could not create a OAuth2 access token to authenticate the request. the request was not sent, as such an access token is required to complete the request successfully. learn more about google cloud authentication at https://cloud.google.com/docs/authentication. the underlying error message was: performwork() - curl error [6]=couldn't resolve host name)\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage - OSError', 'course': 'data-engineering-zoomcamp', 'id': '7c4326eb'}, 'a1fc1a14': {'text': \"Problem: The following error occurs when attempting to export data from Mage to a GCS bucket. Assigned service account doesn’t have the necessary permissions access Google Cloud Storage Bucket\\nPermissionError: [Errno 13] google::cloud::Status(PERMISSION_DENIED: Permanent error GetBucketMetadata:... .iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist). error_info={reason=forbidden, domain=global, metadata={http_status_code=403}}). Detail: [errno 13] Permission denied\\nSolution: Add Cloud Storage Admin role to the service account:\\nGo to project in Google Cloud Console>IAM & Admin>IAM\\nClick Edit principal (pencil symbol) to the right of the service account you are using\\nClick + ADD ANOTHER ROLE\\nSelect Cloud Storage>Storage Admin\\nClick Save\", 'section': 'Module 2: Workflow Orchestration', 'question': 'Mage - PermissionError service account does not have storage.buckets.get access to the Google Cloud Storage bucket', 'course': 'data-engineering-zoomcamp', 'id': 'a1fc1a14'}, '6d67fba9': {'text': '1. Make sure your pyspark script is ready to be send to Dataproc cluster\\n2. Create a Dataproc Cluster in GCP Console\\n3. Make sure to edit the service account and add new role - Dataproc Editor\\n4. Copy the python script ./notebooks/pyspark_script.py and place it under GCS bucket path\\n5. Make sure gcloud cli is installed either in Mage manually or  via your Dockerfile and docker-compose files. This is needed to let Mage access google Dataproc and the script it needs to execute. Refer - Installing the latest gcloud CLI\\n6. Use the Bigquery/Dataproc script mentioned here - https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/code/cloud.md . Use Mage to trigger the query', 'section': 'Module 3: Data Warehousing', 'question': 'Trigger Dataproc from Mage', 'course': 'data-engineering-zoomcamp', 'id': '6d67fba9'}, '06876291': {'text': 'A:\\n1 solution) Add -Y flag, so that apt-get automatically agrees to install additional packages\\n2) Use python ZipFile package, which is included in all modern python distributions', 'section': 'Module 3: Data Warehousing', 'question': 'Docker-compose takes infinitely long to install zip unzip packages for linux, which are required to unpack datasets', 'course': 'data-engineering-zoomcamp', 'id': '06876291'}, '690ba010': {'text': 'Make sure to use Nullable dataTypes, such as Int64 when appliable.', 'section': 'Module 3: Data Warehousing', 'question': 'GCS Bucket - error when writing data from web to GCS:', 'course': 'data-engineering-zoomcamp', 'id': '690ba010'}, 'b6fdd91d': {'text': 'Ultimately, when trying to ingest data into a BigQuery table, all files within a given directory must have the same schema.\\nWhen dealing for example with the FHV Datasets from 2019, however (see image below), one can see that the files for \\'2019-05\\', and 2019-06, have the columns \"PUlocationID\" and \"DOlocationID\" as Integers, while for the period of \\'2019-01\\' through \\'2019-04\\', the same column is defined as FLOAT.\\nSo while importing these files as parquet to BigQuery, the first one will be used to define the schema of the table, while all files following that will be used to append data on the existing table. Which means, they must all follow the very same schema of the file that created the table.\\nSo, in order to prevent errors like that, make sure to enforce the data types for the columns on the DataFrame before you serialize/upload them to BigQuery. Like this:\\npd.read_csv(\"path_or_url\").astype({\\n\\t\"col1_name\": \"datatype\",\\t\\n\\t\"col2_name\": \"datatype\",\\t\\n\\t...\\t\\t\\t\\t\\t\\n\\t\"colN_name\": \"datatype\" \\t\\n})', 'section': 'Module 3: Data Warehousing', 'question': \"GCS Bucket - Failed to create table: Error while reading data, error message: Parquet column 'XYZ' has type INT which does not match the target cpp_type DOUBLE. File: gs://path/to/some/blob.parquet\", 'course': 'data-engineering-zoomcamp', 'id': 'b6fdd91d'}, '155aa868': {'text': \"If you receive the error gzip.BadGzipFile: Not a gzipped file (b'\\\\n\\\\n'), this is because you have specified the wrong URL to the FHV dataset. Make sure to use https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/{dataset_file}.csv.gz\\nEmphasising the ‘/releases/download’ part of the URL.\", 'section': 'Module 3: Data Warehousing', 'question': 'GCS Bucket - Fix Error when importing FHV data to GCS', 'course': 'data-engineering-zoomcamp', 'id': '155aa868'}, 'e78cf960': {'text': 'Krishna Anand', 'section': 'Module 3: Data Warehousing', 'question': 'GCS Bucket - Load Data From URL list in to GCP Bucket', 'course': 'data-engineering-zoomcamp', 'id': 'e78cf960'}, '9afa1f74': {'text': 'Check the Schema\\nYou might have a wrong formatting\\nTry to upload the CSV.GZ files without formatting or going through pandas via wget\\nSee this Slack conversation for helpful tips', 'section': 'Module 3: Data Warehousing', 'question': 'GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?', 'course': 'data-engineering-zoomcamp', 'id': '9afa1f74'}, 'fac138a7': {'text': 'Run the following command to check if “BigQuery Command Line Tool” is installed or not: gcloud components list\\nYou can also use bq.cmd instead of bq to make it work.', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - “bq: command not found”', 'course': 'data-engineering-zoomcamp', 'id': 'fac138a7'}, '0174dde5': {'text': 'Use big queries carefully,\\nI created by bigquery dataset on an account where my free trial was exhausted, and got a bill of $80.\\nUse big query in free credits and destroy all the datasets after creation.\\nCheck your Billing daily! Especially if you’ve spinned up a VM.', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Caution in using bigquery:no', 'course': 'data-engineering-zoomcamp', 'id': '0174dde5'}, '1023ee65': {'text': 'Be careful when you create your resources on GCP, all of them have to share the same Region in order to allow load data from GCS Bucket to BigQuery. If you forgot it when you created them, you can create a new dataset on BigQuery using the same Region which you used on your GCS Bucket.\\nThis means that your GCS Bucket and the BigQuery dataset are placed in different regions. You have to create a new dataset inside BigQuery in the same region with your GCS bucket and store the data in the newly created dataset.', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Cannot read and write in different locations: source: EU, destination: US - Loading data from GCS into BigQuery (different Region):', 'course': 'data-engineering-zoomcamp', 'id': '1023ee65'}, 'effd2bfa': {'text': \"Make sure to create the BigQuery dataset in the very same location that you've created the GCS Bucket. For instance, if your GCS Bucket was created in `us-central1`, then BigQuery dataset must be created in the same region (us-central1, in this example)\", 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Cannot read and write in different locations: source: <REGION_HERE>, destination: <ANOTHER_REGION_HERE>', 'course': 'data-engineering-zoomcamp', 'id': 'effd2bfa'}, '5b55273c': {'text': 'By the way, this isn’t a problem/solution, but a useful hint:\\nPlease, remember to save your progress in BigQuery SQL Editor.\\nI was almost finishing the homework, when my Chrome Tab froze and I had to reload it. Then I lost my entire SQL script.\\nSave your script from time to time. Just click on the button at the top bar. Your saved file will be available on the left panel.\\nAlternatively, you can copy paste your queries into an .sql file in your preferred editor (Notepad++, VS Code, etc.). Using the .sql extension will provide convenient color formatting.', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Remember to save your queries', 'course': 'data-engineering-zoomcamp', 'id': '5b55273c'}, '1835bfe0': {'text': 'Ans :  While real-time analytics might not be explicitly mentioned, BigQuery has real-time data streaming capabilities, allowing for potential integration in future project iterations.', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Can I use BigQuery for real-time analytics in this project?', 'course': 'data-engineering-zoomcamp', 'id': '1835bfe0'}, '04656af5': {'text': \"could not parse 'pickup_datetime' as timestamp for field pickup_datetime (position 2)\\nThis error is caused by invalid data in the timestamp column. A way to identify the problem is to define the schema from the external table using string datatype. This enables the queries to work at which point we can filter out the invalid rows from the import to the materialised table and insert the fields with the timestamp data type.\", 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Unable to load data from external tables into a materialized table in BigQuery due to an invalid timestamp error that are added while appending data to the file in Google Cloud Storage', 'course': 'data-engineering-zoomcamp', 'id': '04656af5'}, '2d6536d3': {'text': 'Background:\\n`pd.read_parquet`\\n`pd.to_datetime`\\n`pq.write_to_dataset`\\nReference:\\nhttps://stackoverflow.com/questions/48314880/are-parquet-file-created-with-pyarrow-vs-pyspark-compatible\\nhttps://stackoverflow.com/questions/57798479/editing-parquet-files-with-python-causes-errors-to-datetime-format\\nhttps://www.reddit.com/r/bigquery/comments/16aoq0u/parquet_timestamp_to_bq_coming_across_as_int/?share_id=YXqCs5Jl6hQcw-kg6-VgF&utm_content=1&utm_medium=ios_app&utm_name=ioscss&utm_source=share&utm_term=1\\nSolution:\\nAdd `use_deprecated_int96_timestamps=True` to `pq.write_to_dataset` function, like below\\npq.write_to_dataset(\\ntable,\\nroot_path=root_path,\\nfilesystem=gcs,\\nuse_deprecated_int96_timestamps=True\\n# Write timestamps to INT96 Parquet format\\n)', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Error Message in BigQuery: annotated as a valid Timestamp, please annotate it as TimestampType(MICROS) or TimestampType(MILLIS)', 'course': 'data-engineering-zoomcamp', 'id': '2d6536d3'}, '0516ccbe': {'text': 'Solution:\\nIf you’re using Mage, in the last Data Exporter that writes to Google Cloud Storage use PyArrow to generate the Parquet file with the correct logical type for the datetime columns, otherwise they won\\'t be converted to timestamp when loaded by BigQuery later on.\\nimport pyarrow as pa\\nimport pyarrow.parquet as pq\\nimport os\\nif \\'data_exporter\\' not in globals():\\nfrom mage_ai.data_preparation.decorators import data_exporter\\n# Replace with the location of your service account key JSON file.\\nos.environ[\\'GOOGLE_APPLICATION_CREDENTIALS\\'] = \\'/home/src/personal-gcp.json\\'\\nbucket_name = \"<YOUR_BUCKET_NAME>\"\\nobject_key = \\'nyc_taxi_data_2022.parquet\\'\\nwhere = f\\'{bucket_name}/{object_key}\\'\\n@data_exporter\\ndef export_data(data, *args, **kwargs):\\ntable = pa.Table.from_pandas(data, preserve_index=False)\\ngcs = pa.fs.GcsFileSystem()\\npq.write_table(\\ntable,\\nwhere,\\n# Convert integer columns in Epoch milliseconds\\n# to Timestamp columns in microseconds (\\'us\\') so\\n# they can be loaded into BigQuery with the right\\n# data type\\ncoerce_timestamps=\\'us\\',\\nfilesystem=gcs\\n)\\nSolution 2:\\nIf you’re using Mage, in the last Data Exporter that writes to Google Cloud Storage, provide PyArrow with explicit schema to generate the Parquet file with the correct logical type for the datetime columns, otherwise they won\\'t be converted to timestamp when loaded by BigQuery later on.\\nschema = pa.schema([\\n(\\'vendor_id\\', pa.int64()),\\n(\\'lpep_pickup_datetime\\', pa.timestamp(\\'ns\\')),\\n(\\'lpep_dropoff_datetime\\', pa.timestamp(\\'ns\\')),\\n(\\'store_and_fwd_flag\\', pa.string()),\\n(\\'ratecode_id\\', pa.int64()),\\n(\\'pu_location_id\\', pa.int64()),\\n(\\'do_location_id\\', pa.int64()),\\n(\\'passenger_count\\', pa.int64()),\\n(\\'trip_distance\\', pa.float64()),\\n(\\'fare_amount\\', pa.float64()),\\n(\\'extra\\', pa.float64()),\\n(\\'mta_tax\\', pa.float64()),\\n(\\'tip_amount\\', pa.float64()),\\n(\\'tolls_amount\\', pa.float64()),\\n(\\'improvement_surcharge\\', pa.float64()),\\n(\\'total_amount\\', pa.float64()),\\n(\\'payment_type\\', pa.int64()),\\n(\\'trip_type\\', pa.int64()),\\n(\\'congestion_surcharge\\', pa.float64()),\\n(\\'lpep_pickup_month\\', pa.int64())\\n])\\ntable = pa.Table.from_pandas(data, schema=schema)', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Datetime columns in Parquet files created from Pandas show up as integer columns in BigQuery', 'course': 'data-engineering-zoomcamp', 'id': '0516ccbe'}, '6052513d': {'text': 'Reference:\\nhttps://cloud.google.com/bigquery/docs/external-data-cloud-storage\\nSolution:\\nfrom google.cloud import bigquery\\n# Set table_id to the ID of the table to create\\ntable_id = f\"{project_id}.{dataset_name}.{table_name}\"\\n# Construct a BigQuery client object\\nclient = bigquery.Client()\\n# Set the external source format of your table\\nexternal_source_format = \"PARQUET\"\\n# Set the source_uris to point to your data in Google Cloud\\nsource_uris = [ f\\'gs://{bucket_name}/{object_key}/*\\']\\n# Create ExternalConfig object with external source format\\nexternal_config = bigquery.ExternalConfig(external_source_format)\\n# Set source_uris that point to your data in Google Cloud\\nexternal_config.source_uris = source_uris\\nexternal_config.autodetect = True\\ntable = bigquery.Table(table_id)\\n# Set the external data configuration of the table\\ntable.external_data_configuration = external_config\\ntable = client.create_table(table)  # Make an API request.\\nprint(f\\'Created table with external source: {table_id}\\')\\nprint(f\\'Format: {table.external_data_configuration.source_format}\\')', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Create External Table using Python', 'course': 'data-engineering-zoomcamp', 'id': '6052513d'}, '7a71fa2c': {'text': 'Reference:\\nhttps://stackoverflow.com/questions/60941726/can-bigquery-api-overwrite-existing-table-view-with-create-table-tables-inser\\nSolution:\\nCombine with “Create External Table using Python”, use it before “client.create_table” function.\\ndef tableExists(tableID, client):\\n\"\"\"\\nCheck if a table already exists using the tableID.\\nreturn : (Boolean)\\n\"\"\"\\ntry:\\ntable = client.get_table(tableID)\\nreturn True\\nexcept Exception as e: # NotFound:\\nreturn False', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Check BigQuery Table Exist And Delete', 'course': 'data-engineering-zoomcamp', 'id': '7a71fa2c'}, 'f83d9435': {'text': 'To avoid this error you can upload data from Google Cloud Storage to BigQuery through BigQuery Cloud Shell using the command:\\n$ bq load  --autodetect --allow_quoted_newlines --source_format=CSV dataset_name.table_name \"gs://dtc-data-lake-bucketname/fhv/fhv_tripdata_2019-*.csv.gz\"', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Error: Missing close double quote (\") character', 'course': 'data-engineering-zoomcamp', 'id': 'f83d9435'}, 'dbf65e11': {'text': 'Solution: This problem arises if your gcs and bigquery storage is in different regions.\\nOne potential way to solve it:\\nGo to your google cloud bucket and check the region in field named “Location”\\nNow in bigquery, click on three dot icon near your project name and select create dataset.\\nIn region filed choose the same regions as you saw in your google cloud bucket', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Cannot read and write in different locations: source: asia-south2, destination: US', 'course': 'data-engineering-zoomcamp', 'id': 'dbf65e11'}, 'c489266b': {'text': 'There are multiple benefits of using Cloud Functions to automate tasks in Google Cloud.\\nUse below Cloud Function python script to load files directly to BigQuery. Use your project id, dataset id & table id as defined by you.\\nimport tempfile\\nimport requests\\nimport logging\\nfrom google.cloud import bigquery\\ndef hello_world(request):\\n# table_id = <project_id.dataset_id.table_id>\\ntable_id = \\'de-zoomcap-project.dezoomcamp.fhv-2019\\'\\n# Create a new BigQuery client\\nclient = bigquery.Client()\\nfor month in range(4, 13):\\n# Define the schema for the data in the CSV.gz files\\nurl = \\'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-{:02d}.csv.gz\\'.format(month)\\n# Download the CSV.gz file from Github\\nresponse = requests.get(url)\\n# Create new table if loading first month data else append\\nwrite_disposition_string = \"WRITE_APPEND\" if month > 1 else \"WRITE_TRUNCATE\"\\n# Defining LoadJobConfig with schema of table to prevent it from changing with every table\\njob_config = bigquery.LoadJobConfig(\\nschema=[\\nbigquery.SchemaField(\"dispatching_base_num\", \"STRING\"),\\nbigquery.SchemaField(\"pickup_datetime\", \"TIMESTAMP\"),\\nbigquery.SchemaField(\"dropOff_datetime\", \"TIMESTAMP\"),\\nbigquery.SchemaField(\"PUlocationID\", \"STRING\"),\\nbigquery.SchemaField(\"DOlocationID\", \"STRING\"),\\nbigquery.SchemaField(\"SR_Flag\", \"STRING\"),\\nbigquery.SchemaField(\"Affiliated_base_number\", \"STRING\"),\\n],\\nskip_leading_rows=1,\\nwrite_disposition=write_disposition_string,\\nautodetect=True,\\nsource_format=\"CSV\",\\n)\\n# Load the data into BigQuery\\n# Create a temporary file to prevent the exception- AttributeError: \\'bytes\\' object has no attribute \\'tell\\'\"\\nwith tempfile.NamedTemporaryFile() as f:\\nf.write(response.content)\\nf.seek(0)\\njob = client.load_table_from_file(\\nf,\\ntable_id,\\nlocation=\"US\",\\njob_config=job_config,\\n)\\njob.result()\\nlogging.info(\"Data for month %d successfully loaded into table %s.\", month, table_id)\\nreturn \\'Data loaded into table {}.\\'.format(table_id)', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - Tip: Using Cloud Function to read csv.gz files from github directly to BigQuery in Google Cloud:', 'course': 'data-engineering-zoomcamp', 'id': 'c489266b'}, 'ebd63566': {'text': 'You need to uncheck cache preferences in query settings', 'section': 'Module 3: Data Warehousing', 'question': 'GCP BQ - When querying two different tables external and materialized you get the same result when count(distinct(*))', 'course': 'data-engineering-zoomcamp', 'id': 'ebd63566'}, 'f7252f17': {'text': 'Problem: When you inject data into GCS using Pandas, there is a chance that some dataset has missing values on  DOlocationID and PUlocationID. Pandas by default will cast these columns as float data type, causing inconsistent data type between parquet in GCS and schema defined in big query. You will see something like this:\\nSolution:\\nFix the data type issue in data pipeline\\nBefore injecting data into GCS, use astype and Int64 (which is different from int64 and accept both missing value and integer exist in the column) to cast the columns.\\nSomething like:\\ndf[\"PUlocationID\"] = df.PUlocationID.astype(\"Int64\")\\ndf[\"DOlocationID\"] = df.DOlocationID.astype(\"Int64\")\\nNOTE: It is best to define the data type of all the columns in the Transformation section of the ETL pipeline before loading to BigQuery', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ - How to handle type error from big query and parquet data?', 'course': 'data-engineering-zoomcamp', 'id': 'f7252f17'}, '47a43bb0': {'text': 'Problem occurs when misplacing content after fro``m clause in BigQuery SQLs.\\nCheck to remove any extra apaces or any other symbols, keep in lowercases, digits and dashes only', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ - Invalid project ID . Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project', 'course': 'data-engineering-zoomcamp', 'id': '47a43bb0'}, 'f3f13def': {'text': 'No. Based on the documentation for Bigquery, it does not support more than 1 column to be partitioned.\\n[source]', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ - Does BigQuery support multiple columns partition?', 'course': 'data-engineering-zoomcamp', 'id': 'f3f13def'}, '4fd37712': {'text': 'Error Message:\\nPARTITION BY expression must be DATE(<timestamp_column>), DATE(<datetime_column>), DATETIME_TRUNC(<datetime_column>, DAY/HOUR/MONTH/YEAR), a DATE column, TIMESTAMP_TRUNC(<timestamp_column>, DAY/HOUR/MONTH/YEAR), DATE_TRUNC(<date_column>, MONTH/YEAR), or RANGE_BUCKET(<int64_column>, GENERATE_ARRAY(<int64_value>, <int64_value>[, <int64_value>]))\\nSolution:\\nConvert the column to datetime first.\\ndf[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])\\ndf[\"dropOff_datetime\"] = pd.to_datetime(df[\"dropOff_datetime\"])', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ - DATE() Error in BigQuery', 'course': 'data-engineering-zoomcamp', 'id': '4fd37712'}, '8abeca36': {'text': 'Native tables are tables where the data is stored in BigQuery.  External tables store the data outside BigQuery, with BigQuery storing metadata about that external table.\\nResources:\\nhttps://cloud.google.com/bigquery/docs/external-tables\\nhttps://cloud.google.com/bigquery/docs/tables-intro', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ - Native tables vs External tables in BigQuery?', 'course': 'data-engineering-zoomcamp', 'id': '8abeca36'}, '16c16ff9': {'text': 'Issue: Tried running command to export ML model from BQ to GCS from Week 3\\nbq --project_id taxi-rides-ny extract -m nytaxi.tip_model gs://taxi_ml_model/tip_model\\nIt is failing on following error:\\nBigQuery error in extract operation: Error processing job Not found: Dataset was not found in location US\\nI verified the BQ data set and gcs bucket are in the same region- us-west1. Not sure how it gets location US. I couldn’t find the solution yet.\\nSolution:  Please enter correct project_id and gcs_bucket folder address. My gcs_bucket folder address is\\ngs://dtc_data_lake_optimum-airfoil-376815/tip_model', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ ML - Unable to run command (shown in video) to export ML model from BQ to GCS', 'course': 'data-engineering-zoomcamp', 'id': '16c16ff9'}, 'c65d8fd9': {'text': \"To solve this error mention the location = US when creating the dim_zones table\\n{{ config(\\nmaterialized='table',\\nlocation='US'\\n) }}\\nJust Update this part to solve the issue and run the dim_zones again and then run the fact_trips\", 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Dim_zones.sql Dataset was not found in location US When Running fact_trips.sql', 'course': 'data-engineering-zoomcamp', 'id': 'c65d8fd9'}, 'c1a95536': {'text': 'Solution: proceed with setting up serving_dir on your computer as in the extract_model.md file. Then instead of\\ndocker pull tensorflow/serving\\nuse\\ndocker pull emacski/tensorflow-serving\\nThen\\ndocker run -p 8500:8500 -p 8501:8501 --mount type=bind,source=`pwd`/serving_dir/tip_model,target=/models/tip_model -e MODEL_NAME=tip_model -t emacski/tensorflow-serving\\nThen run the curl command as written, and you should get a prediction.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'GCP BQ ML - Export ML model to make predictions does not work for MacBook with Apple M1 chip (arm architecture).', 'course': 'data-engineering-zoomcamp', 'id': 'c1a95536'}, 'bba0da04': {'text': 'Try deleting data you’ve saved to your VM locally during ETLs\\nKill processes related to deleted files\\nDownload ncdu and look for large files (pay particular attention to files related to Prefect)\\nIf you delete any files related to Prefect, eliminate caching from your flow code', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'VMs - What do I do if my VM runs out of space?', 'course': 'data-engineering-zoomcamp', 'id': 'bba0da04'}, 'a2120335': {'text': \"Ans: What they mean is that they don't want you to do anything more than that. You should load the files into the bucket and create an external table based on those files (but nothing like cleaning the data and putting it in parquet format)\", 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': \"Homework - What does it mean “Stop with loading the files into a bucket.' Stop with loading the files into a bucket?”\", 'course': 'data-engineering-zoomcamp', 'id': 'a2120335'}, 'a4ba2478': {'text': 'If for whatever reason you try to read parquets directly from nyc.gov’s cloudfront into pandas, you might run into this error:\\npyarrow.lib.ArrowInvalid: Casting from timestamp[us] to timestamp[ns] would result in out of bounds\\nCause:\\nthere is one errant data record where the dropOff_datetime was set to year 3019 instead of 2019.\\npandas uses “timestamp[ns]” (as noted above), and int64 only allows a ~580 year range, centered on 2000. See `pd.Timestamp.max` and `pd.Timestamp.min`\\nThis becomes out of bounds when pandas tries to read it because 3019 > 2300 (approx value of pd.Timestamp.Max\\nFix:\\nUse pyarrow to read it:\\nimport pyarrow.parquet as pq df = pq.read_table(\\'fhv_tripdata_2019-02.parquet\\').to_pandas(safe=False)\\nHowever this results in weird timestamps for the offending record\\nRead the datetime columns separately using pq.read_table\\n\\ntable = pq.read_table(‘taxi.parquet’)\\ndatetimes = [‘list of datetime column names’]\\ndf_dts = pd.DataFrame()\\nfor col in datetimes:\\ndf_dts[col] = pd.to_datetime(table .column(col), errors=\\'coerce\\')\\n\\nThe `errors=’coerce’` parameter will convert the out of bounds timestamps into either the max or the min\\nUse parquet.compute.filter to remove the offending rows\\n\\nimport pyarrow.compute as pc\\ntable = pq.read_table(\"‘taxi.parquet\")\\ndf = table.filter(\\npc.less_equal(table[\"dropOff_datetime\"], pa.scalar(pd.Timestamp.max))\\n).to_pandas()', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Homework - Reading parquets from nyc.gov directly into pandas returns Out of bounds error', 'course': 'data-engineering-zoomcamp', 'id': 'a4ba2478'}, '74c361fe': {'text': 'Answer: The 2022 NYC taxi data parquet files are available for each month separately. Therefore, you need to add all 12 files to your GCS bucket and then refer to them using the URIs option when creating an external table in BigQuery. You can use the wildcard \"*\" to refer to all 12 files using a single string.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Question: for homework 3 , we need all 12 parquet files for green taxi 2022 right ?', 'course': 'data-engineering-zoomcamp', 'id': '74c361fe'}, 'b9b3ef9f': {'text': 'This can help avoid schema issues in the homework. \\nDownload files locally and use the ‘upload files’ button in GCS at the desired path. You can upload many files at once. You can also choose to upload a folder.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Homework - Uploading files to GCS via GUI', 'course': 'data-engineering-zoomcamp', 'id': 'b9b3ef9f'}, '009ac612': {'text': 'Ans: Take a careful look at the format of the dates in the question.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Homework - Qn 5: The partitioned/clustered table isn’t giving me the prediction I expected', 'course': 'data-engineering-zoomcamp', 'id': '009ac612'}, '68815ec2': {'text': 'Many people aren’t getting an exact match, but are very close to one of the options. As per Alexey said to choose the closest option.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Homework - Qn 6: Did anyone get an exact match for one of the options given in Module 3 homework Q6?', 'course': 'data-engineering-zoomcamp', 'id': '68815ec2'}, 'c8ad08b3': {'text': 'UnicodeDecodeError: \\'utf-8\\' codec can\\'t decode byte 0xa0 in position 41721: invalid start byte\\nSolution:\\nStep 1: When reading the data from the web into the pandas dataframe mention the encoding as follows:\\npd.read_csv(dataset_url, low_memory=False, encoding=\\'latin1\\')\\nStep 2: When writing the dataframe from the local system to GCS as a csv mention the encoding as follows:\\ndf.to_csv(path_on_gsc, compression=\"gzip\", encoding=\\'utf-8\\')\\nAlternative: use pd.read_parquet(url)', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Python - invalid start byte Error Message', 'course': 'data-engineering-zoomcamp', 'id': 'c8ad08b3'}, 'd68b433f': {'text': 'A generator is a function in python that returns an iterator using the yield keyword.\\nA generator is a special type of iterable, similar to a list or a tuple, but with a crucial difference. Instead of creating and storing all the values in memory at once, a generator generates values on-the-fly as you iterate over it. This makes generators memory-efficient, particularly when dealing with large datasets.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Python - Generators in python', 'course': 'data-engineering-zoomcamp', 'id': 'd68b433f'}, 'e265ee5a': {'text': 'The read_parquet function supports a list of files as an argument. The list of files will be merged into a single result table.', 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Python - Easiest way to read multiple files at the same time?', 'course': 'data-engineering-zoomcamp', 'id': 'e265ee5a'}, '0e7dfddc': {'text': \"Incorrect:\\ndf['DOlocationID'] = pd.to_numeric(df['DOlocationID'], downcast=integer) or\\ndf['DOlocationID'] = df['DOlocationID'].astype(int)\\nCorrect:\\ndf['DOlocationID'] = df['DOlocationID'].astype('Int64')\", 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': \"Python - These won't work. You need to make sure you use Int64:\", 'course': 'data-engineering-zoomcamp', 'id': '0e7dfddc'}, '0a059700': {'text': \"ValueError: Path /Users/kt/.prefect/storage/44ccce0813ed4f24ab2d3783de7a9c3a does not exist.\\nRemove ```cache_key_fn=task_input_hash ``` as it’s in argument in your function & run your flow again.\\nNote: catche key is beneficial if you happen to run the code multiple times, it won't repeat the process which you have finished running in the previous run.  That means, if you have this ```cache_key``` in your initial run, this might cause the error.\", 'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", 'question': 'Prefect - Error on Running Prefect Flow to Load data to GCS', 'course': 'data-engineering-zoomcamp', 'id': '0a059700'}, 'feca7402': {'text': '@task\\ndef download_file(url: str, file_path: str):\\nresponse = requests.get(url)\\nopen(file_path, \"wb\").write(response.content)\\nreturn file_path\\n@flow\\ndef extract_from_web() -> None:\\nfile_path = download_file(url=f\\'{url-filename}.csv.gz\\',file_path=f\\'{filename}.csv.gz\\')', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Prefect - Tip: Downloading csv.gz from a url in a prefect environment (sample snippet).', 'course': 'data-engineering-zoomcamp', 'id': 'feca7402'}, '1f519b1a': {'text': 'Update the seed column types in the dbt_project.yaml file\\nfor using double : float\\nfor using int : numeric\\nDBT Cloud production error: prod dataset not available in location EU\\nProblem: I am trying to deploy my DBT  models to production, using DBT Cloud. The data should live in BigQuery.  The dataset location is EU.  However, when I am running the model in production, a prod dataset is being create in BigQuery with a location US and the dbt invoke build is failing giving me \"ERROR 404: porject.dataset:prod not available in location EU\". I tried different ways to fix this. I am not sure if there is a more simple solution then creating my project or buckets in location US. Hope anyone can help here.\\nNote: Everything is working fine in development mode, the issue is just happening when scheduling and running job in production\\nSolution: I created the prod dataset manually in BQ and specified EU, then I ran the job.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'If you are getting not found in location us error.', 'course': 'data-engineering-zoomcamp', 'id': '1f519b1a'}, '43c454c7': {'text': 'Error: This project does not have a development environment configured. Please create a development environment and configure your development credentials to use the dbt IDE.\\nThe error itself tells us how to solve this issue, the guide is here. And from videos @1:42 and also slack chat', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Setup - No development environment', 'course': 'data-engineering-zoomcamp', 'id': '43c454c7'}, 'd7ad69da': {'text': \"Runtime Error\\ndbt was unable to connect to the specified database.\\nThe database returned the following error:\\n>Database Error\\nAccess Denied: Project <project_name>: User does not have bigquery.jobs.create permission in project <project_name>.\\nCheck your database credentials and try again. For more information, visit:\\nhttps://docs.getdbt.com/docs/configure-your-profile\\nSteps to resolve error in Google Cloud:\\n1. Navigate to IAM & Admin and select IAM\\n2. Click Grant Access if your newly created dbt service account isn't listed\\n3. In New principals field, add your service account\\n4. Select a Role and search for BigQuery Job User to add\\n5. Go back to dbt cloud project setup and Test your connection\\n6. Note: Also add BigQuery Data Owner, Storage Object Admin, & Storage Admin to prevent permission issues later in the course\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Setup - Connecting dbt Cloud with BigQuery Error', 'course': 'data-engineering-zoomcamp', 'id': 'd7ad69da'}, '03fdb780': {'text': 'error: This dbt Cloud run was cancelled because a valid dbt project was not found. Please check that the repository contains a proper dbt_project.yml config file. If your dbt project is located in a subdirectory of the connected repository, be sure to specify its location on the Project settings page in dbt Cloud', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Dbt build error', 'course': 'data-engineering-zoomcamp', 'id': '03fdb780'}, '9c85f3aa': {'text': \"Error: Failed to clone repository.\\ngit clone git@github.com:DataTalksClub/data-engineering-zoomcamp.git /usr/src/develop/…\\nCloning into '/usr/src/develop/...\\nWarning: Permanently added 'github.com,140.82.114.4' (ECDSA) to the list of known hosts.\\ngit@github.com: Permission denied (publickey).\\nfatal: Could not read from remote repository.\\nIssue: You don’t have permissions to write to DataTalksClub/data-engineering-zoomcamp.git\\nSolution 1: Clone the repository and use this forked repo, which contains your github username. Then, proceed to specify the path, as in:\\n[your github username]/data-engineering-zoomcamp.git\\nSolution 2: create a fresh repo for dbt-lessons. We’d need to do branching and PRs in this lesson, so it might be a good idea to also not mess up your whole other repo. Then you don’t have to create a subfolder for the dbt project files\\nSolution 3: Use https link\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Setup - Failed to clone repository.', 'course': 'data-engineering-zoomcamp', 'id': '9c85f3aa'}, '63026349': {'text': \"Solution:\\nCheck if you’re on the Developer Plan. As per the prerequisites, you'll need to be enrolled in the Team Plan or Enterprise Plan to set up a CI Job in dbt Cloud.\\nSo If you're on the Developer Plan, you'll need to upgrade to utilise CI Jobs.\\nNote from another user: I’m in the Team Plan (trial period) but the option is still disabled. What worked for me instead was this. It works for the Developer (free) plan.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'dbt job - Triggered by pull requests is disabled when I try to create a new Continuous Integration job in dbt cloud.', 'course': 'data-engineering-zoomcamp', 'id': '63026349'}, '6ba02f77': {'text': 'Issue: If the DBT cloud IDE loading indefinitely then giving you this error\\nSolution: check the dbt_cloud_setup.md  file and make a SSH Key and use gitclone to import repo into dbt project, copy and paste deploy key back in your repo setting.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Setup - Your IDE session was unable to start. Please contact support.', 'course': 'data-engineering-zoomcamp', 'id': '6ba02f77'}, '8b14286c': {'text': 'Issue: If you don’t define the column format while converting from csv to parquet Python will “choose” based on the first rows.\\n✅Solution: Defined the schema while running web_to_gcp.py pipeline.\\nSebastian adapted the script:\\nhttps://github.com/sebastian2296/data-engineering-zoomcamp/blob/main/week_4_analytics_engineering/web_to_gcs.py\\nNeed a quick change to make the file work with gz files, added the following lines (and don’t forget to delete the file at the end of each iteration of the loop to avoid any problem of disk space)\\nfile_name_gz = f\"{service}_tripdata_{year}-{month}.csv.gz\"\\nopen(file_name_gz, \\'wb\\').write(r.content)\\nos.system(f\"gzip -d {file_name_gz}\")\\nos.system(f\"rm {file_name_init}.*\")\\nSame ERROR - When running dbt run for fact_trips.sql, the task failed with error:\\n“Parquet column \\'ehail_fee\\' has type DOUBLE which does not match the target cpp_type INT64”\\n开启屏幕阅读器支持\\n要启用屏幕阅读器支持，请按Ctrl+Alt+Z。要了解键盘快捷键，请按Ctrl+斜杠。\\n查找和替换\\nReason: Parquet files have their own schema. Some parquet files for green data have records with decimals in ehail_fee column.\\nThere are some possible fixes:\\nDrop ehail_feel column since it is not really used. For instance when creating a partitioned table from the external table in BigQuery\\nSELECT * EXCEPT (ehail_fee) FROM…\\nModify stg_green_tripdata.sql model using this line cast(0 as numeric) as ehail_fee.\\nModify Airflow dag to make the conversion and avoid the error.\\npv.read_csv(src_file, convert_options=pv.ConvertOptions(column_types = {\\'ehail_fee\\': \\'float64\\'}))\\nSame type of ERROR - parquet files with different data types - Fix it with pandas\\nHere is another possibility that could be interesting:\\nYou can specify the dtypes when importing the file from csv to a dataframe with pandas\\npd.from_csv(..., dtype=type_dict)\\nOne obstacle is that the regular int64 pandas use (I think this is from the numpy library) does not accept null values (NaN, not a number). But you can use the pandas Int64 instead, notice capital ‘I’. The type_dict is a python dictionary mapping the column names to the dtypes.\\nSources:\\nhttps://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\\nNullable integer data type — pandas 1.5.3 documentation', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT - I am having problems with columns datatype while running DBT/BigQuery', 'course': 'data-engineering-zoomcamp', 'id': '8b14286c'}, '14a876ea': {'text': 'If the provided URL isn’t working for you (https://nyc-tlc.s3.amazonaws.com/trip+data/):\\nWe can use the GitHub CLI to easily download the needed trip data from https://github.com/DataTalksClub/nyc-tlc-data, and manually upload to a GCS bucket.\\nInstructions on how to download the CLI here: https://github.com/cli/cli\\nCommands to use:\\ngh auth login\\ngh release list -R DataTalksClub/nyc-tlc-data\\ngh release download yellow -R DataTalksClub/nyc-tlc-data\\ngh release download green -R DataTalksClub/nyc-tlc-data\\netc.\\nNow you can upload the files to a GCS bucket using the GUI.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Ingestion: When attempting to use the provided quick script to load trip data into GCS, you receive error Access Denied from the S3 bucket', 'course': 'data-engineering-zoomcamp', 'id': '14a876ea'}, '1cf5be74': {'text': \"R: This conversion is needed for the question 3 of homework, in order to process files for fhv data. The error is:\\npyarrow.lib.ArrowInvalid: CSV parse error: Expected 7 columns, got 1: B02765\\nCause: Some random line breaks in this particular file.\\nFixed by opening a bash in the container executing the dag and manually running the following command that deletes all \\\\n not preceded by \\\\r.\\nperl -i -pe 's/(?<!\\\\r)\\\\n/\\\\1/g' fhv_tripdata_2020-01.csv\\nAfter that, clear the failed task in Airflow to force re-execution.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Ingestion - Error thrown by format_to_parquet_task when converting fhv_tripdata_2020-01.csv using Airflow', 'course': 'data-engineering-zoomcamp', 'id': '1cf5be74'}, '315ac3cc': {'text': 'I initially followed data-engineering-zoomcamp/03-data-warehouse/extras/web_to_gcs.py at main · DataTalksClub/data-engineering-bootcamp (github.com)\\nBut it was taking forever for the yellow trip data and when I tried to download and upload the parquet files directly to GCS, that works fine but when creating the Bigquery table, there was a schema inconsistency issue\\nThen I found another hack shared in the slack which was suggested by Victoria.\\n[Optional] Hack for loading data to BigQuery for Week 4 - YouTube\\nPlease watch until the end as there is few schema changes required to be done', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Hack to load yellow and green trip data for 2019 and 2020', 'course': 'data-engineering-zoomcamp', 'id': '315ac3cc'}, 'c5c3beba': {'text': '“gs\\\\storage_link\\\\*.parquet” need to be added in destination folder', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Move many files (more than one) from Google cloud storage bucket to Big query', 'course': 'data-engineering-zoomcamp', 'id': 'c5c3beba'}, 'f19be91b': {'text': 'One common cause experienced is lack of space after running prefect several times. When running prefect, check the folder ‘.prefect/storage’ and delete the logs now and then to avoid the problem.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'GCP VM - All of sudden ssh stopped working for my VM after my last restart', 'course': 'data-engineering-zoomcamp', 'id': 'f19be91b'}, '33db7dc7': {'text': 'You can try to do this steps:', 'section': 'Module 4: analytics engineering with dbt', 'question': 'GCP VM - If you have lost SSH access to your machine due to lack of space. Permission denied (publickey)', 'course': 'data-engineering-zoomcamp', 'id': '33db7dc7'}, '67ef8f87': {'text': 'R: Go to BigQuery, and check the location of BOTH\\nThe source dataset (trips_data_all), and\\nThe schema you’re trying to write to (name should be \\tdbt_<first initial><last name> (if you didn’t change the default settings at the end when setting up your project))\\nLikely, your source data will be in your region, but the write location will be a multi-regional location (US in this example). Delete these datasets, and recreate them with your specified region and the correct naming format.\\nAlternatively, instead of removing datasets, you can specify the single-region location you are using. E.g. instead of ‘location: US’, specify the region, so ‘location: US-east1’. See this Github comment for more detail. Additionally please see this post of Sandy\\nIn DBT cloud you can actually specify the location using the following steps:\\nGPo to your profile page (top right drop-down --> profile)\\nThen go to under Credentials --> Analytics (you may have customised this name)\\nClick on Bigquery >\\nHit Edit\\nUpdate your location, you may need to re-upload your service account JSON to re-fetch your private key, and save. (NOTE: be sure to exactly copy the region BigQuery specifies your dataset is in.)', 'section': 'Module 4: analytics engineering with dbt', 'question': '404 Not found: Dataset eighth-zenith-372015:trip_data_all was not found in location us-west1', 'course': 'data-engineering-zoomcamp', 'id': '67ef8f87'}, '6acf2e77': {'text': 'Error: `dbt_utils.surrogate_key` has been replaced by `dbt_utils.generate_surrogate_key`\\nFix:\\nReplace dbt_utils.surrogate_key  with dbt_utils.generate_surrogate_key in stg_green_tripdata.sql\\nWhen executing dbt run after fact_trips.sql has been created, the task failed with error:\\nR: “Access Denied: BigQuery BigQuery: Permission denied while globbing file pattern.”\\n1. Fixed by adding the Storage Object Viewer role to the service account in use in BigQuery.\\n2. Add the related roles to the service account in use in GCS.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'When executing dbt run after installing dbt-utils latest version i.e., 1.0.0 warning has generated', 'course': 'data-engineering-zoomcamp', 'id': '6acf2e77'}, '18430f10': {'text': 'You need to create packages.yml file in main project directory and add packages’ meta data:\\npackages:\\n- package: dbt-labs/dbt_utils\\nversion: 0.8.0\\nAfter creating file run:\\nAnd hit enter.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'When You are getting error dbt_utils not found', 'course': 'data-engineering-zoomcamp', 'id': '18430f10'}, 'afb7a40a': {'text': \"Ensure you properly format your yml file. Check the build logs if the run was completed successfully. You can expand the command history console (where you type the --vars '{'is_test_run': 'false'}')  and click on any stage’s logs to expand and read errors messages or warnings.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Lineage is currently unavailable. Check that your project does not contain compilation errors or contact support if this error persists.', 'course': 'data-engineering-zoomcamp', 'id': 'afb7a40a'}, 'd6a5b80e': {'text': \"Make sure you use:\\ndbt run --var ‘is_test_run: false’ or\\ndbt build --var ‘is_test_run: false’\\n(watch out for formatted text from this document: re-type the single quotes). If that does not work, use --vars '{'is_test_run': 'false'}' with each phrase separately quoted.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Build - Why do my Fact_trips only contain a few days of data?', 'course': 'data-engineering-zoomcamp', 'id': 'd6a5b80e'}, 'de426d2f': {'text': 'Check if you specified if_exists argument correctly when writing data from GCS to BigQuery. When I wrote my automated flow for each month of the years 2019 and 2020 for green and yellow data I had specified if_exists=\"replace\" while I was experimenting with the flow setup. Once you want to run the flow for all months in 2019 and 2020 make sure to set if_exists=\"append\"\\nif_exists=\"replace\" will replace the whole table with only the month data that you are writing into BigQuery in that one iteration -> you end up with only one month in BigQuery (the last one you inserted)\\nif_exists=\"append\" will append the new monthly data -> you end up with data from all months', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Build - Why do my fact_trips only contain one month of data?', 'course': 'data-engineering-zoomcamp', 'id': 'de426d2f'}, '354f0e10': {'text': \"R: After the second SELECT, change this line:\\ndate_trunc('month', pickup_datetime) as revenue_month,\\nTo this line:\\ndate_trunc(pickup_datetime, month) as revenue_month,\\nMake sure that “month” isn’t surrounded by quotes!\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'BigQuery returns an error when I try to run the dm_monthly_zone_revenue.sql model.', 'course': 'data-engineering-zoomcamp', 'id': '354f0e10'}, '98fae8d0': {'text': 'For this instead:\\n{{ dbt_utils.generate_surrogate_key([ \\n     field_a, \\n     field_b, \\n     field_c,\\n     …,\\n     field_z\\n]) }}', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Replace: \\n{{ dbt_utils.surrogate_key([ \\n     field_a, \\n     field_b, \\n     field_c,\\n     …,\\n     field_z     \\n]) }}', 'course': 'data-engineering-zoomcamp', 'id': '98fae8d0'}, 'cb678fde': {'text': 'Remove the dataset from BigQuery which was created by dbt and run dbt run again so that it will recreate the dataset in BigQuery with the correct location', 'section': 'Module 4: analytics engineering with dbt', 'question': 'I changed location in dbt, but dbt run still gives me an error', 'course': 'data-engineering-zoomcamp', 'id': 'cb678fde'}, '39bfb043': {'text': 'Remove the dataset from BigQuery created by dbt and run again (with test disabled) to ensure the dataset created has all the rows.\\nDBT - Why am I getting a new dataset after running my CI/CD Job? / What is this new dbt dataset in BigQuery?\\nAnswer: when you create the CI/CD job, under ‘Compare Changes against an environment (Deferral) make sure that you select ‘ No; do not defer to another environment’ - otherwise dbt won’t merge your dev models into production models; it will create a new environment called ‘dbt_cloud_pr_number of pull request’', 'section': 'Module 4: analytics engineering with dbt', 'question': 'I ran dbt run without specifying variable which gave me a table of 100 rows. I ran again with the variable value specified but my table still has 100 rows in BQ.', 'course': 'data-engineering-zoomcamp', 'id': '39bfb043'}, '351a078a': {'text': \"Vic created three different datasets in the videos.. dbt_<name> was used for development and you used a production dataset for the production environment. What was the use for the staging dataset?\\nR: Staging, as the name suggests, is like an intermediate between the raw datasets and the fact and dim tables, which are the finished product, so to speak. You'll notice that the datasets in staging are materialised as views and not tables.\\nVic didn't use it for the project, you just need to create production and dbt_name + trips_data_all that you had already.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Why do we need the Staging dataset?', 'course': 'data-engineering-zoomcamp', 'id': '351a078a'}, '61da1919': {'text': 'Try removing the “network: host” line in docker-compose.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT Docs Served but Not Accessible via Browser', 'course': 'data-engineering-zoomcamp', 'id': '61da1919'}, '6528c6ae': {'text': 'Go to Account settings >> Project >> Analytics >> Click on your connection >> go all the way down to Location and type in the GCP location just as displayed in GCP (e.g. europe-west6). You might need to reupload your GCP key.\\nDelete your dataset in GBQ\\nRebuild project: dbt build\\nNewly built dataset should be in the correct location', 'section': 'Module 4: analytics engineering with dbt', 'question': 'BigQuery adapter: 404 Not found: Dataset was not found in location europe-west6', 'course': 'data-engineering-zoomcamp', 'id': '6528c6ae'}, 'c0d3a2e8': {'text': 'Create a new branch to edit. More on this can be found here in the dbt docs.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Dbt+git - Main branch is “read-only”', 'course': 'data-engineering-zoomcamp', 'id': 'c0d3a2e8'}, '859a97c5': {'text': 'Create a new branch for development, then you can merge it to the main branch\\nCreate a new branch and switch to this branch. It allows you to make changes. Then you can commit and push the changes to the “main” branch.', 'section': 'Module 4: analytics engineering with dbt', 'question': \"Dbt+git - It appears that I can't edit the files because I'm in read-only mode. Does anyone know how I can change that?\", 'course': 'data-engineering-zoomcamp', 'id': '859a97c5'}, '32469a2d': {'text': \"Error:\\nTriggered by pull requests\\nThis feature is only available for dbt repositories connected through dbt Cloud's native integration with Github, Gitlab, or Azure DevOps\\nSolution: Contrary to the guide on DTC repo, don’t use the Git Clone option. Use the Github one instead. Step-by-step guide to UN-LINK Git Clone and RE-LINK with Github in the next entry below\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Dbt deploy + Git CI - cannot create CI checks job for deployment to Production. See more discussion in slack chat', 'course': 'data-engineering-zoomcamp', 'id': '32469a2d'}, 'c599b3a0': {'text': 'If you’re trying to configure CI with Github and on the job’s options you can’t see Run on Pull Requests? on triggers, you have to reconnect with Github using native connection instead clone by SSH. Follow these steps:\\nOn Profile Settings > Linked Accounts connect your Github account with dbt project allowing the permissions asked. More info at https://docs.getdbt.com/docs/collaborate/git/connect-gith\\nDisconnect your current Github’s configuration from Account Settings > Projects (analytics) > Github connection. At the bottom left appears the button Disconnect, press it.\\nOnce we have confirmed the change, we can configure it again. This time, choose Github and it will appear in all repositories which you have allowed to work with dbt. Select your repository and it’s ready.\\nGo to the Deploy > job configuration’s page and go down until Triggers and now you can see the option Run on Pull Requests:', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Dbt deploy + Git CI - Unable to configure Continuous Integration (CI) with Github', 'course': 'data-engineering-zoomcamp', 'id': 'c599b3a0'}, '179df18d': {'text': \"If you're following video DE Zoomcamp 4.3.1 - Building the First DBT Models, you may have encountered an issue at 14:25 where the Lineage graph isn't displayed and a Compilation Error occurs, as shown in the attached image. Don't worry - a quick fix for this is to simply save your schema.yml file. Once you've done this, you should be able to view your Lineage graph without any further issues.\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"Compilation Error (Model 'model.my_new_project.stg_green_tripdata' (models/staging/stg_green_tripdata.sql) depends on a source named 'staging.green_trip_external' which was not found)\", 'course': 'data-engineering-zoomcamp', 'id': '179df18d'}, '1ce1a275': {'text': '> in macro test_accepted_values (tests/generic/builtin.sql)\\n> called by test accepted_values_stg_green_tripdata_Payment_type__False___var_payment_type_values_ (models/staging/schema.yml)\\nRemember that you have to add to dbt_project.yml the vars:\\nvars:\\npayment_type_values: [1, 2, 3, 4, 5, 6]', 'section': 'Module 4: analytics engineering with dbt', 'question': \"'NoneType' object is not iterable\", 'course': 'data-engineering-zoomcamp', 'id': '1ce1a275'}, 'b529b0bc': {'text': \"You will face this issue if you copied and pasted the exact macro directly from data-engineering-zoomcamp repo.\\nBigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('No matching signature for operator CASE for argument types: STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, NULL at [35:5]; reason: invalidQuery, location: query, message: No matching signature for operator CASE for argument types: STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, NULL at [35:5]')\\nWhat you’d have to do is to change the data type of the numbers (1, 2, 3 etc.) to text by inserting ‘’, as the initial ‘payment_type’ data type should be string (Note: I extracted and loaded the green trips data using Google BQ Marketplace)\\n{#\\nThis macro returns the description of the payment_type\\n#}\\n{% macro get_payment_type_description(payment_type) -%}\\ncase {{ payment_type }}\\nwhen '1' then 'Credit card'\\nwhen '2' then 'Cash'\\nwhen '3' then 'No charge'\\nwhen '4' then 'Dispute'\\nwhen '5' then 'Unknown'\\nwhen '6' then 'Voided trip'\\nend\\n{%- endmacro %}\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'dbt macro errors with get_payment_type_description(payment_type)', 'course': 'data-engineering-zoomcamp', 'id': 'b529b0bc'}, '2e51a111': {'text': 'The dbt error  log contains a link to BigQuery. When you follow it you will see your query and the problematic line will be highlighted.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Troubleshooting in dbt:', 'course': 'data-engineering-zoomcamp', 'id': '2e51a111'}, '6e1a0834': {'text': 'It is a default behaviour of dbt to append custom schema to initial schema. To override this behaviour simply create a macro named “generate_schema_name.sql”:\\n{% macro generate_schema_name(custom_schema_name, node) -%}\\n{%- set default_schema = target.schema -%}\\n{%- if custom_schema_name is none -%}\\n{{ default_schema }}\\n{%- else -%}\\n{{ custom_schema_name | trim }}\\n{%- endif -%}\\n{%- endmacro %}\\nNow you can override default custom schema in “dbt_project.yml”:', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Why changing the target schema to “marts” actually creates a schema named “dbt_marts” instead?', 'course': 'data-engineering-zoomcamp', 'id': '6e1a0834'}, 'a8657e65': {'text': 'There is a project setting which allows you to set `Project subdirectory` in dbt cloud:', 'section': 'Module 4: analytics engineering with dbt', 'question': 'How to set subdirectory of the github repository as the dbt project root', 'course': 'data-engineering-zoomcamp', 'id': 'a8657e65'}, '2678d8c2': {'text': \"Remember that you should modify accordingly your .sql models, to read from existing table names in BigQuery/postgres db\\nExample: select * from {{ source('staging',<your table name in the database>') }}\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"Compilation Error : Model 'model.XXX' (models/<model_path>/XXX.sql) depends on a source named '<a table name>' which was not found\", 'course': 'data-engineering-zoomcamp', 'id': '2678d8c2'}, 'aa85c6ae': {'text': 'Make sure that you create a pull request from your Development branch to the Production branch (main by default). After that, check in your ‘seeds’ folder if the seed file is inside it.\\nAnother thing to check is your .gitignore file. Make sure that the .csv extension is not included.', 'section': 'Module 4: analytics engineering with dbt', 'question': \"Compilation Error : Model '<model_name>' (<model_path>) depends on a node named '<seed_name>' which was not found   (Production Environment)\", 'course': 'data-engineering-zoomcamp', 'id': 'aa85c6ae'}, 'de06929d': {'text': '1. Go to your dbt cloud service account\\n1. Adding the  [Storage Object Admin,Storage Admin] role in addition tco BigQuery Admin.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'When executing dbt run after using fhv_tripdata as an external table: you get “Access Denied: BigQuery BigQuery: Permission denied”', 'course': 'data-engineering-zoomcamp', 'id': 'de06929d'}, 'b087fa95': {'text': 'Problem: when injecting data to bigquery, you may face the type error. This is because pandas by default will parse integer columns with missing value as float type.\\nSolution:\\nOne way to solve this problem is to specify/ cast data type Int64 during the data transformation stage.\\nHowever, you may be lazy to type all the int columns. If that is the case, you can simply use convert_dtypes to infer the data type\\n# Make pandas to infer correct data type (as pandas parse int with missing as float)\\ndf.fillna(-999999, inplace=True)\\ndf = df.convert_dtypes()\\ndf = df.replace(-999999, None)', 'section': 'Module 4: analytics engineering with dbt', 'question': 'How to automatically infer the column data type (pandas missing value issues)?', 'course': 'data-engineering-zoomcamp', 'id': 'b087fa95'}, '3c41892d': {'text': 'Seed files loaded from directory with name ‘seed’, that’s why you should rename dir with name ‘data’ to ‘seed’', 'section': 'Module 4: analytics engineering with dbt', 'question': 'When loading github repo raise exception that ‘taxi_zone_lookup’ not found', 'course': 'data-engineering-zoomcamp', 'id': '3c41892d'}, '4842f3e8': {'text': 'Check the .gitignore file and make sure you don’t have *.csv in it\\n\\nDbt error 404 was not found in location\\nMy specific error:\\nRuntime Error in rpc request (from remote system.sql) 404 Not found: Table dtc-de-0315:trips_data_all.green_tripdata_partitioned was not found in location europe-west6 Location: europe-west6 Job ID: 168ee9bd-07cd-4ca4-9ee0-4f6b0f33897c\\nMake sure all of your datasets have the correct region and not a generalised region:\\nEurope-west6 as opposed to EU\\n\\nMatch this in dbt settings:\\ndbt -> projects -> optional settings -> manually set location to match', 'section': 'Module 4: analytics engineering with dbt', 'question': '‘taxi_zone_lookup’ not found', 'course': 'data-engineering-zoomcamp', 'id': '4842f3e8'}, '5eaf61fe': {'text': \"The easiest way to avoid these errors is by ingesting the relevant data in a .csv.gz file type. Then, do:\\nCREATE OR REPLACE EXTERNAL TABLE `dtc-de.trips_data_all.fhv_tripdata`\\nOPTIONS (\\nformat = 'CSV',\\nuris = ['gs://dtc_data_lake_dtc-de-updated/data/fhv_all/fhv_tripdata_2019-*.csv.gz']\\n);\\nAs an example. You should no longer have any data type issues for week 4.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Data type errors when ingesting with parquet files', 'course': 'data-engineering-zoomcamp', 'id': '5eaf61fe'}, '8ed36cea': {'text': 'This is due to the way the deduplication is done in the two staging files.\\nSolution: add order by in the partition by part of both staging files. Keep adding columns to order by until the number of rows in the fact_trips table is consistent when re-running the fact_trips model.\\nExplanation (a bit convoluted, feel free to clarify, correct etc.)\\nWe partition by vendor id and pickup_datetime and choose the first row (rn=1) from all these partitions. These partitions are not ordered, so every time we run this, the first row might be a different one. Since the first row is different between runs, it might or might not contain an unknown borough. Then, in the fact_trips model we will discard a different number of rows when we discard all values with an unknown borough.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Inconsistent number of rows when re-running fact_trips model', 'course': 'data-engineering-zoomcamp', 'id': '8ed36cea'}, '46aebc79': {'text': 'If you encounter data type error on trip_type column, it may due to some nan values that isn’t null in bigquery.\\nSolution: try casting it to FLOAT datatype instead of NUMERIC', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Data Type Error when running fact table', 'course': 'data-engineering-zoomcamp', 'id': '46aebc79'}, 'e2d2bc58': {'text': \"This error could result if you are using some select * query without mentioning the name of table for ex:\\nwith dim_zones as (\\nselect * from `engaged-cosine-374921`.`dbt_victoria_mola`.`dim_zones`\\nwhere borough != 'Unknown'\\n),\\nfhv as (\\nselect * from `engaged-cosine-374921`.`dbt_victoria_mola`.`stg_fhv_tripdata`\\n)\\nselect * from fhv\\ninner join dim_zones as pickup_zone\\non fhv.PUlocationID = pickup_zone.locationid\\ninner join dim_zones as dropoff_zone\\non fhv.DOlocationID = dropoff_zone.locationid\\n);\\nTo resolve just replace use : select fhv.* from fhv\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'CREATE TABLE has columns with duplicate name locationid.', 'course': 'data-engineering-zoomcamp', 'id': 'e2d2bc58'}, '137aab88': {'text': 'Some ehail fees are null and casting them to integer gives Bad int64 value: 0.0 error,\\nSolution:\\nUsing safe_cast returns NULL instead of throwing an error. So use safe_cast from dbt_utils function in the jinja code for casting into integer as follows:\\n{{ dbt_utils.safe_cast(\\'ehail_fee\\',  api.Column.translate_type(\"integer\"))}} as ehail_fee,\\nCan also just use safe_cast(ehail_fee as integer) without relying on dbt_utils.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Bad int64 value: 0.0 error', 'course': 'data-engineering-zoomcamp', 'id': '137aab88'}, 'a260e651': {'text': \"You might encounter this when building the fact_trips.sql model. The issue may be with the payment_type_description field.\\nUsing safe_cast as above, would cause the entire field to become null. A better approach is to drop the offending decimal place, then cast to integer.\\ncast(replace({{ payment_type }},'.0','') as integer)\\nBad int64 value: 1.0 error (again)\\n\\nI found that there are more columns causing the bad INT64: ratecodeid and trip_type on Green_tripdata table.\\nYou can use the queries below to address them:\\nCAST(\\nREGEXP_REPLACE(CAST(rate_code AS STRING), r'\\\\.0', '') AS INT64\\n) AS ratecodeid,\\nCAST(\\nCASE\\nWHEN REGEXP_CONTAINS(CAST(trip_type AS STRING), r'\\\\.\\\\d+') THEN NULL\\nELSE CAST(trip_type AS INT64)\\nEND AS INT64\\n) AS trip_type,\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Bad int64 value: 2.0/1.0 error', 'course': 'data-engineering-zoomcamp', 'id': 'a260e651'}, 'da8d9fcc': {'text': 'The two solution above don’t work for me - I used the line below in `stg_green_trips.sql` to replace the original ehail_fee line:\\n`{{ dbt.safe_cast(\\'ehail_fee\\',  api.Column.translate_type(\"numeric\"))}} as ehail_fee,`', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT - Error on building fact_trips.sql: Parquet column \\'ehail_fee\\' has type DOUBLE which does not match the target cpp_type INT64. File: gs://<gcs bucket>/<table>/green_taxi_2019-01.parquet\")', 'course': 'data-engineering-zoomcamp', 'id': 'da8d9fcc'}, '2314e3c4': {'text': \"Remember to add a space between the variable and the value. Otherwise, it won't be interpreted as a dictionary.\\nIt should be:\\ndbt run --var 'is_test_run: false'\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'The - vars argument must be a YAML dictionary, but was of type str', 'course': 'data-engineering-zoomcamp', 'id': '2314e3c4'}, 'e7bdbba6': {'text': \"You don't need to change the environment type. If you are following the videos, you are creating a Production Deployment, so the only available option is the correct one.'\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Not able to change Environment Type as it is greyed out and inaccessible', 'course': 'data-engineering-zoomcamp', 'id': 'e7bdbba6'}, '52cccade': {'text': 'Database Error in model stg_yellow_tripdata (models/staging/stg_yellow_tripdata.sql)\\nAccess Denied: Table taxi-rides-ny-339813-412521:trips_data_all.yellow_tripdata: User does not have permission to query table taxi-rides-ny-339813-412521:trips_data_all.yellow_tripdata, or perhaps it does not exist in location US.\\ncompiled Code at target/run/taxi_rides_ny/models/staging/stg_yellow_tripdata.sql\\nIn my case, I was set up in a different branch, so always check the branch you are working on. Change the 04-analytics-engineering/taxi_rides_ny/models/staging/schema.yml file in the\\nsources:\\n- name: staging\\ndatabase: your_database_name\\nIf this error will continue when running dbt job, As for changing the branch for your job, you can use the ‘Custom Branch’ settings in your dbt Cloud environment. This allows you to run your job on a different branch than the default one (usually main). To do this, you need to:\\nGo to an environment and select Settings to edit it\\nSelect Only run on a custom branch in General settings\\nEnter the name of your custom branch (e.g. HW)\\nClick Save\\nCould not parse the dbt project. please check that the repository contains a valid dbt project\\nRunning the Environment on the master branch causes this error, you must activate “Only run on a custom branch” checkbox and specify the branch you are  working when Environment is setup.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Access Denied: Table taxi-rides-ny-339813-412521:trips_data_all.yellow_tripdata: User does not have permission to query table taxi-rides-ny-339813-412521:trips_data_all.yellow_tripdata, or perhaps it does not exist in location US.', 'course': 'data-engineering-zoomcamp', 'id': '52cccade'}, '11a814ea': {'text': 'Change to main branch, make a pull request from the development branch.\\nNote: this will take you to github.\\nApprove the merging and rerun you job, it would work as planned now', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Made change to your modelling files and commit the your development branch, but Job still runs on old file?', 'course': 'data-engineering-zoomcamp', 'id': '11a814ea'}, '0d1e02d5': {'text': 'Before you can develop some data model on dbt, you should create development environment and set some parameter on it. After the model being developed, we should also create deployment environment to create and run some jobs.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Setup - I’ve set Github and Bigquery to dbt successfully. Why nothing showed in my Develop tab?', 'course': 'data-engineering-zoomcamp', 'id': '0d1e02d5'}, '0a0cc4c3': {'text': 'Error Message:\\nInvestigate Sentry error: ProtocolError \"Invalid input ConnectionInputs.SEND_HEADERS in state ConnectionState.CLOSED\"\\nSolution:\\nreference\\nRun it again because it happens sometimes. Or wait a few minutes, it will continue.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Prefect Agent retrieving runs from queue sometimes fails with httpx.LocalProtocolError', 'course': 'data-engineering-zoomcamp', 'id': '0a0cc4c3'}, 'cb912983': {'text': \"My taxi data was loaded into gcs with etl_web_to_gcs.py script that converts csv data into parquet. Then I placed raw data trips into external tables and when I executed dbt run I got an error message: Parquet column 'passenger_count' has type INT64 which does not match the target cpp_type DOUBLE. It is because several columns in files have different formats of data.\\nWhen I added df[col] = df[col].astype('Int64') transformation to the columns: passenger_count, payment_type, RatecodeID, VendorID, trip_type it went ok. Several people also faced this error and more about it you can read on the slack channel.\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'BigQuery returns an error when i try to run ‘dbt run’:', 'course': 'data-engineering-zoomcamp', 'id': 'cb912983'}, '2d4e434f': {'text': 'Use the syntax below instead if the code in the tutorial is not working.\\ndbt run --select stg_green_tripdata --vars \\'{\"is_test_run\": false}\\'', 'section': 'Module 4: analytics engineering with dbt', 'question': \"Running dbt run --models stg_green_tripdata --var 'is_test_run: false' is not returning anything:\", 'course': 'data-engineering-zoomcamp', 'id': '2d4e434f'}, 'bb6655b9': {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', 'id': 'bb6655b9'}, 'fc2eb036': {'text': \"If you have problems editing dbt_project.yml when using Docker after ‘docker-compose run dbt-bq-dtc init’, to change profile ‘taxi_rides_ny’ to 'bq-dbt-workshop’, just run:\\nsudo chown -R username path\\nDBT - Internal Error: Profile should not be None if loading is completed\\nWhen  running dbt debug, change the directory to the newly created subdirectory (e.g: the newly created `taxi_rides_ny` directory, which contains the dbt project).\", 'section': 'Module 4: analytics engineering with dbt', 'question': '\\u200b\\u200bVS Code: NoPermissions (FileSystemError): Error: EACCES: permission denied (linux)', 'course': 'data-engineering-zoomcamp', 'id': 'fc2eb036'}, '25daead9': {'text': 'When running a query on BigQuery sometimes could appear a this table is not on the specified location error.\\nFor this problem there is not a straightforward solution, you need to dig a little, but the problem could be one of these:\\nCheck the locations of your bucket, datasets and tables. Make sure they are all on the same one.\\nChange the query settings to the location you are in: on the query window select more -> query settings -> select the location\\nCheck if all the paths you are using in your query to your tables are correct: you can click on the table -> details -> and copy the path.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Google Cloud BigQuery Location Problems', 'course': 'data-engineering-zoomcamp', 'id': '25daead9'}, '2221d75e': {'text': 'This happens because we have moved the dbt project to another directory on our repo.\\nOr might be that you’re on a different branch than is expected to be merged from / to.\\nSolution:\\nGo to the projects window on dbt cloud -> settings -> edit -> and add directory (the extra path to the dbt project)\\nFor example:\\n/week5/taxi_rides_ny\\nMake sure your file explorer path and this Project settings path matches and there’s no files waiting to be committed to github if you’re running the job to deploy to PROD.\\nAnd that you had setup the PROD environment to check in the main branch, or whichever you specified.\\nIn the picture below, I had set it to ella2024 to be checked as “production-ready” by the “freshness” check mark at the PROD environment settings. So each time I merge a branch from something else into ella2024 and then trigger the PR, the CI check job would kick-in. But we still do need to Merge and close the PR manually, I believe, that part is not automated.\\nYou set up the PROD custom branch (if not default main) in the Environment setup screen.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT Deploy - This dbt Cloud run was cancelled because a valid dbt project was not found.', 'course': 'data-engineering-zoomcamp', 'id': '2221d75e'}, '94524a9d': {'text': 'When you are creating the pull request and running the CI, dbt is creating a new schema on BIgQuery. By default that new schema will be created on ‘US’ location, if you have your dataset, schemas and tables on ‘EU’ that will generate an error and the pull request will not be accepted. To change that location to ‘EU’ on the connection to BigQuery from dbt we need to add the location ‘EU’ on the connection optional settings:\\nDbt -> project -> settings -> connection BIgQuery -> OPtional Settings -> Location -> EU', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT Deploy + CI - Location Problems on BigQuery', 'course': 'data-engineering-zoomcamp', 'id': '94524a9d'}, '1f1ecbb7': {'text': 'When running trying to run the dbt project on prod there is some things you need to do and check on your own:\\nFirst Make the pull request and Merge the branch into the main.\\nMake sure you have the latest version, if you made changes to the repo in another place.\\nCheck if the dbt_project.yml file is accessible to the project, if not check this solution (Dbt: This dbt Cloud run was cancelled because a valid dbt project was not found.).\\nCheck if the name you gave to the dataset on BigQuery is the same you put on the dataset spot on the production environment created on dbt cloud.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT Deploy - Error When trying to run the dbt project on Prod', 'course': 'data-engineering-zoomcamp', 'id': '1f1ecbb7'}, 'c5af32ab': {'text': 'In the step in this video (DE Zoomcamp 4.3.1 - Build the First dbt Models), after creating `stg_green_tripdata.sql` and clicking `build`, I encountered an error saying dataset not found in location EU. The default location for dbt Bigquery is the US, so when generating the new Bigquery schema for dbt, unless specified, the schema locates in the US.\\nSolution:\\nTurns out I forgot to specify Location to be `EU` when adding connection details.\\nDevelop -> Configure Cloud CLI -> Projects -> taxi_rides_ny -> (connection) Bigquery -> Edit -> Location (Optional) -> type `EU` -> Save', 'section': 'Module 4: analytics engineering with dbt', 'question': 'DBT - Error: “404 Not found: Dataset <dataset_name>:<dbt_schema_name> was not found in location EU” after building from stg_green_tripdata.sql', 'course': 'data-engineering-zoomcamp', 'id': 'c5af32ab'}, '1e6b7da1': {'text': 'Issue: If you’re having problems loading the FHV_20?? data from the github repo into GCS and then into BQ (input file not of type parquet), you need to do two things. First, append the URL Template link with ‘?raw=true’ like so:\\nURL_TEMPLATE = URL_PREFIX + \"/fhv_tripdata_{{ execution_date.strftime(\\\\\\'%Y-%m\\\\\\') }}.parquet?raw=true\"\\nSecond, update make sure the URL_PREFIX is set to the following value:\\n\\nURL_PREFIX = \"https://github.com/alexeygrigorev/datasets/blob/master/nyc-tlc/fhv\"\\nIt is critical that you use this link with the keyword blob. If your link has ‘tree’ here, replace it. Everything else can stay the same, including the curl -sSLf command. ‘', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Homework - Ingesting FHV_20?? data', 'course': 'data-engineering-zoomcamp', 'id': '1e6b7da1'}, '259481c4': {'text': 'I found out that the easies way to upload datasets form github for the homework is utilising this script git_csv_to_gcs.py. Thank you Lidia!!\\nIt is similar to a script that Alexey provided us in 03-data-warehouse/extras/web_to_gcs.py', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Homework - Ingesting NYC TLC Data', 'course': 'data-engineering-zoomcamp', 'id': '259481c4'}, 'edbae698': {'text': 'If you have to securely put your credentials for a project and, probably, push it to a git repository then the best option is to use an environment variable\\nFor example for web_to_gcs.py or git_csv_to_gcs.py we have to set these variables:\\nGOOGLE_APPLICATION_CREDENTIALS\\nGCP_GCS_BUCKET\\nThe easises option to do it  is to use .env  (dotenv).\\nInstall it and add a few lines of code that inject these variables for your project\\npip install python-dotenv\\nfrom dotenv import load_dotenv\\nimport os\\n# Load environment variables from .env file\\nload_dotenv()\\n# Now you can access environment variables like GCP_GCS_BUCKET and GOOGLE_APPLICATION_CREDENTIALS\\ncredentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\\nBUCKET = os.environ.get(\"GCP_GCS_BUCKET\")', 'section': 'Module 4: analytics engineering with dbt', 'question': 'How to set environment variable easily for any credentials', 'course': 'data-engineering-zoomcamp', 'id': 'edbae698'}, '67217f4c': {'text': \"If you uploaded manually the fvh 2019 csv files, you may face errors regarding date types. Try to create an the external table in bigquery but define the pickup_datetime and dropoff_datetime to be strings\\nCREATE OR REPLACE EXTERNAL TABLE `gcp_project.trips_data_all.fhv_tripdata`  (\\ndispatching_base_num STRING,\\npickup_datetime STRING,\\ndropoff_datetime STRING,\\nPUlocationID STRING,\\nDOlocationID STRING,\\nSR_Flag STRING,\\nAffiliated_base_number STRING\\n)\\nOPTIONS (\\nformat = 'csv',\\nuris = ['gs://bucket/*.csv']\\n);\\nThen when creating the fhv core model in dbt, use TIMESTAMP(CAST(()) to ensure it first parses as a string and then convert it to timestamp.\\nwith fhv_tripdata as (\\nselect * from {{ ref('stg_fhv_tripdata') }}\\n),\\ndim_zones as (\\nselect * from {{ ref('dim_zones') }}\\nwhere borough != 'Unknown'\\n)\\nselect fhv_tripdata.dispatching_base_num,\\nTIMESTAMP(CAST(fhv_tripdata.pickup_datetime AS STRING)) AS pickup_datetime,\\nTIMESTAMP(CAST(fhv_tripdata.dropoff_datetime AS STRING)) AS dropoff_datetime,\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"Invalid date types after Ingesting FHV data through CSV files: Could not parse 'pickup_datetime' as a timestamp\", 'course': 'data-engineering-zoomcamp', 'id': '67217f4c'}, '2aadd232': {'text': \"If you uploaded manually the fvh 2019 parquet files manually after downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-*.parquet you may face errors regarding date types while loading the data in a landing table (say fhv_tripdata). Try to create an the external table with the schema defines as following and load each month in a loop.\\n-----Correct load with schema defination----will not throw error----------------------\\nCREATE OR REPLACE EXTERNAL TABLE `dw-bigquery-week-3.trips_data_all.external_tlc_fhv_trips_2019` (\\ndispatching_base_num STRING,\\npickup_datetime TIMESTAMP,\\ndropoff_datetime TIMESTAMP,\\nPUlocationID FLOAT64,\\nDOlocationID FLOAT64,\\nSR_Flag FLOAT64,\\nAffiliated_base_number STRING\\n)\\nOPTIONS (\\nformat = 'PARQUET',\\nuris = ['gs://project id/fhv_2019_8.parquet']\\n);\\nCan Also USE  uris = ['gs://project id/fhv_2019_*.parquet'] (THIS WILL remove the need for the loop and can be done for all month in single RUN )\\n– THANKYOU FOR THIS –\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'Invalid data types after Ingesting FHV data through parquet files: Could not parse SR_Flag as Float64,Couldn’t parse datetime column as timestamp,couldn’t handle NULL values in PULocationID,DOLocationID', 'course': 'data-engineering-zoomcamp', 'id': '2aadd232'}, 'adcd914a': {'text': 'When accessing Looker Studio through the Google Cloud Project console, you may be prompted to subscribe to the Pro version and receive the following errors:\\nInstead, navigate to https://lookerstudio.google.com/navigation/reporting which will take you to the free version.', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Google Looker Studio - you have used up your 30-day trial', 'course': 'data-engineering-zoomcamp', 'id': 'adcd914a'}, 'bbf094b3': {'text': 'Ans: Dbt provides a mechanism called \"ref\" to manage dependencies between models. By referencing other models using the \"ref\" keyword in SQL, dbt automatically understands the dependencies and ensures the correct execution order.\\nLoading FHV Data goes into slumber using Mage?\\nTry loading the data using jupyter notebooks in a local environment. There might be bandwidth issues with Mage.\\nLoad the data into a pandas dataframe using the urls, make necessary transformations, upload the gcp bucket / alternatively download the parquet/csv files locally and then upload to GCP manually.\\nRegion Mismatch in DBT and BigQuery\\nIf you are using the datasets copied into BigQuery from BigQuery public datasets, the region will be set as US by default and hence it is much easier to set your dbt profile location as US while transforming the tables and views. \\nYou can change the location as follows:', 'section': 'Module 4: analytics engineering with dbt', 'question': 'How does dbt handle dependencies between models?', 'course': 'data-engineering-zoomcamp', 'id': 'bbf094b3'}, '2fdc5057': {'text': \"Use the PostgreSQL COPY FROM feature that is compatible with csv files\\nCOPY table_name [ ( column_name [, ...] ) ]\\nFROM { 'filename' | PROGRAM 'command' | STDIN }\\n[ [ WITH ] ( option [, ...] ) ]\\n[ WHERE condition ]\", 'section': 'Module 4: analytics engineering with dbt', 'question': 'What is the fastest way to upload taxi data to dbt-postgres?', 'course': 'data-engineering-zoomcamp', 'id': '2fdc5057'}, '95e302f7': {'text': 'Update the line:\\nWith:', 'section': 'Module 5: pyspark', 'question': 'When configuring the profiles.yml file for dbt-postgres with jinja templates with environment variables, I\\'m getting \"Credentials in profile \"PROFILE_NAME\", target: \\'dev\\', invalid: \\'5432\\'is not of type \\'integer\\'', 'course': 'data-engineering-zoomcamp', 'id': '95e302f7'}, '1ac2c13c': {'text': 'Install SDKMAN:\\ncurl -s \"https://get.sdkman.io\" | bash\\nsource \"$HOME/.sdkman/bin/sdkman-init.sh\"\\nUsing SDKMAN, install Java 11 and Spark 3.3.2:\\nsdk install java 11.0.22-tem\\nsdk install spark 3.3.2\\nOpen a new terminal or run the following in the same shell:\\nsource \"$HOME/.sdkman/bin/sdkman-init.sh\"\\nVerify the locations and versions of Java and Spark that were installed:\\necho $JAVA_HOME\\njava -version\\necho $SPARK_HOME\\nspark-submit --version', 'section': 'Module 5: pyspark', 'question': 'Setting up Java and Spark (with PySpark) on Linux (Alternative option using SDKMAN)', 'course': 'data-engineering-zoomcamp', 'id': '1ac2c13c'}, '5cc0e4d9': {'text': 'If you’re seriously struggling to set things up \"locally\" (here locally meaning non/partly-managed environment like own laptop, a VM or Codespaces) you can use the following guide to use Spark in Google Colab:\\nhttps://medium.com/gitconnected/launch-spark-on-google-colab-and-connect-to-sparkui-342cad19b304\\nStarter notebook:\\nhttps://github.com/aaalexlit/medium_articles/blob/main/Spark_in_Colab.ipynb\\nIt’s advisable to spend some time setting things up locally rather than jumping right into this solution.', 'section': 'Module 5: pyspark', 'question': 'PySpark - Setting Spark up in Google Colab', 'course': 'data-engineering-zoomcamp', 'id': '5cc0e4d9'}, '17090545': {'text': 'If after installing Java (either jdk or openjdk), Hadoop and Spark, and setting the corresponding environment variables you find the following error when spark-shell is run at CMD:\\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x3c947bc5) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed\\nmodule @0x3c947bc5\\nSolution: Java 17 or 19 is not supported by Spark. Spark 3.x: requires Java 8/11/16. Install Java 11 from the website provided in the windows.md setup file.', 'section': 'Module 5: pyspark', 'question': 'Spark-shell: unable to load native-hadoop library for platform - Windows', 'course': 'data-engineering-zoomcamp', 'id': '17090545'}, 'd17e30c6': {'text': 'I found this error while executing the user defined function in Spark (crazy_stuff_udf). I am working on Windows and using conda. After following the setup instructions, I found that the PYSPARK_PYTHON environment variable was not set correctly, given that conda has different python paths for each environment.\\nSolution:\\npip install findspark on the command line inside proper environment\\nAdd to the top of the script\\nimport findspark\\nfindspark.init()', 'section': 'Module 5: pyspark', 'question': 'PySpark - Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.', 'course': 'data-engineering-zoomcamp', 'id': 'd17e30c6'}, '1520b5bc': {'text': 'This is because Python 3.11 has some inconsistencies with such an old version of Spark. The solution is a downgrade in the Python version. Python 3.9 using a conda environment takes care of it. Or install newer PySpark >= 3.5.1 works for me (Ella) [source].', 'section': 'Module 5: pyspark', 'question': 'PySpark - TypeError: code() argument 13 must be str, not int  , while executing `import pyspark`  (Windows/ Spark 3.0.3 - Python 3.11)', 'course': 'data-engineering-zoomcamp', 'id': '1520b5bc'}, 'e86ca928': {'text': 'If anyone is a Pythonista or becoming one (which you will essentially be one along this journey), and desires to have all python dependencies under same virtual environment (e.g. conda) as done with prefect and previous exercises, simply follow these steps\\nInstall OpenJDK 11,\\non MacOS: $ brew install java11\\nAdd export PATH=\"/opt/homebrew/opt/openjdk@11/bin:$PATH\"\\nto ~/.bashrc or ~/zshrc\\nActivate working environment (by pipenv / poetry / conda)\\nRun $ pip install pyspark\\nWork with exercises as normal\\nAll default commands of spark will be also available at shell session under activated enviroment.\\nHope this can help!\\nP.s. you won’t need findspark to firstly initialize.\\nPy4J - Py4JJavaError: An error occurred while calling (...)  java.net.ConnectException: Connection refused: no further information;\\nIf you\\'re getting `Py4JavaError` with a generic root cause, such as the described above (Connection refused: no further information). You\\'re most likely using incompatible versions of the JDK or Python with Spark.\\nAs of the current latest Spark version (3.5.0), it supports JDK 8 / 11 / 17. All of which can be easily installed with SDKMan! on macOS or Linux environments\\n\\n$ sdk install java 17.0.10-librca\\n$ sdk install spark 3.5.0\\n$ sdk install hadoop 3.3.5\\nAs PySpark 3.5.0 supports Python 3.8+ make sure you\\'re setting up your virtualenv with either 3.8 / 3.9 / 3.10 / 3.11 (Most importantly avoid using 3.12 for now as not all libs in the data-science/engineering ecosystem are fully package for that)\\n\\n\\n$ conda create -n ENV_NAME python=3.11\\n$ conda activate ENV_NAME\\n$ pip install pyspark==3.5.0\\nThis setup makes installing `findspark` and the likes of it unnecessary. Happy coding.\\nPy4J - Py4JJavaError: An error occurred while calling o54.parquet. Or any kind of Py4JJavaError that show up after run df.write.parquet(\\'zones\\')(On window)\\nThis assume you already correctly set up the PATH in the nano ~/.bashrc\\nHere my\\nexport JAVA_HOME=\"/c/tools/jdk-11.0.21\"\\nexport PATH=\"${JAVA_HOME}/bin:${PATH}\"\\nexport HADOOP_HOME=\"/c/tools/hadoop-3.2.0\"\\nexport PATH=\"${HADOOP_HOME}/bin:${PATH}\"\\nexport SPARK_HOME=\"/c/tools/spark-3.3.2-bin-hadoop3\"\\nexport PATH=\"${SPARK_HOME}/bin:${PATH}\"\\nexport PYTHONPATH=\"${SPARK_HOME}/python/:$PYTHONPATH\"\\nexport PYTHONPATH=\"${SPARK_HOME}spark-3.5.1-bin-hadoop3py4j-0.10.9.5-src.zip:$PYTHONPATH\"\\nYou also need to add environment variables correctly which paths to java jdk, spark and hadoop through\\nGo to Stephenlaye2/winutils3.3.0: winutils.exe hadoop.dll and hdfs.dll binaries for hadoop windows (github.com), download the right winutils for hadoop-3.2.0. Then create a new folder,bin and put every thing in side to make a /c/tools/hadoop-3.2.0/bin(You might not need to do this, but after testing it without the /bin I could not make it to work)\\nThen follow the solution in this video: How To Resolve Issue with Writing DataFrame to Local File | winutils | msvcp100.dll (youtube.com)\\nRemember to restart IDE and computer, After the error An error occurred while calling o54.parquet.  is fixed but new errors like o31.parquet. Or o35.parquet. appear.', 'section': 'Module 5: pyspark', 'question': 'Java+Spark - Easy setup with miniconda env (worked on MacOS)', 'course': 'data-engineering-zoomcamp', 'id': 'e86ca928'}, '3b5b4eb3': {'text': 'After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nspark = SparkSession.builder \\\\\\n.master(\"local[*]\") \\\\\\n.appName(\\'test\\') \\\\\\n.getOrCreate()\\ndf = spark.read \\\\\\n.option(\"header\", \"true\") \\\\\\n.csv(\\'taxi+_zone_lookup.csv\\')\\ndf.show()\\nit gives the error:\\nRuntimeError: Java gateway process exited before sending its port number\\n✅The solution (for me) was:\\npip install findspark on the command line and then\\nAdd\\nimport findspark\\nfindspark.init()\\nto the top of the script.\\nAnother possible solution is:\\nCheck that pyspark is pointing to the correct location.\\nRun pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\\nIf it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\\nTo add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\\nOnce everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.', 'section': 'Module 5: pyspark', 'question': 'lsRuntimeError: Java gateway process exited before sending its port number', 'course': 'data-engineering-zoomcamp', 'id': '3b5b4eb3'}, '489c366f': {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', 'id': '489c366f'}, '59381b15': {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', 'id': '59381b15'}, '220b1cf3': {'text': 'If below does not work, then download the latest available py4j version with\\nconda install -c conda-forge py4j\\nTake care of the latest version number in the website to replace appropriately.\\nNow add\\nexport PYTHONPATH=\"${SPARK_HOME}/python/:$PYTHONPATH\"\\nexport PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH\"\\nin your  .bashrc file.', 'section': 'Module 5: pyspark', 'question': \"Py4J Error - ModuleNotFoundError: No module named 'py4j' (Solve with latest version)\", 'course': 'data-engineering-zoomcamp', 'id': '220b1cf3'}, 'd970a0da': {'text': 'Even after we have exported our paths correctly you may find that  even though Jupyter is installed you might not have Jupyter Noteboopgak for one reason or another. Full instructions are found here (for my walkthrough) or here (where I got the original instructions from) but are included below. These instructions include setting up a virtual environment (handy if you are on your own machine doing this and not a VM):\\nFull steps:\\nUpdate and upgrade packages:\\nsudo apt update && sudo apt -y upgrade\\nInstall Python:\\nsudo apt install python3-pip python3-dev\\nInstall Python virtualenv:\\nsudo -H pip3 install --upgrade pip\\nsudo -H pip3 install virtualenv\\nCreate a Python Virtual Environment:\\nmkdir notebook\\ncd notebook\\nvirtualenv jupyterenv\\nsource jupyterenv/bin/activate\\nInstall Jupyter Notebook:\\npip install jupyter\\nRun Jupyter Notebook:\\njupyter notebook', 'section': 'Module 5: pyspark', 'question': 'Exception: Jupyter command `jupyter-notebook` not found.', 'course': 'data-engineering-zoomcamp', 'id': 'd970a0da'}, '5fa98bd0': {'text': 'Code executed:\\ndf = spark.read.parquet(pq_path)\\n… some operations on df …\\ndf.write.parquet(pq_path, mode=\"overwrite\")\\njava.io.FileNotFoundException: File file:/home/xxx/code/data/pq/fhvhv/2021/02/part-00021-523f9ad5-14af-4332-9434-bdcb0831f2b7-c000.snappy.parquet does not exist\\nThe problem is that Sparks performs lazy transformations, so the actual action that trigger the job is df.write, which does delete the parquet files that is trying to read (mode=”overwrite”)\\n✅Solution: Write to a different directorydf\\ndf.write.parquet(pq_path_temp, mode=\"overwrite\")', 'section': 'Module 5: pyspark', 'question': 'Error java.io.FileNotFoundException', 'course': 'data-engineering-zoomcamp', 'id': '5fa98bd0'}, 'ce508f3c': {'text': 'You need to create the Hadoop /bin directory manually and add the downloaded files in there, since the shell script provided for Windows installation just puts them in /c/tools/hadoop-3.2.0/ .', 'section': 'Module 5: pyspark', 'question': 'Hadoop - FileNotFoundException: Hadoop bin directory does not exist , when trying to write (Windows)', 'course': 'data-engineering-zoomcamp', 'id': 'ce508f3c'}, 'b7b9487d': {'text': 'Actually Spark SQL is one independent “type” of SQL - Spark SQL.\\nThe several SQL providers are very similar:\\nSELECT [attributes]\\nFROM [table]\\nWHERE [filter]\\nGROUP BY [grouping attributes]\\nHAVING [filtering the groups]\\nORDER BY [attribute to order]\\n(INNER/FULL/LEFT/RIGHT) JOIN [table2]\\nON [attributes table joining table2] (...)\\nWhat differs the most between several SQL providers are built-in functions.\\nFor Built-in Spark SQL function check this link: https://spark.apache.org/docs/latest/api/sql/index.html\\nExtra information on SPARK SQL :\\nhttps://databricks.com/glossary/what-is-spark-sql#:~:text=Spark%20SQL%20is%20a%20Spark,on%20existing%20deployments%20and%20data.', 'section': 'Module 5: pyspark', 'question': 'Which type of SQL is used in Spark? Postgres? MySQL? SQL Server?', 'course': 'data-engineering-zoomcamp', 'id': 'b7b9487d'}, 'a74de125': {'text': \"✅Solution: I had two notebooks running, and the one I wanted to look at had opened a port on localhost:4041.\\nIf a port is in use, then Spark uses the next available port number. It can be even 4044. Clean up after yourself when a port does not work or a container does not run.\\nYou can run spark.sparkContext.uiWebUrl\\nand result will be some like\\n'http://172.19.10.61:4041'\", 'section': 'Module 5: pyspark', 'question': 'The spark viewer on localhost:4040 was not showing the current run', 'course': 'data-engineering-zoomcamp', 'id': 'a74de125'}, 'e5270303': {'text': '✅Solution: replace Java Developer Kit 11 with Java Developer Kit 8.\\nJava - RuntimeError: Java gateway process exited before sending its port number\\nShows java_home is not set on the notebook log\\nhttps://sparkbyexamples.com/pyspark/pyspark-exception-java-gateway-process-exited-before-sending-the-driver-its-port-number/\\nhttps://twitter.com/drkrishnaanand/status/1765423415878463839', 'section': 'Module 5: pyspark', 'question': 'Java - java.lang.NoSuchMethodError: sun.nio.ch.DirectBuffer.cleaner()Lsun/misc/Cleaner Error during repartition call (conda pyspark installation)', 'course': 'data-engineering-zoomcamp', 'id': 'e5270303'}, 'cabe8a5b': {'text': '✅I got it working using `gcs-connector-hadoop-2.2.5-shaded.jar` and Spark 3.1\\nI also added the google_credentials.json and .p12 to auth with gcs. These files are downloadable from GCP Service account.\\nTo create the SparkSession:\\nspark = SparkSession.builder.master(\\'local[*]\\') \\\\\\n.appName(\\'spark-read-from-bigquery\\') \\\\\\n.config(\\'BigQueryProjectId\\',\\'razor-project-xxxxxxx) \\\\\\n.config(\\'BigQueryDatasetLocation\\',\\'de_final_data\\') \\\\\\n.config(\\'parentProject\\',\\'razor-project-xxxxxxx) \\\\\\n.config(\"google.cloud.auth.service.account.enable\", \"true\") \\\\\\n.config(\"credentialsFile\", \"google_credentials.json\") \\\\\\n.config(\"GcpJsonKeyFile\", \"google_credentials.json\") \\\\\\n.config(\"spark.driver.memory\", \"4g\") \\\\\\n.config(\"spark.executor.memory\", \"2g\") \\\\\\n.config(\"spark.memory.offHeap.enabled\",True) \\\\\\n.config(\"spark.memory.offHeap.size\",\"5g\") \\\\\\n.config(\\'google.cloud.auth.service.account.json.keyfile\\', \"google_credentials.json\") \\\\\\n.config(\"fs.gs.project.id\", \"razor-project-xxxxxxx\") \\\\\\n.config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\\\\n.config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\\\\n.getOrCreate()', 'section': 'Module 5: pyspark', 'question': 'Spark fails when reading from BigQuery and using `.show()` on `SELECT` queries', 'course': 'data-engineering-zoomcamp', 'id': 'cabe8a5b'}, 'e3c0f777': {'text': 'While creating a SparkSession using the config spark.jars.packages as com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.23.2\\nspark = SparkSession.builder.master(\\'local\\').appName(\\'bq\\').config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.23.2\").getOrCreate()\\nautomatically downloads the required dependency jars and configures the connector, removing the need to manage this dependency. More details available here', 'section': 'Module 5: pyspark', 'question': 'Spark BigQuery connector Automatic configuration', 'course': 'data-engineering-zoomcamp', 'id': 'e3c0f777'}, '50c009ef': {'text': 'Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\\nThere’s a few extra steps to go into reading from GCS with PySpark\\n1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\\nAs the name implies, this .jar file is what essentially connects PySpark with your GCS\\n2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\\n3.) In your Python script, there are a few extra classes you’ll have to import:\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.conf import SparkConf\\nfrom pyspark.context import SparkContext\\n4.) You must set up your configurations before building your SparkSession. Here’s my code snippet:\\nconf = SparkConf() \\\\\\n.setMaster(\\'local[*]\\') \\\\\\n.setAppName(\\'test\\') \\\\\\n.set(\"spark.jars\", \"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\") \\\\\\n.set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\\\\n.set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\\nsc = SparkContext(conf=conf)\\nsc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\\nsc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\\nsc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\\nsc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\\n5.) Once you run that, build your SparkSession with the new parameters we’d just instantiated in the previous step:\\nspark = SparkSession.builder \\\\\\n.config(conf=sc.getConf()) \\\\\\n.getOrCreate()\\n6.) Finally, you’re able to read your files straight from GCS!\\ndf_green = spark.read.parquet(\"gs://{BUCKET}/green/202*/\")', 'section': 'Module 5: pyspark', 'question': 'Spark Cloud Storage connector', 'course': 'data-engineering-zoomcamp', 'id': '50c009ef'}, '3fe85b16': {'text': 'from pyarrow.parquet import ParquetFile\\npf = ParquetFile(\\'fhvhv_tripdata_2021-01.parquet\\')\\n#pyarrow builds tables, not dataframes\\ntbl_small = next(pf.iter_batches(batch_size = 1000))\\n#this function converts the table to a dataframe of manageable size\\ndf = tbl_small.to_pandas()\\nAlternatively without PyArrow:\\ndf = spark.read.parquet(\\'fhvhv_tripdata_2021-01.parquet\\')\\ndf1 = df.sort(\\'DOLocationID\\').limit(1000)\\npdf = df1.select(\"*\").toPandas()\\ngcsu', 'section': 'Module 5: pyspark', 'question': 'How can I read a small number of rows from the parquet file directly?', 'course': 'data-engineering-zoomcamp', 'id': '3fe85b16'}, '0fe0c76a': {'text': 'Probably you’ll encounter this if you followed the video ‘5.3.1 - First Look at Spark/PySpark’ and used the parquet file from the TLC website (csv was used in the video).\\nWhen defining the schema, the PULocation and DOLocationID are defined as IntegerType. This will cause an error because the Parquet file is INT64 and you’ll get an error like:\\nParquet column cannot be converted in file [...] Column [...] Expected: int, Found: INT64\\nChange the schema definition from IntegerType to LongType and it should work', 'section': 'Module 5: pyspark', 'question': 'DataType error when creating Spark DataFrame with a specified schema?', 'course': 'data-engineering-zoomcamp', 'id': '0fe0c76a'}, '18c5bafe': {'text': 'df_finalx=df_finalw.select([col(x).alias(x.replace(\" \",\"\")) for x in df_finalw.columns])\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Remove white spaces from column names in Pyspark', 'course': 'data-engineering-zoomcamp', 'id': '18c5bafe'}, '59e86b40': {'text': 'This error comes up on the Spark video 5.3.1 - First Look at Spark/PySpark,\\nbecause as at the creation of the video, 2021 data was the most recent which utilised csv files but as at now its parquet.\\nSo when you run the command spark.createDataFrame(df1_pandas).show(),\\nYou get the Attribute error. This is caused by the pandas version 2.0.0 which seems incompatible with Spark 3.3.2, so to fix it you have to downgrade pandas to 1.5.3 using the command pip install -U pandas==1.5.3\\nAnother option is adding the following after importing pandas, if one does not want to downgrade pandas version (source) :\\npd.DataFrame.iteritems = pd.DataFrame.items\\nNote that this problem is solved with Spark versions from 3.4.1', 'section': 'Module 5: pyspark', 'question': \"AttributeError: 'DataFrame' object has no attribute 'iteritems'\", 'course': 'data-engineering-zoomcamp', 'id': '59e86b40'}, '1ac3ea8f': {'text': 'Another alternative is to install pandas 2.0.1 (it worked well as at the time of writing this), and it is compatible with Pyspark 3.5.1. Make sure to add or edit your environment variable like this:\\nexport SPARK_HOME=\"${HOME}/spark/spark-3.5.1-bin-hadoop3\"\\nexport PATH=\"${SPARK_HOME}/bin:${PATH}\"', 'section': 'Module 5: pyspark', 'question': \"AttributeError: 'DataFrame' object has no attribute 'iteritems'\", 'course': 'data-engineering-zoomcamp', 'id': '1ac3ea8f'}, 'e04529ac': {'text': 'Open a CMD terminal in administrator mode\\ncd %SPARK_HOME%\\nStart a master node: bin\\\\spark-class org.apache.spark.deploy.master.Master\\nStart a worker node: bin\\\\spark-class org.apache.spark.deploy.worker.Worker spark://<master_ip>:<port> --host <IP_ADDR>\\nbin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077 --host <IP_ADDR>\\nspark://<master_ip>:<port>: copy the address from the previous command, in my case it was spark://localhost:7077\\nUse --host <IP_ADDR> if you want to run the worker on a different machine. For now leave it empty.\\nNow you can access Spark UI through localhost:8080\\nHomework for Module 5:\\nDo not refer to the homework file located under /05-batch/code/. The correct file is located under\\nhttps://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/05-batch/homework.md', 'section': 'Module 5: pyspark', 'question': 'Spark Standalone Mode on Windows', 'course': 'data-engineering-zoomcamp', 'id': 'e04529ac'}, 'a602a7f8': {'text': 'You can either type the export command every time you run a new session, add it to the .bashrc/ which you can find in /home or run this command at the beginning of your homebook:\\nimport findspark\\nfindspark.init()', 'section': 'Module 5: pyspark', 'question': 'Export PYTHONPATH command in linux is temporary', 'course': 'data-engineering-zoomcamp', 'id': 'a602a7f8'}, '9336ce2c': {'text': 'I solved this issue: unzip the file with:\\nf\\nbefore creating head.csv', 'section': 'Module 5: pyspark', 'question': 'Compressed file ended before the end-of-stream marker was reached', 'course': 'data-engineering-zoomcamp', 'id': '9336ce2c'}, 'bac4e0f7': {'text': 'In the code along from Video 5.3.3 Alexey downloads the CSV files from the NYT website and gzips them in their bash script. If we now (2023) follow along but download the data from the GH course Repo, it will already be zippes as csv.gz files. Therefore we zip it again if we follow the code from the video exactly. This then leads to gibberish outcome when we then try to cat the contents or count the lines with zcat, because the file is zipped twitch and zcat only unzips it once.\\n✅solution: do not gzip the files downloaded from the course repo. Just wget them and save them as they are as csv.gz files. Then the zcat command and the showSchema command will also work\\nURL=\"${URL_PREFIX}/${TAXI_TYPE}/${TAXI_TYPE}_tripdata_${YEAR}-${FMONTH}.csv.gz\"\\nLOCAL_PREFIX=\"data/raw/${TAXI_TYPE}/${YEAR}/${FMONTH}\"\\nLOCAL_FILE=\"${TAXI_TYPE}_tripdata_${YEAR}_${FMONTH}.csv.gz\"\\nLOCAL_PATH=\"${LOCAL_PREFIX}/${LOCAL_FILE}\"\\necho \"downloading ${URL} to ${LOCAL_PATH}\"\\nmkdir -p ${LOCAL_PREFIX}\\nwget ${URL} -O ${LOCAL_PATH}\\necho \"compressing ${LOCAL_PATH}\"\\n# gzip ${LOCAL_PATH} <- uncomment this line', 'section': 'Module 5: pyspark', 'question': 'Compression Error: zcat output is gibberish, seems like still compressed', 'course': 'data-engineering-zoomcamp', 'id': 'bac4e0f7'}, '13dad632': {'text': 'Occurred while running : spark.createDataFrame(df_pandas).show()\\nThis error is usually due to the python version, since spark till date of 2 march 2023 doesn’t support python 3.11, try creating a new env with python version 3.8 and then run this command.\\nOn the virtual machine, you can create a conda environment (here called myenv) with python 3.10 installed:\\nconda create -n myenv python=3.10 anaconda\\nThen you must run conda activate myenv to run python 3.10. Otherwise you’ll still be running version 3.11. You can deactivate by typing conda deactivate.', 'section': 'Module 5: pyspark', 'question': 'PicklingError: Could not serialise object: IndexError: tuple index out of range.', 'course': 'data-engineering-zoomcamp', 'id': '13dad632'}, 'ddc3c75b': {'text': 'Make sure you have your credentials of your GCP in your VM under the location defined in the script.', 'section': 'Module 5: pyspark', 'question': 'Connecting from local Spark to GCS - Spark does not find my google credentials as shown in the video?', 'course': 'data-engineering-zoomcamp', 'id': 'ddc3c75b'}, '095b667f': {'text': 'To run spark in docker setup\\n1. Build bitnami spark docker\\na. clone bitnami repo using command\\ngit clone https://github.com/bitnami/containers.git\\n(tested on commit 9cef8b892d29c04f8a271a644341c8222790c992)\\nb. edit file `bitnami/spark/3.3/debian-11/Dockerfile` and update java and spark version as following\\n\"python-3.10.10-2-linux-${OS_ARCH}-debian-11\" \\\\\\n\"java-17.0.5-8-3-linux-${OS_ARCH}-debian-11\" \\\\\\nreference: https://github.com/bitnami/containers/issues/13409\\nc. build docker image by navigating to above directory and running docker build command\\nnavigate cd bitnami/spark/3.3/debian-11/\\nbuild command docker build -t spark:3.3-java-17 .\\n2. run docker compose\\nusing following file\\n```yaml docker-compose.yml\\nversion: \\'2\\'\\nservices:\\nspark:\\nimage: spark:3.3-java-17\\nenvironment:\\n- SPARK_MODE=master\\n- SPARK_RPC_AUTHENTICATION_ENABLED=no\\n- SPARK_RPC_ENCRYPTION_ENABLED=no\\n- SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no\\n- SPARK_SSL_ENABLED=no\\nvolumes:\\n- \"./:/home/jovyan/work:rw\"\\nports:\\n- \\'8080:8080\\'\\n- \\'7077:7077\\'\\nspark-worker:\\nimage: spark:3.3-java-17\\nenvironment:\\n- SPARK_MODE=worker\\n- SPARK_MASTER_URL=spark://spark:7077\\n- SPARK_WORKER_MEMORY=1G\\n- SPARK_WORKER_CORES=1\\n- SPARK_RPC_AUTHENTICATION_ENABLED=no\\n- SPARK_RPC_ENCRYPTION_ENABLED=no\\n- SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no\\n- SPARK_SSL_ENABLED=no\\nvolumes:\\n- \"./:/home/jovyan/work:rw\"\\nports:\\n- \\'8081:8081\\'\\nspark-nb:\\nimage: jupyter/pyspark-notebook:java-17.0.5\\nenvironment:\\n- SPARK_MASTER_URL=spark://spark:7077\\nvolumes:\\n- \"./:/home/jovyan/work:rw\"\\nports:\\n- \\'8888:8888\\'\\n- \\'4040:4040\\'\\n```\\nrun command to deploy docker compose\\ndocker-compose up\\nAccess jupyter notebook using link logged in docker compose logs\\nSpark master url is spark://spark:7077', 'section': 'Module 5: pyspark', 'question': 'Spark docker-compose setup', 'course': 'data-engineering-zoomcamp', 'id': '095b667f'}, '56a67c23': {'text': 'To do this\\npip install gcsfs,\\nThereafter copy the uri path to the file and use \\ndf = pandas.read_csc(gs://path)', 'section': 'Module 5: pyspark', 'question': 'How do you read data stored in gcs on pandas with your local computer?', 'course': 'data-engineering-zoomcamp', 'id': '56a67c23'}, '7fed7813': {'text': 'Error:\\nspark.createDataFrame(df_pandas).schema\\nTypeError: field Affiliated_base_number: Can not merge type <class \\'pyspark.sql.types.StringType\\'> and <class \\'pyspark.sql.types.DoubleType\\'>\\nSolution:\\nAffiliated_base_number is a mix of letters and numbers (you can check this with a preview of the table), so it cannot be set to DoubleType (only for double-precision numbers). The suitable type would be StringType. Spark  inferSchema is more accurate than Pandas infer type method in this case. You can set it to  true  while reading the csv, so you don’t have to take out any data from your dataset. Something like this can help:\\ndf = spark.read \\\\\\n.options(\\nheader = \"true\", \\\\\\ninferSchema = \"true\", \\\\\\n) \\\\\\n.csv(\\'path/to/your/csv/file/\\')\\nSolution B:\\nIt\\'s because some rows in the affiliated_base_number are null and therefore it is assigned the datatype String and this cannot be converted to type Double. So if you really want to convert this pandas df to a pyspark df only take the  rows from the pandas df that are not null in the \\'Affiliated_base_number\\' column. Then you will be able to apply the pyspark function createDataFrame.\\n# Only take rows that have no null values\\npandas_df= pandas_df[pandas_df.notnull().all(1)]', 'section': 'Module 5: pyspark', 'question': 'TypeError when using spark.createDataFrame function on a pandas df', 'course': 'data-engineering-zoomcamp', 'id': '7fed7813'}, 'a0e7e259': {'text': 'Default executor memory is 1gb. This error appeared when working with the homework dataset.\\nError: MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\\nScaling row group sizes to 95.00% for 8 writers\\nSolution:\\nIncrease the memory of the executor when creating the Spark session like this:\\nRemember to restart the Jupyter session (ie. close the Spark session) or the config won’t take effect.', 'section': 'Module 5: pyspark', 'question': 'MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory', 'course': 'data-engineering-zoomcamp', 'id': 'a0e7e259'}, '4ca14331': {'text': 'Change the working directory to the spark directory:\\nif you have setup up your SPARK_HOME variable, use the following;\\ncd %SPARK_HOME%\\nif not, use the following;\\ncd <path to spark installation>\\nCreating a Local Spark Cluster\\nTo start Spark Master:\\nbin\\\\spark-class org.apache.spark.deploy.master.Master --host localhost\\nStarting up a cluster:\\nbin\\\\spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077 --host localhost', 'section': 'Module 5: pyspark', 'question': 'How to spark standalone cluster is run on windows OS', 'course': 'data-engineering-zoomcamp', 'id': '4ca14331'}, '6fdd09eb': {'text': 'I added PYTHONPATH, JAVA_HOME and SPARK_HOME to ~/.bashrc, import pyspark worked ok in iPython in terminal, but couldn’t be found in .ipynb opened in VS Code\\nAfter adding new lines to ~/.bashrc, need to restart the shell to activate the new lines, do either\\nsource ~/.bashrc\\nexec bash\\nInstead of configuring paths in ~/.bashrc, I created .env file in the root of my workspace:', 'section': 'Module 5: pyspark', 'question': 'Env variables set in ~/.bashrc are not loaded to Jupyter in VS Code', 'course': 'data-engineering-zoomcamp', 'id': '6fdd09eb'}, '64bfb2c3': {'text': 'I don’t use visual studio, so I did it the old fashioned way: ssh -L 8888:localhost:8888 <my user>@<VM IP> (replace user and IP with the ones used by the GCP VM, e.g. : ssh -L 8888:localhost:8888 myuser@34.140.188.1', 'section': 'Module 5: pyspark', 'question': 'How to port forward outside VS Code', 'course': 'data-engineering-zoomcamp', 'id': '64bfb2c3'}, '33dd4516': {'text': 'If you are doing wc -l fhvhv_tripdata_2021-01.csv.gz  with the gzip file as the file argument, you will get a different result, obviously! Since the file is compressed.\\nUnzip the file and then do wc -l fhvhv_tripdata_2021-01.csv to get the right results.', 'section': 'Module 5: pyspark', 'question': '“wc -l” is giving a different result then shown in the video', 'course': 'data-engineering-zoomcamp', 'id': '33dd4516'}, '504b8570': {'text': 'when trying to:\\nURL=\"spark://$HOSTNAME:7077\"\\nspark-submit \\\\\\n--master=\"{$URL}\" \\\\\\n06_spark_sql.py \\\\\\n--input_green=data/pq/green/2021/*/ \\\\\\n--input_yellow=data/pq/yellow/2021/*/ \\\\\\n--output=data/report-2021\\nand you get errors like the following (SUMMARIZED):\\nWARN Utils: Your hostname, <HOSTNAME> resolves to a loopback address..\\nWARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address Setting default log level to \"WARN\".\\nException in thread \"main\" org.apache.spark.SparkException: Master must either be yarn or start with spark, mesos, k8s, or local at …\\nTry replacing --master=\"{$URL}\"\\nwith --master=$URL (edited)\\nExtra edit for spark version 3.4.2 - if encountering:\\n`Error: Unrecognized option: --master=`\\n→ Replace `--master=\"{$URL}\"` with  `--master \"${URL}\"`', 'section': 'Module 5: pyspark', 'question': '`spark-submit` errors', 'course': 'data-engineering-zoomcamp', 'id': '504b8570'}, '42e933c5': {'text': 'If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\\nFor Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\\\bin” to the PATH variable.\\nAdditional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io', 'section': 'Module 5: pyspark', 'question': 'Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z', 'course': 'data-engineering-zoomcamp', 'id': '42e933c5'}, 'fe9240b0': {'text': \"Change the hadoop version to 3.0.1.Replace all the files in the local hadoop bin folder with the files in this repo:  winutils/hadoop-3.0.1/bin at master · cdarlint/winutils (github.com)\\nIf this does not work try to change other versions found in this repository.\\nFor more information please see this link: This version of %1 is not compatible with the version of Windows you're running · Issue #20 · cdarlint/winutils (github.com)\", 'section': 'Module 5: pyspark', 'question': 'Java.io.IOException. Cannot run program “C:\\\\hadoop\\\\bin\\\\winutils.exe”. CreateProcess error=216, This version of 1% is not compatible with the version of Windows you are using.', 'course': 'data-engineering-zoomcamp', 'id': 'fe9240b0'}, 'c0a46e5d': {'text': 'Fix is to set the flag like the error states. Get your project ID from your dashboard and set it like so:\\ngcloud dataproc jobs submit pyspark \\\\\\n--cluster=my_cluster \\\\\\n--region=us-central1 \\\\\\n--project=my-dtc-project-1010101 \\\\\\ngs://my-dtc-bucket-id/code/06_spark_sql.py\\n-- \\\\\\n…', 'section': 'Module 5: pyspark', 'question': 'Dataproc - ERROR: (gcloud.dataproc.jobs.submit.pyspark) The required property [project] is not currently set. It can be set on a per-command basis by re-running your command with the [--project] flag.', 'course': 'data-engineering-zoomcamp', 'id': 'c0a46e5d'}, '943c2466': {'text': 'Go to %SPARK_HOME%\\\\bin\\nRun spark-class org.apache.spark.deploy.master.Master to run the master. This will give you a URL of the form spark://ip:port\\nRun spark-class org.apache.spark.deploy.worker.Worker spark://ip:port to run the worker. Make sure you use the URL you obtained in step 2.\\nCreate a new Jupyter notebook:\\nspark = SparkSession.builder \\\\\\n.master(\"spark://{ip}:7077\") \\\\\\n.appName(\\'test\\') \\\\\\n.getOrCreate()\\nCheck on Spark UI the master, worker and app.', 'section': 'Module 5: pyspark', 'question': 'Run Local Cluster Spark in Windows 10 with CMD', 'course': 'data-engineering-zoomcamp', 'id': '943c2466'}, 'f41ef231': {'text': 'This occurs because you are not logged in “gcloud auth login” and maybe the project id is not settled. Then type in a terminal:\\ngcloud auth login\\nThis will open a tab in the browser, accept the terms, after that close the tab if you want. Then set the project is like:\\ngcloud config set project <YOUR PROJECT_ID>\\nThen you can run the command to upload the pq dir to a GCS Bucket:\\ngsutil -m cp -r pq/ <YOUR URI from gsutil>/pq', 'section': 'Module 5: pyspark', 'question': \"lServiceException: 401 Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).\", 'course': 'data-engineering-zoomcamp', 'id': 'f41ef231'}, '6b26d73c': {'text': \"When submit a job, it might throw an error about Java in log panel within Dataproc. I changed the Versioning Control when I created a cluster, so it means that I delete the cluster and created a new one, and instead of choosing Debian-Hadoop-Spark, I switch to Ubuntu 20.02-Hadoop3.3-Spark3.3 for Versioning Control feature, the main reason to choose this is because I have the same Ubuntu version in mi laptop, I tried to find documentation to sustent this but unfortunately I couldn't nevertheless it works for me.\", 'section': 'Module 5: pyspark', 'question': 'py4j.protocol.Py4JJavaError  GCP', 'course': 'data-engineering-zoomcamp', 'id': '6b26d73c'}, '830e2936': {'text': \"Use both repartition and coalesce, like so:\\ndf = df.repartition(6)\\ndf = df.coalesce(6)\\ndf.write.parquet('fhv/2019/10', mode='overwrite')\", 'section': 'Module 5: pyspark', 'question': 'Repartition the Dataframe to 6 partitions using df.repartition(6) - got 8 partitions instead', 'course': 'data-engineering-zoomcamp', 'id': '830e2936'}, '02007b7c': {'text': \"Possible solution - Try to forward the port using ssh cli instead of vs code.\\nRun > “ssh -L <local port>:<VM host/ip>:<VM port> <ssh hostname>”\\nssh hostname is the name you specified in the ~/.ssh/config file\\nIn case of Jupyter Notebook run\\n“ssh -L 8888:localhost:8888 gcp-vm”\\nfrom your local machine’s cli.\\nNOTE: If you logout from the session, the connection would break. Also while creating the spark session notice the block's log because sometimes it fails to run at 4040 and then switches to 4041.\\n~Abhijit Chakrborty: If you are having trouble accessing localhost ports from GCP VM consider adding the forwarding instructions to .ssh/config file as following:\\n```\\nHost <hostname>\\nHostname <external-gcp-ip>\\nUser xxxx\\nIdentityFile yyyy\\nLocalForward 8888 localhost:8888\\nLocalForward 8080 localhost:8080\\nLocalForward 5432 localhost:5432\\nLocalForward 4040 localhost:4040\\n```\\nThis should automatically forward all ports and will enable accessing localhost ports.\", 'section': 'Module 5: pyspark', 'question': 'Jupyter Notebook or SparkUI not loading properly at localhost after port forwarding from VS code?', 'course': 'data-engineering-zoomcamp', 'id': '02007b7c'}, '1ebb9a47': {'text': '~ Abhijit Chakraborty\\n`sdk list java`  to check for available java sdk versions.\\n`sdk install java 11.0.22-amzn`  as  java-11.0.22-amzn was available for my codespace.\\nclick on Y if prompted to change the default java version.\\nCheck for java version using `java -version `.\\nIf working fine great, else `sdk default java 11.0.22-amzn` or whatever version you have installed.', 'section': 'Module 5: pyspark', 'question': 'Installing Java 11 on codespaces', 'course': 'data-engineering-zoomcamp', 'id': '1ebb9a47'}, '80125745': {'text': 'Sometimes while creating a dataproc cluster on GCP, the following error is encountered.\\nSolution: As mentioned here, sometimes there might not be enough resources in the given region to allocate the request. Usually, gets freed up in a bit and one can create a cluster. – abhirup ghosh\\nSolution 2:  Changing the type of boot-disk from PD-Balanced to PD-Standard, in terraform, helped solve the problem.- Sundara Kumar Padmanabhan', 'section': 'Module 5: pyspark', 'question': \"Error: Insufficient 'SSD_TOTAL_GB' quota. Requested 500.0, available 470.0.\", 'course': 'data-engineering-zoomcamp', 'id': '80125745'}, 'f01df45b': {'text': \"Pyspark converts the difference of two TimestampType values to Python's native datetime.timedelta object. The timedelta object only stores the duration in terms of days, seconds, and microseconds. Each of the three units of time must be manually converted into hours in order to express the total duration between the two timestamps using only hours.\\nAnother way for achieving this is using the datediff (sql function). It receives this parameters\\nUpper Date: the closest date you have. For example dropoff_datetime\\nLower Date: the farthest date you have.  For example pickup_datetime\\nAnd the result is returned in terms of days, so you could multiply the result for 24 in order to get the hours.\", 'section': 'Module 5: pyspark', 'question': 'Homework - how to convert the time difference of two timestamps to hours', 'course': 'data-engineering-zoomcamp', 'id': 'f01df45b'}, '06014eec': {'text': 'This version combination worked for me:\\nPySpark = 3.3.2\\nPandas = 1.5.3\\n\\nIf it still has an error,', 'section': 'Module 5: pyspark', 'question': 'PicklingError: Could not serialize object: IndexError: tuple index out of range', 'course': 'data-engineering-zoomcamp', 'id': '06014eec'}, '54653ca9': {'text': \"Run this before SparkSession\\nimport os\\nimport sys\\nos.environ['PYSPARK_PYTHON'] = sys.executable\\nos.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\", 'section': 'Module 5: pyspark', 'question': 'Py4JJavaError: An error occurred while calling o180.showString. : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 6) (host.docker.internal executor driver): org.apache.spark.SparkException: Python worker failed to connect back.', 'course': 'data-engineering-zoomcamp', 'id': '54653ca9'}, 'f95304db': {'text': \"import os\\nimport sys\\nos.environ['PYSPARK_PYTHON'] = sys.executable\\nos.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\\nDataproc Pricing: https://cloud.google.com/dataproc/pricing#on_gke_pricing\", 'section': 'Module 5: pyspark', 'question': 'RuntimeError: Python in worker has different version 3.11 than that in driver 3.10, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.', 'course': 'data-engineering-zoomcamp', 'id': 'f95304db'}, '591df4e6': {'text': 'Ans: No, you can submit a job to DataProc from your local computer by installing gsutil (https://cloud.google.com/storage/docs/gsutil_install) and configuring it. Then, you can execute the following command from your local computer.\\ngcloud dataproc jobs submit pyspark \\\\\\n--cluster=de-zoomcamp-cluster \\\\\\n--region=europe-west6 \\\\\\ngs://dtc_data_lake_de-zoomcamp-nytaxi/code/06_spark_sql.py \\\\\\n-- \\\\\\n--input_green=gs://dtc_data_lake_de-zoomcamp-nytaxi/pq/green/2020/*/ \\\\\\n--input_yellow=gs://dtc_data_lake_de-zoomcamp-nytaxi/pq/yellow/2020/*/ \\\\\\n--output=gs://dtc_data_lake_de-zoomcamp-nytaxi/report-2020 (edited)', 'section': 'Module 5: pyspark', 'question': 'Dataproc Qn: Is it essential to have a VM on GCP for running Dataproc and submitting jobs ?', 'course': 'data-engineering-zoomcamp', 'id': '591df4e6'}, '5cb7f597': {'text': \"AttributeError: 'DataFrame' object has no attribute 'iteritems'\\nthis is because the method inside the pyspark refers to a package that has been already deprecated\\n(https://stackoverflow.com/questions/76404811/attributeerror-dataframe-object-has-no-attribute-iteritems)\\nYou can do this code below, which is mentioned in the stackoverflow link above:\\nQ: DE Zoomcamp 5.6.3 - Setting up a Dataproc Cluster I cannot create a cluster and get this message. I tried many times as the FAQ said, but it didn't work. What can I do?\\nError\\nInsufficient 'SSD_TOTAL_GB' quota. Requested 500.0, available 250.0.\\nRequest ID: 17942272465025572271\\nA: The master and worker nodes are allocated a maximum of 250 GB of memory combined. In the configuration section, adhere to the following specifications:\\nMaster Node:\\nMachine type: n2-standard-2\\nPrimary disk size: 85 GB\\nWorker Node:\\nNumber of worker nodes: 2\\nMachine type: n2-standard-2\\nPrimary disk size: 80 GB\\nYou can allocate up to 82.5 GB memory for worker nodes, keeping in mind that the total memory allocated across all nodes cannot exceed 250 GB.\", 'section': 'Module 5: pyspark', 'question': 'In module 5.3.1, trying to run spark.createDataFrame(df_pandas).show() returns error', 'course': 'data-engineering-zoomcamp', 'id': '5cb7f597'}, 'c5de1f96': {'text': 'The MacOS setup instruction (https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/macos.md#installing-java) for setting the JAVA_HOME environment variable is for Intel-based Macs which have a default install location at /usr/local/. If you have an Apple Silicon mac, you will have to set JAVA_HOME to /opt/homebrew/, specifically in your .bashrc or .zshrc:\\nexport JAVA_HOME=\"/opt/homebrew/opt/openjdk/bin\"\\nexport PATH=\"$JAVA_HOME:$PATH\"\\nConfirm that your path was correctly set by running the command: which java\\nYou should expect to see the output:\\n/opt/homebrew/opt/openjdk/bin/java\\nReference: https://docs.brew.sh/Installation', 'section': 'Module 6: streaming with kafka', 'question': 'Setting JAVA_HOME with Homebrew on Apple Silicon', 'course': 'data-engineering-zoomcamp', 'id': 'c5de1f96'}, '70ac8e80': {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.', 'section': 'Module 6: streaming with kafka', 'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.', 'course': 'data-engineering-zoomcamp', 'id': '70ac8e80'}, 'f6551ffb': {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", 'section': 'Module 6: streaming with kafka', 'question': 'Module “kafka” not found when trying to run producer.py', 'course': 'data-engineering-zoomcamp', 'id': 'f6551ffb'}, '0ec021de': {'text': 'ImportError: DLL load failed while importing cimpl: The specified module could not be found\\nVerify Python Version:\\nMake sure you are using a compatible version of Python with the Avro library. Check the Python version and compatibility requirements specified by the Avro library documentation.\\n... you may have to load librdkafka-5d2e2910.dll in the code. Add this before importing avro:\\nfrom ctypes import CDLL\\nCDLL(\"C:\\\\\\\\Users\\\\\\\\YOUR_USER_NAME\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\dtcde\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\confluent_kafka.libs\\\\librdkafka-5d2e2910.dll\")\\nIt seems that the error may occur depending on the OS and python version installed.\\nALTERNATIVE:\\nImportError: DLL load failed while importing cimpl\\n✅SOLUTION: $env:CONDA_DLL_SEARCH_MODIFICATION_ENABLE=1 in Powershell.\\nYou need to set this DLL manually in Conda Env.\\nSource: https://githubhot.com/repo/confluentinc/confluent-kafka-python/issues/1186?page=2', 'section': 'Module 6: streaming with kafka', 'question': 'Error importing cimpl dll when running avro examples', 'course': 'data-engineering-zoomcamp', 'id': '0ec021de'}, '1edd4630': {'text': \"✅SOLUTION: pip install confluent-kafka[avro].\\nFor some reason, Conda also doesn't include this when installing confluent-kafka via pip.\\nMore sources on Anaconda and confluent-kafka issues:\\nhttps://github.com/confluentinc/confluent-kafka-python/issues/590\\nhttps://github.com/confluentinc/confluent-kafka-python/issues/1221\\nhttps://stackoverflow.com/questions/69085157/cannot-import-producer-from-confluent-kafka\", 'section': 'Module 6: streaming with kafka', 'question': \"ModuleNotFoundError: No module named 'avro'\", 'course': 'data-engineering-zoomcamp', 'id': '1edd4630'}, '4664ae28': {'text': 'If you get an error while running the command python3 stream.py worker\\nRun pip uninstall kafka-python\\nThen run pip install kafka-python==1.4.6\\nWhat is the use of  Redpanda ?\\nRedpanda: Redpanda is built on top of the Raft consensus algorithm and is designed as a high-performance, low-latency alternative to Kafka. It uses a log-centric architecture similar to Kafka but with different underlying principles.\\nRedpanda is a powerful, yet simple, and cost-efficient streaming data platform that is compatible with Kafka® APIs while eliminating Kafka complexity.', 'section': 'Module 6: streaming with kafka', 'question': 'Error while running python3 stream.py worker', 'course': 'data-engineering-zoomcamp', 'id': '4664ae28'}, '676e1b76': {'text': 'Got this error because the docker container memory was exhausted. The dta file was upto 800MB but my docker container does not have enough memory to handle that.\\nSolution was to load the file in chunks with Pandas, then create multiple parquet files for each dat file I was processing. This worked smoothly and the issue was resolved.', 'section': 'Module 6: streaming with kafka', 'question': 'Negsignal:SIGKILL while converting dta files to parquet format', 'course': 'data-engineering-zoomcamp', 'id': '676e1b76'}, 'a3c84279': {'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv', 'section': 'Module 6: streaming with kafka', 'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing', 'course': 'data-engineering-zoomcamp', 'id': 'a3c84279'}, '119c917d': {'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka- python videos have low audio and hard to follow up', 'course': 'data-engineering-zoomcamp', 'id': '119c917d'}, 'f1284c1f': {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp', 'id': 'f1284c1f'}, '49a7db28': {'text': 'Ankush said we can focus on horizontal scaling option.\\n“think of scaling in terms of scaling from consumer end. Or consuming message via horizontal scaling”', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka homwork Q3, there are options that support scaling concept more than the others:', 'course': 'data-engineering-zoomcamp', 'id': '49a7db28'}, '196cb0f2': {'text': 'If you get this error, know that you have not built your sparks and juypter images. This images aren’t readily available on dockerHub.\\nIn the spark folder, run ./build.sh from a bash cli to to build all images before running docker compose', 'section': 'Module 6: streaming with kafka', 'question': \"How to fix docker compose error: Error response from daemon: pull access denied for spark-3.3.1, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\", 'course': 'data-engineering-zoomcamp', 'id': '196cb0f2'}, '1e50eab7': {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: ./build.sh: Permission denied Error', 'course': 'data-engineering-zoomcamp', 'id': '1e50eab7'}, 'a7a6d0d7': {'text': 'Restarting all services worked for me:\\ndocker-compose down\\ndocker-compose up', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: ‘KafkaTimeoutError: Failed to update metadata after 60.0 secs.’ when running stream-example/producer.py', 'course': 'data-engineering-zoomcamp', 'id': 'a7a6d0d7'}, '0996213a': {'text': 'While following tutorial 13.2 , when running ./spark-submit.sh streaming.py, encountered the following error:\\n…\\n24/03/11 09:48:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077...\\n24/03/11 09:48:36 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:7077 after 10 ms (0 ms spent in bootstraps)\\n24/03/11 09:48:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\\n24/03/11 09:48:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077…\\n24/03/11 09:49:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077...\\n24/03/11 09:49:36 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.\\n24/03/11 09:49:36 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.\\n…\\npy4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.SparkSession.\\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\\n…\\nSolution:\\nDowngrade your local PySpark to 3.3.1 (same as Dockerfile)\\nThe reason for the failed connection in my case was the mismatch of PySpark versions. You can see that from the logs of spark-master in the docker container.\\nSolution 2:\\nCheck what Spark version your local machine has\\npyspark –version\\nspark-submit –version\\nAdd your version to SPARK_VERSION in build.sh', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: ./spark-submit.sh streaming.py - ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.', 'course': 'data-engineering-zoomcamp', 'id': '0996213a'}, '311bf368': {'text': 'Start a new terminal\\nRun: docker ps\\nCopy the CONTAINER ID of the spark-master container\\nRun: docker exec -it <spark_master_container_id> bash\\nRun: cat logs/spark-master.out\\nCheck for the log when the error happened\\nGoogle the error message from there', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails', 'course': 'data-engineering-zoomcamp', 'id': '311bf368'}, 'c1551650': {'text': 'Make sure your java version is 11 or 8.\\nCheck your version by:\\njava --version\\nCheck all your versions by:\\n/usr/libexec/java_home -V\\nIf you already have got java 11 but just not selected as default, select the specific version by:\\nexport JAVA_HOME=$(/usr/libexec/java_home -v 11.0.22)\\n(or other version of 11)', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: ./spark-submit.sh streaming.py Error: py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.', 'course': 'data-engineering-zoomcamp', 'id': 'c1551650'}, 'f9b673cf': {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp', 'id': 'f9b673cf'}, '5479dce2': {'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py', 'course': 'data-engineering-zoomcamp', 'id': '5479dce2'}, '02cf2317': {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal', 'course': 'data-engineering-zoomcamp', 'id': '02cf2317'}, '947c07a6': {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp', 'id': '947c07a6'}, 'bea22953': {'text': 'Situation: in VS Code, usually there will be a triangle icon next to each test. I couldn’t see it at first and had to do some fixes.\\nSolution:\\n(Source)\\nVS Code\\n→ Explorer (first icon on the left navigation bar)\\n→ JAVA PROJECTS (bottom collapsable)\\n→  icon next in the rightmost position to JAVA PROJECTS\\n→  clean Workspace\\n→ Confirm by clicking Reload and Delete\\nNow you will be able to see the triangle icon next to each test like what you normally see in python tests.\\nE.g.:\\nYou can also add classes and packages in this window instead of creating files in the project directory', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: Tests are not picked up in VSCode', 'course': 'data-engineering-zoomcamp', 'id': 'bea22953'}, 'a1603359': {'text': 'In Confluent Cloud:\\nEnvironment → default (or whatever you named your environment as) → The right navigation bar →  “Stream Governance API” →  The URL under “Endpoint”\\nAnd create credentials from Credentials section below it', 'section': 'Module 6: streaming with kafka', 'question': 'Confluent Kafka: Where can I find schema registry URL?', 'course': 'data-engineering-zoomcamp', 'id': 'a1603359'}, 'a85a6a91': {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.', 'section': 'Module 6: streaming with kafka', 'question': 'How do I check compatibility of local and container Spark versions?', 'course': 'data-engineering-zoomcamp', 'id': 'a85a6a91'}, '343864f5': {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead', 'section': 'Project', 'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?', 'course': 'data-engineering-zoomcamp', 'id': '343864f5'}, '6cb3b4a9': {'text': 'Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\\nYou will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\\nThe final grade you get will be the median score of the grades you get from the peer reviewers.\\nAnd of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.', 'section': 'Project', 'question': 'How is my capstone project going to be evaluated?', 'course': 'data-engineering-zoomcamp', 'id': '6cb3b4a9'}, '5959ea3c': {'text': 'There is only ONE project for this Zoomcamp. You do not need to submit or create two projects. There are simply TWO chances to pass the course. You can use the Second Attempt if you a) fail the first attempt b) do not have the time due to other engagements such as holiday or sickness etc. to enter your project into the first attempt.', 'section': 'Project', 'question': 'Project 1 & Project 2', 'course': 'data-engineering-zoomcamp', 'id': '5959ea3c'}, '202af70b': {'text': 'See a list of datasets here: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_7_project/datasets.md', 'section': 'Project', 'question': 'Does anyone know nice and relatively large datasets?', 'course': 'data-engineering-zoomcamp', 'id': '202af70b'}, 'f2705fe7': {'text': 'You need to redefine the python environment variable to that of your user account', 'section': 'Project', 'question': 'How to run python as start up script?', 'course': 'data-engineering-zoomcamp', 'id': 'f2705fe7'}, '74f412c4': {'text': 'Initiate a Spark Session\\nspark = (SparkSession\\n.builder\\n.appName(app_name)\\n.master(master=master)\\n.getOrCreate())\\nspark.streams.resetTerminated()\\nquery1 = spark\\n.readStream\\n…\\n…\\n.load()\\nquery2 = spark\\n.readStream\\n…\\n…\\n.load()\\nquery3 = spark\\n.readStream\\n…\\n…\\n.load()\\nquery1.start()\\nquery2.start()\\nquery3.start()\\nspark.streams.awaitAnyTermination() #waits for any one of the query to receive kill signal or error failure. This is asynchronous\\n# On the contrary query3.start().awaitTermination() is a blocking ex call. Works well when we are reading only from one topic.', 'section': 'Project', 'question': 'Spark Streaming - How do I read from multiple topics in the same Spark Session', 'course': 'data-engineering-zoomcamp', 'id': '74f412c4'}, '5214eb93': {'text': 'Transformed data can be moved in to azure blob storage and then it can be moved in to azure SQL DB, instead of moving directly from databricks to Azure SQL DB.', 'section': 'Project', 'question': 'Data Transformation from Databricks to Azure SQL DB', 'course': 'data-engineering-zoomcamp', 'id': '5214eb93'}, '3cfd16a7': {'text': 'The trial dbt account provides access to dbt API. Job will still be needed to be added manually. Airflow will run the job using a python operator calling the API. You will need to provide api key, job id, etc. (be careful not committing it to Github).\\nDetailed explanation here: https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment\\nSource code example here: https://github.com/sungchun12/airflow-toolkit/blob/95d40ac76122de337e1b1cdc8eed35ba1c3051ed/dags/examples/dbt_cloud_example.py', 'section': 'Project', 'question': 'Orchestrating dbt with Airflow', 'course': 'data-engineering-zoomcamp', 'id': '3cfd16a7'}, 'a7cecdf9': {'text': 'https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/operators/dataproc/index.html\\nhttps://airflow.apache.org/docs/apache-airflow-providers-google/stable/_modules/airflow/providers/google/cloud/operators/dataproc.html\\nGive the following roles to you service account:\\nDataProc Administrator\\nService Account User (explanation here)\\nUse DataprocSubmitPySparkJobOperator, DataprocDeleteClusterOperator and  DataprocCreateClusterOperator.\\nWhen using  DataprocSubmitPySparkJobOperator, do not forget to add:\\ndataproc_jars = [\"gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.24.0.jar\"]\\nBecause DataProc does not already have the BigQuery Connector.', 'section': 'Project', 'question': 'Orchestrating DataProc with Airflow', 'course': 'data-engineering-zoomcamp', 'id': 'a7cecdf9'}, '2aad1011': {'text': 'You can trigger your dbt job in Mage pipeline. For this get your dbt cloud api key under settings/Api tokens/personal tokens. Add it safely to  your .env\\nFor example\\ndbt_api_trigger=dbt_**\\nNavigate to job page and find api trigger  link\\nThen create a custom mage Python block with a simple http request like here\\nfrom dotenv import load_dotenv\\nfrom pathlib import Path\\ndotenv_path = Path(\\'/home/src/.env\\')\\nload_dotenv(dotenv_path=dotenv_path)\\ndbt_api_trigger= os.getenv(dbt_api_trigger)\\nurl = f\"https://cloud.getdbt.com/api/v2/accounts/{dbt_account_id}/jobs/<job_id>/run/\"\\nheaders = {\\n        \"Authorization\": f\"Token {dbt_api_trigger}\",\\n        \"Content-Type\": \"application/json\" }\\nbody = {\\n        \"cause\": \"Triggered via API\"\\n    }\\n    response = requests.post(url, headers=headers, json=body)\\nvoila! You triggered dbt job form your mage pipeline.', 'section': 'Project', 'question': 'Orchestrating dbt cloud with Mage', 'course': 'data-engineering-zoomcamp', 'id': '2aad1011'}, 'cb478996': {'text': \"The slack thread : thttps://datatalks-club.slack.com/archives/C01FABYF2RG/p1677678161866999\\nThe question is that sometimes even if you take plenty of effort to document every single step, and we can't even sure if the person doing the peer review will be able to follow-up, so how this criteria will be evaluated?\\nAlex clarifies: “Ideally yes, you should try to re-run everything. But I understand that not everyone has time to do it, so if you check the code by looking at it and try to spot errors, places with missing instructions and so on - then it's already great”\", 'section': 'Project', 'question': 'Project evaluation - Reproducibility', 'course': 'data-engineering-zoomcamp', 'id': 'cb478996'}, 'b4ef8ca7': {'text': 'The key valut in Azure cloud is used to store credentials or passwords or secrets of different tech stack used in Azure. For example if u do not want to expose the password in SQL database, then we can save the password under a given name and use them in other Azure stack.', 'section': 'Project', 'question': 'Key Vault in Azure cloud stack', 'course': 'data-engineering-zoomcamp', 'id': 'b4ef8ca7'}, '8e74f943': {'text': 'You can get the version of py4j from inside docker using this command\\ndocker exec -it --user airflow airflow-airflow-scheduler-1 bash -c \"ls /opt/spark/python/lib\"', 'section': 'Project', 'question': \"Spark docker - `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', 'id': '8e74f943'}, 'a73ed357': {'text': 'Either use conda or pip for managing venv, using both of them together will cause incompatibility.\\nIf you’re using conda, install psycopg2 using the conda-forge channel, which may handle the architecture compatibility automatically\\nconda install -c conda-forge psycopg2\\nIf pip, do the normal install\\npip install psycopg2', 'section': 'Project', 'question': 'psycopg2 complains of incompatible environment e.g x86 instead of amd', 'course': 'data-engineering-zoomcamp', 'id': 'a73ed357'}, 'd5b6ef5d': {'text': 'This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\\nI had the postgres instance from week 2 (year 2024) up (the docker-compose)\\nmkdir dbt\\nvi dbt/profiles.yml\\nAnd here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\\ncd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\\nmkdir project && cd project && mv dbt-starter-project/* .\\nMake sure that you align the profile name in profiles.yml with the dbt_project.yml file\\nAdd this line anywhere on the dbt_project.yml file:\\nconfig-version: 2\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\nIf you have trouble run\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug', 'section': 'Project', 'question': 'Setting up dbt locally with Docker and Postgres', 'course': 'data-engineering-zoomcamp', 'id': 'd5b6ef5d'}, 'b406d90e': {'text': 'The following line should be included in pyspark configuration\\n# Example initialization of SparkSession variable\\nspark = (SparkSession.builder\\n.master(...)\\n.appName(...)\\n# Add the following configuration\\n.config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-3.5-bigquery:0.37.0\")\\n)', 'section': 'Project', 'question': 'How to connect Pyspark with BigQuery?', 'course': 'data-engineering-zoomcamp', 'id': 'b406d90e'}, '0002ab8b': {'text': 'Install the astronomer-cosmos package as a dependency. (see Terraform example).\\nMake a new folder, dbt/, inside the dags/ folder of your Composer GCP bucket and copy paste your dbt-core project there. (see example)\\nEnsure your profiles.yml is configured to authenticate with a service account key. (see BigQuery example)\\nCreate a new DAG using the DbtTaskGroup class and a ProfileConfig specifying a profiles_yml_filepath that points to the location of your JSON key file. (see example)\\nYour dbt lineage graph should now appear as tasks inside a task group like this:', 'section': 'Course Management Form for Homeworks', 'question': 'How to run a dbt-core project as an Airflow Task Group on Google Cloud Composer using a service account JSON key', 'course': 'data-engineering-zoomcamp', 'id': '0002ab8b'}, '138b55c7': {'text': 'The display name listed on the leaderboard is an auto-generated randomized name. You can edit it to be a nickname, or your real name, if you prefer. Your entry on the Leaderboard is the one highlighted in teal(?) / light green (?).\\nThe Certificate name should be your actual name that you want to appear on your certificate after completing the course.\\nThe \"Display on Leaderboard\" option indicates whether you want your name to be listed on the course leaderboard.\\nQuestion: Is it possible to create external tables in BigQuery using URLs, such as those from the NY Taxi data website?\\nAnswer: Not really, only Bigtable, Cloud Storage, and Google Drive are supported data stores.', 'section': 'Workshop 1 - dlthub', 'question': 'Edit Course Profile.', 'course': 'data-engineering-zoomcamp', 'id': '138b55c7'}, '154d7705': {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\", 'section': 'Workshop 1 - dlthub', 'question': 'How do I install the necessary dependencies to run the code?', 'course': 'data-engineering-zoomcamp', 'id': '154d7705'}, 'f96517d9': {'text': 'If you are running Jupyter Notebook on a fresh new Codespace or in local machine with a new Virtual Environment, you will need this package to run the starter Jupyter Notebook offered by the teacher. Execute this:\\npip install jupyter', 'section': 'Workshop 1 - dlthub', 'question': 'Other packages needed but not listed', 'course': 'data-engineering-zoomcamp', 'id': 'f96517d9'}, '773587dd': {'text': 'Alternatively, you can switch to in-file storage with:', 'section': 'Workshop 1 - dlthub', 'question': 'How can I use DuckDB In-Memory database with dlt ?', 'course': 'data-engineering-zoomcamp', 'id': '773587dd'}, '73aff710': {'text': 'After loading, you should have a total of 8 records, and ID 3 should have age 33\\nQuestion: Calculate the sum of ages of all the people loaded as described above\\nThe sum of all eight records\\' respective ages is too big to be in the choices. You need to first filter out the people whose occupation is equal to None in order to get an answer that is close to or present in the given choices. 😃\\n----------------------------------------------------------------------------------------\\nFIXED = use a raw string and keep the file:/// at the start of your file path\\nI\\'m having an issue with the dlt workshop notebook. The \\'Load to Parquet file\\' section specifically. No matter what I change the file path to, it\\'s still saving the dlt files directly to my C drive.\\n# Set the bucket_url. We can also use a local folder\\nos.environ[\\'DESTINATION__FILESYSTEM__BUCKET_URL\\'] = r\\'file:///content/.dlt/my_folder\\'\\nurl = \"https://storage.googleapis.com/dtc_zoomcamp_api/yellow_tripdata_2009-06.jsonl\"\\n# Define your pipeline\\npipeline = dlt.pipeline(\\npipeline_name=\\'my_pipeline\\',\\ndestination=\\'filesystem\\',\\ndataset_name=\\'mydata\\'\\n)\\n# Run the pipeline with the generator we created earlier.\\nload_info = pipeline.run(stream_download_jsonl(url), table_name=\"users\", loader_file_format=\"parquet\")\\nprint(load_info)\\n# Get a list of all Parquet files in the specified folder\\nparquet_files = glob.glob(\\'/content/.dlt/my_folder/mydata/users/*.parquet\\')\\n# show parquet files\\nfor file in parquet_files:\\nprint(file)', 'section': 'Workshop 2 - RisingWave', 'question': 'Homework - dlt Exercise 3 - Merge a generator concerns', 'course': 'data-engineering-zoomcamp', 'id': '73aff710'}, '0728ca67': {'text': 'Check the contents of the repository with ls - the command.sh file should be in the root folder\\nIf it is not, verify that you had cloned the correct repository - https://github.com/risingwavelabs/risingwave-data-talks-workshop-2024-03-04', 'section': 'Workshop 2 - RisingWave', 'question': 'command.sh Error - source: no such file or directory: command.sh', 'course': 'data-engineering-zoomcamp', 'id': '0728ca67'}, '49a51e24': {'text': \"psql is a command line tool that is installed alongside PostgreSQL DB, but since we've always been running PostgreSQL in a container, you've only got `pgcli`, which lacks the feature to run a sql script into the DB. Besides, having a command line for each database flavor you'll have to deal with as a Data Professional is far from ideal.\\nSo, instead, you can use usql. Check the docs for details on how to install for your OS. On macOS, it supports `homebrew`, and on Windows, it supports scoop.\\nSo, to run the taxi_trips.sql script with usql:\", 'section': 'Workshop 2 - RisingWave', 'question': 'psql - command not found: psql (alternative install)', 'course': 'data-engineering-zoomcamp', 'id': '49a51e24'}, 'f0d552a7': {'text': 'If you encounter this error and are certain that you have docker compose installed, but typically run it as docker compose without the hyphen, then consider editing command.sh file by removing the hyphen from ‘docker-compose’. Example:\\nstart-cluster() {\\ndocker compose -f docker/docker-compose.yml up -d\\n}', 'section': 'Workshop 2 - RisingWave', 'question': 'Setup - source command.sh - error: “docker-compose” not found', 'course': 'data-engineering-zoomcamp', 'id': 'f0d552a7'}, '9c750080': {'text': 'ERROR: The Compose file \\'./docker/docker-compose.yml\\' is invalid because:\\nInvalid top-level property \"x-image\". Valid top-level sections for this Compose file are: version, services, networks, volumes, secrets, configs, and extensions starting with \"x-\".\\nYou might be seeing this error because you\\'re using the wrong Compose file version. Either specify a supported version (e.g \"2.2\" or \"3.3\") and place your service definitions under the `services` key, or omit the `version` key and place your service definitions at the root of the file to use version 1.\\nFor more on the Compose file format versions, see https://docs.docker.com/compose/compose-file/\\nIf you encounter the above error and have docker-compose installed, try updating your version of docker-compose. At the time of reporting this issue (March 17 2024), Ubuntu does not seem to support a docker-compose version high enough to run the required docker images. If you have this error and are on a Ubuntu machine, consider starting a VM with a Debian machine or look for an alternative way to download docker-compose at the latest version on your machine.', 'section': 'Workshop 2 - RisingWave', 'question': 'Setup - start-cluster error: Invalid top-level property x-image', 'course': 'data-engineering-zoomcamp', 'id': '9c750080'}, '6f4998e6': {'text': 'Ans: [source] Yes, it is so that we can observe the changes as we’re working on the queries in real-time. The script is changing the date timestamp to the current time, so our queries with the now()filter would work. Open another terminal tab to copy+paste the queries while the stream-kafka script is running in the background.\\nNoel: I have recently increased this up to 100 at a time, you may pull the latest changes from the repository.', 'section': 'Workshop 2 - RisingWave', 'question': 'stream-kafka Qn: Is it expected that the records are being ingested 10 at a time?', 'course': 'data-engineering-zoomcamp', 'id': '6f4998e6'}, '97170587': {'text': 'Ans: No, it is not.', 'section': 'Workshop 2 - RisingWave', 'question': 'Setup - Qn: Is kafka install required for the RisingWave workshop? [source]', 'course': 'data-engineering-zoomcamp', 'id': '97170587'}, '4def6541': {'text': 'Ans: about 7GB free for all the containers to be provisioned and then the psql still needs to run and ingest the taxi data, so maybe 10gb in total?', 'section': 'Workshop 2 - RisingWave', 'question': 'Setup - Qn: How much free disk space should we have? [source]', 'course': 'data-engineering-zoomcamp', 'id': '4def6541'}, '66e117dd': {'text': 'Replace psycopg2==2.9.9 with psycopg2-binary in the requirements.txt file [source] [another]\\nWhen you open another terminal to run the psql, remember to do the source command.sh step for each terminal session\\n---------------------------------------------------------------------------------------------', 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 - issues when running stream-kafka script', 'course': 'data-engineering-zoomcamp', 'id': '66e117dd'}, '94fd2476': {'text': \"If you’re using an Anaconda installation:\\nCd home/\\nConda install gcc\\nSource back to your RisingWave Venv - source .venv/bin/activate\\nPip install psycopg2-binary\\nPip install -r requirements.txt\\nFor some reason this worked - the Conda base doesn’t have the GCC installed - (GNU Compiler Collection) a compiler system that supports various programming languages. Without this the it fails to install pyproject.toml-based projects\\n“It's possible that in your specific environment, the gcc installation was required at the system level rather than within the virtual environment. This can happen if the build process for psycopg2 tries to access system-level dependencies during installation.\\nInstalling gcc in your main Python installation (Conda) would make it available system-wide, allowing any Python environment to access it when necessary for building packages.”\\ngcc stands for GNU Compiler Collection. It is a compiler system developed by the GNU Project that supports various programming languages, including C, C++, Objective-C, and Fortran.\\nGCC is widely used for compiling source code written in these languages into executable programs or libraries. It's a key tool in the software development process, particularly in the compilation stage where source code is translated into machine code that can be executed by a computer's processor.\\nIn addition to compiling source code, GCC also provides various optimization options, debugging support, and extensive documentation, making it a powerful and versatile tool for developers across different platforms and architectures.\\n—-----------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 - `Could not build wheels for psycopg2, which is required to install pyproject.toml-based projects`', 'course': 'data-engineering-zoomcamp', 'id': '94fd2476'}, '70d83d78': {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.', 'course': 'data-engineering-zoomcamp', 'id': '70d83d78'}, 'accb7285': {'text': 'In case the script gets stuck on\\n%3|1709652240.100|FAIL|rdkafka#producer-2| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)gre\\nafter trying to load the trip data, check the logs of the message_queue container in docker. If it keeps restarting with Could not initialize seastar: std::runtime_error (insufficient physical memory: needed 4294967296 available 4067422208)  as the last message, then go to the docker-compose file in the docker folder of the project and change the ‘memory’ command for the message_queue service for some lower value.\\nSolution: lower the memory allocation of the service “message_queue” in your docker-compose file from 4GB. If you have the “insufficient physical memory” error message (try 3GB)\\nIssue: Running psql -f risingwave-sql/table/trip_data.sql after starting services with ‘default’ values using docker-compose up gives the error  “psql:risingwave-sql/table/trip_data.sql:61: ERROR:  syntax error at or near \".\" LINE 60:       properties.bootstrap.server=\\'message_queue:29092\\'”\\nSolution: Make sure you have run source commands.sh in each terminal window', 'section': 'Workshop 2 - RisingWave', 'question': 'Running stream-kafka script gets stuck on a loop with Connection Refused', 'course': 'data-engineering-zoomcamp', 'id': 'accb7285'}, 'cbca4495': {'text': 'Use seed-kafka instead of stream-kafka to get a static set of results.', 'section': 'Workshop 2 - RisingWave', 'question': 'For the homework questions is there a specific number of records that have to be processed to obtain the final answer?', 'course': 'data-engineering-zoomcamp', 'id': 'cbca4495'}, '78fce6ad': {'text': 'It is best to use the order by and limit clause on the query to the materialized view instead of the materialized view creation in order to guarantee consistent results\\nHomework - The answers in the homework do not match the provided options: You must follow the following steps: 1. clean-cluster 2. docker volume prune and use seed-kafka instead of stream-kafka. Ensure that the number of records is 100K.', 'section': 'Workshop 2 - RisingWave', 'question': 'Homework - Materialized view does not guarantee order by warning', 'course': 'data-engineering-zoomcamp', 'id': '78fce6ad'}, '68842c02': {'text': 'For this workshop, and if you are following the view from Noel (2024) this requires you to install postgres to use it on your terminal. Found this steps (commands) to get it done [source]:\\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\\nsudo sh -c \\'echo \"deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main\" >> /etc/apt/sources.list.d/pgdg.list\\'\\nsudo apt update\\napt install postgresql postgresql-contrib\\n(comment): now let’s check the service for postgresql\\nservice postgresql status\\n(comment) If down: use the next command\\nservice postgresql start\\n(comment) And your are done', 'section': 'Workshop 2 - RisingWave', 'question': 'How to install postgress on Linux like OS', 'course': 'data-engineering-zoomcamp', 'id': '68842c02'}, '71b1984b': {'text': 'Refer to the solution given in the first solution here:\\nhttps://stackoverflow.com/questions/24683221/xdg-open-no-method-available-even-after-installing-xdg-utils\\nInstead of w3m use any other browser of your choice.\\nIt is just trying to open the index.html file. Which you can do from your File Explorer/Finder. If you’re on wsl try using explorer.exe index.html', 'section': 'Workshop 2 - RisingWave', 'question': 'Unable to Open Dashboard as xdg-open doesn’t open any browser', 'course': 'data-engineering-zoomcamp', 'id': '71b1984b'}, 'd452b490': {'text': 'Example Error:\\nWhen attempting to execute a Python script named seed-kafka.py or server.py with the following shebang line specifying Python 3 as the interpreter:\\nUsers may encounter the following error in a Unix-like environment:\\nThis error indicates that there is a problem with the Python interpreter path specified in the shebang line. The presence of the \\\\r character suggests that the script was edited or created in a Windows environment, causing the interpreter path to be incorrect when executed in Unix-like environments.\\n2 Solutions:\\nEither one or the other\\nUpdate Shebang Line:\\nVerify Python Interpreter Path: Use the which python3 command to determine the path to the Python 3 interpreter available in the current environment.\\nUpdate Shebang Line: Open the script file in a text editor. Modify the shebang line to point to the correct Python interpreter path found in the previous step. Ensure that the shebang line is consistent with the Python interpreter path in the execution environment.\\nExample Shebang Line:\\nReplace /usr/bin/env python3 with the correct Python interpreter path found using which python3.\\nConvert Line Endings:\\nUse the dos2unix command-line tool to convert the line endings of the script from Windows-style to Unix-style.\\nThis removes the extraneous carriage return characters (\\\\r), resolving issues related to unexpected tokens and ensuring compatibility with Unix-like environments.\\nExample Command:', 'section': 'Workshop 2 - RisingWave', 'question': 'Resolving Python Interpreter Path Inconsistencies in Unix-like Environments', 'course': 'data-engineering-zoomcamp', 'id': 'd452b490'}, '707cae8f': {'text': 'Ans : Windowing in streaming SQL involves defining a time-based or row-based boundary for data processing. It allows you to analyze and aggregate data over specific time intervals or based on the number of events received, providing a way to manage and organize streaming data for analysis.', 'section': 'Workshop 2 - RisingWave', 'question': 'How does windowing work in Sql?', 'course': 'data-engineering-zoomcamp', 'id': '707cae8f'}, 'ffbf3311': {'text': 'Python 3.12.1, is not compatible with kafka-python-2.0.2. Therefore, instead of running \"pip install kafka-python\", you can resolve the issue by using \"pip install git+https://github.com/dpkp/kafka-python.git\". If you have already installed kafka-python, you need to run \"pip uninstall kafka-python\" before executing \"pip install git+https://github.com/dpkp/kafka-python.git\" to resolve the compatibility issue.\\nQ:In the Mage pipeline, individual blocks run successfully. However, when executing the pipeline as a whole, some blocks fail.\\nA: I have the following key-value pair in io_config.yaml file configured but still Mage blocks failed to generate OAuth and authenticate with GCP: GOOGLE_SERVICE_ACC_KEY_FILEPATH: \"{{ env_var(\\'GCP_CREDENTIALS\\') }}\". The GCP_CREDENTIALS variable holds the full path to the service account key\\'s JSON file. Adding the following line within the failed code block resolved the issue: os.environ[\\'GOOGLE_APPLICATION_CREDENTIALS\\'] = os.environ.get(\\'GCP_CREDENTIALS\\').\\nThis occurs because the path to profiles.yml is not correctly specified. You can rectify this by:\\n“export DBT_PROFILES_DBT=path/to/profiles.yml”\\nEg., /home/src/magic-zoomcamp/dbt/project_name/\\nDo the similar for DBT_PROJECT_DIR if getting similar issue with dbt_project.yml.\\nOnce DIRs are set,:\\n“dbt debug –config-dir”\\nThis would update your paths. To maintain same path across sessions, use the path variables in your .env file.\\nTo add triggers in mage pipelines via CLI, you can create a trigger of type API, and copy the API links.\\nEg. link: http://localhost:6789/api/pipeline_schedules/10/pipeline_runs/f3a1a4228fc64cfd85295b668c93f3b2\\nThen create a trigger.py as such:\\nimport os\\nimport requests\\nclass MageTrigger:\\nOPTIONS = {\\n\"<pipeline_name>\": {\\n\"trigger_id\": 10,\\n\"key\": \"f3a1a4228fc64cfd85295b668c93f3b2\"\\n}\\n}\\n@staticmethod\\ndef trigger_pipeline(pipeline_name, variables=None):\\ntrigger_id = MageTrigger.OPTIONS[pipeline_name][\"trigger_id\"]\\nkey = MageTrigger.OPTIONS[pipeline_name][\"key\"]\\nendpoint = f\"http://localhost:6789/api/pipeline_schedules/{trigger_id}/pipeline_runs/{key}\"\\nheaders = {\\'Content-Type\\': \\'application/json\\'}\\npayload = {}\\nif variables is not None:\\npayload[\\'pipeline_run\\'] = {\\'variables\\': variables}\\nresponse = requests.post(endpoint, headers=headers, json=payload)\\nreturn response\\nMageTrigger.trigger_pipeline(\"<pipeline_name>\")\\nFinally, after the mage server is up an running, simply this command:\\npython trigger.py from mage directory in terminal.\\nCan I do data partitioning & clustering run by dbt pipeline, or I would need to do this manually in BigQuery afterwards?\\nYou can use this configuration in your DBT model:\\n{\\n\"field\": \"<field name>\",\\n\"data_type\": \"<timestamp | date | datetime | int64>\",\\n\"granularity\": \"<hour | day | month | year>\"\\n# Only required if data_type is \"int64\"\\n\"range\": {\\n\"start\": <int>,\\n\"end\": <int>,\\n\"interval\": <int>\\n}\\n}\\nand for clustering\\n{{\\nconfig(\\nmaterialized = \"table\",\\ncluster_by = \"order_id\",\\n)\\n}}\\nmore details in: https://docs.getdbt.com/reference/resource-configs/bigquery-configs', 'section': 'Triggers in Mage via CLI', 'question': 'Encountering the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\" when running \"from kafka import KafkaProducer\" in Jupyter Notebook for Module 6 Homework?', 'course': 'data-engineering-zoomcamp', 'id': 'ffbf3311'}, '3916f4a9': {'text': 'Docker Commands\\n# Create a Docker Image from a base image\\nDocker run -it ubuntu bash\\n#List docker images\\nDocker images list\\n#List  Running containers\\nDocker ps -a\\n#List with full container ids\\nDocker ps -a --no-trunc\\n#Add onto existing image to create new image\\nDocker commit -a <User_Name> -m \"Message\" container_id New_Image_Name\\n# Create a Docker Image with an entrypoint from a base image\\nDocker run -it --entry_point=bash python:3.11\\n#Attach to a stopped container\\nDocker start -ai <Container_Name>\\n#Attach to a running container\\ndocker exec -it <Container_ID> bash\\n#copying from host to container\\nDocker cp <SRC_PATH/file> <containerid>:<dest_path>\\n#copying from container to host\\nDocker cp <containerid>:<Srct_path> <Dest Path on host/file>\\n#Create an image from a docker file\\nDocker build -t <Image_Name> <Location of Dockerfile>\\n#DockerFile Options and best practices\\nhttps://devopscube.com/build-docker-image/\\n#Docker delete all images forcefully\\ndocker rmi -f $(docker images -aq)\\n#Docker delete all containers forcefully\\ndocker rm -f $(docker ps -qa)\\n#docker compose creation\\nhttps://www.composerize.com/\\nGCP Commands\\n1.     Create SSH Keys\\n2.     Added to the Settings of Compute Engine VM Instance\\n3.     SSH-ed into the VM Instance with a config similar to following\\nHost my-website.com\\nHostName my-website.com\\nUser my-user\\nIdentityFile ~/.ssh/id_rsa\\n4.     Installed Anaconda by installing the sh file through bash <Anaconda.sh>\\n5.     Install Docker after\\na.     Sudo apt-get update\\nb.     Sudo apt-get docker\\n6.     To run Docker without SUDO permissions\\na.     https://github.com/sindresorhus/guides/blob/main/docker-without-sudo.md\\n7.     Google cloud remote copy\\na.     gcloud compute scp LOCAL_FILE_PATHVM_NAME:REMOTE_DIR\\nInstall GCP Cloud SDK on Docker Machine\\nhttps://stackoverflow.com/questions/23247943/trouble-installing-google-cloud-sdk-in-ubuntu\\nsudo apt-get install apt-transport-https ca-certificates gnupg && echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\"| sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list&& curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - && sudo apt-get update && sudo apt-get install google-cloud-sdk && sudo apt-get install google-cloud-sdk-app-engine-java && sudo apt-get install google-cloud-sdk-app-engine-python && gcloud init\\nAnaconda Commands\\n#Activate environment\\nConda Activate <environment_name>\\n#DeActivate environment\\nConda DeActivate <environment_name>\\n#Start iterm without conda environment\\nconda config --set auto_activate_base false\\n# Using Conda forge as default (Community driven packaging recipes and solutions)\\nhttps://conda-forge.org/docs/user/introduction.html\\nconda --version\\nconda update conda\\nconda config --add channels conda-forge\\nconda config --set channel_priority strict\\n#Using Libmamba as Solver\\nconda install pgcli  --solver=libmamba\\nLinux/MAC Commands\\nStarting and Stopping Services on Linux\\n●  \\tsudo systemctl start postgresql\\n●  \\tsudo systemctl stop postgresql\\nStarting and Stopping Services on MAC\\n●      launchctl start postgresql\\n●      launchctl stop postgresql\\nIdentifying processes listening to a Port across MAC/Linux\\nsudo lsof -i -P -n | grep LISTEN\\n$ sudo netstat -tulpn | grep LISTEN\\n$ sudo ss -tulpn | grep LISTEN\\n$ sudo lsof -i:22 ## see a specific port such as 22 ##\\n$ sudo nmap -sTU -O IP-address-Here\\nInstalling a package on Debian\\nsudo apt install <packagename>\\nListing all package on Debian\\nDpkg -l | grep <packagename>\\nUnInstalling a package on Debian\\nSudo apt remove <packagename>\\nSudo apt autoclean  && sudo apt autoremove\\nList all Processes on Debian/Ubuntu\\nPs -aux\\napt-get update && apt-get install procps\\napt-get install iproute2 for ss -tulpn\\n#Postgres Install\\nsudo sh -c \\'echo \"deb https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list\\'\\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\\nsudo apt-get update\\nsudo apt-get -y install postgresql\\n#Changing Postgresql port to 5432\\n- sudo service postgresql stop - sed -e \\'s/^port.*/port = 5432/\\' /etc/postgresql/10/main/postgresql.conf > postgresql.conf\\n- sudo chown postgres postgresql.conf\\n- sudo mv postgresql.conf /etc/postgresql/10/main\\n- sudo systemctl restart postgresql', 'section': 'Triggers in Mage via CLI', 'question': 'Basic Commands', 'course': 'data-engineering-zoomcamp', 'id': '3916f4a9'}, '0227b872': {'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork', 'section': 'General course-related questions', 'question': 'How do I sign up?', 'course': 'machine-learning-zoomcamp', 'id': '0227b872'}, '39fda9f0': {'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.', 'section': 'General course-related questions', 'question': 'Is it going to be live? When?', 'course': 'machine-learning-zoomcamp', 'id': '39fda9f0'}, '5170565b': {'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.', 'section': 'General course-related questions', 'question': 'What if I miss a session?', 'course': 'machine-learning-zoomcamp', 'id': '5170565b'}, 'ecca790c': {'text': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\", 'section': 'General course-related questions', 'question': 'How much theory will you cover?', 'course': 'machine-learning-zoomcamp', 'id': 'ecca790c'}, 'c25b3de4': {'text': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\", 'section': 'General course-related questions', 'question': \"I don't know math. Can I take the course?\", 'course': 'machine-learning-zoomcamp', 'id': 'c25b3de4'}, '6ba259b1': {'text': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\", 'section': 'General course-related questions', 'question': \"I filled the form, but haven't received a confirmation email. Is it normal?\", 'course': 'machine-learning-zoomcamp', 'id': '6ba259b1'}, '67e2fd13': {'text': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)', 'section': 'General course-related questions', 'question': 'How long is the course?', 'course': 'machine-learning-zoomcamp', 'id': '67e2fd13'}, 'a6897e8c': {'text': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article', 'section': 'General course-related questions', 'question': 'How much time do I need for this course?', 'course': 'machine-learning-zoomcamp', 'id': 'a6897e8c'}, '2eba08e3': {'text': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.', 'section': 'General course-related questions', 'question': 'Will I get a certificate?', 'course': 'machine-learning-zoomcamp', 'id': '2eba08e3'}, '1d644223': {'text': \"Yes, it's possible. See the previous answer.\", 'section': 'General course-related questions', 'question': 'Will I get a certificate if I missed the midterm project?', 'course': 'machine-learning-zoomcamp', 'id': '1d644223'}, '14890cd2': {'text': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)', 'section': 'General course-related questions', 'question': 'How much Python should I know?', 'course': 'machine-learning-zoomcamp', 'id': '14890cd2'}, 'a4fad482': {'text': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)', 'section': 'General course-related questions', 'question': \"Any particular hardware requirements for the course or everything is mostly cloud? TIA! Couldn't really find this in the FAQ.\", 'course': 'machine-learning-zoomcamp', 'id': 'a4fad482'}, '34b7fd35': {'text': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/', 'section': 'General course-related questions', 'question': 'How to setup TensorFlow with GPU support on Ubuntu?', 'course': 'machine-learning-zoomcamp', 'id': '34b7fd35'}, '4930aa19': {'text': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\", 'section': 'General course-related questions', 'question': 'I’m new to Slack and can’t find the course channel. Where is it?', 'course': 'machine-learning-zoomcamp', 'id': '4930aa19'}, 'ee58a693': {'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp', 'id': 'ee58a693'}, '636f55d5': {'text': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).', 'section': 'General course-related questions', 'question': 'When does the next iteration start?', 'course': 'machine-learning-zoomcamp', 'id': '636f55d5'}, 'c839b764': {'text': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.', 'section': 'General course-related questions', 'question': 'Can I submit the homework after the due date?', 'course': 'machine-learning-zoomcamp', 'id': 'c839b764'}, '0a278fb2': {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus', 'section': 'General course-related questions', 'question': 'I just joined. What should I do next? How can I access course materials?', 'course': 'machine-learning-zoomcamp', 'id': '0a278fb2'}, '8de4fefd': {'text': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)', 'section': 'General course-related questions', 'question': 'What are the deadlines in this course?', 'course': 'machine-learning-zoomcamp', 'id': '8de4fefd'}, '94e86808': {'text': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.', 'section': 'General course-related questions', 'question': 'What’s the difference between the previous iteration of the course (2022) and this one (2023)?', 'course': 'machine-learning-zoomcamp', 'id': '94e86808'}, 'e7ba6b8a': {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.', 'section': 'General course-related questions', 'question': 'The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?', 'course': 'machine-learning-zoomcamp', 'id': 'e7ba6b8a'}, 'f7bc2f65': {'text': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.', 'section': 'General course-related questions', 'question': 'Submitting learning in public links', 'course': 'machine-learning-zoomcamp', 'id': 'f7bc2f65'}, 'ae52a907': {'text': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\", 'section': 'General course-related questions', 'question': 'Adding community notes', 'course': 'machine-learning-zoomcamp', 'id': 'ae52a907'}, 'dab5a24a': {'text': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\", 'section': '1. Introduction to Machine Learning', 'question': 'Computing the hash for the leaderboard and project review', 'course': 'machine-learning-zoomcamp', 'id': 'dab5a24a'}, '49f9bda9': {'text': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)', 'section': '1. Introduction to Machine Learning', 'question': 'wget is not recognized as an internal or external command', 'course': 'machine-learning-zoomcamp', 'id': '49f9bda9'}, 'd44de7d1': {'text': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/', 'section': '1. Introduction to Machine Learning', 'question': 'Retrieving csv inside notebook', 'course': 'machine-learning-zoomcamp', 'id': 'd44de7d1'}, '314ebe32': {'text': '(Tyler Simpson)', 'section': '1. Introduction to Machine Learning', 'question': 'Windows WSL and VS Code\\nIf you have a Windows 11 device and would like to use the built in WSL to access linux you can use the Microsoft Learn link Set up a WSL development environment | Microsoft Learn. To connect this to VS Code download the Microsoft verified VS Code extension ‘WSL’ this will allow you to remotely connect to your WSL Ubuntu instance as if it was a virtual machine.', 'course': 'machine-learning-zoomcamp', 'id': '314ebe32'}, '98cff602': {'text': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)', 'section': '1. Introduction to Machine Learning', 'question': 'Uploading the homework to Github', 'course': 'machine-learning-zoomcamp', 'id': '98cff602'}, '54ec0de4': {'text': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\", 'section': '1. Introduction to Machine Learning', 'question': 'Singular Matrix Error', 'course': 'machine-learning-zoomcamp', 'id': '54ec0de4'}, 'f81f4ecb': {'text': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)', 'section': '1. Introduction to Machine Learning', 'question': 'Conda is not an internal command', 'course': 'machine-learning-zoomcamp', 'id': 'f81f4ecb'}, 'be760b92': {'text': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)', 'section': '1. Introduction to Machine Learning', 'question': 'Read-in the File in Windows OS', 'course': 'machine-learning-zoomcamp', 'id': 'be760b92'}, 'a2cfa1c9': {'text': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)', 'section': '1. Introduction to Machine Learning', 'question': \"'403 Forbidden' error message when you try to push to a GitHub repository\", 'course': 'machine-learning-zoomcamp', 'id': 'a2cfa1c9'}, '7b907071': {'text': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\", 'section': '1. Introduction to Machine Learning', 'question': \"Fatal: Authentication failed for 'https://github.com/username\", 'course': 'machine-learning-zoomcamp', 'id': '7b907071'}, 'fc2e0a61': {'text': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\", 'section': '1. Introduction to Machine Learning', 'question': \"wget: unable to resolve host address 'raw.githubusercontent.com'\", 'course': 'machine-learning-zoomcamp', 'id': 'fc2e0a61'}, 'd43e5742': {'text': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)', 'section': '1. Introduction to Machine Learning', 'question': 'Setting up an environment using VS Code', 'course': 'machine-learning-zoomcamp', 'id': 'd43e5742'}, '32bc0538': {'text': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml', 'section': '1. Introduction to Machine Learning', 'question': 'Conda Environment Setup', 'course': 'machine-learning-zoomcamp', 'id': '32bc0538'}, 'b6730228': {'text': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\", 'section': '1. Introduction to Machine Learning', 'question': 'Floating Point Precision', 'course': 'machine-learning-zoomcamp', 'id': 'b6730228'}, '3ce9bbb8': {'text': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)', 'section': '1. Introduction to Machine Learning', 'question': 'What does pandas.DataFrame.info() do?', 'course': 'machine-learning-zoomcamp', 'id': '3ce9bbb8'}, '4e584d06': {'text': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\", 'section': '1. Introduction to Machine Learning', 'question': \"NameError: name 'np' is not defined\", 'course': 'machine-learning-zoomcamp', 'id': '4e584d06'}, 'ff4da2b6': {'text': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\", 'section': '1. Introduction to Machine Learning', 'question': 'How to select column by dtype', 'course': 'machine-learning-zoomcamp', 'id': 'ff4da2b6'}, '58c1c168': {'text': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi', 'section': '1. Introduction to Machine Learning', 'question': 'How to identify the shape of dataset in Pandas', 'course': 'machine-learning-zoomcamp', 'id': '58c1c168'}, '96076a1a': {'text': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera', 'section': '1. Introduction to Machine Learning', 'question': 'How to avoid Value errors with array shapes in homework?', 'course': 'machine-learning-zoomcamp', 'id': '96076a1a'}, '3218389a': {'text': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar', 'section': '1. Introduction to Machine Learning', 'question': 'Question 5: How and why do we replace the NaN values with average of the column?', 'course': 'machine-learning-zoomcamp', 'id': '3218389a'}, '183a1c90': {'text': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach', 'section': '1. Introduction to Machine Learning', 'question': 'Question 7: Mathematical formula for linear regression', 'course': 'machine-learning-zoomcamp', 'id': '183a1c90'}, 'f0bc1c19': {'text': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu', 'section': '1. Introduction to Machine Learning', 'question': 'Question 7: FINAL MULTIPLICATION not having 5 column', 'course': 'machine-learning-zoomcamp', 'id': 'f0bc1c19'}, '735e6c78': {'text': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin', 'section': '1. Introduction to Machine Learning', 'question': 'Question 7: Multiplication operators.', 'course': 'machine-learning-zoomcamp', 'id': '735e6c78'}, 'b8ca1cd3': {'text': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak', 'section': '1. Introduction to Machine Learning', 'question': 'Error launching Jupyter notebook', 'course': 'machine-learning-zoomcamp', 'id': 'b8ca1cd3'}, 'efdb235f': {'text': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again', 'section': '1. Introduction to Machine Learning', 'question': 'wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv hangs on MacOS Ventura M1', 'course': 'machine-learning-zoomcamp', 'id': 'efdb235f'}, '355348f0': {'text': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\", 'section': '1. Introduction to Machine Learning', 'question': 'In case you are using mac os and having trouble with WGET', 'course': 'machine-learning-zoomcamp', 'id': '355348f0'}, '67afabf5': {'text': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\", 'section': '2. Machine Learning for Regression', 'question': 'How to output only a certain number of decimal places', 'course': 'machine-learning-zoomcamp', 'id': '67afabf5'}, '50d737e7': {'text': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~', 'section': '2. Machine Learning for Regression', 'question': 'How do I get started with Week 2?', 'course': 'machine-learning-zoomcamp', 'id': '50d737e7'}, 'bbc0fca3': {'text': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)', 'section': '2. Machine Learning for Regression', 'question': 'Checking long tail of data', 'course': 'machine-learning-zoomcamp', 'id': 'bbc0fca3'}, '6f3bdd20': {'text': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)', 'section': '2. Machine Learning for Regression', 'question': 'LinAlgError: Singular matrix', 'course': 'machine-learning-zoomcamp', 'id': '6f3bdd20'}, '27c2d90a': {'text': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS', 'section': '2. Machine Learning for Regression', 'question': 'California housing dataset', 'course': 'machine-learning-zoomcamp', 'id': '27c2d90a'}, '88e9600a': {'text': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada', 'section': '2. Machine Learning for Regression', 'question': 'Getting NaNs after applying .mean()', 'course': 'machine-learning-zoomcamp', 'id': '88e9600a'}, 'd59d8df7': {'text': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto', 'section': '2. Machine Learning for Regression', 'question': 'Target variable transformation', 'course': 'machine-learning-zoomcamp', 'id': 'd59d8df7'}, '0b3eaf92': {'text': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand', 'section': '2. Machine Learning for Regression', 'question': 'Reading the dataset directly from github', 'course': 'machine-learning-zoomcamp', 'id': '0b3eaf92'}, '8fe56032': {'text': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\", 'section': '2. Machine Learning for Regression', 'question': 'Loading the dataset directly through Kaggle Notebooks', 'course': 'machine-learning-zoomcamp', 'id': '8fe56032'}, 'af833e0a': {'text': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi', 'section': '2. Machine Learning for Regression', 'question': 'Filter a dataset by using its values', 'course': 'machine-learning-zoomcamp', 'id': 'af833e0a'}, '8d209d6d': {'text': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson', 'section': '2. Machine Learning for Regression', 'question': 'Alternative way to load the data using requests', 'course': 'machine-learning-zoomcamp', 'id': '8d209d6d'}, '0bc4c3da': {'text': 'When creating a duplicate of your dataframe by doing the following:\\nX_train = df_train\\nX_val = df_val\\nYou’re still referencing the original variable, this is called a shallow copy. You can make sure that no references are attaching both variables and still keep the copy of the data do the following to create a deep copy:\\nX_train = df_train.copy()\\nX_val = df_val.copy()\\nAdded by Ixchel García', 'section': '2. Machine Learning for Regression', 'question': 'Null column is appearing even if I applied .fillna()', 'course': 'machine-learning-zoomcamp', 'id': '0bc4c3da'}, 'c0ee2665': {'text': 'Yes, you can. Here we implement it ourselves to better understand how it works, but later we will only rely on Scikit-Learn’s functions. If you want to start using it earlier — feel free to do it', 'section': '2. Machine Learning for Regression', 'question': 'Can I use Scikit-Learn’s train_test_split for this week?', 'course': 'machine-learning-zoomcamp', 'id': 'c0ee2665'}, '3f60871d': {'text': 'Yes, you can. We will also do that next week, so don’t worry, you will learn how to do it.', 'section': '2. Machine Learning for Regression', 'question': 'Can I use LinearRegression from Scikit-Learn for this week?', 'course': 'machine-learning-zoomcamp', 'id': '3f60871d'}, 'f30217a7': {'text': 'What are equivalents in Scikit-Learn for the linear regression with and without regularization used in week 2.\\nCorresponding function for model without regularization:\\nsklearn.linear_model.LinearRegression\\nCorresponding function for model with regularization:\\nsklearn.linear_model.Ridge\\nThe linear model from Scikit-Learn are explained  here:\\nhttps://scikit-learn.org/stable/modules/linear_model.html\\nAdded by Sylvia Schmitt', 'section': '2. Machine Learning for Regression', 'question': 'Corresponding Scikit-Learn functions for Linear Regression (with and without Regularization)', 'course': 'machine-learning-zoomcamp', 'id': 'f30217a7'}, '91fc573d': {'text': '`r` is a regularization parameter.\\nIt’s similar to `alpha` in sklearn.Ridge(), as both control the \"strength\" of regularization (increasing both will lead to stronger regularization), but mathematically not quite, here\\'s how both are used:\\nsklearn.Ridge()\\n||y - Xw||^2_2 + alpha * ||w||^2_2\\nlesson’s notebook (`train_linear_regression_reg` function)\\nXTX = XTX + r * np.eye(XTX.shape[0])\\n`r` adds “noise” to the main diagonal to prevent multicollinearity, which “breaks” finding inverse matrix.', 'section': '2. Machine Learning for Regression', 'question': 'Question 4: what is `r`, is it the same as `alpha` in sklearn.Ridge()?', 'course': 'machine-learning-zoomcamp', 'id': '91fc573d'}, 'fe3139f6': {'text': 'Q: “In lesson 2.8 why is y_pred different from y? After all, we trained X_train to get the weights that when multiplied by X_train should give exactly y, or?”\\nA: linear regression is a pretty simple model, it neither can nor should fit 100% (nor any other model, as this would be the sign of overfitting). This picture might illustrate some intuition behind this, imagine X is a single feature:\\nAs our model is linear, how would you draw a line to fit all the \"dots\"?\\nYou could \"fit\" all the \"dots\" on this pic using something like scipy.optimize.curve_fit (non-linear least squares) if you wanted to, but imagine how it would perform on previously unseen data.\\nAdded by Andrii Larkin', 'section': '2. Machine Learning for Regression', 'question': 'Why linear regression doesn’t provide a “perfect” fit?', 'course': 'machine-learning-zoomcamp', 'id': 'fe3139f6'}, '48aac030': {'text': 'One of the questions on the homework calls for using a random seed of 42. When using 42, all my missing values ended up in my training dataframe and not my validation or test dataframes, why is that?\\nThe purpose of the seed value is to randomly generate the proportion split. Using a seed of 42 ensures that all learners are on the same page by getting the same behavior (in this case, all missing values ending up in the training dataframe). If using a different seed value (e.g. 9), missing values will then appear in all other dataframes.', 'section': '2. Machine Learning for Regression', 'question': 'Random seed 42', 'course': 'machine-learning-zoomcamp', 'id': '48aac030'}, '28321bc2': {'text': 'It is possible to do the shuffling of the dataset with the pandas built-in function pandas.DataFrame.sample.The complete dataset can be shuffled including resetting the index with the following commands:\\nSetting frac=1 will result in returning a shuffled version of the complete Dataset.\\nSetting random_state=seed will result in the same randomization as used in the course resources.\\ndf_shuffled = df.sample(frac=1, random_state=seed)\\ndf_shuffled.reset_index(drop=True, inplace=True)\\nAdded by Sylvia Schmitt', 'section': '2. Machine Learning for Regression', 'question': 'Shuffling the initial dataset using pandas built-in function', 'course': 'machine-learning-zoomcamp', 'id': '28321bc2'}, 'edb92d22': {'text': 'That’s normal. We all have different environments: our computers have different versions of OS and different versions of libraries — even different versions of Python.\\nIf it’s the case, just select the option that’s closest to your answer', 'section': '2. Machine Learning for Regression', 'question': \"The answer I get for one of the homework questions doesn't match any of the options. What should I do?\", 'course': 'machine-learning-zoomcamp', 'id': 'edb92d22'}, 'f488ce85': {'text': \"In question 3 of HW02 it is mentioned: ‘For computing the mean, use the training only’. What does that mean?\\nIt means that you should use only the training data set for computing the mean, not validation or  test data set. This is how you can calculate the mean\\ndf_train['column_name'].mean( )\\nAnother option:\\ndf_train[‘column_name’].describe()\\n(Bhaskar Sarma)\", 'section': '2. Machine Learning for Regression', 'question': 'Meaning of mean in homework 2, question 3', 'course': 'machine-learning-zoomcamp', 'id': 'f488ce85'}, 'bf395099': {'text': 'When the target variable has a long tail distribution, like in prices, with a wide range, you can transform the target variable with np.log1p() method, but be aware if your target variable has negative values, this method will not work', 'section': '2. Machine Learning for Regression', 'question': 'When should we transform the target variable to logarithm distribution?', 'course': 'machine-learning-zoomcamp', 'id': 'bf395099'}, '01cd3b35': {'text': 'If we try to perform an arithmetic operation between 2 arrays of different shapes or different dimensions, it throws an error like operands could not be broadcast together with shapes. There are some scenarios when broadcasting can occur and when it fails.\\nIf this happens sometimes we can use * operator instead of dot() method to solve the issue. So that the error is solved and also we get the dot product.\\n(Santhosh Kumar)', 'section': '2. Machine Learning for Regression', 'question': 'ValueError: shapes not aligned', 'course': 'machine-learning-zoomcamp', 'id': '01cd3b35'}, '5551c92e': {'text': 'Copy of a dataframe is made with X_copy = X.copy().\\nThis is called creating a deep copy.  Otherwise it will keep changing the original dataframe if used like this: X_copy = X.\\nAny changes to X_copy will reflect back to X. This is not a real copy, instead it is a “view”.\\n(Memoona Tahira)', 'section': '2. Machine Learning for Regression', 'question': 'How to copy a dataframe without changing the original dataframe?', 'course': 'machine-learning-zoomcamp', 'id': '5551c92e'}, '94f928d2': {'text': 'One of the most important characteristics of the normal distribution is that mean=median=mode, this means that the most popular value, the mean of the distribution and 50% of the sample are under the same value, this is equivalent to say that the area under the curve (black) is the same on the left and on the right. The long tail (red curve) is the result of having a few observations with high values, now the behaviour of the distribution changes, first of all, the area is different on each side and now the mean, median and mode are different. As a consequence, the mean is no longer representative, the range is larger than before and the probability of being on the left or on the right is not the same.\\n(Tatiana Dávila)', 'section': '2. Machine Learning for Regression', 'question': 'What does ‘long tail’ mean?', 'course': 'machine-learning-zoomcamp', 'id': '94f928d2'}, '266faa6d': {'text': 'In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. [Wikipedia] The formula to calculate standard deviation is:\\n(Aadarsha Shrestha)', 'section': '2. Machine Learning for Regression', 'question': 'What is standard deviation?', 'course': 'machine-learning-zoomcamp', 'id': '266faa6d'}, 'c21f99f5': {'text': 'The application of regularization depends on the specific situation and problem. It is recommended to consider it when training machine learning models, especially with small datasets or complex models, to prevent overfitting. However, its necessity varies depending on the data quality and size. Evaluate each case individually to determine if it is needed.\\n(Daniel Muñoz Viveros)', 'section': '2. Machine Learning for Regression', 'question': 'Do we need to apply regularization techniques always? Or only in certain scenarios?', 'course': 'machine-learning-zoomcamp', 'id': 'c21f99f5'}, '13702957': {'text': 'As it speeds up the development:\\nprepare_df(initial_df, seed, fill_na_type)  - that prepared all 3 dataframes and 3 y_vectors. Fillna() can be done before the initial_df is split.\\nOf course, you can reuse other functions: rmse() and train_linear_regression(X,y,r) from the class notebook\\n(Ivan Brigida)', 'section': '2. Machine Learning for Regression', 'question': 'Shortcut: define functions for faster execution', 'course': 'machine-learning-zoomcamp', 'id': '13702957'}, '7cd652c5': {'text': 'If we have a list or series of data for example x = [1,2,3,4,5]. We can use pandas to find the standard deviation. We can pass our list into panda series and call standard deviation directly on the series pandas.Series(x).std().\\n(Quinn Avila)', 'section': '2. Machine Learning for Regression', 'question': 'How to use pandas to find standard deviation', 'course': 'machine-learning-zoomcamp', 'id': '7cd652c5'}, 'e1f93d10': {'text': 'Numpy and Pandas packages use different equations to compute the standard deviation. Numpy uses  population standard deviation, whereas pandas uses sample standard deviation by default.\\nNumpy\\nPandas\\npandas default standard deviation is computed using one degree of freedom. You can change degree in of freedom in NumPy to change this to unbiased estimator by using ddof parameter:\\nimport numpy as np\\nnp.std(df.weight, ddof=1)\\nThe result will be similar if we change the dof = 1 in numpy\\n(Harish Balasundaram)', 'section': '2. Machine Learning for Regression', 'question': 'Standard Deviation Differences in Numpy and Pandas', 'course': 'machine-learning-zoomcamp', 'id': 'e1f93d10'}, '36b9d1b7': {'text': \"In pandas you can use built in Pandas function names std() to get standard deviation. For example\\ndf['column_name'].std() to get standard deviation of that column.\\ndf[['column_1', 'column_2']].std() to get standard deviation of multiple columns.\\n(Khurram Majeed)\", 'section': '2. Machine Learning for Regression', 'question': 'Standard deviation using Pandas built in Function', 'course': 'machine-learning-zoomcamp', 'id': '36b9d1b7'}, '3c8b32a1': {'text': 'Use ‘pandas.concat’ function (https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to combine two dataframes. To combine two numpy arrays use numpy.concatenate (https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) function. So the code would be as follows:\\ndf_train_combined = pd.concat([df_train, df_val])\\ny_train = np.concatenate((y_train, y_val), axis=0)\\n(George Chizhmak)', 'section': '2. Machine Learning for Regression', 'question': 'How to combine train and validation datasets', 'course': 'machine-learning-zoomcamp', 'id': '3c8b32a1'}, '05fb3a16': {'text': 'The Root Mean Squared Error (RMSE) is one of the primary metrics to evaluate the performance of a regression model. It calculates the average deviation between the model\\'s predicted values and the actual observed values, offering insight into the model\\'s ability to accurately forecast the target variable. To calculate RMSE score:\\nLibraries needed\\nimport numpy as np\\nfrom sklearn.metrics import mean_squared_error\\nmse = mean_squared_error(actual_values, predicted_values)\\nrmse = np.sqrt(mse)\\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\\n(Aminat Abolade)', 'section': '2. Machine Learning for Regression', 'question': 'Understanding RMSE and how to calculate RMSE score', 'course': 'machine-learning-zoomcamp', 'id': '05fb3a16'}, '225506b9': {'text': 'If you would like to use multiple conditions as an example below you will get the error. The correct syntax for OR is |, and for AND is &\\n(Olga Rudakova)\\n–', 'section': '2. Machine Learning for Regression', 'question': 'What syntax use in Pandas for multiple conditions using logical AND and OR', 'course': 'machine-learning-zoomcamp', 'id': '225506b9'}, 'bd4a1395': {'text': 'I found this video pretty usual for understanding how we got the normal form with linear regression Normal Equation Derivation for Regression', 'section': '2. Machine Learning for Regression', 'question': 'Deep dive into normal equation for regression', 'course': 'machine-learning-zoomcamp', 'id': 'bd4a1395'}, '81b8e8d0': {'text': '(Hrithik Kumar Advani)', 'section': '2. Machine Learning for Regression', 'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook', 'course': 'machine-learning-zoomcamp', 'id': '81b8e8d0'}, 'a7f6a33c': {'text': 'The instruction for applying log transformation to the ‘median_house_value’ variable is provided before Q3 in the homework for Week-2 under the ‘Prepare and split the dataset’ heading.\\nHowever, this instruction is absent in the subsequent questions of the homework, and I got stuck with Q5 for a long time, trying to figure out why my RMSE was so huge, when it clicked to me that I forgot to apply log transformation to the target variable. Please remember to apply log transformation to the target variable for each question.\\n(Added by Soham Mundhada)', 'section': '2. Machine Learning for Regression', 'question': 'Caution for applying log transformation in Week-2 2023 cohort homework', 'course': 'machine-learning-zoomcamp', 'id': 'a7f6a33c'}, '129b4ac0': {'text': 'Version 0.24.2 and Python 3.8.11\\n(Added by Diego Giraldo)', 'section': '3. Machine Learning for Classification', 'question': 'What sklearn version is Alexey using in the youtube videos?', 'course': 'machine-learning-zoomcamp', 'id': '129b4ac0'}, 'b8cca8b7': {'text': 'Week 3 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/03-classification/homework.md\\nSubmit HW Week 3: https://docs.google.com/forms/d/e/1FAIpQLSeXS3pqsv_smRkYmVx-7g6KIZDnG29g2s7pdHo-ASKNqtfRFQ/viewform\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nEvaluation Matrix: https://docs.google.com/spreadsheets/d/e/2PACX-1vQCwqAtkjl07MTW-SxWUK9GUvMQ3Pv_fF8UadcuIYLgHa0PlNu9BRWtfLgivI8xSCncQs82HDwGXSm3/pubhtml\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 3.X --- https://www.youtube.com/watch?v=0Zw04wdeTQo&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=29\\n~~Nukta Bhatia~~', 'section': '3. Machine Learning for Classification', 'question': 'How do I get started with Week 3?', 'course': 'machine-learning-zoomcamp', 'id': 'b8cca8b7'}, '1091b10f': {'text': \"The error message “could not convert string to float: ‘Nissan’” typically occurs when a machine learning model or function is expecting numerical input, but receives a string instead. In this case, it seems like the model is trying to convert the car brand ‘Nissan’ into a numerical value, which isn’t possible.\\nTo resolve this issue, you can encode categorical variables like car brands into numerical values. One common method is one-hot encoding, which creates new binary columns for each category/label present in the original column.\\nHere’s an example of how you can perform one-hot encoding using pandas:\\nimport pandas as pd\\n# Assuming 'data' is your DataFrame and 'brand' is the column with car brands\\ndata_encoded = pd.get_dummies(data, columns=['brand'])\\nIn this code, pd.get_dummies() creates a new DataFrame where the ‘brand’ column is replaced with binary columns for each brand (e.g., ‘brand_Nissan’, ‘brand_Toyota’, etc.). Each row in the DataFrame has a 1 in the column that corresponds to its brand and 0 in all other brand columns.\\n-Mohammad Emad Sharifi-\", 'section': '3. Machine Learning for Classification', 'question': \"Could not convert string to float:’Nissan’rt string to float: 'Nissan'\", 'course': 'machine-learning-zoomcamp', 'id': '1091b10f'}, '0c7715a1': {'text': 'Solution: Mutual Information score calculates the relationship between categorical variables or discrete variables. So in the homework, because the target which is median_house_value is continuous, we had to change it to binary format which in other words, makes its values discrete as either 0 or 1. If we allowed it to remain in the continuous variable format, the mutual information score could be calculated, but the algorithm would have to divide the continuous variables into bins and that would be highly subjective. That is why continuous variables are not used for mutual information score calculation.\\n—Odimegwu David—-', 'section': '3. Machine Learning for Classification', 'question': 'Why did we change the targets to binary format when calculating mutual information score in the homework?', 'course': 'machine-learning-zoomcamp', 'id': '0c7715a1'}, 'd2043cf5': {'text': \"Q2 asks about correlation matrix and converting median_house_value from numeric to binary. Just to make sure here we are only dealing with df_train not df_train_full, right? As the question explicitly mentions the train dataset.\\nYes. I think it is only on df_train. The reason behind this is that df_train_full also contains the validation dataset, so at this stage we don't want to make conclusions based on the validation data, since we want to test how we did without using that portion of the data.\\nPastor Soto\", 'section': '3. Machine Learning for Classification', 'question': 'What data should we use for correlation matrix', 'course': 'machine-learning-zoomcamp', 'id': 'd2043cf5'}, '44d22817': {'text': \"The background of any dataframe can be colored (not only the correlation matrix) based on the numerical values the dataframe contains by using the method pandas.io.formats.style.Styler.background_graident.\\nHere an example on how to color the correlation matrix. A color map of choice can get passed, here ‘viridis’ is used.\\n# ensure to have only numerical values in the dataframe before calling 'corr'\\ncorr_mat = df_numerical_only.corr()\\ncorr_mat.style.background_gradient(cmap='viridis')\\nHere is an example of how the coloring will look like using a dataframe containing random values and applying “background_gradient” to it.\\nnp.random.seed = 3\\ndf_random = pd.DataFrame(data=np.random.random(3*3).reshape(3,3))\\ndf_random.style.background_gradient(cmap='viridis')\\nAdded by Sylvia Schmitt\", 'section': '3. Machine Learning for Classification', 'question': 'Coloring the background of the pandas.DataFrame.corr correlation matrix directly', 'course': 'machine-learning-zoomcamp', 'id': '44d22817'}, '1f76dbeb': {'text': 'data_corr = pd.DataFrame(data_num.corr().round(3).abs().unstack().sort_values(ascending=False))\\ndata_corr.head(10)\\nAdded by Harish Balasundaram\\nYou can also use seaborn to create a heatmap with the correlation. The code for doing that:\\nsns.heatmap(df[numerical_features].corr(),\\nannot=True,\\nsquare=True,\\nfmt=\".2g\",\\ncmap=\"crest\")\\nAdded by Cecile Guillot\\nYou can refine your heatmap and plot only a triangle, with a blue to red color gradient, that will show every correlation between your numerical variables without redundant information with this function:\\nWhich outputs, in the case of churn dataset:\\n(Mélanie Fouesnard)', 'section': '3. Machine Learning for Classification', 'question': 'Identifying highly correlated feature pairs easily through unstack', 'course': 'machine-learning-zoomcamp', 'id': '1f76dbeb'}, 'b8071a54': {'text': \"Should we perform EDA on the base of train or train+validation or train+validation+test dataset?\\nIt's indeed good practice to only rely on the train dataset for EDA. Including validation might be okay. But we aren't supposed to touch the test dataset, even just looking at it isn't a good idea. We indeed pretend that this is the future unseen data\\nAlena Kniazeva\", 'section': '3. Machine Learning for Classification', 'question': 'What data should be used for EDA?', 'course': 'machine-learning-zoomcamp', 'id': 'b8071a54'}, 'b8da9037': {'text': 'Validation dataset helps to validate models and prediction on unseen data. This helps get an estimate on its performance on fresh data. It helps optimize the model.\\nEdidiong Esu\\nBelow is an extract of Alexey\\'s book explaining this point. Hope is useful\\nWhen we apply the fit method, this method is looking at the content of the df_train dictionaries we are passing to the DictVectorizer instance, and fit is figuring out (training) how to map the values of these dictionaries. If categorical, applies one-hot encoding, if numerical it will leave it as it is.\\nWith this context, if we apply the fit to the validation model, we are \"giving the answers\" and we are not letting the \"fit\" do its job for data that we haven\\'t seen. By not applying the fit to the validation model we can know how well it was trained.\\nBelow is an extract of Alexey\\'s book explaining this point.\\nHumberto Rodriguez\\nThere is no need to initialize another instance of dictvectorizer after fitting it on the train set as it will overwrite what it learnt from being fit on the train data.\\nThe correct way is to fit_transform the train set, and only transform the validation and test sets.\\nMemoona Tahira', 'section': '3. Machine Learning for Classification', 'question': 'Fitting DictVectorizer on validation', 'course': 'machine-learning-zoomcamp', 'id': 'b8da9037'}, '467e0cec': {'text': 'For Q5 in homework, should we calculate the smallest difference in accuracy in real values (i.e. -0.001 is less than -0.0002) or in absolute values (i.e. 0.0002 is less than 0.001)?\\nWe should select the “smallest” difference, and not the “lowest”, meaning we should reason in absolute values.\\nIf the difference is negative, it means that the model actually became better when we removed the feature.', 'section': '3. Machine Learning for Classification', 'question': 'Feature elimination', 'course': 'machine-learning-zoomcamp', 'id': '467e0cec'}, 'b69f32f6': {'text': \"Instead use the method “.get_feature_names_out()” from DictVectorizer function and the warning will be resolved , but we need not worry about the waning as there won't be any warning\\nSanthosh Kumar\", 'section': '3. Machine Learning for Classification', 'question': 'FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2', 'course': 'machine-learning-zoomcamp', 'id': 'b69f32f6'}, '3b3b1989': {'text': 'Fitting the logistic regression takes a long time / kernel crashes when calling predict() with the fitted model.\\nMake sure that the target variable for the logistic regression is binary.\\nKonrad Muehlberg', 'section': '3. Machine Learning for Classification', 'question': 'Logistic regression crashing Jupyter kernel', 'course': 'machine-learning-zoomcamp', 'id': '3b3b1989'}, 'eb5771a0': {'text': 'Ridge regression is a linear regression technique used to mitigate the problem of multicollinearity (when independent variables are highly correlated) and prevent overfitting in predictive modeling. It adds a regularization term to the linear regression cost function, penalizing large coefficients.\\nsag Solver: The sag solver stands for \"Stochastic Average Gradient.\" It\\'s particularly suitable for large datasets, as it optimizes the regularization term using stochastic gradient descent (SGD). sag can be faster than some other solvers for large datasets.\\nAlpha: The alpha parameter  controls the strength of the regularization in Ridge regression. A higher alpha value leads to stronger regularization, which means the model will have smaller coefficient values, reducing the risk of overfitting.\\nfrom sklearn.linear_model import Ridge\\nridge = Ridge(alpha=alpha, solver=\\'sag\\', random_state=42)\\nridge.fit(X_train, y_train)\\nAminat Abolade', 'section': '3. Machine Learning for Classification', 'question': 'Understanding Ridge', 'course': 'machine-learning-zoomcamp', 'id': 'eb5771a0'}, 'bca10281': {'text': 'DictVectorizer(sparse=True) produces CSR format, which is both more memory efficient and converges better during fit(). Basically it stores non-zero values and indices instead of adding a column for each class of each feature (models of cars produced 900+ columns alone in the current task).\\nUsing “sparse” format like on the picture above, both via pandas.get_dummies() and DictVectorizer(sparse=False) - is slower (around 6-8min for Q6 task - Linear/Ridge Regression) for high amount of classes (like models of cars for eg) and gives a bit “worse” results in both Logistic and Linear/Ridge Regression, while also producing convergence warnings for Linear/Ridge Regression.\\nLarkin Andrii', 'section': '3. Machine Learning for Classification', 'question': 'pandas.get_dummies() and DictVectorizer(sparse=False) produce the same type of one-hot encodings:', 'course': 'machine-learning-zoomcamp', 'id': 'bca10281'}, '34a8edb0': {'text': 'Ridge with sag solver requires feature to be of the same scale. You may get the following warning: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\\nPlay with different scalers. See notebook-scaling-ohe.ipynb\\nDmytro Durach\\n(Oscar Garcia)  Use a StandardScaler for the numeric fields and OneHotEncoder (sparce = False) for the categorical features.  This help with the warning. Separate the features (num/cat) without using the encoder first and see if that helps.', 'section': '3. Machine Learning for Classification', 'question': 'Convergence Problems in W3Q6', 'course': 'machine-learning-zoomcamp', 'id': '34a8edb0'}, 'f625307b': {'text': \"When encountering convergence errors during the training of a Ridge regression model, consider the following steps:\\nFeature Normalization: Normalize your numerical features using techniques like MinMaxScaler or StandardScaler. This ensures that numerical features are on a \\tsimilar scale, preventing convergence issues.\\nCategorical Feature Encoding: If your dataset includes categorical features, apply \\tcategorical encoding techniques such as OneHotEncoder (OHE) to \\tconvert them into a numerical format. OHE is commonly used to represent categorical variables as binary vectors, making them compatible with regression models like Ridge.\\nCombine Features: After \\tnormalizing numerical features and encoding categorical features using OneHotEncoder, combine them to form a single feature matrix (X_train). This combined dataset serves as the input for training the Ridge regression model.\\nBy following these steps, you can address convergence errors and enhance the stability of your Ridge model training process. It's important to note that the choice of encoding method, such as OneHotEncoder, is appropriate for handling categorical features in this context.\\nYou can find an example here.\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tOsman Ali\", 'section': '3. Machine Learning for Classification', 'question': 'Dealing with Convergence in Week 3 q6', 'course': 'machine-learning-zoomcamp', 'id': 'f625307b'}, '7fa98526': {'text': 'A sparse matrix is more memory-efficient because it only stores the non-zero values and their positions in memory. This is particularly useful when working with large datasets with many zero or missing values.\\nThe default DictVectorizer configuration is a sparse matrix. For week3 Q6 using the default sparse is an interesting option because of the size of the matrix. Training the model was also more performant and didn’t give an error message like dense mode.\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tQuinn Avila', 'section': '3. Machine Learning for Classification', 'question': 'Sparse matrix compared dense matrix', 'course': 'machine-learning-zoomcamp', 'id': '7fa98526'}, '0807f0f3': {'text': 'The warnings on the jupyter notebooks can be disabled/ avoided with the following comments:\\nImport warnings\\nwarnings.filterwarnings(“ignore”)\\nKrishna Anand', 'section': '3. Machine Learning for Classification', 'question': 'How  to Disable/avoid Warnings in Jupyter Notebooks', 'course': 'machine-learning-zoomcamp', 'id': '0807f0f3'}, '6d0fb418': {'text': 'Question: Regarding RMSE, how do we decide on the correct score to choose? In the study group discussion    about week two homework, all of us got it wrong and one person had the lowest score selected as well.\\nAnswer: You need to find RMSE for each alpha. If RMSE scores  are equal, you will select the lowest alpha.\\nAsia Saeed', 'section': '3. Machine Learning for Classification', 'question': 'How to select the alpha parameter in Q6', 'course': 'machine-learning-zoomcamp', 'id': '6d0fb418'}, 'fbda1f40': {'text': 'Question: Could you please help me with HW3 Q3: \"Calculate the mutual information score with the (binarized) price for the categorical variable that we have. Use the training set only.\" What is the second variable that we need to use to calculate the mutual information score?\\nAnswer: You need to calculate the mutual info score between the binarized price (above_average) variable & ocean_proximity, the only original categorical variable in the dataset.\\nAsia Saeed', 'section': '3. Machine Learning for Classification', 'question': 'Second variable that we need to use to calculate the mutual information score', 'course': 'machine-learning-zoomcamp', 'id': 'fbda1f40'}, '0f88b7ac': {'text': 'Do we need to train the model only with the features: total_rooms, total_bedrooms, population and households? or with all the available features and then pop once at a time each of the previous features and train the model to make the accuracy comparison?\\nYou need to create a list of all features in this question and evaluate the model one time to obtain the accuracy, this will be the original accuracy, and then remove one feature each time, and in each time, train the model, find the accuracy and the difference between the original accuracy and the found accuracy. Finally, find out which feature has the smallest absolute accuracy difference.\\nWhile calculating differences between accuracy scores while training on the whole model, versus dropping one feature at a time and comparing its accuracy to the model to judge impact of the feature on the accuracy of the model, do we take the smallest difference or smallest absolute difference?\\nSince order of subtraction between the two accuracy scores can result in a negative number, we will take its absolute value as we are interested in the smallest value difference, not the lowest difference value. Case in point, if difference is -4 and -2, the smallest difference is abs(-2), and not abs(-4)', 'section': '3. Machine Learning for Classification', 'question': 'Features for homework Q5', 'course': 'machine-learning-zoomcamp', 'id': '0f88b7ac'}, '9ffcc895': {'text': 'Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard', 'section': '3. Machine Learning for Classification', 'question': 'What is the difference between OneHotEncoder and DictVectorizer?', 'course': 'machine-learning-zoomcamp', 'id': '9ffcc895'}, '94a3b2fb': {'text': 'They are basically the same. There are some key differences with regards to their input/output types, handling of missing values, etc, but they are both techniques to one-hot-encode categorical variables with identical results. The biggest difference is get_dummies are a convenient choice when you are working with Pandas Dataframes, while if you are building a scikit-learn-based machine learning pipeline and need to handle categorical data as part of that pipeline, OneHotEncoder is a more suitable choice. [Abhirup Ghosh]', 'section': '3. Machine Learning for Classification', 'question': 'What is the difference between pandas get_dummies and sklearn OnehotEncoder?', 'course': 'machine-learning-zoomcamp', 'id': '94a3b2fb'}, 'fb9a45d8': {'text': \"For the test_train_split question on week 3's homework, are we supposed to use 42 as the random_state in both splits or only the 1st one?\\nAnswer: for both splits random_state = 42 should be used\\n(Bhaskar Sarma)\", 'section': '3. Machine Learning for Classification', 'question': 'Use of random seed in HW3', 'course': 'machine-learning-zoomcamp', 'id': 'fb9a45d8'}, 'e31051f7': {'text': 'Should correlation be calculated after splitting or before splitting. And lastly I know how to find the correlation but how do i find the two most correlated features.\\nAnswer: Correlation matrix of your train dataset. Thus, after splitting. Two most correlated features are the ones having the highest correlation coefficient in terms of absolute values.', 'section': '3. Machine Learning for Classification', 'question': 'Correlation before or after splitting the data', 'course': 'machine-learning-zoomcamp', 'id': 'e31051f7'}, '493b7b59': {'text': 'Make sure that the features used in ridge regression model are only NUMERICAL ones not categorical.\\nDrop all categorical features first before proceeding.\\n(Aileah Gotladera)\\nWhile it is True that ridge regression accepts only numerical values, the categorical ones can be useful for your model. You have to transform them using one-hot encoding before training the model. To avoid the error of non convergence, put sparse=True when doing so.\\n(Erjon)', 'section': '3. Machine Learning for Classification', 'question': 'Features in Ridge Regression Model', 'course': 'machine-learning-zoomcamp', 'id': '493b7b59'}, '4a55c510': {'text': \"You need to use all features. and price for target. Don't include the average variable we created before.\\nIf you use DictVectorizer then make sure to use sparce=True to avoid convergence errors\\nI also used StandardScalar for numerical variable you can try running with or without this\\n(Peter Pan)\", 'section': '3. Machine Learning for Classification', 'question': 'Handling Column Information for Homework 3 Question 6', 'course': 'machine-learning-zoomcamp', 'id': '4a55c510'}, '3ca0b489': {'text': 'Use sklearn.preprocessing encoders and scalers, e.g. OneHotEncoder, OrdinalEncoder, and StandardScaler.', 'section': '3. Machine Learning for Classification', 'question': 'Transforming Non-Numerical Columns into Numerical Columns', 'course': 'machine-learning-zoomcamp', 'id': '3ca0b489'}, '690d97f1': {'text': 'These both methods receive the dictionary as an input. While the DictVectorizer will store the big vocabulary and takes more memory. FeatureHasher create a vectors with predefined length. They are both used for categorical features.\\nWhen you have a high cardinality for categorical features better to use FeatureHasher. If you want to preserve feature names in transformed data and have a small number of unique values is DictVectorizer. But your choice will dependence on your data.\\nYou can read more by follow the link https://scikit-learn.org/stable/auto_examples/text/plot_hashing_vs_dict_vectorizer.html\\nOlga Rudakova', 'section': '3. Machine Learning for Classification', 'question': 'What is the better option FeatureHasher or DictVectorizer', 'course': 'machine-learning-zoomcamp', 'id': '690d97f1'}, 'eb5a25cb': {'text': '(Question by Connie S.)\\nThe reason it\\'s good/recommended practice to do it after splitting is to avoid data leakage - you don\\'t want any data from the test set influencing the training stage (similarly from the validation stage in the initial training). See e.g. scikit-learn documentation on \"Common pitfalls and recommended practices\": https://scikit-learn.org/stable/common_pitfalls.html\\nAnswered/added by Rileen Sinha', 'section': '3. Machine Learning for Classification', 'question': \"Isn't it easier to use DictVertorizer or get dummies before splitting the data into train/val/test? Is there a reason we wouldn't do this? Or is it the same either way?\", 'course': 'machine-learning-zoomcamp', 'id': 'eb5a25cb'}, '6d9e0a6f': {'text': 'If you are getting 1.0 as accuracy then there is a possibility you have overfitted the model. Dropping the column msrp/price can help you solve this issue.\\nAdded by Akshar Goyal', 'section': '3. Machine Learning for Classification', 'question': 'HW3Q4 I am getting 1.0 as accuracy. Should I use the closest option?', 'course': 'machine-learning-zoomcamp', 'id': '6d9e0a6f'}, '618ad97a': {'text': 'We can use sklearn & numpy packages to calculate Root Mean Squared Error\\nfrom sklearn.metrics import mean_squared_error\\nimport numpy as np\\nRmse = np.sqrt(mean_squared_error(y_pred, y_val/ytest)\\nAdded by Radikal Lukafiardi\\nYou can also refer to Alexey’s notebook for Week 2:\\nhttps://github.com/alexeygrigorev/mlbookcamp-code/blob/master/chapter-02-car-price/02-carprice.ipynb\\nwhich includes the following code:\\ndef rmse(y, y_pred):\\nerror = y_pred - y\\nmse = (error ** 2).mean()\\nreturn np.sqrt(mse)\\n(added by Rileen Sinha)', 'section': '3. Machine Learning for Classification', 'question': 'How to calculate Root Mean Squared Error?', 'course': 'machine-learning-zoomcamp', 'id': '618ad97a'}, '683495d2': {'text': 'The solution is to use “get_feature_names_out” instead. See details: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html\\nGeorge Chizhmak', 'section': '3. Machine Learning for Classification', 'question': \"AttributeError: 'DictVectorizer' object has no attribute 'get_feature_names'\", 'course': 'machine-learning-zoomcamp', 'id': '683495d2'}, 'dc1897b5': {'text': 'To use RMSE without math or numpy, ‘sklearn.metrics’ has a mean_squared_error function with a squared kwarg (defaults to True). Setting squared to False will return the RMSE.\\nfrom sklearn.metrics import mean_squared_error\\nrms = mean_squared_error(y_actual, y_predicted, squared=False)\\nSee details: https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\\nAhmed Okka', 'section': '3. Machine Learning for Classification', 'question': 'Root Mean Squared Error', 'course': 'machine-learning-zoomcamp', 'id': 'dc1897b5'}, '826098f2': {'text': 'This article explains different encoding techniques used https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02\\nHrithik Kumar Advani', 'section': '3. Machine Learning for Classification', 'question': 'Encoding Techniques', 'course': 'machine-learning-zoomcamp', 'id': '826098f2'}, '821dfc08': {'text': \"I got this error multiple times here is the code:\\n“accuracy_score(y_val, y_pred >= 0.5)”\\nTypeError: 'numpy.float64' object is not callable\\nI solve it using\\nfrom sklearn import metrics\\nmetrics.accuracy_score(y_train, y_pred>= 0.5)\\nOMAR Wael\", 'section': '4. Evaluation Metrics for Classification', 'question': 'Error in use of accuracy_score from sklearn in jupyter (sometimes)', 'course': 'machine-learning-zoomcamp', 'id': '821dfc08'}, '27c8d5da': {'text': 'Week 4 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/04-evaluation/homework.md\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nEvaluation Matrix: https://docs.google.com/spreadsheets/d/e/2PACX-1vQCwqAtkjl07MTW-SxWUK9GUvMQ3Pv_fF8UadcuIYLgHa0PlNu9BRWtfLgivI8xSCncQs82HDwGXSm3/pubhtml\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYouTube Link: 4.X --- https://www.youtube.com/watch?v=gmg5jw1bM8A&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=40\\nSci-Kit Learn on Evaluation:\\nhttps://scikit-learn.org/stable/model_selection.html\\n~~Nukta Bhatia~~', 'section': '4. Evaluation Metrics for Classification', 'question': 'How do I get started with Week 4?', 'course': 'machine-learning-zoomcamp', 'id': '27c8d5da'}, 'a52d4739': {'text': 'https://datatalks-club.slack.com/archives/C0288NJ5XSA/p1696475675887119\\nMetrics can be used on a series or a dataframe\\n~~Ella Sahnan~~', 'section': '4. Evaluation Metrics for Classification', 'question': 'Using a variable to score', 'course': 'machine-learning-zoomcamp', 'id': 'a52d4739'}, 'dc55359c': {'text': 'Ie particularly in module-04 homework Qn2 vs Qn5. https://datatalks-club.slack.com/archives/C0288NJ5XSA/p1696760905214979\\nRefer to the sklearn docs, random_state is to ensure the “randomness” that is used to shuffle dataset is reproducible, and it usually requires both random_state and shuffle params to be set accordingly.\\n~~Ella Sahnan~~', 'section': '4. Evaluation Metrics for Classification', 'question': 'Why do we sometimes use random_state and not at other times?', 'course': 'machine-learning-zoomcamp', 'id': 'dc55359c'}, '2ab49e43': {'text': 'How to get classification metrics - precision, recall, f1 score, accuracy simultaneously\\nUse classification_report from sklearn. For more info check here.\\nAbhishek N', 'section': '4. Evaluation Metrics for Classification', 'question': 'How to get all classification metrics?', 'course': 'machine-learning-zoomcamp', 'id': '2ab49e43'}, 'b431e7eb': {'text': 'I am getting multiple thresholds with the same F1 score, does this indicate I am doing something wrong or is there a method for choosing? I would assume just pick the lowest?\\nChoose the one closest to any of the options\\nAdded by Azeez Enitan Edunwale\\nYou can always use scikit-learn (or other standard libraries/packages) to verify results obtained using your own code, e.g. you can use  “classification_report” (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to obtain precision, recall and F1-score.\\nAdded by Rileen Sinha', 'section': '4. Evaluation Metrics for Classification', 'question': 'Multiple thresholds for Q4', 'course': 'machine-learning-zoomcamp', 'id': 'b431e7eb'}, 'c5fdeba9': {'text': \"Solution description: duplicating the\\ndf.churn = (df.churn == 'yes').astype(int)\\nThis is causing you to have only 0's in your churn column. In fact, match with the error you are getting:  ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.\\nIt is telling us that it only contains 0's.\\nDelete one of the below cells and you will get the accuracy\\nHumberto Rodriguez\", 'section': '4. Evaluation Metrics for Classification', 'question': 'ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0', 'course': 'machine-learning-zoomcamp', 'id': 'c5fdeba9'}, 'b8c9eaf1': {'text': 'Use Yellowbrick. Yellowbrick in a library that combines scikit-learn with matplotlib to produce visualizations for your models. It produces colorful classification reports.\\nKrishna Annad', 'section': '4. Evaluation Metrics for Classification', 'question': 'Method to get beautiful classification report', 'course': 'machine-learning-zoomcamp', 'id': 'b8c9eaf1'}, 'c54058a1': {'text': 'That’s fine, use the closest option', 'section': '4. Evaluation Metrics for Classification', 'question': 'I’m not getting the exact result in homework', 'course': 'machine-learning-zoomcamp', 'id': 'c54058a1'}, 'b4b85c4b': {'text': 'Check the solutions from the 2021 iteration of the course. You should use roc_auc_score.', 'section': '4. Evaluation Metrics for Classification', 'question': 'Use AUC to evaluate feature importance of numerical variables', 'course': 'machine-learning-zoomcamp', 'id': 'b4b85c4b'}, '7d40f6f6': {'text': 'When calculating the ROC AUC score using sklearn.metrics.roc_auc_score the function expects two parameters “y_true” and “y_score”. So for each numerical value in the dataframe it will be passed as the “y_score” to the function and the target variable will get passed a “y_true” each time.\\nSylvia Schmitt', 'section': '4. Evaluation Metrics for Classification', 'question': 'Help with understanding: “For each numerical value, use it as score and compute AUC”', 'course': 'machine-learning-zoomcamp', 'id': '7d40f6f6'}, 'f5dc446c': {'text': 'You must use the `dt_val` dataset to compute the metrics asked in Question 3 and onwards, as you did in Question 2.\\nDiego Giraldo', 'section': '4. Evaluation Metrics for Classification', 'question': 'What dataset should I use to compute the metrics in Question 3', 'course': 'machine-learning-zoomcamp', 'id': 'f5dc446c'}, 'd30fc29d': {'text': \"What does this line do?\\nKFold(n_splits=n_splits, shuffle=True, random_state=1)\\nIf I do it inside the loop [0.01, 0.1, 1, 10] or outside the loop in Q6, HW04 it doesn't make any difference to my answers. I am wondering why and what is the right way, although it doesn't make a difference!\\nDid you try using a different random_state? From my understanding, KFold just makes N (which is equal to n_splits) separate pairs of datasets (train+val).\\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\\nIn my case changing random state changed results\\n(Arthur Minakhmetov)\\nChanging the random state makes a difference in my case too, but not whether it is inside or outside the for loop. I think I have got the answer. kFold = KFold(n_splits=n_splits, shuffle = True, random_state = 1)  is just a generator object and it contains only the information n_splits, shuffle and random_state. The k-fold splitting actually happens in the next for loop for train_idx, val_idx in kFold.split(df_full_train): . So it doesn't matter where we generate the object, before or after the first loop. It will generate the same information. But from the programming point of view, it is better to do it before the loop. No point doing it again and again inside the loop\\n(Bhaskar Sarma)\\nIn case of KFold(n_splits=n_splits, shuffle=True, random_state=1) and C= [0.01, 0.1, 1, 10], it is better to loop through the different values of Cs as the video explained. I had separate train() and predict() functions, which were reused after dividing the dataset via KFold. The model ran about 10 minutes and provided a good score.\\n(Ani Mkrtumyan)\", 'section': '4. Evaluation Metrics for Classification', 'question': 'What does KFold do?', 'course': 'machine-learning-zoomcamp', 'id': 'd30fc29d'}, '8eca9f73': {'text': \"I’m getting “ValueError: multi_class must be in ('ovo', 'ovr')” when using roc_auc_score to evaluate feature importance of numerical variables in question 1.\\nI was getting this error because I was passing the parameters to roc_auc_score incorrectly (df_train[col] , y_train) . The correct way is to pass the parameters in this way: roc_auc_score(y_train, df_train[col])\\nAsia Saeed\", 'section': '4. Evaluation Metrics for Classification', 'question': \"ValueError: multi_class must be in ('ovo', 'ovr')\", 'course': 'machine-learning-zoomcamp', 'id': '8eca9f73'}, '7b9eb7f7': {'text': 'from tqdm.auto import tqdm\\nTqdm - terminal progress bar\\nKrishna Anand', 'section': '4. Evaluation Metrics for Classification', 'question': 'Monitoring Wait times and progress of the code execution can be done with:', 'course': 'machine-learning-zoomcamp', 'id': '7b9eb7f7'}, 'c4aaeed9': {'text': 'Inverting or negating variables with ROC AUC scores less than the threshold is a valuable technique to improve feature importance and model performance when dealing with negatively correlated features. It helps ensure that the direction of the correlation aligns with the expectations of most machine learning algorithms.\\nAileah Gotladera', 'section': '4. Evaluation Metrics for Classification', 'question': 'What is the use of inverting or negating the variables less than the threshold?', 'course': 'machine-learning-zoomcamp', 'id': 'c4aaeed9'}, '3af31e2a': {'text': 'In case of using predict(X) for this task we are getting the binary classification predictions which are 0 and 1. This may lead to incorrect evaluation values.\\nThe solution is to use predict_proba(X)[:,1], where we get the probability that the value belongs to one of the classes.\\nVladimir Yesipov\\nPredict_proba shows probailites per class.\\nAni Mkrtumyan', 'section': '4. Evaluation Metrics for Classification', 'question': 'Difference between predict(X) and predict_proba(X)[:, 1]', 'course': 'machine-learning-zoomcamp', 'id': '3af31e2a'}, '746342ff': {'text': 'For churn/not churn predictions, I need help to interpret the following scenario please, what is happening when:\\nThe threshold is 1.0\\nFPR is 0.0\\nAnd TPR is 0.0\\nWhen the threshold is 1.0, the condition for belonging to the positive class (churn class) is g(x)>=1.0 But g(x) is a sigmoid function for a binary classification problem. It has values between 0 and 1. This function  never becomes equal to outermost values, i.e. 0 and 1.\\nThat is why there is no object, for which churn-condition could be satisfied. And that is why there is no any positive  (churn) predicted value (neither true positive, nor false positive), if threshold is equal to 1.0\\nAlena Kniazeva', 'section': '4. Evaluation Metrics for Classification', 'question': 'Why are FPR and TPR equal to 0.0, when threshold = 1.0?', 'course': 'machine-learning-zoomcamp', 'id': '746342ff'}, 'bda2c9b3': {'text': \"Matplotlib has a cool method to annotate where you could provide an X,Y point and annotate with an arrow and text. For example this will show an arrow pointing to the x,y point optimal threshold.\\nplt.annotate(f'Optimal Threshold: {optimal_threshold:.2f}\\\\nOptimal F1 Score: {optimal_f1_score:.2f}',\\nxy=(optimal_threshold, optimal_f1_score),\\nxytext=(0.3, 0.5),\\ntextcoords='axes fraction',\\narrowprops=dict(facecolor='black', shrink=0.05))\\nQuinn Avila\", 'section': '4. Evaluation Metrics for Classification', 'question': 'How can I annotate a graph?', 'course': 'machine-learning-zoomcamp', 'id': 'bda2c9b3'}, '41521c92': {'text': \"It's a complex and abstract topic and it requires some time to understand. You can move on without fully understanding the concept.\\nNonetheless, it might be useful for you to rewatch the video, or even watch videos/lectures/notes by other people on this topic, as the ROC AUC is one of the most important metrics used in Binary Classification models.\", 'section': '4. Evaluation Metrics for Classification', 'question': 'I didn’t fully understand the ROC curve. Can I move on?', 'course': 'machine-learning-zoomcamp', 'id': '41521c92'}, '25481ce5': {'text': 'One main reason behind that, is the way of splitting data. For example, we want to split data into train/validation/test with the ratios 60%/20%/20% respectively.\\nAlthough the following two options end up with the same ratio, the data itself is a bit different and not 100% matching in each case.\\n1)\\ndf_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)\\ndf_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\\n2)\\ndf_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\\nTherefore, I would recommend using the second method which is more consistent with the lessons and thus the homeworks.\\nIbraheem Taha', 'section': '4. Evaluation Metrics for Classification', 'question': 'Why do I have different values of accuracy than the options in the homework?', 'course': 'machine-learning-zoomcamp', 'id': '25481ce5'}, '1427d567': {'text': 'You can find the intercept between these two curves using numpy diff (https://numpy.org/doc/stable/reference/generated/numpy.diff.html ) and sign (https://numpy.org/doc/stable/reference/generated/numpy.sign.html):\\nI suppose here that you have your df_scores ready with your three columns ‘threshold’, ‘precision’ and ‘recall’:\\nYou want to know at which index (or indices) you have your intercept between precision and recall (namely: where the sign of the difference between precision and recall changes):\\nidx = np.argwhere(\\nnp.diff(\\nnp.sign(np.array(df_scores[\"precision\"]) - np.array(df_scores[\"recall\"]))\\n)\\n).flatten()\\nYou can print the result to easily read it:\\nprint(\\nf\"The precision and recall curves intersect at a threshold equal to {df_scores.loc[idx][\\'threshold\\']}.\"\\n)\\n(Mélanie Fouesnard)', 'section': '4. Evaluation Metrics for Classification', 'question': 'How to find the intercept between precision and recall curves by using numpy?', 'course': 'machine-learning-zoomcamp', 'id': '1427d567'}, '76c91dfb': {'text': \"In the demonstration video, we are shown how to calculate the precision and recall manually. You can use the Scikit Learn library to calculate the confusion matrix. precision, recall, f1_score without having to first define true positive, true negative, false positive, and false negative.\\nfrom sklearn.metrics import precision_score, recall_score, f1_score\\nprecision_score(y_true, y_pred, average='binary')\\nrecall_score(y_true, y_pred, average='binary')\\nf1_score(y_true, y_pred, average='binary')\\nRadikal Lukafiardi\", 'section': '4. Evaluation Metrics for Classification', 'question': 'Compute Recall, Precision, and F1 Score using scikit-learn library', 'course': 'machine-learning-zoomcamp', 'id': '76c91dfb'}, 'e4dd91cf': {'text': 'Cross-validation evaluates the performance of a model and chooses the best hyperparameters. Cross-validation does this by splitting the dataset into multiple parts (folds), typically 5 or 10. It then trains and evaluates your model multiple times, each time using a different fold as the validation set and the remaining folds as the training set.\\n\"C\" is a hyperparameter that is typically associated with regularization in models like Support Vector Machines (SVM) and logistic regression.\\nSmaller \"C\" values: They introduce more regularization, which means the model will try to find a simpler decision boundary, potentially underfitting the data. This is because it penalizes the misclassification of training examples more severely.\\nLarger \"C\" values: They reduce the regularization effect, allowing the model to fit the training data more closely, potentially overfitting. This is because it penalizes misclassification less severely, allowing the model to prioritize getting training examples correct.\\nAminat Abolade', 'section': '4. Evaluation Metrics for Classification', 'question': 'Why do we use cross validation?', 'course': 'machine-learning-zoomcamp', 'id': 'e4dd91cf'}, 'cc53ae94': {'text': \"Model evaluation metrics can be easily computed using off the shelf calculations available in scikit learn library. This saves a lot of time and more precise compared to our own calculations from the scratch using numpy and pandas libraries.\\nfrom sklearn.metrics import (accuracy_score,\\nprecision_score,\\nrecall_score,\\nf1_score,\\nroc_auc_score\\n)\\naccuracy = accuracy_score(y_val, y_pred)\\nprecision = precision_score(y_val, y_pred)\\nrecall = recall_score(y_val, y_pred)\\nf1 = f1_score(y_val, y_pred)\\nroc_auc = roc_auc_score(y_val, y_pred)\\nprint(f'Accuracy: {accuracy}')\\nprint(f'Precision: {precision}')\\nprint(f'Recall: {recall}')\\nprint(f'F1-Score: {f1}')\\nprint(f'ROC AUC: {roc_auc}')\\n(Harish Balasundaram)\", 'section': '4. Evaluation Metrics for Classification', 'question': 'Evaluate the Model using scikit learn metrics', 'course': 'machine-learning-zoomcamp', 'id': 'cc53ae94'}, '403bbdd8': {'text': 'Scikit-learn offers another way: precision_recall_fscore_support\\nExample:\\nfrom sklearn.metrics import precision_recall_fscore_support\\nprecision, recall, fscore, support = precision_recall_fscore_support(y_val, y_val_pred, zero_division=0)\\n(Gopakumar Gopinathan)', 'section': '4. Evaluation Metrics for Classification', 'question': 'Are there other ways to compute Precision, Recall and F1 score?', 'course': 'machine-learning-zoomcamp', 'id': '403bbdd8'}, '7c68ace0': {'text': '- ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.\\n- The reason for this recommendation is that ROC curves present an optimistic picture of the model on datasets with a class imbalance.\\n-This is because of the use of true negatives in the False Positive Rate in the ROC Curve and the careful avoidance of this rate in the Precision-Recall curve.\\n- If the proportion of positive to negative instances changes in a test set, the ROC curves will not change. Metrics such as accuracy, precision, lift and F scores use values from both columns of the confusion matrix. As a class distribution changes these measures will change as well, even if the fundamental classifier performance does not. ROC graphs are based upon TP rate and FP rate, in which each dimension is a strict columnar ratio, so cannot give an accurate picture of performance when there is class imbalance.\\n(Anudeep Vanjavakam)', 'section': '4. Evaluation Metrics for Classification', 'question': 'When do I use ROC vs Precision-Recall curves?', 'course': 'machine-learning-zoomcamp', 'id': '7c68ace0'}, '147577f5': {'text': 'You can use roc_auc_score function from sklearn.metrics module and pass the vector of the target variable (‘above_average’) as the first argument and the vector of feature values as the second one. This function will return AUC score for the feature that was passed as a second argument.\\n(Denys Soloviov)', 'section': '4. Evaluation Metrics for Classification', 'question': 'How to evaluate feature importance for numerical variables with AUC?', 'course': 'machine-learning-zoomcamp', 'id': '147577f5'}, 'd3ffb802': {'text': 'Precision-recall curve, and thus the score, explicitly depends on the ratio  of positive to negative test cases. This means that comparison of the F-score across different problems with differing class ratios is problematic. One way to address this issue is to use a standard class ratio  when making such comparisons.\\n(George Chizhmak)', 'section': '4. Evaluation Metrics for Classification', 'question': 'Dependence of the F-score on class imbalance', 'course': 'machine-learning-zoomcamp', 'id': 'd3ffb802'}, 'cc04d27a': {'text': \"We can import precision_recall_curve from scikit-learn and plot the graph as follows:\\nfrom sklearn.metrics import precision_recall_curve\\nprecision, recall, thresholds = precision_recall_curve(y_val, y_predict)\\nplt.plot(thresholds, precision[:-1], label='Precision')\\nplt.plot(thresholds, recall[:-1], label='Recall')\\nplt.legend()\\nHrithik Kumar Advani\", 'section': '4. Evaluation Metrics for Classification', 'question': 'Quick way to plot Precision-Recall Curve', 'course': 'machine-learning-zoomcamp', 'id': 'cc04d27a'}, '927b5e09': {'text': 'For multiclass classification it is important to keep class balance when you split the data set. In this case Stratified k-fold returns folds that contains approximately the sme percentage of samples of each classes.\\nPlease check the realisation in sk-learn library:\\nhttps://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold\\nOlga Rudakova', 'section': '5. Deploying Machine Learning Models', 'question': 'What is Stratified k-fold?', 'course': 'machine-learning-zoomcamp', 'id': '927b5e09'}, 'd22efea7': {'text': 'Week 5 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/05-deployment/homework.md\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nHW 3 Solution: https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/03-classification/homework_3.ipynb\\nEvaluation Matrix: https://docs.google.com/spreadsheets/d/e/2PACX-1vQCwqAtkjl07MTW-SxWUK9GUvMQ3Pv_fF8UadcuIYLgHa0PlNu9BRWtfLgivI8xSCncQs82HDwGXSm3/pubhtml\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYouTube Link: 5.X --- https://www.youtube.com/watch?v=agIFak9A3m8&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=49\\n~~~ Nukta Bhatia ~~~', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I get started with Week 5?', 'course': 'machine-learning-zoomcamp', 'id': 'd22efea7'}, 'd1409f67': {'text': 'While weeks 1-4 can relatively easily be followed and the associated homework completed with just about any default environment / local setup, week 5 introduces several layers of abstraction and dependencies.\\nIt is advised to prepare your “homework environment” with a cloud provider of your choice. A thorough step-by-step guide for doing so for an AWS EC2 instance is provided in an introductory video taken from the MLOPS course here:\\nhttps://www.youtube.com/watch?v=IXSiYkP23zo\\nNote that (only) small AWS instances can be run for free, and that larger ones will be billed hourly based on usage (but can and should be stopped when not in use).\\nAlternative ways are sketched here:\\nhttps://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/01-intro/06-environment.md', 'section': '5. Deploying Machine Learning Models', 'question': 'Errors related to the default environment: WSL, Ubuntu, proper Python version, installing pipenv etc.', 'course': 'machine-learning-zoomcamp', 'id': 'd1409f67'}, 'e07759e9': {'text': \"You’ll need a kaggle account\\nGo to settings, API and click `Create New Token`. This will download a `kaggle.json` file which contains your `username` and `key` information\\nIn the same location as your Jupyter NB, place the `kaggle.json` file\\nRun `!chmod 600 <ENTER YOUR FILEPATH>/kaggle.json`\\nMake sure to import os via `import os` and then run:\\nos.environ['KAGGLE_CONFIG_DIR'] = <STRING OF YOUR FILE PATH>\\nFinally you can run directly in your NB: `!kaggle datasets download -d kapturovalexander/bank-credit-scoring`\\nAnd then you can unzip the file and access the CSV via: `!unzip -o bank-credit-scoring.zip`\\n>>> Michael Fronda <<<\", 'section': '5. Deploying Machine Learning Models', 'question': 'How to download CSV data via Jupyter NB and the Kaggle API, for one seamless experience', 'course': 'machine-learning-zoomcamp', 'id': 'e07759e9'}, '620fb76e': {'text': 'Cd .. (go back)\\nLs (see current folders)\\nCd ‘path’/ (go to this path)\\nPwd (home)\\nCat “file name’ --edit txt file in ubuntu\\nAileah Gotladera', 'section': '5. Deploying Machine Learning Models', 'question': 'Basic Ubuntu Commands:', 'course': 'machine-learning-zoomcamp', 'id': '620fb76e'}, '957280d8': {'text': 'Open terminal and type the code below to check the version on your laptop\\npython3 --version\\nFor windows,\\nVisit the official python website at  https://www.python.org/downloads/ to download the python version you need for installation\\nRun the installer and  ensure to check the box that says “Add Python to PATH” during installation and complete the installation by following the prompts\\nOr\\nFor Python 3,\\nOpen your command prompt or terminal and run the following command:\\npip install --upgrade python\\nAminat Abolade', 'section': '5. Deploying Machine Learning Models', 'question': 'Installing and updating to the python version 3.10 and higher', 'course': 'machine-learning-zoomcamp', 'id': '957280d8'}, '185096ad': {'text': 'It is quite simple, and you can follow these instructions here:\\nhttps://www.youtube.com/watch?v=qYlgUDKKK5A&ab_channel=NeuralNine\\nMake sure that you have “Virtual Machine Platform” feature activated in your Windows “Features”. To do that, search “features” in the research bar and see if the checkbox is selected. You also need to make sure that your system (in the bios) is able to virtualize. This is usually the case.\\nIn the Microsoft Store: look for ‘Ubuntu’ or ‘Debian’ (or any linux distribution you want) and install it\\nOnce it is downloaded, open the app and choose a username and a password (secured one). When you type your password, nothing will show in the window, which is normal: the writing is invisible.\\nYou are now inside of your linux system. You can test some commands such as “pwd”. You are not in your Windows system.\\nTo go to your windows system: you need to go back two times with cd ../.. And then go to the “mnt” directory with cd mnt. If you list here your files, you will see your disks. You can move to the desired folder, for example here I moved to the ML_Zoomcamp folder:\\nPython should be already installed but you can check it by running sudo apt install python3 command.\\nYou can make your actual folder your default folder when you open your Ubuntu terminal with this command : echo \"cd ../../mnt/your/folder/path\" >> ~/.bashrc\\nYou can disable bell sounds (when you type something that does not exist for example) by modifying the inputrc file with this command: sudo vim /etc/inputrc\\nYou have to uncomment the set bell-style none line -> to do that, press the “i” keyboard letter (for insert) and go with your keyboard to this line. Delete the # and then press the Escape keyboard touch and finally press “:wq” to write (it saves your modifications) then quit.\\nYou can check that your modifications are taken into account by opening a new terminal (you can pin it to your task bar so you do not have to go to the Microsoft app each time).\\nYou will need to install pip by running this command sudo apt install python3-pip\\nNB: I had this error message when trying to install pipenv (https://github.com/microsoft/WSL/issues/5663):\\n/sbin/ldconfig.real: Can\\'t link /usr/lib/wsl/lib/libnvoptix_loader.so.1 to libnvoptix.so.1\\n/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link\\nSo I had to create the following symbolic link:\\nsudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/lib64/libcuda.so\\n(Mélanie Fouesnard)', 'section': '5. Deploying Machine Learning Models', 'question': 'How to install WSL on Windows 10 and 11 ?', 'course': 'machine-learning-zoomcamp', 'id': '185096ad'}, 'ec88d101': {'text': \"Do you get errors building the Docker image on the Mac M1 chipset?\\nThe error I was getting was:\\nCould not open '/lib64/ld-linux-x86-64.so.2': No such file or directory\\nThe fix (from here): vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\\nOpen mlbookcamp-code/course-zoomcamp/01-intro/environment/Dockerfile\\nReplace line 1 with\\nFROM --platform=linux/amd64 ubuntu:latest\\nNow build the image as specified. In the end it took over 2 hours to build the image but it did complete in the end.\\nDavid Colton\", 'section': '5. Deploying Machine Learning Models', 'question': 'Error building Docker images on Mac with M1 silicon', 'course': 'machine-learning-zoomcamp', 'id': 'ec88d101'}, '7156679d': {'text': 'Import waitress\\nprint(waitress.__version__)\\nKrishna Anand', 'section': '5. Deploying Machine Learning Models', 'question': 'Method to find the version of any install python libraries in jupyter notebook', 'course': 'machine-learning-zoomcamp', 'id': '7156679d'}, '4b2a3181': {'text': 'Working on getting Docker installed - when I try running hello-world I am getting the error.\\nDocker: Cannot connect to the docker daemon at unix:///var/run/docker.sock. Is the Docker daemon running ?\\nSolution description\\nIf you’re getting this error on WSL, re-install your docker: remove the docker installation from WSL and install Docker Desktop on your host machine (Windows).\\nOn Linux, start the docker daemon with either of these commands:\\nsudo dockerd\\nsudo service docker start\\nAdded by Ugochukwu Onyebuchi', 'section': '5. Deploying Machine Learning Models', 'question': 'Cannot connect to the docker daemon. Is the Docker daemon running?', 'course': 'machine-learning-zoomcamp', 'id': '4b2a3181'}, '73bd7fa1': {'text': 'After using the command “docker build -t churn-prediction .” to build the Docker image, the above error is raised and the image is not created.\\nIn your Dockerfile, change the Python version in the first line the Python version installed in your system:\\nFROM python:3.7.5-slim\\nTo find your python version, use the command python --version. For example:\\npython --version\\n>> Python 3.9.7\\nThen, change it on your Dockerfile:\\nFROM python:3.9.7-slim\\nAdded by Filipe Melo', 'section': '5. Deploying Machine Learning Models', 'question': \"The command '/bin/sh -c pipenv install --deploy --system &&  rm -rf /root/.cache' returned a non-zero code: 1\", 'course': 'machine-learning-zoomcamp', 'id': '73bd7fa1'}, 'a4d3b1e5': {'text': 'When the facilitator was adding sklearn to the virtual environment in the lectures, he used sklearn==0.24.1 and it ran smoothly. But while doing the homework and you are asked to use the 1.0.2 version of sklearn, it gives errors.\\nThe solution is to use the full name of sklearn. That is, run it as “pipenv install scikit-learn==1.0.2” and the error will go away, allowing you to install sklearn for the version in your virtual environment.\\nOdimegwu David\\nHomework asks you to install 1.3.1\\nPipenv install scikit-learn==1.3.1\\nUse Pipenv to install Scikit-Learn version 1.3.1\\nGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'Running “pipenv install sklearn==1.0.2” gives errors. What should I do?', 'course': 'machine-learning-zoomcamp', 'id': 'a4d3b1e5'}, '1d462fe0': {'text': 'What is the reason we don’t want to keep the docker image in our system and why do we need to run docker containers with `--rm` flag?\\nFor best practice, you don’t want to have a lot of abandoned docker images in your system. You just update it in your folder and trigger the build one more time.\\nThey consume extra space on your disk. Unless you don’t want to re-run the previously existing containers, it is better to use the `--rm` option.\\nThe right way to say: “Why do we remove the docker container in our system?”. Well the docker image is still kept; it is the container that is not kept. Upon execution, images are not modified; only containers are.\\nThe option `--rm` is for removing containers. The images remain until you remove them manually. If you don’t specify a version when building an image, it will always rebuild and replace the latest tag. `docker images` shows you all the image you have pulled or build so far.\\nDuring development and testing you usually specify `--rm` to get the containers auto removed upon exit. Otherwise they get accumulated in a stopped state, taking up space. `docker ps -a` shows you all the containers you have in your host. Each time you change Pipfile (or any file you baked into the container), you rebuild the image under the same tag or a new tag. It’s important to understand the difference between the term “docker image” and “docker container”. Image is what we build with all the resources baked in. You can move it around, maintain it in a repository, share it. Then we use the image to spin up instances of it and they are called containers.\\nAdded by Muhammad Awon', 'section': '5. Deploying Machine Learning Models', 'question': 'Why do we need the --rm flag', 'course': 'machine-learning-zoomcamp', 'id': '1d462fe0'}, '366d7563': {'text': 'When you create the dockerfile the name should be dockerfile and needs to be without extension. One of the problems we can get at this point is to create the dockerfile as a dockerfile extension Dockerfile.dockerfile which creates an error when we build the docker image. Instead we just need to create the file without extension: Dockerfile and will run perfectly.\\nAdded by Pastor Soto', 'section': '5. Deploying Machine Learning Models', 'question': 'Failed to read Dockerfile', 'course': 'machine-learning-zoomcamp', 'id': '366d7563'}, 'cef156d1': {'text': 'Refer to the page https://docs.docker.com/desktop/install/mac-install/ remember to check if you have apple chip or intel chip.', 'section': '5. Deploying Machine Learning Models', 'question': 'Install docker on MacOS', 'course': 'machine-learning-zoomcamp', 'id': 'cef156d1'}, 'b632d2ea': {'text': 'Problem: When I am trying to pull the image with the docker pull svizor/zoomcamp-model command I am getting an error:\\nUsing default tag: latest\\nError response from daemon: manifest for svizor/zoomcamp-model:latest not found: manifest unknown: manifest unknown\\nSolution: The docker by default uses the latest tag to avoid this use the correct tag from image description. In our case use command:\\ndocker pull svizor/zoomcamp-model:3.10.12-slim\\nAdded by Vladimir Yesipov', 'section': '5. Deploying Machine Learning Models', 'question': 'I cannot pull the image with docker pull command', 'course': 'machine-learning-zoomcamp', 'id': 'b632d2ea'}, '514e27bb': {'text': 'Using the command docker images or docker image ls will dump all information for all local Docker images. It is possible to dump the information only for a specified image by using:\\ndocker image ls <image name>\\nOr alternatively:\\ndocker images <image name>\\nIn action to that it is possible to only dump specific information provided using the option --format which will dump only the size for the specified image name when using the command below:\\ndocker image ls --format \"{{.Size}}\" <image name>\\nOr alternatively:\\ndocker images --format \"{{.Size}}\" <image name>\\nSylvia Schmitt', 'section': '5. Deploying Machine Learning Models', 'question': 'Dumping/Retrieving only the size of for a specific Docker image', 'course': 'machine-learning-zoomcamp', 'id': '514e27bb'}, '5c67e086': {'text': \"It creates them in\\nOSX/Linux: ~/.local/share/virtualenvs/folder-name_cyrptic-hash\\nWindows: C:\\\\Users\\\\<USERNAME>\\\\.virtualenvs\\\\folder-name_cyrptic-hash\\nEg: C:\\\\Users\\\\Ella\\\\.virtualenvs\\\\code-qsdUdabf (for module-05 lesson)\\nThe environment name is the name of the last folder in the folder directory where we used the pipenv install command (or any other pipenv command). E.g. If you run any pipenv command in folder path ~/home/user/Churn-Flask-app, it will create an environment named Churn-Flask-app-some_random_characters, and it's path will be like this: /home/user/.local/share/virtualenvs/churn-flask-app-i_mzGMjX.\\nAll libraries of this environment will be installed inside this folder. To activate this environment, I will need to cd into the project folder again, and type pipenv shell. In short, the location of the project folder acts as an identifier for an environment, in place of any name.\\n(Memoona Tahira)\", 'section': '5. Deploying Machine Learning Models', 'question': 'Where does pipenv create environments and how does it name them?', 'course': 'machine-learning-zoomcamp', 'id': '5c67e086'}, '63a81b57': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp', 'id': '63a81b57'}, '047f57fb': {'text': \"$ docker exec -it 1e5a1b663052 bash\\nthe input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'\\nFix:\\nwinpty docker exec -it 1e5a1b663052 bash\\nA TTY is a terminal interface that supports escape sequences, moving the cursor around, etc.\\nWinpty is a Windows software package providing an interface similar to a Unix pty-master for communicating with Windows console programs.\\nMore info on terminal, shell, console applications hi and so on:\\nhttps://conemu.github.io/en/TerminalVsShell.html\\n(Marcos MJD)\", 'section': '5. Deploying Machine Learning Models', 'question': 'The input device is not a TTY when running docker in interactive mode (Running Docker on Windows in GitBash)', 'course': 'machine-learning-zoomcamp', 'id': '047f57fb'}, '11f7371c': {'text': 'Initially, I did not assume there was a model2. I copied the original model1.bin and dv.bin. Then when I tried to load using\\nCOPY [\"model2.bin\", \"dv.bin\", \"./\"]\\nthen I got the error above in MINGW64 (git bash) on Windows.\\nThe temporary solution I found was to use\\nCOPY [\"*\", \"./\"]\\nwhich I assume combines all the files from the original docker image and the files in your working directory.\\nAdded by Muhammed Tan', 'section': '5. Deploying Machine Learning Models', 'question': 'Error: failed to compute cache key: \"/model2.bin\" not found: not found', 'course': 'machine-learning-zoomcamp', 'id': '11f7371c'}, '45f39b76': {'text': 'Create a virtual environment using the Cmd command (command) and use pip freeze command to write the requirements in the text file\\nKrishna Anand', 'section': '5. Deploying Machine Learning Models', 'question': 'Failed to write the dependencies to pipfile and piplock file', 'course': 'machine-learning-zoomcamp', 'id': '45f39b76'}, '94e17563': {'text': 'f-String not properly keyed in: does anyone knows why i am getting error after import pickle?\\nThe first error showed up because your f-string is using () instead of {} around C. So, should be: f’model_C={C}.bin’\\nThe second error as noticed by Sriniketh, your are missing one parenthesis it should be pickle.dump((dv, model), f_out)\\n(Humberto R.)', 'section': '5. Deploying Machine Learning Models', 'question': 'f-strings', 'course': 'machine-learning-zoomcamp', 'id': '94e17563'}, '9dd8efd2': {'text': \"This error happens because pipenv is already installed but you can't access it from the path.\\nThis error comes out if you run.\\npipenv  --version\\npipenv shell\\nSolution for Windows\\nOpen this option\\nClick here\\nClick in Edit Button\\nMake sure the next two locations are on the PATH, otherwise, add it.\\nC:\\\\Users\\\\AppData\\\\....\\\\Python\\\\PythonXX\\\\\\nC:\\\\Users\\\\AppData\\\\....\\\\Python\\\\PythonXX\\\\Scripts\\\\\\nAdded by Alejandro Aponte\\nNote: this answer assumes you don’t use Anaconda. For Windows, using Anaconda would be a better choice and less prone to errors.\", 'section': '5. Deploying Machine Learning Models', 'question': \"'pipenv' is not recognized as an internal or external command, operable program or batch file.\", 'course': 'machine-learning-zoomcamp', 'id': '9dd8efd2'}, '9531dc92': {'text': 'Following the instruction from video week-5.6, using pipenv to install python libraries throws below error\\nSolution to this error is to make sure that you are working with python==3.9 (as informed in the very first lesson of the zoomcamp) and not python==3.10.\\nAdded by Hareesh Tummala', 'section': '5. Deploying Machine Learning Models', 'question': 'AttributeError: module ‘collections’ has no attribute ‘MutableMapping’', 'course': 'machine-learning-zoomcamp', 'id': '9531dc92'}, '14e0e697': {'text': 'After entering `pipenv shell` don’t forget to use `exit` before `pipenv --rm`, as it may cause errors when trying to install packages, it is unclear whether you are “in the shell”(using Windows) at the moment as there are no clear markers for it.\\nIt can also mess up PATH, if that’s the case, here’s terminal commands for fixing that:\\n# for Windows\\nset VIRTUAL_ENV \"\"\\n# for Unix\\nexport VIRTUAL_ENV=\"\"\\nAlso manually re-creating removed folder at `C:\\\\Users\\\\username\\\\.virtualenvs\\\\removed-envname` can help, removed-envname can be seen at the error message.\\nAdded by Andrii Larkin', 'section': '5. Deploying Machine Learning Models', 'question': \"Q: ValueError: Path not found or generated: WindowsPath('C:/Users/username/.virtualenvs/envname/Scripts')\", 'course': 'machine-learning-zoomcamp', 'id': '14e0e697'}, '6189375f': {'text': 'Set the host to ‘0.0.0.0’ on the flask app and dockerfile then RUN the url using localhost.\\n(Theresa S.)', 'section': '5. Deploying Machine Learning Models', 'question': \"ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\", 'course': 'machine-learning-zoomcamp', 'id': '6189375f'}, '3419ee27': {'text': 'Solution:\\nThis error occurred because I used single quotes around the filenames. Stick to double quotes', 'section': '5. Deploying Machine Learning Models', 'question': 'docker  build ERROR [x/y] COPY …', 'course': 'machine-learning-zoomcamp', 'id': '3419ee27'}, '8b8c1603': {'text': 'I tried the first solution on Stackoverflow which recommended running `pipenv lock` to update the Pipfile.lock. However, this didn’t resolve it. But the following switch to the pipenv installation worked\\nRUN pipenv install --system --deploy --ignore-pipfile', 'section': '5. Deploying Machine Learning Models', 'question': 'Fix error during installation of Pipfile inside Docker container', 'course': 'machine-learning-zoomcamp', 'id': '8b8c1603'}, 'e54d5411': {'text': 'Solution\\nThis error was because there was another instance of gunicorn running. So I thought of removing this along with the zoomcamp_test image. However, it didn’t let me remove the orphan container. So I did the following\\nRunning the following commands\\ndocker ps -a <to list all docker containers>\\ndocker images <to list images>\\ndocker stop <container ID>\\ndocker rm <container ID>\\ndocker rmi image\\nI rebuilt the Docker image, and ran it once again; this time it worked correctly and I was able to serve the test script to the endpoint.', 'section': '5. Deploying Machine Learning Models', 'question': 'How to fix error after running the Docker run command', 'course': 'machine-learning-zoomcamp', 'id': 'e54d5411'}, 'f7b38587': {'text': 'I was getting the below error when I rebuilt the docker image although the port was not allocated, and it was working fine.\\nError message:\\nError response from daemon: driver failed programming external connectivity on endpoint beautiful_tharp (875be95c7027cebb853a62fc4463d46e23df99e0175be73641269c3d180f7796): Bind for 0.0.0.0:9696 failed: port is already allocated.\\nSolution description\\nIssue has been resolved running the following command:\\ndocker kill $(docker ps -q)\\nhttps://github.com/docker/for-win/issues/2722\\nAsia Saeed', 'section': '5. Deploying Machine Learning Models', 'question': 'Bind for 0.0.0.0:9696 failed: port is already allocated', 'course': 'machine-learning-zoomcamp', 'id': 'f7b38587'}, 'be86b333': {'text': 'I was getting the error on client side with this\\nClient Side:\\nFile \"C:\\\\python\\\\lib\\\\site-packages\\\\urllib3\\\\connectionpool.py\", line 703, in urlopen …………………..\\nraise ConnectionError(err, request=request)\\nrequests.exceptions.ConnectionError: (\\'Connection aborted.\\', RemoteDisconnected(\\'Remote end closed connection without response\\'))\\nSevrer Side:\\nIt showed error for gunicorn\\nThe waitress  cmd was running smoothly from server side\\nSolution:\\nUse the ip-address as 0.0.0.0:8000 or 0.0.0.0:9696.They are the ones which do work max times\\nAamir Wani', 'section': '5. Deploying Machine Learning Models', 'question': 'Bind for 127.0.0.1:5000 showing error', 'course': 'machine-learning-zoomcamp', 'id': 'be86b333'}, '4ea80460': {'text': 'Install it by using command\\n% brew install md5sha1sum\\nThen run command to check hash for file to check if they the same with the provided\\n% md5sum model1.bin dv.bin\\nOlga Rudakova', 'section': '5. Deploying Machine Learning Models', 'question': 'Installing md5sum on Macos', 'course': 'machine-learning-zoomcamp', 'id': '4ea80460'}, '8006b496': {'text': 'Problem description:\\nI started a web-server in terminal (command window, powershell, etc.). How can I run another python script, which makes a request to this server?\\nSolution description:\\nJust open another terminal (command window, powershell, etc.) and run a python script.\\nAlena Kniazeva', 'section': '5. Deploying Machine Learning Models', 'question': 'How to run a script while a web-server is working?', 'course': 'machine-learning-zoomcamp', 'id': '8006b496'}, '704f95d8': {'text': \"Problem description:\\nIn video 5.5 when I do pipenv shell and then pipenv run gunicorn --bind 0.0.0.0:9696 predict:app, I get the following warning:\\nUserWarning: Trying to unpickle estimator DictVectorizer from version 1.1.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\\nSolution description:\\nWhen you create a virtual env, you should use the same version of Scikit-Learn that you used for training the model on this case it's 1.1.1. There is version conflicts so we need to make sure our model and dv files are created from the version we are using for the project.\\nBhaskar Sarma\", 'section': '5. Deploying Machine Learning Models', 'question': 'Version-conflict in pipenv', 'course': 'machine-learning-zoomcamp', 'id': '704f95d8'}, 'a5b3296b': {'text': \"If you install packages via pipenv install, and get an error that ends like this:\\npipenv.vendor.plette.models.base.ValidationError: {'python_version': '3.9', 'python_full_version': '3.9.13'}\\npython_full_version: 'python_version' must not be present with 'python_full_version'\\npython_version: 'python_full_version' must not be present with 'python_version'\\nDo this:\\nopen Pipfile in nano editor, and remove either the python_version or python_full_version line, press CTRL+X, type Y and click Enter to save changed\\nType pipenv lock to create the Pipfile.lock.\\nDone. Continue what you were doing\", 'section': '5. Deploying Machine Learning Models', 'question': 'Python_version and Python_full_version error after running pipenv install:', 'course': 'machine-learning-zoomcamp', 'id': 'a5b3296b'}, 'a23b276a': {'text': 'If during running the  docker build command, you get an error like this:\\nYour Pipfile.lock (221d14) is out of date. Expected: (939fe0).\\nUsage: pipenv install [OPTIONS] [PACKAGES]...\\nERROR:: Aborting deploy\\nOption 1: Delete the pipfile.lock via rm Pipfile, and then rebuild the lock via  pipenv lock from the terminal before retrying the docker build command.\\nOption 2:  If it still doesn’t work, remove the pipenv environment, Pipfile and Pipfile.lock, and create a new one before building docker again. Commands to remove pipenv environment and removing pipfiles:\\npipenv  --rm\\nrm Pipfile*', 'section': '5. Deploying Machine Learning Models', 'question': 'Your Pipfile.lock (221d14) is out of date (during Docker build)', 'course': 'machine-learning-zoomcamp', 'id': 'a23b276a'}, '3537eeee': {'text': 'Ans: Pip uninstall waitress mflow. Then reinstall just mlflow. By this time you should have successfully built your docker image so you dont need to reinstall waitress. All good. Happy learning.\\nAdded by 🅱🅻🅰🆀', 'section': '5. Deploying Machine Learning Models', 'question': 'You are using windows. Conda environment. You then use waitress instead of gunicorn. After a few runs, suddenly mlflow server fails to run.', 'course': 'machine-learning-zoomcamp', 'id': '3537eeee'}, '1d6d5b51': {'text': \"Ans: so you have created the env. You need to make sure you're in eu-west-1 (ireland) when you check the EB environments. Maybe you're in a different region in your console.\\nAdded by Edidiong Esu\", 'section': '5. Deploying Machine Learning Models', 'question': 'Completed creating the environment locally but could not find the environment on AWS.', 'course': 'machine-learning-zoomcamp', 'id': '1d6d5b51'}, '3a98b6b7': {'text': 'Running \\'pip install waitress\\' as a command on GitBash was not downloading the executable file \\'waitress-serve.exe\\'. You need this file to be able to run commands with waitress in Git Bash. To solve this:\\nopen a Jupyter notebook and run the same command \\' pip install waitress\\'. This way the executable file will be downloaded. The notebook may give you this warning : \\'WARNING: The script waitress-serve.exe is installed in \\'c:\\\\Users\\\\....\\\\anaconda3\\\\Scripts\\' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\'\\nAdd the path where \\'waitress-serve.exe\\' is installed into gitbash\\'s PATH as such:\\nenter the following command in gitbash: nano ~/.bashrc\\nadd the path to \\'waitress-serve.exe\\' to PATH using this command: export PATH=\"/path/to/waitress:$PATH\"\\nclose gitbash and open it again and you should be good to go\\nAdded by Bachar Kabalan', 'section': '5. Deploying Machine Learning Models', 'question': 'Installing waitress on Windows via GitBash: “waitress-serve” command not found', 'course': 'machine-learning-zoomcamp', 'id': '3a98b6b7'}, 'd42eb923': {'text': 'Q2.1: Use Pipenv to install Scikit-Learn version 1.3.1\\nThis is an error I got while executing the above step in the ml-zoomcamp conda environment. The error is not fatal and just warns you that explicit language specifications are not set out in our bash profile. A quick-fix is here:\\nhttps://stackoverflow.com/questions/49436922/getting-error-while-trying-to-run-this-command-pipenv-install-requests-in-ma\\nBut one can proceed without addressing it.\\nAdded by Abhirup Ghosh', 'section': '5. Deploying Machine Learning Models', 'question': 'Warning: the environment variable LANG is not set!', 'course': 'machine-learning-zoomcamp', 'id': 'd42eb923'}, '42aebe10': {'text': 'The provided image FROM svizor/zoomcamp-model:3.10.12-slim has a model and dictvectorizer that should be used for question 6. \"model2.bin\", \"dv.bin\"\\nAdded by Quinn Avila', 'section': '5. Deploying Machine Learning Models', 'question': 'Module5 HW Question 6', 'course': 'machine-learning-zoomcamp', 'id': '42aebe10'}, 'e4f62713': {'text': 'https://apps.microsoft.com/detail/windows-terminal/9N0DX20HK701?hl=es-419&gl=CO\\nAdded by Dawuta Smit', 'section': '5. Deploying Machine Learning Models', 'question': 'Terminal Used in Week 5 videos:', 'course': 'machine-learning-zoomcamp', 'id': 'e4f62713'}, 'c13d811f': {'text': \"Question:\\nWhen running\\npipenv run waitress-serve --listen=localhost:9696 q4-predict:app\\nI get the following:\\nThere was an exception (ValueError) importing your module.\\nIt had these arguments:\\n1. Malformed application 'q4-predict:app'\\nAnswer:\\nWaitress doesn’t accept a dash in the python file name.\\nThe solution is to rename the file replacing a dash with something else for instance with an underscore eg q4_predict.py\\nAdded by Alex Litvinov\", 'section': '5. Deploying Machine Learning Models', 'question': 'waitress-serve shows Malformed application', 'course': 'machine-learning-zoomcamp', 'id': 'c13d811f'}, 'dfb41f7e': {'text': 'I wanted to have a fast and simple way to check if the HTTP POST requests are working just running a request from command line. This can be done running ‘curl’. \\n(Used with WSL2 on Windows, should also work on Linux and MacOS)\\ncurl --json \\'<json data>\\' <url>\\n# piping the structure to the command\\ncat <json file path> | curl --json @- <url>\\necho \\'<json data>\\' | curl --json @- <url>\\n# example using piping\\necho \\'{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\\'\\\\\\n| curl --json @- http://localhost:9696/predict\\nAdded by Sylvia Schmitt', 'section': '5. Deploying Machine Learning Models', 'question': 'Testing HTTP POST requests from command line using curl', 'course': 'machine-learning-zoomcamp', 'id': 'dfb41f7e'}, 'd04e77f8': {'text': 'Question:\\nWhen executing\\neb local run  --port 9696\\nI get the following error:\\nERROR: NotSupportedError - You can use \"eb local\" only with preconfigured, generic and multicontainer Docker platforms.\\nAnswer:\\nThere are two options to fix this:\\nRe-initialize by running eb init -i and choosing the options from a list (the first default option for docker platform should be fine).\\nEdit the ‘.elasticbeanstalk/config.yml’ directly changing the default_platform from Docker to default_platform: Docker running on 64bit Amazon Linux 2023\\nThe disadvantage of the second approach is that the option might not be available the following years\\nAdded by Alex Litvinov', 'section': '5. Deploying Machine Learning Models', 'question': 'NotSupportedError - You can use \"eb local\" only with preconfigured, generic and multicontainer Docker platforms.', 'course': 'machine-learning-zoomcamp', 'id': 'd04e77f8'}, '451c067f': {'text': \"You need to include the protocol scheme: 'http://localhost:9696/predict'.\\nWithout the http:// part, requests has no idea how to connect to the remote server.\\nNote that the protocol scheme must be all lowercase; if your URL starts with HTTP:// for example, it won’t find the http:// connection adapter either.\\nAdded by George Chizhmak\", 'section': '5. Deploying Machine Learning Models', 'question': \"Requests Error: No connection adapters were found for 'localhost:9696/predict'.\", 'course': 'machine-learning-zoomcamp', 'id': '451c067f'}, '9fbfcd61': {'text': 'While running the docker image if you get the same result check which model you are using.\\nRemember you are using a model downloading model + python version so remember to change the model in your file when running your prediction test.\\nAdded by Ahmed Okka', 'section': '5. Deploying Machine Learning Models', 'question': 'Getting the same result', 'course': 'machine-learning-zoomcamp', 'id': '9fbfcd61'}, '1ed8cfde': {'text': 'Ensure that you used pipenv to install the necessary modules including gunicorn. As pipfiles for virtual environments, you can use pipenv shell and then build+run your docker image. - Akshar Goyal', 'section': '5. Deploying Machine Learning Models', 'question': 'Trying to run a docker image I built but it says it’s unable to start the container process', 'course': 'machine-learning-zoomcamp', 'id': '1ed8cfde'}, '3f97f50f': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\", 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from my local machine to docker container?', 'course': 'machine-learning-zoomcamp', 'id': '3f97f50f'}, 'a24a874a': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker container’s working directory?', 'course': 'machine-learning-zoomcamp', 'id': 'a24a874a'}, 'bf563b1f': {'text': 'I struggled with the command :\\neb init -p docker tumor-diagnosis-serving -r eu-west-1\\nWhich resulted in an error when running : eb local run --port 9696\\nERROR: NotSupportedError - You can use \"eb local\" only with preconfigured, generic and multicontainer Docker platforms.\\nI replaced it with :\\neb init -p \"Docker running on 64bit Amazon Linux 2\" tumor-diagnosis-serving -r eu-west-1\\nThis allowed the recognition of the Dockerfile and the build/run of the docker container.\\nAdded by Mélanie Fouesnard', 'section': '5. Deploying Machine Learning Models', 'question': 'I can’t create the environment on AWS Elastic Beanstalk with the command proposed during the video', 'course': 'machine-learning-zoomcamp', 'id': 'bf563b1f'}, '21e9facf': {'text': \"I had this error when creating a AWS ElasticBean environment: eb create tumor-diagnosis-env\\nERROR   Instance deployment: Both 'Dockerfile' and 'Dockerrun.aws.json' are missing in your source bundle. Include at least one of them. The deployment failed.\\nI did not committed the files used to build the container, particularly the Dockerfile. After a git add and git commit of the modified files, the command works.\\nAdded by Mélanie Fouesnard\", 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Dockerfile missing when creating the AWS ElasticBean environment', 'course': 'machine-learning-zoomcamp', 'id': '21e9facf'}, 'aef786aa': {'text': 'Week 6 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/06-trees/homework.md\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nHW 4 Solution: https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/04-evaluation/homework_4.ipynb\\nEvaluation Matrix: https://docs.google.com/spreadsheets/d/e/2PACX-1vQCwqAtkjl07MTW-SxWUK9GUvMQ3Pv_fF8UadcuIYLgHa0PlNu9BRWtfLgivI8xSCncQs82HDwGXSm3/pubhtml\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYouTube Link: 6.X --- https://www.youtube.com/watch?v=GJGmlfZoCoU&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=57\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~~Nukta Bhatia~~~', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'How to get started with Week 6?', 'course': 'machine-learning-zoomcamp', 'id': 'aef786aa'}, '68858294': {'text': 'During the XGBoost lesson, we created a parser to extract the training and validation auc from the standard output. However, we can accomplish that in a more straightforward way.\\nWe can use the evals_result  parameters, which takes an empty dictionary and updates it for each tree. Additionally, you can store the data in a dataframe and plot it in an easier manner.\\nAdded by Daniel Coronel', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'How to get the training and validation metrics from XGBoost?', 'course': 'machine-learning-zoomcamp', 'id': '68858294'}, '85ac722e': {'text': 'You should create sklearn.ensemble.RandomForestRegressor object. It’s rather similar to sklearn.ensemble.RandomForestClassificator for classification problems. Check https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html for more information.\\nAlena Kniazeva', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'How to solve regression problems with random forest in scikit-learn?', 'course': 'machine-learning-zoomcamp', 'id': '85ac722e'}, 'b61d2e92': {'text': 'In question 6, I was getting ValueError: feature_names must be string, and may not contain [, ] or < when I was creating DMatrix for train and validation\\nSolution description\\nThe cause of this error is that some of the features names contain special characters like = and <, and I fixed the error by removing them as  follows:\\nfeatures= [i.replace(\"=<\", \"_\").replace(\"=\",\"_\") for i in features]\\nAsia Saeed\\nAlternative Solution:\\nIn my case the equal sign “=” was not a problem, so in my opinion the first part of Asias solution features= [i.replace(\"=<\", \"_\") should work as well.\\nFor me this works:\\nfeatures = []\\nfor f in dv.feature_names_:\\nstring = f.replace(“=<”, “-le”)\\nfeatures.append(string)\\nPeter Ernicke', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'ValueError: feature_names must be string, and may not contain [, ] or <', 'course': 'machine-learning-zoomcamp', 'id': 'b61d2e92'}, '8d7392cb': {'text': 'If you’re getting this error, It is likely because the feature names in dv.get_feature_names_out() are a np.ndarray instead of a list so you have to convert them into a list by using the to_list() method.\\nAli Osman', 'section': '6. Decision Trees and Ensemble Learning', 'question': \"`TypeError: Expecting a sequence of strings for feature names, got: <class 'numpy.ndarray'> ` when training xgboost model.\", 'course': 'machine-learning-zoomcamp', 'id': '8d7392cb'}, 'c920eef3': {'text': \"If you’re getting TypeError:\\n“TypeError: Expecting a sequence of strings for feature names, got: <class 'numpy.ndarray'>”,\\nprobably you’ve done this:\\nfeatures = dv.get_feature_names_out()\\nIt gets you np.ndarray instead of list. Converting to list list(features) will not fix this, read below.\\nIf you’re getting ValueError:\\n“ValueError: feature_names must be string, and may not contain [, ] or <”,\\nprobably you’ve either done:\\nfeatures = list(dv.get_feature_names_out())\\nor:\\nfeatures = dv.feature_names_\\nreason is what you get from DictVectorizer here looks like this:\\n['households',\\n'housing_median_age',\\n'latitude',\\n'longitude',\\n'median_income',\\n'ocean_proximity=<1H OCEAN',\\n'ocean_proximity=INLAND',\\n'population',\\n'total_bedrooms',\\n'total_rooms']\\nit has symbols XGBoost doesn’t like ([, ] or <).\\nWhat you can do, is either do not specify “feature_names=” while creating xgb.DMatrix or:\\nimport re\\nfeatures = dv.feature_names_\\npattern = r'[\\\\[\\\\]<>]'\\nfeatures = [re.sub(pattern, '  ', f) for f in features]\\nAdded by Andrii Larkin\", 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Q6: ValueError or TypeError while setting xgb.DMatrix(feature_names=)', 'course': 'machine-learning-zoomcamp', 'id': 'c920eef3'}, '5017c9a4': {'text': 'To install Xgboost, use the code below directly in your jupyter notebook:\\n(Pip 21.3+ is required)\\npip install xgboost\\nYou can update your pip by using the code below:\\npip install --upgrade pip\\nFor more about xgbboost and installation, check here:\\nhttps://xgboost.readthedocs.io/en/stable/install.html\\nAminat Abolade', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'How to Install Xgboost', 'course': 'machine-learning-zoomcamp', 'id': '5017c9a4'}, '6ffe101d': {'text': 'Sometimes someone might wonder what eta means in the tunable hyperparameters of XGBoost and how it helps the model.\\nETA is the learning rate of the model. XGBoost uses gradient descent to calculate and update the model. In gradient descent, we are looking for the minimum weights that help the model to learn the data very well. This minimum weights for the features is updated each time the model passes through the features and learns the features during training. Tuning the learning rate helps you tell the model what speed it would use in deriving the minimum for the weights.', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'What is eta in XGBoost', 'course': 'machine-learning-zoomcamp', 'id': '6ffe101d'}, 'a55b29ff': {'text': 'For ensemble algorithms, during the week 6, one bagging algorithm and one boosting algorithm were presented: Random Forest and XGBoost, respectively.\\nRandom Forest trains several models in parallel. The output can be, for example, the average value of all the outputs of each model. This is called bagging.\\nXGBoost trains several models sequentially: the previous model error is used to train the following model. Weights are used to ponderate the models such as the best models have higher weights and are therefore favored for the final output. This method is called boosting.\\nNote that boosting is not necessarily better than bagging.\\nMélanie Fouesnard\\nBagging stands for “Bootstrap Aggregation” - it involves taking multiple samples with replacement to derive multiple training datasets from the original training dataset (bootstrapping), training a classifier (e.g. decision trees or stumps for Random Forests) on each such training dataset, and then combining the the predictions (aggregation) to obtain the final prediction. For classification, predictions are combined via voting; for regression, via averaging. Bagging can be done in parallel, since the various classifiers are independent. Bagging decreases variance (but not bias) and is robust against overfitting.\\nBoosting, on the other hand, is sequential - each model learns from the mistakes of its predecessor. Observations are given different weights - observations/samples misclassified by the previous classifier are given a higher weight, and this process is continued until a stopping condition is reached (e.g. max. No. of models is reached, or error is acceptably small, etc.). Boosting reduces bias & is generally more accurate than bagging, but can be prone to overfitting.\\nRileen', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'What is the difference between bagging and boosting?', 'course': 'machine-learning-zoomcamp', 'id': 'a55b29ff'}, 'eac70ce3': {'text': 'I wanted to directly capture the output from the xgboost training for multiple eta values to a dictionary without the need to run the same cell multiple times and manually editing the eta value in between or copy the code for a second eta value.\\nUsing the magic cell command “%%capture output” I was only able to capture the complete output for all iterations for the loop, but. I was able to solve this using the following approach. This is just a code sample to grasp the idea.\\n# This would be the content of the Jupyter Notebook cell\\nfrom IPython.utils.capture import capture_output\\nimport sys\\ndifferent_outputs = {}\\nfor i in range(3):\\nwith capture_output(sys.stdout) as output:\\nprint(i)\\nprint(\"testing capture\")\\ndifferent_outputs[i] = output.stdout\\n# different_outputs\\n# {0: \\'0\\\\ntesting capture\\\\n\\',\\n#  1: \\'1\\\\ntesting capture\\\\n\\',\\n#  2: \\'2\\\\ntesting capture\\\\n\\'}\\nAdded by Sylvia Schmitt', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Capture stdout for each iterations of a loop separately', 'course': 'machine-learning-zoomcamp', 'id': 'eac70ce3'}, '5f91f8ca': {'text': 'Calling roc_auc_score() to get auc is throwing the above error.\\nSolution to this issue is to make sure that you pass y_actuals as 1st argument and y_pred as 2nd argument.\\nroc_auc_score(y_train, y_pred)\\nHareesh Tummala', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'ValueError: continuous format is not supported', 'course': 'machine-learning-zoomcamp', 'id': '5f91f8ca'}, 'a3be507a': {'text': 'When rmse stops improving means, when it stops to decrease or remains almost similar.\\nPastor Soto', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Question 3 of homework 6 if i see that rmse goes up at a certain number of n_estimators but then goes back down lower than it was before, should the answer be the number of n_estimators after which rmse initially went up, or the number after which it was its overall lowest value?', 'course': 'machine-learning-zoomcamp', 'id': 'a3be507a'}, '9a8faa50': {'text': 'dot_data = tree.export_graphviz(regr, out_file=None,\\nfeature_names=boston.feature_names,\\nfilled=True)\\ngraphviz.Source(dot_data, format=\"png\")\\nKrishna Anand\\nfrom sklearn import tree\\ntree.plot_tree(dt,feature_names=dv.feature_names_)\\nAdded By Ryan Pramana', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'One of the method to visualize the decision trees', 'course': 'machine-learning-zoomcamp', 'id': '9a8faa50'}, 'a6e384fe': {'text': 'Solution: This problem happens because you use DecisionTreeClassifier instead of DecisionTreeRegressor. You should check if you want to use a Decision tree for classification or regression.\\nAlejandro Aponte', 'section': '6. Decision Trees and Ensemble Learning', 'question': \"ValueError: Unknown label type: 'continuous'\", 'course': 'machine-learning-zoomcamp', 'id': 'a6e384fe'}, 'ddc14ada': {'text': 'When I run dt = DecisionTreeClassifier() in jupyter in same laptop, each time I re-run it or do (restart kernel + run) I get different values of auc. Some of them are 0.674, 0.652, 0.642, 0.669 and so on.  Anyone knows why it could be? I am referring to 7:40-7:45 of video 6.3.\\nSolution: try setting the random seed e.g\\ndt = DecisionTreeClassifier(random_state=22)\\nBhaskar Sarma', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Different values of auc, each time code is re-run', 'course': 'machine-learning-zoomcamp', 'id': 'ddc14ada'}, '593f7569': {'text': \"They both do the same, it's just less typing from the script.\", 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?', 'course': 'machine-learning-zoomcamp', 'id': '593f7569'}, '6cb56405': {'text': 'When I tried to run example from the video using function ping and can not import it. I use import ping and it was unsuccessful. To fix it I use the statement:\\n\\nfrom [file name] import ping\\nOlga Rudakova', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'No module named ‘ping’?', 'course': 'machine-learning-zoomcamp', 'id': '6cb56405'}, 'a22a93f1': {'text': 'The DictVectorizer has a function to get the feature names get_feature_names_out(). This is helpful for example if you need to analyze feature importance but use the dict vectorizer for one hot encoding. Just keep in mind it does return a numpy array so you may need to convert this to a list depending on your usage for example dv.get_feature_names_out() will return a ndarray array of string objects. list(dv.get_feature_names_out()) will convert to a standard list of strings. Also keep in mind that you first need to fit the predictor and response arrays before you have access to the feature names.\\nQuinn Avila', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'DictVectorizer feature names', 'course': 'machine-learning-zoomcamp', 'id': 'a22a93f1'}, 'b6259dea': {'text': 'This error occurs because the list of feature names contains some characters like \"<\" that are not supported. To fix this issue, you can replace those problematic characters with supported ones. If you want to create a consistent list of features with no special characters, you can achieve it like this:\\nYou can address this error by replacing problematic characters in the feature names with underscores, like so:\\nfeatures = [f.replace(\\'=<\\', \\'_\\').replace(\\'=\\', \\'_\\') for f in features]\\nThis code will go through the list of features and replace any instances of \"=<\" with \"\", as well as any \"=\" with \"\", ensuring that the feature names only consist of supported characters.', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'ValueError: feature_names must be string, and may not contain [, ] or <', 'course': 'machine-learning-zoomcamp', 'id': 'b6259dea'}, 'bcfdc6f4': {'text': \"To make it easier for us to determine which features are important, we can use a horizontal bar chart to illustrate feature importance sorted by value.\\n1. # extract the feature importances from the model\\nfeature_importances = list(zip(features_names, rdr_model.feature_importances_))\\nimportance_df = pd.DataFrame(feature_importances, columns=['feature_names', 'feature_importances'])\\n2. # sort descending the dataframe by using feature_importances value\\nimportance_df = importance_df.sort_values(by='feature_importances', ascending=False)\\n3. # create a horizontal bar chart\\nplt.figure(figsize=(8, 6))\\nsns.barplot(x='feature_importances', y='feature_names', data=importance_df, palette='Blues_r')\\nplt.xlabel('Feature Importance')\\nplt.ylabel('Feature Names')\\nplt.title('Feature Importance Chart')\\nRadikal Lukafiardi\", 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Visualize Feature Importance by using horizontal bar chart', 'course': 'machine-learning-zoomcamp', 'id': 'bcfdc6f4'}, 'a7e7cdd2': {'text': 'Instead of using np.sqrt() as the second step. You can extract it using like this way :\\nmean_squared_error(y_val, y_predict_val,squared=False)\\nAhmed Okka', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'RMSE using metrics.root_meas_square()', 'course': 'machine-learning-zoomcamp', 'id': 'a7e7cdd2'}, '55477da8': {'text': 'I like this visual implementation of features importance in scikit-learn library:\\nhttps://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\\nIt actually adds std.errors to features importance -> so that you can trace stability of features (important for a model’s explainability) over the different params of the model.\\nIvan Brigida', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Features Importance graph', 'course': 'machine-learning-zoomcamp', 'id': '55477da8'}, '6a245a05': {'text': 'Expanded error says: xgboost.core.XGBoostError: sklearn needs to be installed in order to use this module. So, sklearn in requirements solved the problem.\\nGeorge Chizhmak', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'xgboost.core.XGBoostError: This app has encountered an error. The original error message is redacted to prevent data leaks.', 'course': 'machine-learning-zoomcamp', 'id': '6a245a05'}, '4405bfca': {'text': 'Information gain  in Y due to X, or the mutual information of Y and X\\nWhere  is the entropy of Y. \\n\\nIf X is completely uninformative about Y:\\nIf X is completely informative about Y: )\\nHrithik Kumar Advani', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Information Gain', 'course': 'machine-learning-zoomcamp', 'id': '4405bfca'}, '3e0acc25': {'text': 'Filling in missing values using an entire dataset before splitting for training/testing/validation causes', 'section': '6. Decision Trees and Ensemble Learning', 'question': 'Data Leakage', 'course': 'machine-learning-zoomcamp', 'id': '3e0acc25'}, 'abaecdf8': {'text': 'Save model by calling ‘booster.save_model’, see eg\\nLoad model:\\nDawuta Smit\\nThis section is moved to Projects', 'section': '8. Neural Networks and Deep Learning', 'question': 'Serialized Model Xgboost error', 'course': 'machine-learning-zoomcamp', 'id': 'abaecdf8'}, 'ff40f83b': {'text': 'TODO', 'section': '8. Neural Networks and Deep Learning', 'question': 'How to get started with Week 8?', 'course': 'machine-learning-zoomcamp', 'id': 'ff40f83b'}, '95a16746': {'text': 'Create or import your notebook into Kaggle.\\nClick on the Three dots at the top right hand side\\nClick on Accelerator\\nChoose T4 GPU\\nKhurram Majeed', 'section': '8. Neural Networks and Deep Learning', 'question': 'How to use Kaggle for Deep Learning?', 'course': 'machine-learning-zoomcamp', 'id': '95a16746'}, '46acdd18': {'text': 'Create or import your notebook into Google Colab.\\nClick on the Drop Down at the top right hand side\\nClick on “Change runtime type”\\nChoose T4 GPU\\nKhurram Majeed', 'section': '8. Neural Networks and Deep Learning', 'question': 'How to use Google Colab for Deep Learning?', 'course': 'machine-learning-zoomcamp', 'id': '46acdd18'}, 'f721d54b': {'text': 'Connecting your GPU on Saturn Cloud to Github repository is not compulsory, since you can just download the notebook and copy it to the Github folder. But if you like technology to do things for you, then follow the solution description below:\\nSolution description: Follow the instructions in these github docs to create an SSH private and public key:\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-ke\\ny-and-adding-it-to-the-ssh-agenthttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account?tool=webui\\nThen the second video on this module about saturn cloud would show you how to add the ssh keys to secrets and authenticate through a terminal.\\nOr alternatively, you could just use the public keys provided by Saturn Cloud by default. To do so, follow these steps:\\nClick on your username and on manage\\nDown below you will see the Git SSH keys section.\\nCopy the default public key provided by Saturn Cloud\\nPaste these key into the SSH keys section of your github repo\\nOpen a terminal on Saturn Cloud and run this command “ssh -T git@github.com”\\nYou will receive a successful authentication notice.\\nOdimegwu David', 'section': '8. Neural Networks and Deep Learning', 'question': 'How do I push from Saturn Cloud to Github?', 'course': 'machine-learning-zoomcamp', 'id': 'f721d54b'}, '69cd4897': {'text': 'This template is referred to in the video 8.1b Setting up the Environment on Saturn Cloud\\nbut the location shown in the video is no longer correct.\\nThis template has been moved to “python deep learning tutorials’ which is shown on the Saturn Cloud home page.\\nSteven Christolis', 'section': '8. Neural Networks and Deep Learning', 'question': 'Where is the Python TensorFlow template on Saturn Cloud?', 'course': 'machine-learning-zoomcamp', 'id': '69cd4897'}, '346e799a': {'text': 'The above error happens since module scipy is not installed in the saturn cloud tensorflow image. While creating the Jupyter server resource, in the “Extra Packages” section under pip in the textbox write scipy. Below the textbox, the pip install scipy command will be displayed. This will ensure when the resource spins up, the scipy package will be automatically installed. This approach can also be followed for additional python packages.\\nSumeet Lalla', 'section': '8. Neural Networks and Deep Learning', 'question': 'Getting error module scipy not found during model training in Saturn Cloud tensorflow image', 'course': 'machine-learning-zoomcamp', 'id': '346e799a'}, '551461b2': {'text': 'Problem description: Uploading the data to saturn cloud from kaggle can be time saving, specially if the dataset is large.\\nYou can just download to your local machine and then upload to a folder on saturn cloud, but there is a better solution that needs to be set once and you have access to all kaggle datasets in saturn cloud.\\nOn your notebook run:\\n!pip install -q kaggle\\nGo to Kaggle website (you need to have an account for this):\\nClick on your profile image -> Account\\nScroll down to the API box\\nClick on Create New API token\\nIt will download a json file with the name kaggle.json store on your local computer. We need to upload this file in the .kaggle folder\\nOn the notebook click on folder icon on the left upper corner\\nThis will take you to the root folder\\nClick on the .kaggle folder\\nOnce inside of the .kaggle folder upload the kaggle.json file that you downloaded\\nRun this command on your notebook:\\n!chmod 600 /home/jovyan/.kaggle/kaggle.json\\nDownload the data using this command:\\n!kaggle datasets download -d agrigorev/dino-or-dragon\\nCreate a folder to unzip your files:\\n!mkdir data\\nUnzip your files inside that folder\\n!unzip dino-or-dragon.zip -d data\\nPastor Soto', 'section': '8. Neural Networks and Deep Learning', 'question': 'How to upload kaggle data to Saturn Cloud?', 'course': 'machine-learning-zoomcamp', 'id': '551461b2'}, 'c3ba4459': {'text': 'In order to run tensorflow with gpu on your local machine you’ll need to setup cuda and cudnn.\\nThe process can be overwhelming. Here’s a simplified guide\\nOsman Ali', 'section': '8. Neural Networks and Deep Learning', 'question': 'How to install CUDA & cuDNN on Ubuntu 22.04', 'course': 'machine-learning-zoomcamp', 'id': 'c3ba4459'}, 'a114ad55': {'text': 'Problem description:\\nWhen loading saved model getting error: ValueError: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.\\nSolution description:\\nBefore loading model need to evaluate the model on input data: model.evaluate(train_ds)\\nAdded by Vladimir Yesipov', 'section': '8. Neural Networks and Deep Learning', 'question': 'Error: (ValueError: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.) when loading model.', 'course': 'machine-learning-zoomcamp', 'id': 'a114ad55'}, 'dd3c8000': {'text': 'Problem description:\\nWhen follow module 8.1b video to setup git in Saturn Cloud, run `ssh -T git@github.com` lead error `git@github.com: Permission denied (publickey).`\\nSolution description:\\nAlternative way, we can setup git in our Saturn Cloud env with generate SSH key in our Saturn Cloud and add it to our git account host. After it, we can access/manage our git through Saturn’s jupyter server. All steps detailed on this following tutorial: https://saturncloud.io/docs/using-saturn-cloud/gitrepo/\\nAdded by Ryan Pramana', 'section': '8. Neural Networks and Deep Learning', 'question': 'Getting error when connect git on Saturn Cloud: permission denied', 'course': 'machine-learning-zoomcamp', 'id': 'dd3c8000'}, '34b0ebfc': {'text': \"Problem description:\\nGetting an error using <git clone git@github.com:alexeygrigorev/clothing-dataset-small.git>\\nThe error:\\nCloning into 'clothing-dataset'...\\nHost key verification failed.\\nfatal: Could not read from remote repository.\\nPlease make sure you have the correct access rights\\nand the repository exists.\\nSolution description:\\nwhen cloning the repo, you can also chose https - then it should work. This happens when you don't have your ssh key configured.\\n<git clone https://github.com/alexeygrigorev/clothing-dataset-small.git>\\nAdded by Gregory Morris\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Host key verification failed.', 'course': 'machine-learning-zoomcamp', 'id': '34b0ebfc'}, '7d11d5ce': {'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\", 'section': '8. Neural Networks and Deep Learning', 'question': 'The same accuracy on epochs', 'course': 'machine-learning-zoomcamp', 'id': '7d11d5ce'}, 'e4e45f15': {'text': 'Problem:\\nWhen resuming training after augmentation, the loss skyrockets (1000+ during first epoch) and accuracy settles around 0.5 – i.e. the model becomes as good as a random coin flip.\\nSolution:\\nCheck that the augmented ImageDataGenerator still includes the option “rescale” as specified in the preceding step.\\nAdded by Konrad Mühlberg', 'section': '8. Neural Networks and Deep Learning', 'question': 'Model breaking after augmentation – high loss + bad accuracy', 'course': 'machine-learning-zoomcamp', 'id': 'e4e45f15'}, 'b3997e6f': {'text': \"While doing:\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nmodel = tf.keras.models.load_model('model_saved.h5')\\nIf you get an error message like this:\\nValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.\\nSolution:\\nSaving a model (either yourself via model.save() or via checkpoint when save_weights_only = False) saves two things: The trained model weights (for example the best weights found during training) and the model architecture.  If the number of channels is not explicitly specified in the Input layer of the model, and is instead defined as a variable, the model architecture will not have the value in the variable stored. Therefore when the model is reloaded, it will complain about not knowing the number of channels. See the code below, in the first line, you need to specify number of channels explicitly:\\n# model architecture:\\ninputs = keras.Input(shape=(input_size, input_size, 3))\\nbase = base_model(inputs, training=False)\\nvectors = keras.layers.GlobalAveragePooling2D()(base)\\ninner = keras.layers.Dense(size_inner, activation='relu')(vectors)\\ndrop = keras.layers.Dropout(droprate)(inner)\\noutputs = keras.layers.Dense(10)(drop)\\nmodel = keras.Model(inputs, outputs)\\n(Memoona Tahira)\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Missing channel value error while reloading model:', 'course': 'machine-learning-zoomcamp', 'id': 'b3997e6f'}, 'e414df91': {'text': \"Problem:\\nA dataset for homework is in a zipped folder. If you unzip it within a jupyter notebook by means of ! unzip command, you’ll see a huge amount of output messages about unzipping of each image. So you need to suppress this output\\nSolution:\\nExecute the next cell:\\n%%capture\\n! unzip zipped_folder_name.zip -d destination_folder_name\\nAdded by Alena Kniazeva\\nInside a Jupyter Notebook:\\nimport zipfile\\nlocal_zip = 'data.zip'\\nzip_ref = zipfile.ZipFile(local_zip, 'r')\\nzip_ref.extractall('data')\\nzip_ref.close()\", 'section': '8. Neural Networks and Deep Learning', 'question': 'How to unzip a folder with an image dataset and suppress output?', 'course': 'machine-learning-zoomcamp', 'id': 'e414df91'}, 'f20a3479': {'text': 'Problem:\\nWhen we run train_gen.flow_from_directory() as in video 8.5, it finds images belonging to 10 classes. Does it understand the names of classes from the names of folders? Or, there is already something going on deep behind?\\nSolution:\\nThe name of class is the folder name\\nIf you just create some random folder with the name \"xyz\", it will also be considered as a class!! The name itself is saying flow_from_directory\\na clear explanation below:\\nhttps://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\\nAdded by Bhaskar Sarma', 'section': '8. Neural Networks and Deep Learning', 'question': 'How keras flow_from_directory know the names of classes in images?', 'course': 'machine-learning-zoomcamp', 'id': 'f20a3479'}, 'e7af4968': {'text': 'Problem:\\nI created a new environment in SaturnCloud and chose the image corresponding to Saturn with Tensorflow, but when I tried to fit the model it showed an error about the missing module: scipy\\nSolution:\\nInstall the module in a new cell: !pip install scipy\\nRestart the kernel and fit the model again\\nAdded by Erick Calderin', 'section': '8. Neural Networks and Deep Learning', 'question': 'Error with scipy missing module in SaturnCloud', 'course': 'machine-learning-zoomcamp', 'id': 'e7af4968'}, '9fad096e': {'text': 'The command to read folders in the dataset in the tensorflow source code is:\\nfor subdir in sorted(os.listdir(directory)):\\n…\\nReference: https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py, line 563\\nThis means folders will be read in alphabetical order. For example, in the case of a folder named dino, and another named dragon, dino will read first and will have class label 0, whereas dragon will be read in next and will have class label 1.\\nWhen a Keras model predicts binary labels, it will only return one value, and this is the probability of class 1 in case of sigmoid activation function in the last dense layer with 2 neurons. The probability of class 0 can be found out by:\\nprob(class(0)) = 1- prob(class(1))\\nIn case of using from_logits to get results, you will get two values for each of the labels.\\nA prediction of 0.8 is saying the probability that the image has class label 1 (in this case dragon), is 0.8, and conversely we can infer the probability that the image has class label 0 is 0.2.\\n(Added by Memoona Tahira)', 'section': '8. Neural Networks and Deep Learning', 'question': 'How are numeric class labels determined in flow_from_directroy using binary class mode and what is meant by the single probability predicted by a binary Keras model:', 'course': 'machine-learning-zoomcamp', 'id': '9fad096e'}, 'bcdf7407': {'text': \"It's fine, some small changes are expected\\nAlexey Grigorev\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Does the actual values matter after predicting with a neural network or it should be treated as like hood of falling in a class?', 'course': 'machine-learning-zoomcamp', 'id': 'bcdf7407'}, '8d1e7e20': {'text': 'Problem:\\nI found running the wasp/bee model on my mac laptop had higher reported accuracy and lower std deviation than the HW answers. This may be because of the SGD optimizer. Running this on my mac printed a message about a new and legacy version that could be used.\\nSolution:\\nTry running the same code on google collab or another way. The answers were closer for me on collab. Another tip is to change the runtime to use T4 and the model run’s faster than just CPU\\nAdded by Quinn Avila', 'section': '8. Neural Networks and Deep Learning', 'question': 'What if your accuracy and std training loss don’t match HW?', 'course': 'machine-learning-zoomcamp', 'id': '8d1e7e20'}, '2023a9dc': {'text': 'When running “model.fit(...)” an additional parameter “workers” can be specified for speeding up the data loading/generation. The default value is “1”. Try out which value between 1 and the cpu count on your system performs best.\\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\\nAdded by Sylvia Schmitt', 'section': '8. Neural Networks and Deep Learning', 'question': 'Using multi-threading for data generation in “model.fit()”', 'course': 'machine-learning-zoomcamp', 'id': '2023a9dc'}, '468f69ff': {'text': 'Reproducibility for training runs can be achieved following these instructions: \\nhttps://www.tensorflow.org/versions/r2.8/api_docs/python/tf/config/experimental/enable_op_determinism\\nseed = 1234\\ntf.keras.utils.set_random_seed(seed)\\ntf.config.experimental.enable_op_determinism()\\nThis will work for a script, if this gets executed multiple times.\\nAdded by Sylvia Schmitt', 'section': '8. Neural Networks and Deep Learning', 'question': 'Reproducibility with TensorFlow using a seed point', 'course': 'machine-learning-zoomcamp', 'id': '468f69ff'}, 'c4ff26e5': {'text': 'Pytorch is also a deep learning framework that allows to do equivalent tasks as keras. Here is a tutorial to create a CNN from scratch using pytorch :\\nhttps://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\\nThe functions have similar goals. The syntax can be slightly different. For the lessons and the homework, we use keras, but one can feel free to make a pull request with the equivalent with pytorch for lessons and homework!\\nMélanie Fouesnard', 'section': '8. Neural Networks and Deep Learning', 'question': 'Can we use pytorch for this lesson/homework ?', 'course': 'machine-learning-zoomcamp', 'id': 'c4ff26e5'}, '62722d72': {'text': \"While training a Keras model you get the error “Failed to find data adapter that can handle input: <class 'keras.src.preprocessing.image.ImageDataGenerator'>, <class 'NoneType'>” you may have unintentionally passed the image generator instead of the dataset to the model\\ntrain_gen = ImageDataGenerator(rescale=1./255)\\ntrain_ds = train_gen.flow_from_directory(…)\\nhistory_after_augmentation = model.fit(\\ntrain_gen, # this should be train_ds!!!\\nepochs=10,\\nvalidation_data=test_gen # this should be test_ds!!!\\n)\\nThe fix is simple and probably obvious once pointed out, use the training and validation dataset (train_ds and val_ds) returned from flow_from_directory\\nAdded by Tzvi Friedman\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Keras model training fails with “Failed to find data adapter”', 'course': 'machine-learning-zoomcamp', 'id': '62722d72'}, 'd1419be1': {'text': 'The command ‘nvidia-smi’ has a built-in function which will run it in subsequently updating it every N seconds without the need of using the command ‘watch’.\\nnvidia-smi -l <N seconds>\\nThe following command will run ‘nvidia-smi’ every 2 seconds until interrupted using CTRL+C.\\nnvidia-smi -l 2\\nAdded by Sylvia Schmitt', 'section': '8. Neural Networks and Deep Learning', 'question': 'Running ‘nvidia-smi’ in a loop without using ‘watch’', 'course': 'machine-learning-zoomcamp', 'id': 'd1419be1'}, 'a5f6f439': {'text': 'The Python package ‘’ is an interactive GPU process viewer similar to ‘htop’ for CPU.\\nhttps://pypi.org/project//\\nImage source: https://pypi.org/project//\\nAdded by Sylvia Schmitt', 'section': '8. Neural Networks and Deep Learning', 'question': 'Checking GPU and CPU utilization using ‘nvitop’', 'course': 'machine-learning-zoomcamp', 'id': 'a5f6f439'}, '879c1ec0': {'text': \"Let’s say we define our Conv2d layer like this:\\n>> tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3))\\nIt means our input image is RGB (3 channels, 150 by 150 pixels), kernel is 3x3 and number of filters (layer’s width) is 32.\\nIf we check model.summary() we will get this:\\n_________________________________________________________________\\nLayer (type)                Output Shape              Param #\\n=================================================================\\nconv2d (Conv2D)             (None, 148, 148, 32)      896\\nSo where does 896 params come from? It’s computed like this:\\n>>> (3*3*3 +1) * 32\\n896\\n# 3x3 kernel, 3 channels RGB, +1 for bias, 32 filters\\nWhat about the number of “features” we get after the Flatten layer?\\nFor our homework model.summary() for last MaxPooling2d and Flatten layers looked like this:\\n_________________________________________________________________\\nLayer (type)                Output Shape              Param #\\n=================================================================\\nmax_pooling2d_3       (None, 7, 7, 128)         0\\nflatten (Flatten)           (None, 6272)              0\\nSo where do 6272 vectors come from? It’s computed like this:\\n>>> 7*7*128\\n6272\\n# 7x7 “image shape” after several convolutions and poolings, 128 filters\\nAdded by Andrii Larkin\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Q: Where does the number of Conv2d layer’s params come from? Where does the number of “features” we get after the Flatten layer come from?', 'course': 'machine-learning-zoomcamp', 'id': '879c1ec0'}, '3ac604c3': {'text': 'It’s quite useful to understand that all types of models in the course are a plain stack of layers where each layer has exactly one input tensor and one output tensor (Sequential model TF page, Sequential class).\\nYou can simply start from an “empty” model and add more and more layers in a sequential order.\\nThis mode is called “Sequential Model API”  (easier)\\nIn Alexey’s videos it is implemented as chained calls of different entities (“inputs”,“base”, “vectors”,  “outputs”) in a more advanced mode “Functional Model API”.\\nMaybe a more complicated way makes sense when you do Transfer Learning and want to separate “Base” model vs. rest, but in the HW you need to recreate the full model from scratch ⇒ I believe it is easier to work with a sequence of “similar” layers.\\nYou can read more about it in this TF2 tutorial.\\nA really useful Sequential model example is shared in the Kaggle’s “Bee or Wasp” dataset folder with code: notebook\\nAdded by Ivan Brigida\\nFresh Run on Neural Nets\\nWhile correcting an error on neural net architecture, it is advised to do fresh run by restarting kernel, else the model learns on top of previous runs.\\nAdded by Abhijit Chakraborty', 'section': '8. Neural Networks and Deep Learning', 'question': 'Sequential vs. Functional Model Modes in Keras (TF2)', 'course': 'machine-learning-zoomcamp', 'id': '3ac604c3'}, '0315aa96': {'text': \"I found this code snippet fixed my OOM errors, as I have an Nvidia GPU. Can't speak to OOM errors on CPU, though.\\nhttps://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\\n```\\nphysical_devices = tf.configlist_physical_devices('GPU')\\ntry:\\ntf.config.experimental.set_memory_growth(physical_devices[0],True)\\nexcept:\\n# Invalid device or cannot modify virtual devices once initialized.\\npass\\n```\", 'section': '8. Neural Networks and Deep Learning', 'question': 'Out of memory errors when running tensorflow', 'course': 'machine-learning-zoomcamp', 'id': '0315aa96'}, 'daf84bc3': {'text': 'When training the models, in the fit function, you can specify the number of workers/threads.\\nThe number of threads apparently also works for GPUs, and came very handy in google colab for the T4 GPU, since it was very very slow, and workers default value is 1.\\nI changed the workers variable to 2560, following this thread in stackoverflow. I am using the free T4 GPU.  (https://stackoverflow.com/questions/68208398/how-to-find-the-number-of-cores-in-google-colabs-gpu)\\nAdded by Ibai Irastorza', 'section': '8. Neural Networks and Deep Learning', 'question': 'Model training very slow in google colab with T4 GPU', 'course': 'machine-learning-zoomcamp', 'id': 'daf84bc3'}, '1e956ca7': {'text': 'From the keras documentation:\\nDeprecated: tf.keras.preprocessing.image.ImageDataGenerator is not recommended for new code. Prefer loading images with tf.keras.utils.image_dataset_from_directory and transforming the output tf.data.Dataset with preprocessing layers. For more information, see the tutorials for loading images and augmenting images, as well as the preprocessing layer guide.\\nHrithik Kumar Advani', 'section': '9. Serverless Deep Learning', 'question': 'Using image_dataset_from_directory instead of ImageDataGeneratorn for loading images', 'course': 'machine-learning-zoomcamp', 'id': '1e956ca7'}, '3ee083ab': {'text': 'TODO', 'section': '9. Serverless Deep Learning', 'question': 'How to get started with Week 9?', 'course': 'machine-learning-zoomcamp', 'id': '3ee083ab'}, 'f826cba4': {'text': 'The week 9 uses a link to github to fetch the models.\\nThe original link was moved to here:\\nhttps://github.com/DataTalksClub/machine-learning-zoomcamp/releases', 'section': '9. Serverless Deep Learning', 'question': 'Where is the model for week 9?', 'course': 'machine-learning-zoomcamp', 'id': 'f826cba4'}, '60fa95ed': {'text': 'Solution description\\nIn the unit 9.6, Alexey ran the command echo ${REMOTE_URI} which turned the URI address in the terminal. There workaround is to set a local variable (REMOTE_URI) and assign your URI address in the terminal and use it to login the registry, for instance, REMOTE_URI=2278222782.dkr.ecr.ap-south-1.amazonaws.com/clothing-tflite-images (fake address). One caveat is that you will lose this variable once the session is terminated.\\nI also had the same problem on Ubuntu terminal. I executed the following two commands:\\n$ export REMOTE_URI=1111111111.dkr.ecr.us-west-1.amazonaws.com/clothing-tflite-images:clothing-model-xception-v4-001\\n$ echo $REMOTE_URI\\n111111111.dkr.ecr.us-west-1.amazonaws.com/clothing-tflite-images:clothing-model-xception-v4-001\\nNote: 1. no curly brackets (e.g. echo ${REMOTE_URI}) needed unlike in video 9.6,\\n2. Replace REMOTE_URI with your URI\\n(Bhaskar Sarma)', 'section': '9. Serverless Deep Learning', 'question': 'Executing the command echo ${REMOTE_URI} returns nothing.', 'course': 'machine-learning-zoomcamp', 'id': '60fa95ed'}, '53f3ee10': {'text': 'The command aws ecr get-login --no-include-email returns an invalid choice error:\\nThe solution is to use the following command instead:  aws ecr get-login-password\\nCould simplify the login process with, just replace the <ACCOUNT_NUMBER> and <REGION> with your values:\\nexport PASSWORD=`aws ecr get-login-password`\\ndocker login -u AWS -p $PASSWORD <ACCOUNT_NUMBER>.dkr.ecr.<REGION>.amazonaws.com/clothing-tflite-images\\nAdded by Martin Uribe', 'section': '9. Serverless Deep Learning', 'question': 'Getting a syntax error while trying to get the password from aws-cli', 'course': 'machine-learning-zoomcamp', 'id': '53f3ee10'}, '93aa4278': {'text': 'We can use the keras.models.Sequential() function to pass many parameters of the cnn at once.\\nKrishna Anand', 'section': '9. Serverless Deep Learning', 'question': 'Pass many parameters in the model at once', 'course': 'machine-learning-zoomcamp', 'id': '93aa4278'}, '0edeb016': {'text': 'This error is produced sometimes when building your docker image from the Amazon python base image.\\nSolution description: The following could solve the problem.\\nUpdate your docker desktop if you haven’t done so.\\nOr restart docker desktop and terminal and then build the image all over again.\\nOr if all else fails, first run the following command: DOCKER_BUILDKIT=0  docker build .  then build your image.\\n(optional) Added by Odimegwu David', 'section': '9. Serverless Deep Learning', 'question': 'Getting  ERROR [internal] load metadata for public.ecr.aws/lambda/python:3.8', 'course': 'machine-learning-zoomcamp', 'id': '0edeb016'}, 'ba186de6': {'text': \"When trying to run the command  !ls -lh in windows jupyter notebook  , I was getting an error message that says “'ls' is not recognized as an internal or external command,operable program or batch file.\\nSolution description :\\nInstead of !ls -lh , you can use this command !dir , and you will get similar output\\nAsia Saeed\", 'section': '9. Serverless Deep Learning', 'question': \"Problem: 'ls' is not recognized as an internal or external command, operable program or batch file.\", 'course': 'machine-learning-zoomcamp', 'id': 'ba186de6'}, 'da2f1cf4': {'text': 'When I run   import tflite_runtime.interpreter as tflite , I get an error message says “ImportError: generic_type: type \"InterpreterWrapper\" is already registered!”\\nSolution description\\nThis error occurs when you import both tensorflow  and tflite_runtime.interpreter  “import tensorflow as tf” and “import tflite_runtime.interpreter as tflite” in the same notebook.  To fix the issue, restart the kernel and import only tflite_runtime.interpreter \" import tflite_runtime.interpreter as tflite\".\\nAsia Saeed', 'section': '9. Serverless Deep Learning', 'question': 'ImportError: generic_type: type \"InterpreterWrapper\" is already registered!', 'course': 'machine-learning-zoomcamp', 'id': 'da2f1cf4'}, '7fd648ca': {'text': 'Problem description:\\nIn command line try to do $ docker build -t dino_dragon\\ngot this Using default tag: latest\\n[2022-11-24T06:48:47.360149000Z][docker-credential-desktop][W] Windows version might not be up-to-date: The system cannot find the file specified.\\nerror during connect: This error may indicate that the docker daemon is not running.: Post\\n.\\nSolution description:\\nYou need to make sure that Docker is not stopped by a third-party program.\\nAndrei Ilin', 'section': '9. Serverless Deep Learning', 'question': 'Windows version might not be up-to-date', 'course': 'machine-learning-zoomcamp', 'id': '7fd648ca'}, '42c09143': {'text': 'When running docker build -t dino-dragon-model it returns the above error\\nThe most common source of this error in this week is because Alex video shows a version of the wheel with python 8, we need to find a wheel with the version that we are working on. In this case python 9. Another common error is to copy the link, this will also produce the same error, we need to download the raw format:\\nhttps://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp39-cp39-linux_x86_64.whl\\nPastor Soto', 'section': '9. Serverless Deep Learning', 'question': 'WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available', 'course': 'machine-learning-zoomcamp', 'id': '42c09143'}, 'd6d534fc': {'text': 'Problem description:\\nIn video 9.6, after installing aswcli, we should configure it with aws configure . There it asks for Access Key ID, Secret Access Key, Default Region Name and also Default output format. What we should put for Default output format? Leaving it as  None is okay?\\nSolution description:\\nYes, in my I case I left everything as the provided defaults (except, obviously, the Access key and the secret access key)\\nAdded by Bhaskar Sarma', 'section': '9. Serverless Deep Learning', 'question': 'How to do AWS configure after installing awscli', 'course': 'machine-learning-zoomcamp', 'id': 'd6d534fc'}, 'b2c0c554': {'text': 'Problem:\\nWhile passing local testing of the lambda function without issues, trying to test the same input with a running docker instance results in an error message like\\n{‘errorMessage’: ‘Unable to marshal response: Object of type float32 is not JSON serializable’, ‘errorType’: ‘Runtime.MarshalError’, ‘requestId’: ‘f155492c-9af2-4d04-b5a4-639548b7c7ac’, ‘stackTrace’: []}\\nThis happens when a model (in this case the dino vs dragon model) returns individual estimation values as numpy float32 values (arrays). They need to be converted individually to base-Python floats in order to become “serializable”.\\nSolution:\\nIn my particular case, I set up the dino vs dragon model in such a way as to return a label + predicted probability for each class as follows (below is a two-line extract of function predict() in the lambda_function.py):\\npreds = [interpreter.get_tensor(output_index)[0][0], \\\\\\n1-interpreter.get_tensor(output_index)[0][0]]\\nIn which case the above described solution will look like this:\\npreds = [float(interpreter.get_tensor(output_index)[0][0]), \\\\\\nfloat(1-interpreter.get_tensor(output_index)[0][0])]\\nThe rest can be made work by following the chapter 9 (and/or chapter 5!) lecture videos step by step.\\nAdded by Konrad Muehlberg', 'section': '9. Serverless Deep Learning', 'question': 'Object of type float32 is not JSON serializable', 'course': 'machine-learning-zoomcamp', 'id': 'b2c0c554'}, '819afebc': {'text': 'I had this error when running the command line : interpreter.set_tensor(input_index, x) that can be seen in the video 9.3 around 12 minutes.\\nValueError: Cannot set tensor: Got value of type UINT8 but expected type FLOAT32 for input 0, name: serving_default_conv2d_input:0\\nThis is because the X is an int but a float is expected.\\nSolution:\\nI found this solution from this question here https://stackoverflow.com/questions/76102508/valueerror-cannot-set-tensor-got-value-of-type-float64-but-expected-type-float :\\n# Need to convert to float32 before set_tensor\\nX = np.float32(X)\\nThen, it works. I work with tensorflow 2.15.0, maybe the fact that this version is more recent involves this change ?\\nAdded by Mélanie Fouesnard', 'section': '9. Serverless Deep Learning', 'question': 'Error with the line “interpreter.set_tensor(input_index, X”)', 'course': 'machine-learning-zoomcamp', 'id': '819afebc'}, '74551c54': {'text': 'To check your file size using the powershell terminal, you can do the following command lines:\\n$File = Get-Item -Path path_to_file\\n$FileSize = (Get-Item -Path $FilePath).Length\\nNow you can check the size of your file, for example in MB:\\nWrite-host \"MB\":($FileSize/1MB)\\nSource: https://www.sharepointdiary.com/2020/10/powershell-get-file-size.html#:~:text=To%20get%20the%20size%20of,the%20file%2C%20including%20its%20size.\\nAdded by Mélanie Fouesnard', 'section': '9. Serverless Deep Learning', 'question': 'How to easily get file size in powershell terminal ?', 'course': 'machine-learning-zoomcamp', 'id': '74551c54'}, '4d98cd09': {'text': 'I wanted to understand how lambda container images work in depth and how lambda functions are initialized, for this reason, I found the following documentation\\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html\\nhttps://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html\\nAdded by Alejandro aponte', 'section': '9. Serverless Deep Learning', 'question': 'How do Lambda container images work?', 'course': 'machine-learning-zoomcamp', 'id': '4d98cd09'}, '59a81fd5': {'text': 'The docker image for aws lambda can be created and pushed to aws ecr and the same can be exposed as a REST API through APIGatewayService in a single go using AWS Serverless Framework. Refer the below article for a detailed walkthrough.\\nhttps://medium.com/hoonio/deploy-containerized-serverless-flask-to-aws-lambda-c0eb87c1404d\\nAdded by Sumeet Lalla', 'section': '9. Serverless Deep Learning', 'question': 'How to use AWS Serverless Framework to deploy on AWS Lambda and expose it as REST API through APIGatewayService?', 'course': 'machine-learning-zoomcamp', 'id': '59a81fd5'}, '35dbd6e2': {'text': 'Problem:\\nWhile trying to build docker image in Section 9.5 with the command:\\ndocker build -t clothing-model .\\nIt throws a pip install error for the tflite runtime whl\\nERROR: failed to solve: process \"/bin/sh -c pip install https://github.com/alexeygrigorev/tflite-aws-lambda/blob/main/tflite/tflite_runtime-2.14.0-cp310-cp310-linux_x86_64.whl\" did not complete successfully: exit code: 1\\nTry to use this link: https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.14.0-cp310-cp310-linux_x86_64.whl\\nIf the link above does not work:\\nThe problem is because of the arm architecture of the M1. You will need to run the code on a PC or Ubuntu OS.\\nOr try the code bellow.\\nAdded by Dashel Ruiz Perez\\nSolution:\\nTo build the Docker image, use the command:\\ndocker build --platform linux/amd64 -t clothing-model .\\nTo run the built image, use the command:\\ndocker run -it --rm -p 8080:8080 --platform linux/amd64 clothing-model:latest\\nAdded by Daniel Egbo', 'section': '9. Serverless Deep Learning', 'question': 'Error building docker image on M1 Mac', 'course': 'machine-learning-zoomcamp', 'id': '35dbd6e2'}, 'e5fe9efe': {'text': \"Problem: Trying to test API gateway in 9.7 - API Gateway: Exposing the Lambda Function, running: $ python test.py\\nWith error message:\\n{'message': 'Missing Authentication Token'}\\nSolution:\\nNeed to get the deployed API URL for the specific path you are invoking. Example:\\nhttps://<random string>.execute-api.us-east-2.amazonaws.com/test/predict\\nAdded by Andrew Katoch\", 'section': '9. Serverless Deep Learning', 'question': 'Error invoking API Gateway deploy API locally', 'course': 'machine-learning-zoomcamp', 'id': 'e5fe9efe'}, '5c043c62': {'text': 'Problem: When trying to install tflite_runtime with\\n!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime\\none gets an error message above.\\nSolution:\\nfflite_runtime is only available for the os-python version combinations that can be found here: https://google-coral.github.io/py-repo/tflite-runtime/\\nyour combination must be missing here\\nyou can see if any of these work for you https://github.com/alexeygrigorev/tflite-aws-lambda/tree/main/tflite\\nand install the needed one using pip\\neg\\npip install https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp38-cp38-linux_x86_64.whl\\nas it is done in the lectures code:\\nhttps://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/09-serverless/code/Dockerfile#L4\\nAlternatively, use a virtual machine (with VM VirtualBox, for example) with a Linux system. The other way is to run a code at a virtual machine within cloud service, for example you can use Vertex AI Workbench at GCP (notebooks and terminals are provided there, so all tasks may be performed).\\nAdded by Alena Kniazeva, modified by Alex Litvinov', 'section': '9. Serverless Deep Learning', 'question': 'Error: Could not find a version that satisfies the requirement tflite_runtime (from versions:none)', 'course': 'machine-learning-zoomcamp', 'id': '5c043c62'}, 'af0739da': {'text': 'docker: Error response from daemon: mkdir /var/lib/docker/overlay2/37be849565da96ac3fce34ee9eb2215bd6cd7899a63ebc0ace481fd735c4cb0e-init: read-only file system.\\nYou need to restart the docker services to get rid of the above error\\nKrishna Anand', 'section': '9. Serverless Deep Learning', 'question': 'Docker run error', 'course': 'machine-learning-zoomcamp', 'id': 'af0739da'}, '451bc25d': {'text': 'The docker image can be saved/exported to tar format in local machine using the below command:\\ndocker image save <image-name> -o <name-of-tar-file.tar>\\nThe individual layers of the docker image for the filesystem content can be viewed by extracting the layer.tar present in the <name-of-tar-file.tar> created from above.\\nSumeet Lalla', 'section': '9. Serverless Deep Learning', 'question': 'Save Docker Image to local machine and view contents', 'course': 'machine-learning-zoomcamp', 'id': '451bc25d'}, 'ea2e7458': {'text': 'On vscode running jupyter notebook. After I ‘pip install pillow’, my notebook did not recognize using the import for example from PIL import image. After restarting the jupyter notebook the imports worked.\\nQuinn Avila', 'section': '9. Serverless Deep Learning', 'question': 'Jupyter notebook not seeing package', 'course': 'machine-learning-zoomcamp', 'id': 'ea2e7458'}, '6ce8e875': {'text': 'Due to experimenting back and forth so much without care for storage, I just ran out of it on my 30-GB AWS instance. It turns out that deleting docker images does not actually free up any space as you might expect. After removing images, you also need to run docker system prune', 'section': '9. Serverless Deep Learning', 'question': 'Running out of space for AWS instance.', 'course': 'machine-learning-zoomcamp', 'id': '6ce8e875'}, 'b50e9e2b': {'text': 'Using the 2.14 version with python 3.11 works fine.\\nIn case it doesn’t work, I tried with tensorflow 2.4.4 whl, however, make sure to run it on top of supported python versions like 3.8, else there will be issues installing tf==2.4.4\\nAdded by Abhijit Chakraborty', 'section': '9. Serverless Deep Learning', 'question': 'Using Tensorflow 2.15 for AWS deployment', 'course': 'machine-learning-zoomcamp', 'id': 'b50e9e2b'}, '29311ef5': {'text': 'see here', 'section': '9. Serverless Deep Learning', 'question': 'Command aws ecr get-login --no-include-email returns “aws: error: argument operation: Invalid choice…”', 'course': 'machine-learning-zoomcamp', 'id': '29311ef5'}, '1e0dc11c': {'text': 'Sign in to the AWS Console: Log in to the AWS Console.\\nNavigate to IAM: Go to the IAM service by clicking on \"Services\" in the top left corner and selecting \"IAM\" under the \"Security, Identity, & Compliance\" section.\\nCreate a new policy: In the left navigation pane, select \"Policies\" and click on \"Create policy.\"\\nSelect the service and actions:\\nClick on \"JSON\" and copy and paste the JSON policy you provided earlier for the specific ECR actions.\\nReview and create the policy:\\nClick on \"Review policy.\"\\nProvide a name and description for the policy.\\nClick on \"Create policy.\"\\nJSON policy:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"VisualEditor0\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"ecr:CreateRepository\",\\n\"ecr:GetAuthorizationToken\",\\n\"ecr:BatchCheckLayerAvailability\",\\n\"ecr:BatchGetImage\",\\n\"ecr:InitiateLayerUpload\",\\n\"ecr:UploadLayerPart\",\\n\"ecr:CompleteLayerUpload\",\\n\"ecr:PutImage\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\nAdded by: Daniel Muñoz-Viveros\\nERROR: failed to solve: public.ecr.aws/lambda/python:3.10: error getting credentials - err: exec: \"docker-credential-desktop.exe\": executable file not found in $PATH, out: ``\\n(WSL2 system)\\nSolved: Delete the file ~/.docker/config.json\\nYishan Zhan', 'section': '9. Serverless Deep Learning', 'question': 'What IAM permission policy is needed to complete Week 9: Serverless?', 'course': 'machine-learning-zoomcamp', 'id': '1e0dc11c'}, '1078aeb7': {'text': 'Add the next lines to vim /etc/docker/daemon.json\\n{\\n\"dns\": [\"8.8.8.8\", \"8.8.4.4\"]\\n}\\nThen, restart docker:  sudo service docker restart\\nIbai Irastorza', 'section': '9. Serverless Deep Learning', 'question': 'Docker Temporary failure in name resolution', 'course': 'machine-learning-zoomcamp', 'id': '1078aeb7'}, '7daaca73': {'text': \"Solution: add compile = False to the load_model function\\nkeras.models.load_model('model_name.h5', compile=False)\\nNadia Paz\", 'section': '9. Serverless Deep Learning', 'question': 'Keras model *.h5 doesn’t load. Error: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`', 'course': 'machine-learning-zoomcamp', 'id': '7daaca73'}, '0cfbe2e2': {'text': 'This deployment setup can be tested locally using AWS RIE (runtime interface emulator).\\nBasically, if your Docker image was built upon base AWS Lambda image (FROM public.ecr.aws/lambda/python:3.10) - just use certain ports for “docker run” and a certain “localhost link” for testing:\\ndocker run -it --rm -p 9000:8080 name\\nThis command runs the image as a container and starts up an endpoint locally at:\\nlocalhost:9000/2015-03-31/functions/function/invocations\\nPost an event to the following endpoint using a curl command:\\ncurl -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d \\'{}\\'\\nExamples of curl testing:\\n* windows testing:\\ncurl -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d \"{\\\\\"url\\\\\": \\\\\"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\\\\\"}\"\\n* unix testing:\\ncurl -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d \\'{\"url\": \"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\"}\\'\\nIf during testing you encounter an error like this:\\n# {\"errorMessage\": \"Unable to marshal response: Object of type float32 is not JSON serializable\", \"errorType\": \"Runtime.MarshalError\", \"requestId\": \"7ea5d17a-e0a2-48d5-b747-a16fc530ed10\", \"stackTrace\": []}\\njust turn your response at lambda_handler() to string - str(result).\\nAdded by Andrii Larkin', 'section': '9. Serverless Deep Learning', 'question': 'How to test AWS Lambda + Docker locally?', 'course': 'machine-learning-zoomcamp', 'id': '0cfbe2e2'}, '1460fb65': {'text': 'Make sure all codes in test.py dont have any dependencies with tensorflow library. One of most common reason that lead the this error is tflite still imported from tensorflow. Change import tensorflow.lite as tflite to import tflite_runtime.interpreter as tflite\\nAdded by Ryan Pramana', 'section': '9. Serverless Deep Learning', 'question': '\"Unable to import module \\'lambda_function\\': No module named \\'tensorflow\\'\" when run python test.py', 'course': 'machine-learning-zoomcamp', 'id': '1460fb65'}, 'd4f9efdc': {'text': 'I’ve tried to do everything in Google Colab. Here is a way to work with Docker in Google Colab:\\nhttps://gist.github.com/mwufi/6718b30761cd109f9aff04c5144eb885\\n\\uec03%%shell\\npip install udocker\\nudocker --allow-root install\\n\\uec02!udocker --allow-root run hello-world\\nAdded by Ivan Brigida\\nLambda API Gateway errors:\\n`Authorization header requires \\'Credential\\' parameter. Authorization header requires \\'Signature\\' parameter. Authorization header requires \\'SignedHeaders\\' parameter. Authorization header requires existence of either a \\'X-Amz-Date\\' or a \\'Date\\' header.`\\n`Missing Authentication Token`\\nimport boto3\\nclient = boto3.client(\\'apigateway\\')\\nresponse = client.test_invoke_method(\\nrestApiId=\\'your_rest_api_id\\',\\nresourceId=\\'your_resource_id\\',\\nhttpMethod=\\'POST\\',\\npathWithQueryString=\\'/test/predict\\', #depend how you set up the api\\nbody=\\'{\"url\": \"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\"}\\'\\n)\\nprint(response[\\'body\\'])\\nYishan Zhan\\nUnable to run pip install tflite_runtime from github wheel links?\\nTo overcome this issue, you can download the whl file to your local project folder and in the Docker file add the following lines:\\nCOPY <file-name> .\\nRUN pip install <file-name>\\nAbhijit Chakraborty', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Install Docker (udocker) in Google Colab', 'course': 'machine-learning-zoomcamp', 'id': 'd4f9efdc'}, '6a417bfe': {'text': 'TODO', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'How to get started with Week 10?', 'course': 'machine-learning-zoomcamp', 'id': '6a417bfe'}, 'ed8b300d': {'text': 'Running a CNN on your CPU can take a long time and once you’ve run out of free time on some cloud providers, it’s time to pay up. Both can be tackled by installing tensorflow with CUDA support on your local machine if you have the right hardware.\\nI was able to get it working by using the following resources:\\nCUDA on WSL :: CUDA Toolkit Documentation (nvidia.com)\\nInstall TensorFlow with pip\\nStart Locally | PyTorch\\nI included the link to PyTorch so that you can get that one installed and working too while everything is fresh on your mind. Just select your options, and for Computer Platform, I chose CUDA 11.7 and it worked for me.\\nAdded by Martin Uribe', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'How to install Tensorflow in Ubuntu WSL2', 'course': 'machine-learning-zoomcamp', 'id': 'ed8b300d'}, 'a64aed6b': {'text': 'If you are running tensorflow on your own machine and you start getting the following errors:\\nAllocator (GPU_0_bfc) ran out of memory trying to allocate 6.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\\nTry adding this code in a cell at the beginning of your notebook:\\nconfig = tf.compat.v1.ConfigProto()\\nconfig.gpu_options.allow_growth = True\\nsession = tf.compat.v1.Session(config=config)\\nAfter doing this most of my issues went away. I say most because there was one instance when I still got the error once more, but only during one epoch. I ran the code again, right after it finished, and I never saw the error again.\\nAdded by Martin Uribe', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Getting: Allocator ran out of memory errors?', 'course': 'machine-learning-zoomcamp', 'id': 'a64aed6b'}, '727238ee': {'text': 'In session 10.3, when creating the virtual environment with pipenv and trying to run the script gateway.py, you might get this error:\\nTypeError: Descriptors cannot not be created directly.\\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\\n1. Downgrade the protobuf package to 3.20.x or lower.\\n2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\\nThis will happen if your version of protobuf is one of the newer ones. As a workaround, you can fix the protobuf version to an older one. In my case I got around the issue by creating the environment with:\\npipenv install --python 3.9.13 requests grpcio==1.42.0 flask gunicorn \\\\\\nkeras-image-helper tensorflow-protobuf==2.7.0 protobuf==3.19.6\\nAdded by Ángel de Vicente', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Problem with recent version of protobuf', 'course': 'machine-learning-zoomcamp', 'id': '727238ee'}, '85d4901d': {'text': 'Due to the uncertainties associated with machines, sometimes you can get the error message like this when you try to run a docker command:\\n”Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?”\\nSolution: The solution is simple. The Docker Desktop might no longer be connecting to the WSL Linux distro. What you need to do is go to your Docker Desktop setting and then click on resources. Under resources, click on WSL Integration. You will get a tab like the image below:\\nJust enable additional distros. That’s all. Even if the additional distro is the same as the default WSL distro.\\nOdimegwu David', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'WSL Cannot Connect To Docker Daemon', 'course': 'machine-learning-zoomcamp', 'id': '85d4901d'}, 'df023a13': {'text': 'In case the HPA instance does not run correctly even after installing the latest version of Metrics Server from the components.yaml manifest with:\\n>>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\\nAnd the targets still appear as <unknown>\\nRun >>kubectl edit deploy -n kube-system metrics-server\\nAnd search for this line:\\nargs:\\n- --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\\nAdd this line in the middle:  - --kubelet-insecure-tls\\nSo that it stays like this:\\nargs:\\n- --kubelet-insecure-tls\\n- --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\\nSave and run again >>kubectl get hpa\\nAdded by Marilina Orihuela', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'HPA instance doesn’t run properly', 'course': 'machine-learning-zoomcamp', 'id': 'df023a13'}, '48e92d65': {'text': 'In case the HPA instance does not run correctly even after installing the latest version of Metrics Server from the components.yaml manifest with:\\n>>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\\nAnd the targets still appear as <unknown>\\nRun the following command:\\nkubectl apply -f https://raw.githubusercontent.com/Peco602/ml-zoomcamp/main/10-kubernetes/kube-config/metrics-server-deployment.yaml\\nWhich uses a metrics server deployment file already embedding the - --kubelet-insecure-tls option.\\nAdded by Giovanni Pecoraro', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'HPA instance doesn’t run properly (easier solution)', 'course': 'machine-learning-zoomcamp', 'id': '48e92d65'}, '1685cae4': {'text': \"When I run pip install grpcio==1.42.0 tensorflow-serving-api==2.7.0 to install the libraries in windows machine,  I was getting the below error :\\nERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\\\\\Users\\\\\\\\Asia\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\google\\\\\\\\protobuf\\\\\\\\internal\\\\\\\\_api_implementation.cp39-win_amd64.pyd'\\nConsider using the `--user` option or check the permissions.\\nSolution description :\\nI was able to install the libraries using below command:\\npip --user install grpcio==1.42.0 tensorflow-serving-api==2.7.0\\nAsia Saeed\", 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Could not install packages due to an OSError: [WinError 5] Access is denied', 'course': 'machine-learning-zoomcamp', 'id': '1685cae4'}, '4fb7b21e': {'text': 'Problem description\\nI was getting the below error message when I run gateway.py after modifying the code & creating virtual environment in  video 10.3 :\\nFile \"C:\\\\Users\\\\Asia\\\\Data_Science_Code\\\\Zoompcamp\\\\Kubernetes\\\\gat.py\", line 9, in <module>\\nfrom tensorflow_serving.apis import predict_pb2\\nFile \"C:\\\\Users\\\\Asia\\\\.virtualenvs\\\\Kubernetes-Ge6Ts1D5\\\\lib\\\\site-packages\\\\tensorflow_serving\\\\apis\\\\predict_pb2.py\", line 14, in <module>\\nfrom tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\\nFile \"C:\\\\Users\\\\Asia\\\\.virtualenvs\\\\Kubernetes-Ge6Ts1D5\\\\lib\\\\site-packages\\\\tensorflow\\\\core\\\\framework\\\\tensor_pb2.py\", line 14, in <module>\\nfrom tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\\nFile \"C:\\\\Users\\\\Asia\\\\.virtualenvs\\\\Kubernetes-Ge6Ts1D5\\\\lib\\\\site-packages\\\\tensorflow\\\\core\\\\framework\\\\resource_handle_pb2.py\", line 14, in <module>\\nfrom tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\\nFile \"C:\\\\Users\\\\Asia\\\\.virtualenvs\\\\Kubernetes-Ge6Ts1D5\\\\lib\\\\site-packages\\\\tensorflow\\\\core\\\\framework\\\\tensor_shape_pb2.py\", line 36, in <module>\\n_descriptor.FieldDescriptor(\\nFile \"C:\\\\Users\\\\Asia\\\\.virtualenvs\\\\Kubernetes-Ge6Ts1D5\\\\lib\\\\site-packages\\\\google\\\\protobuf\\\\descriptor.py\", line 560, in __new__\\n_message.Message._CheckCalledFromGeneratedFile()\\nTypeError: Descriptors cannot not be created directly.\\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\\n1. Downgrade the protobuf package to 3.20.x or lower.\\n2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\\nSolution description:\\nIssue has been resolved by downgrading protobuf to version 3.20.1.\\npipenv install protobuf==3.20.1\\nAsia Saeed', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'TypeError: Descriptors cannot not be created directly.', 'course': 'machine-learning-zoomcamp', 'id': '4fb7b21e'}, '8bd3bfc2': {'text': 'To install kubectl on windows using the terminal in vscode (powershell), I followed this tutorial: https://medium.com/@ggauravsigra/install-kubectl-on-windows-af77da2e6fff\\nI first downloaded kubectl with curl, with these command lines: https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/#install-kubectl-binary-with-curl-on-windows\\nAt step 3, I followed the tutorial with the copy of the exe file in a specific folder on C drive.\\nThen I added this folder path to PATH in my environment variables.\\nKind can be installed the same way with the curl command on windows, by specifying a folder that will be added to the path environment variable.\\nAdded by Mélanie Fouesnard', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'How to install easily kubectl on windows ?', 'course': 'machine-learning-zoomcamp', 'id': '8bd3bfc2'}, '03b5fc59': {'text': \"First you need to launch a powershell terminal with administrator privilege.\\nFor this we need to install choco library first through the following syntax in powershell:\\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\\nKrishna Anand\", 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Install kind through choco library', 'course': 'machine-learning-zoomcamp', 'id': '03b5fc59'}, '7c31bc9a': {'text': 'If you are having challenges installing Kind through the Windows Powershell as provided on the website and Choco Library as I did, you can simply install Kind through Go.\\n> Download and Install Go (https://go.dev/doc/install)\\n> Confirm installation by typing the following in Command Prompt -  go version\\n> Proceed by installing Kind by following this command - go install sigs.k8s.io/kind@v0.20.0\\n>Confirm Installation kind --version\\nIt works perfectly.', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Install Kind via Go package', 'course': 'machine-learning-zoomcamp', 'id': '7c31bc9a'}, '605efc12': {'text': \"I ran into an issue where kubectl wasn't working.\\nI kept getting the following error:\\nkubectl get service\\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\\nI searched online for a resolution, but everyone kept talking about creating an environment variable and creating some admin.config file in my home directory.\\nAll hogwash.\\nThe solution to my problem was to just start over.\\nkind delete cluster\\nrm -rf ~/.kube\\nkind create cluster\\nNow when I try the same command again:\\nkubectl get service\\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\\nkubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   53s\\nAdded by Martin Uribe\", 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'The connection to the server localhost:8080 was refused - did you specify the right host or port?', 'course': 'machine-learning-zoomcamp', 'id': '605efc12'}, 'c5cde96c': {'text': 'Problem description\\nDue to experimenting back and forth so much without care for storage, I just ran out of it on my 30-GB AWS instance.\\nMy first reflex was to remove some zoomcamp directories, but of course those are mostly code so it didn’t help much.\\nSolution description\\n> docker images\\nrevealed that I had over 20 GBs worth of superseded / duplicate models lying around, so I proceeded to > docker rmi\\na bunch of those — but to no avail!\\nIt turns out that deleting docker images does not actually free up any space as you might expect. After removing images, you also need to run\\n> docker system prune\\nSee also: https://stackoverflow.com/questions/36799718/why-removing-docker-containers-and-images-does-not-free-up-storage-space-on-wind\\nAdded by Konrad Mühlberg', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Running out of storage after building many docker images', 'course': 'machine-learning-zoomcamp', 'id': 'c5cde96c'}, 'd45d2da6': {'text': 'Yes, the question does require for you to specify values for CPU and memory in the yaml file, however the question that it is use in the form only refers to the port which do have a define correct value for this specific homework.\\nPastor Soto', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'In HW10 Q6 what does it mean “correct value for CPU and memory”? Aren’t they arbitrary?', 'course': 'machine-learning-zoomcamp', 'id': 'd45d2da6'}, '59823c72': {'text': 'In Kubernetes resource specifications, such as CPU requests and limits, the \"m\" stands for milliCPU, which is a unit of computing power. It represents one thousandth of a CPU core.\\ncpu: \"100m\" means the container is requesting 100 milliCPUs, which is equivalent to 0.1 CPU core.\\ncpu: \"500m\" means the container has a CPU limit of 500 milliCPUs, which is equivalent to 0.5 CPU core.\\nThese values are specified in milliCPUs to allow fine-grained control over CPU resources. It allows you to express CPU requirements and limits in a more granular way, especially in scenarios where your application might not need a full CPU core.\\nAdded by Andrii Larkin', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Why cpu vals for Kubernetes deployment.yaml look like “100m” and “500m”? What does \"m\" mean?', 'course': 'machine-learning-zoomcamp', 'id': '59823c72'}, '665f7b27': {'text': 'Problem: Failing to load docker-image to cluster (when you’ved named a cluster)\\nkind load docker-image zoomcamp-10-model:xception-v4-001\\nERROR: no nodes found for cluster \"kind\"\\nSolution: Specify cluster name with -n\\nkind -n clothing-model load docker-image zoomcamp-10-model:xception-v4-001\\nAndrew Katoch', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Kind cannot load docker image', 'course': 'machine-learning-zoomcamp', 'id': '665f7b27'}, '0a406fe0': {'text': \"Problem: I download kind from the next command:\\ncurl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.17.0/kind-windows-amd64\\nWhen I try\\nkind --version\\nI get: 'kind' is not recognized as an internal or external command, operable program or batch file\\nSolution: The default name of executable is kind-windows-amd64.exe, so that you have to rename this file to  kind.exe. Put this file in specific folder, and add it to PATH\\nAlejandro Aponte\", 'section': '10. Kubernetes and TensorFlow Serving', 'question': \"'kind' is not recognized as an internal or external command, operable program or batch file. (In Windows)\", 'course': 'machine-learning-zoomcamp', 'id': '0a406fe0'}, '64b209b0': {'text': 'Using kind with Rootless Docker or Rootless Podman requires some changes on the system (Linux), see kind – Rootless (k8s.io).\\nSylvia Schmitt', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Running kind on Linux with Rootless Docker or Rootless Podman', 'course': 'machine-learning-zoomcamp', 'id': '64b209b0'}, '518c4cb8': {'text': 'Deploy and Access the Kubernetes Dashboard\\nLuke', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Kubernetes-dashboard', 'course': 'machine-learning-zoomcamp', 'id': '518c4cb8'}, '00882c83': {'text': 'Make sure you are on AWS CLI v2 (check with aws --version)\\nhttps://docs.aws.amazon.com/cli/latest/userguide/cliv2-migration-instructions.html', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Correct AWS CLI version for eksctl', 'course': 'machine-learning-zoomcamp', 'id': '00882c83'}, 'd6d483ce': {'text': 'Problem Description:\\nIn video 10.3, when I was testing a flask service, I got the above error. I ran docker run .. in one terminal. When in second terminal I run python gateway.py, I get the above error.\\nSolution: This error has something to do with versions of Flask and Werkzeug. I got the same error, if I just import flask with from flask import Flask.\\nBy running pip freeze > requirements.txt,I found that their versions are Flask==2.2.2 and Werkzeug==2.2.2. This error appears while using an old version of werkzeug (2.2.2) with new version of flask (2.2.2). I solved it by pinning version of Flask into an older version with pipenv install Flask==2.1.3.\\nAdded by Bhaskar Sarma', 'section': '10. Kubernetes and TensorFlow Serving', 'question': \"TypeError: __init__() got an unexpected keyword argument 'unbound_message' while importing Flask\", 'course': 'machine-learning-zoomcamp', 'id': 'd6d483ce'}, 'f9711723': {'text': 'As per AWS documentation:\\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html\\nYou need to do: (change the fields in red)\\naws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com\\nAlternatively you can run the following command without changing anything given you have a default region configured\\naws ecr get-login-password --region $(aws configure get region) | docker login --username AWS --password-stdin \"$(aws sts get-caller-identity --query \"Account\" --output text).dkr.ecr.$(aws configure get region).amazonaws.com\"\\nAdded by Humberto Rodriguez', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Command aws ecr get-login --no-include-email returns “aws: error: argument operation: Invalid choice…”', 'course': 'machine-learning-zoomcamp', 'id': 'f9711723'}, '5bda3b94': {'text': 'While trying to run the docker code on M1:\\ndocker run --platform linux/amd64 -it --rm \\\\\\n-p 8500:8500 \\\\\\n-v $(pwd)/clothing-model:/models/clothing-model/1 \\\\\\n-e MODEL_NAME=\"clothing-model\" \\\\\\ntensorflow/serving:2.7.0\\nIt outputs the error:\\nError:\\nStatus: Downloaded newer image for tensorflow/serving:2.7.0\\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/generated_message_reflection.cc:2345] CHECK failed: file != nullptr:\\nterminate called after throwing an instance of \\'google::protobuf::FatalException\\'\\nwhat():  CHECK failed: file != nullptr:\\nqemu: uncaught target signal 6 (Aborted) - core dumped\\n/usr/bin/tf_serving_entrypoint.sh: line 3:     8 Aborted                 tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"\\nSolution\\ndocker pull emacski/tensorflow-serving:latest\\ndocker run -it --rm \\\\\\n-p 8500:8500 \\\\\\n-v $(pwd)/clothing-model:/models/clothing-model/1 \\\\\\n-e MODEL_NAME=\"clothing-model\" \\\\\\nemacski/tensorflow-serving:latest-linux_arm64\\nSee more here: https://github.com/emacski/tensorflow-serving-arm\\nAdded by Daniel Egbo', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Error downloading  tensorflow/serving:2.7.0 on Apple M1 Mac', 'course': 'machine-learning-zoomcamp', 'id': '5bda3b94'}, 'cccd31cf': {'text': 'Similar to the one above but with a different solution the main reason is that emacski doesn’t seem to maintain the repo any more, the latest image is from 2 years ago at the time of writing (December 2023)\\nProblem:\\nWhile trying to run the docker code on Mac M2 apple silicon:\\ndocker run --platform linux/amd64 -it --rm \\\\\\n-p 8500:8500 \\\\\\n-v $(pwd)/clothing-model:/models/clothing-model/1 \\\\\\n-e MODEL_NAME=\"clothing-model\" \\\\\\ntensorflow/serving\\nYou get an error:\\n/usr/bin/tf_serving_entrypoint.sh: line 3:     7 Illegal instruction     tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"\\nSolution:\\nUse bitnami/tensorflow-serving base image\\nLaunch it either using docker run\\ndocker run -d \\\\\\n--name tf_serving \\\\\\n-p 8500:8500 \\\\\\n-p 8501:8501 \\\\\\n-v $(pwd)/clothing-model:/bitnami/model-data/1 \\\\\\n-e TENSORFLOW_SERVING_MODEL_NAME=clothing-model \\\\\\nbitnami/tensorflow-serving:2\\nOr the following docker-compose.yaml\\nversion: \\'3\\'\\nservices:\\ntf_serving:\\nimage: bitnami/tensorflow-serving:2\\nvolumes:\\n- ${PWD}/clothing-model:/bitnami/model-data/1\\nports:\\n- 8500:8500\\n- 8501:8501\\nenvironment:\\n- TENSORFLOW_SERVING_MODEL_NAME=clothing-model\\nAnd run it with\\ndocker compose up\\nAdded by Alex Litvinov', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'Illegal instruction error when running tensorflow/serving image on Mac M2 Apple Silicon (potentially on M1 as well)', 'course': 'machine-learning-zoomcamp', 'id': 'cccd31cf'}, '57f49999': {'text': 'Problem: CPU metrics Shows Unknown\\nNAME         REFERENCE           TARGETS         MINPODS   MAXPODS   REPLICAS   AGE\\ncredit-hpa   Deployment/credit   <unknown>/20%   1         3         1          18s\\nFailedGetResourceMetric       2m15s (x169 over 44m)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API:\\nSolution:\\n-> Delete HPA (kubectl delete hpa credit-hpa)\\n-> kubectl apply -f https://raw.githubusercontent.com/pythianarora/total-practice/master/sample-kubernetes-code/metrics-server.yaml\\n-> Create HPA\\nThis should solve the cpu metrics report issue.\\nAdded by Priya V', 'section': '11. KServe', 'question': 'HPA doesn’t show CPU metrics', 'course': 'machine-learning-zoomcamp', 'id': '57f49999'}, '5cb58698': {'text': 'Problem description:\\nRunning this:\\ncurl -s \"https://raw.githubusercontent.com/kserve/kserve/release-0.9/hack/quick_install.sh\" | bash\\nFails with errors because of istio failing to update resources, and you are on kubectl > 1.25.0.\\nCheck kubectl version with kubectl version\\nSolution description\\nEdit the file “quick_install.bash” by downloading it with curl without running bash. Edit the versions of Istio and Knative as per the matrix on the KServe website.\\nRun the bash script now.\\nAdded by Andrew Katoch', 'section': '11. KServe', 'question': 'Errors with istio during installation', 'course': 'machine-learning-zoomcamp', 'id': '5cb58698'}, 'de650b41': {'text': 'Problem description\\nSolution description\\n(optional) Added by Name', 'section': 'Projects (Midterm and Capstone)', 'question': 'Problem title', 'course': 'machine-learning-zoomcamp', 'id': 'de650b41'}, '9ffacaac': {'text': 'Answer: You can see them here (it’s taken from the 2022 cohort page). Go to the cohort folder for your own cohort’s deadline.', 'section': 'Projects (Midterm and Capstone)', 'question': 'What are the project deadlines?', 'course': 'machine-learning-zoomcamp', 'id': '9ffacaac'}, '4dfb5d4f': {'text': 'Answer: All midterms and capstones are meant to be solo projects. [source @Alexey]', 'section': 'Projects (Midterm and Capstone)', 'question': 'Are projects solo or collaborative/group work?', 'course': 'machine-learning-zoomcamp', 'id': '4dfb5d4f'}, '0b8739b7': {'text': 'Answer: Ideally midterms up to module-06, capstones include all modules in that cohort’s syllabus. But you can include anything extra that you want to feature. Just be sure to document anything not covered in class.\\nAlso watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nMore discussions:\\n[source1] [source2] [source3]', 'section': 'Projects (Midterm and Capstone)', 'question': 'What modules, topics, problem-sets should a midterm/capstone project cover? Can I do xyz?', 'course': 'machine-learning-zoomcamp', 'id': '0b8739b7'}, '9eb52679': {'text': \"These links apply to all projects, actually. Again, for some cohorts, the modules/syllabus might be different, so always check in your cohort’s folder as well for additional or different instructions, if any.\\nMidterm Project Sample: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp/cohorts/2021/07-midterm-project\\nMidTerm Project Deliverables: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp/projects\\nSubmit MidTerm Project: https://docs.google.com/forms/d/e/1FAIpQLSfgmOk0QrmHu5t0H6Ri1Wy_FDVS8I_nr5lY3sufkgk18I6S5A/viewform\\nDatasets:\\nhttps://www.kaggle.com/datasets and https://www.kaggle.com/competitions\\nhttps://archive.ics.uci.edu/ml/index.php\\nhttps://data.europa.eu/en\\nhttps://www.openml.org/search?type=data\\nhttps://newzealand.ai/public-data-sets\\nhttps://datasetsearch.research.google.com\\nWhat to do and Deliverables\\nThink of a problem that's interesting for you and find a dataset for that\\nDescribe this problem and explain how a model could be used\\nPrepare the data and doing EDA, analyze important features\\nTrain multiple models, tune their performance and select the best model\\nExport the notebook into a script\\nPut your model into a web service and deploy it locally with Docker\\nBonus points for deploying the service to the cloud\", 'section': 'Projects (Midterm and Capstone)', 'question': 'Crucial Links', 'course': 'machine-learning-zoomcamp', 'id': '9eb52679'}, '7a1fcfd9': {'text': 'Answer: Previous cohorts projects page has instructions (youtube).\\nhttps://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2022/projects.md#midterm-project\\nAlexey and his team will compile a g-sheet with links to submitted projects with our hashed emails (just like when we check leaderboard for homework) that are ours to review within the evaluation deadline.\\n~~~ Added by Nukta Bhatia ~~~', 'section': 'Projects (Midterm and Capstone)', 'question': 'How to conduct peer reviews for projects?', 'course': 'machine-learning-zoomcamp', 'id': '7a1fcfd9'}, '1cfa62c5': {'text': 'See the answer here.', 'section': 'Projects (Midterm and Capstone)', 'question': 'Computing the hash for project review', 'course': 'machine-learning-zoomcamp', 'id': '1cfa62c5'}, '2a78f52e': {'text': 'For the learning in public for this midterm project it seems that has a total value of 14!, Does this mean that we need make 14 posts?, Or the regular seven posts for each module and each one with a value of 2?, Or just one with a total value of 14?\\n14 posts, one for each day', 'section': 'Projects (Midterm and Capstone)', 'question': 'Learning in public links for the projects', 'course': 'machine-learning-zoomcamp', 'id': '2a78f52e'}, '68aeab64': {'text': 'You can use git-lfs (https://git-lfs.com/) for upload large file to github repository.\\nRyan Pramana', 'section': 'Projects (Midterm and Capstone)', 'question': \"My dataset is too large and I can't loaded in GitHub , do anyone knows about a solution?\", 'course': 'machine-learning-zoomcamp', 'id': '68aeab64'}, '9a7c26e0': {'text': 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu', 'section': 'Projects (Midterm and Capstone)', 'question': 'What If I submitted only two projects and failed to submit the third?', 'course': 'machine-learning-zoomcamp', 'id': '9a7c26e0'}, '1fd83eb9': {'text': 'Yes. You only need to review peers when you submit your project.\\nConfirmed on Slack by Alexey Grigorev (added by Rileen Sinha)', 'section': 'Projects (Midterm and Capstone)', 'question': \"I did the first two projects and skipped the last one so I wouldn't have two peer review in second capstone right?\", 'course': 'machine-learning-zoomcamp', 'id': '1fd83eb9'}, 'fbaa5b20': {'text': 'Regarding Point 4 in the midterm deliverables, which states, \"Train multiple models, tune their performance, and select the best model,\" you might wonder, how many models should you train? The answer is simple: train as many as you can. The term \"multiple\" implies having more than one model, so as long as you have more than one, you\\'re on the right track.', 'section': 'Projects (Midterm and Capstone)', 'question': 'How many models should I train?', 'course': 'machine-learning-zoomcamp', 'id': 'fbaa5b20'}, '37eab341': {'text': 'I am not sure how the project evaluate assignment works? Where do I find this? I have access to all the capstone 2 project, perhaps, I can randomly pick any to review.\\nAnswer:\\nThe link provided for example (2023/Capstone link ): https://docs.google.com/forms/d/e/1FAIpQLSdgoepohpgbM4MWTAHWuXa6r3NXKnxKcg4NDOm0bElAdXdnnA/viewform contains a list of all submitted projects to be evaluated. More specific, you are to review 3 assigned peer projects. In the spreadsheet are 3 hash values of your assigned peer projects. However, you need to derive the your hash value of your email address and find the value on the spreadsheet under the (reviewer_hash) heading.\\nTo calculate your hash value run the python code below:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode(\\'utf-8\\')).hexdigest()\\n# Example usage **** enter your email below (Example1@gmail.com)****\\nemail = \"Example1@gmail.com\"\\nhashed_email = compute_hash(email)\\nprint(\"Original Email:\", email)\\nprint(\"Hashed Email (SHA-1):\", hashed_email)\\nEdit the above code to replace Example1@gmail.com as your email address\\nStore and run the above python code from your terminal. See below as the Hashed Email (SHA-1) value\\nYou then go to the link: https://docs.google.com/spreadsheets/d/e/2PACX-1vR-7RRtq7AMx5OzI-tDbkzsbxNLm-NvFOP5OfJmhCek9oYcDx5jzxtZW2ZqWvBqc395UZpHBv1of9R1/pubhtml?gid=876309294&single=true\\nLastly, copy the “Hashed Email (SHA-1): bd9770be022dede87419068aa1acd7a2ab441675” value and search for 3 identical entries. There you should see your peer project to be reviewed.\\nBy Emmanuel Ayeni', 'section': 'Projects (Midterm and Capstone)', 'question': 'How does the project evaluation work for you as a peer reviewer?', 'course': 'machine-learning-zoomcamp', 'id': '37eab341'}, '57754faf': {'text': 'Alexey Grigorev: “It’s based on all the scores to make sure most of you pass.”                                                   By Annaliese Bronz\\nOther course-related questions that don’t fall into any of the categories above or can apply to more than one category/module', 'section': 'Miscellaneous', 'question': 'Do you pass a project based on the average of everyone else’s scores or based on the total score you earn?', 'course': 'machine-learning-zoomcamp', 'id': '57754faf'}, '6979c5d1': {'text': 'Answer: The train.py file will be used by your peers to review your midterm project. It is for them to cross-check that your training process works on someone else’s system. It should also be included in the environment in conda or with pipenv.\\nOdimegwu David', 'section': 'Miscellaneous', 'question': 'Why do I need to provide a train.py file when I already have the notebook.ipynb file?', 'course': 'machine-learning-zoomcamp', 'id': '6979c5d1'}, 'a1bd8c34': {'text': \"Pip install pillow - install pillow library\\nfrom PIL import Image\\nimg = Image.open('aeroplane.png')\\nFrom numpy import asarray\\nnumdata=asarray(img)\\nKrishna Anand\", 'section': 'Miscellaneous', 'question': 'Loading the Image with PILLOW library and converting to numpy array', 'course': 'machine-learning-zoomcamp', 'id': 'a1bd8c34'}, 'b2ab0fc1': {'text': \"Ans: train.py has to be a python file. This is because running a python script for training a model is much simpler than running a notebook and that's how training jobs usually look like in real life.\", 'section': 'Miscellaneous', 'question': 'Is a train.py file necessary when you have a train.ipynb file in your midterm project directory?', 'course': 'machine-learning-zoomcamp', 'id': 'b2ab0fc1'}, '80c439a9': {'text': 'Yes, you can create a mobile app or interface that manages these forms and validations. But you should also perform validations on backend.\\nYou can also check Streamlit: https://github.com/DataTalksClub/project-of-the-week/blob/main/2022-08-14-frontend.md\\nAlejandro Aponte', 'section': 'Miscellaneous', 'question': 'Is there a way to serve up a form for users to enter data for the model to crunch on?', 'course': 'machine-learning-zoomcamp', 'id': '80c439a9'}, 'ff93b86e': {'text': \"Using model.feature_importances_ can gives you an error:\\nAttributeError: 'Booster' object has no attribute 'feature_importances_'\\nAnswer: if you train the model like this: model = xgb.train you should use get_score() instead\\nEkaterina Kutovaia\", 'section': 'Miscellaneous', 'question': 'How to get feature importance for XGboost model', 'course': 'machine-learning-zoomcamp', 'id': 'ff93b86e'}, 'fcd86c8f': {'text': 'In the Elastic Container Service task log, error “[Errno 12] Cannot allocate memory” showed up.\\nJust increase the RAM and CPU in your task definition.\\nHumberto Rodriguez', 'section': 'Miscellaneous', 'question': '[Errno 12] Cannot allocate memory in AWS Elastic Container Service', 'course': 'machine-learning-zoomcamp', 'id': 'fcd86c8f'}, '236864c2': {'text': \"When running a docker container with waitress serving the app.py for making predictions, pickle will throw an error that can't get attribute <name_of_class> on module __main__.\\nThis does not happen when Flask is used directly, i.e. not through waitress.\\nThe problem is that the model uses a custom column transformer class, and when the model was saved, it was saved from the __main__ module (e.g. python train.py). Pickle will reference the class in the global namespace (top-level code): __main__.<custom_class>.\\nWhen using waitress, waitress will load the predict_app module and this will call pickle.load, that will try to find __main__.<custom_class> that does not exist.\\nSolution:\\nPut the class into a separate module and import it in both the script that saves the model (e.g. train.py) and the script that loads the model (e.g. predict.py)\\nNote: If Flask is used (no waitress) in predict.py, and predict.py has the definition of the class, When  it is run: python predict.py, it will work because the class is in the same namespace as the one used when the model was saved (__main__).\\nDetailed info: https://stackoverflow.com/questions/27732354/unable-to-load-files-using-pickle-and-multiple-modules\\nMarcos MJD\", 'section': 'Miscellaneous', 'question': 'Pickle error: can’t get attribute XXX on module __main__', 'course': 'machine-learning-zoomcamp', 'id': '236864c2'}, 'efc4a04f': {'text': 'There are different techniques, but the most common used are the next:\\nDataset transformation (for example, log transformation)\\nClipping high values\\nDropping these observations\\nAlena Kniazeva', 'section': 'Miscellaneous', 'question': 'How to handle outliers in a dataset?', 'course': 'machine-learning-zoomcamp', 'id': 'efc4a04f'}, '15f361b7': {'text': 'I was getting the below error message when I was trying to create docker image using bentoml\\n[bentoml-cli] `serve` failed: Failed loading Bento from directory /home/bentoml/bento: Failed to import module \"service\": No module named \\'sklearn\\'\\nSolution description\\nThe cause was because , in bentofile.yaml, I wrote sklearn instead of scikit-learn. Issue was fixed after I modified the packages list as below.\\npackages: # Additional pip packages required by the service\\n- xgboost\\n- scikit-learn\\n- pydantic\\nAsia Saeed', 'section': 'Miscellaneous', 'question': 'Failed loading Bento from directory /home/bentoml/bento: Failed to import module \"service\": No module named \\'sklearn\\'', 'course': 'machine-learning-zoomcamp', 'id': '15f361b7'}, 'dbbce78b': {'text': \"You might see a long error message with something about sparse matrices, and in the swagger UI, you get a code 500 error with “” (empty string) as output.\\nPotential reason: Setting DictVectorizer or OHE to sparse while training, and then storing this in a pipeline or custom object in the benotml model saving stage in train.py. This means that when the custom object is called in service.py, it will convert each input to a different sized sparse matrix, and this can't be batched due to inconsistent length. In this case, bentoml model signatures should have batchable set to False for production during saving the bentoml mode in train.py.\\n(Memoona Tahira)\", 'section': 'Miscellaneous', 'question': 'BentoML not working with –production flag at any stage: e.g. with bentoml serve and while running the bentoml container', 'course': 'machine-learning-zoomcamp', 'id': 'dbbce78b'}, 'f3a00e15': {'text': 'Problem description:\\nDo we have to run everything?\\nYou are encouraged, if you can, to run them. As this provides another opportunity to learn from others.\\nNot everyone will be able to run all the files, in particular the neural networks.\\nSolution description:\\nAlternatively, can you see that everything you need to reproduce is there: the dataset is there, the instructions are there, are there any obvious errors and so on.\\nRelated slack conversation here.\\n(Gregory Morris)', 'section': 'Miscellaneous', 'question': 'Reproducibility', 'course': 'machine-learning-zoomcamp', 'id': 'f3a00e15'}, '9102b3c0': {'text': \"If your model is too big for github one option is to try and compress the model using joblib. For example joblib.dump(model, model_filename, compress=('zlib', 6) will use zlib to compress the model. Just note this could take a few moments as the model is being compressed.\\nQuinn Avila\", 'section': 'Miscellaneous', 'question': 'Model too big', 'course': 'machine-learning-zoomcamp', 'id': '9102b3c0'}, '70d89fdf': {'text': \"When you try to push the docker image to Google Container Registry and get this message “unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials.”, type this below on console, but first install https://cloud.google.com/sdk/docs/install, this is to be able to use gcloud in console:\\ngcloud auth configure-docker\\n(Jesus Acuña)\", 'section': 'Miscellaneous', 'question': 'Permissions to push docker to Google Container Registry', 'course': 'machine-learning-zoomcamp', 'id': '70d89fdf'}, 'c5d6a804': {'text': 'I am getting this error message when I tried to install tflite in a pipenv environment\\nError:  An error occurred while installing tflite_runtime!\\nError text:\\nERROR: Could not find a version that satisfies the requirement tflite_runtime (from versions: none)\\nERROR: No matching distribution found for tflite_runtime\\nThis version of tflite do not run on python 3.10, the way we can make it work is by install python 3.9, after that it would install the tflite_runtime without problem.\\nPastor Soto\\nCheck all available versions here:\\nhttps://google-coral.github.io/py-repo/tflite-runtime/\\nIf you don’t find a combination matching your setup, try out the options at\\nhttps://github.com/alexeygrigorev/tflite-aws-lambda/tree/main/tflite\\nwhich you can install as shown in the lecture, e.g.\\npip install https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp38-cp38-linux_x86_64.whl\\nFinally, if nothing works, use the TFLite included in TensorFlow for local development, and use Docker for testing Lambda.\\nRileen Sinha (based on discussions on Slack)', 'section': 'Miscellaneous', 'question': 'Tflite_runtime unable to install', 'course': 'machine-learning-zoomcamp', 'id': 'c5d6a804'}, '8c7f089f': {'text': \"Error: ImageDataGenerator name 'scipy' is not defined.\\nCheck that scipy is installed in your environment.\\nRestart jupyter kernel and try again.\\nMarcos MJD\", 'section': 'Miscellaneous', 'question': 'Error when running ImageDataGenerator.flow_from_dataframe', 'course': 'machine-learning-zoomcamp', 'id': '8c7f089f'}, '739bcccf': {'text': 'Tim from BentoML has prepared a dedicated video tutorial wrt this use case here:\\nhttps://www.youtube.com/watch?v=7gI1UH31xb4&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=97\\nKonrad Muehlberg', 'section': 'Miscellaneous', 'question': 'How to pass BentoML content / docker container to Amazon Lambda', 'course': 'machine-learning-zoomcamp', 'id': '739bcccf'}, '4603e4e5': {'text': \"In deploying model part, I wanted to test my model locally on a test-image data and I had this silly error after the following command:\\nurl = 'https://github.com/bhasarma/kitchenware-classification-project/blob/main/test-image.jpg'\\nX = preprocessor.from_url(url)\\nI got the error:\\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f797010a590>\\nSolution:\\nAdd ?raw=true after .jpg in url. E.g. as below\\nurl = ‘https://github.com/bhasarma/kitchenware-classification-project/blob/main/test-image.jpg?raw=true’\\nBhaskar Sarma\", 'section': 'Miscellaneous', 'question': 'Error UnidentifiedImageError: cannot identify image file', 'course': 'machine-learning-zoomcamp', 'id': '4603e4e5'}, '0a7c328e': {'text': 'Problem: If you run pipenv install and get this message. Maybe manually change Pipfile and Pipfile.lock.\\nSolution: Run: ` pipenv lock` for fix this problem and dependency files\\nAlejandro Aponte', 'section': 'Miscellaneous', 'question': '[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies', 'course': 'machine-learning-zoomcamp', 'id': '0a7c328e'}, '77efd069': {'text': 'Problem: In the course this function worked to get the features from the dictVectorizer instance: dv.get_feature_names(). But in my computer did not work. I think it has to do with library versions and but apparently that function will be deprecated soon:\\nOld: https://scikit-learn.org/0.22/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.get_feature_names\\nNew: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.get_feature_names\\nSolution: change the line dv.get_feature_names() to list(dv.get_feature_names_out))\\nIbai Irastorza', 'section': 'Miscellaneous', 'question': 'Get_feature_names() not found', 'course': 'machine-learning-zoomcamp', 'id': '77efd069'}, 'cc60f7bc': {'text': 'Problem happens when contacting the server waiting to send your predict-test and your data here in the correct shape.\\nThe problem was the format input to the model wasn’t in the right shape. Server receives the data in json format (dict) which is not suitable for the model. U should convert it to like numpy arrays.\\nAhmed Okka', 'section': 'Miscellaneous', 'question': 'Error decoding JSON response: Expecting value: line 1 column 1 (char 0)', 'course': 'machine-learning-zoomcamp', 'id': 'cc60f7bc'}, 'aa13dd66': {'text': \"Q: Hii folks, I tried deploying my docker image on Render, but it won't I get SIGTERM everytime.\\nI think .5GB RAM is not enough, is there any other free alternative available ?\\nA: aws (amazon), gcp (google), saturn.\\nBoth aws and gcp give microinstance for free for a VERY long time, and a bunch more free stuff.\\nSaturn even provides free GPU instances. Recent promo link from mlzoomcamp for Saturn:\\n“You can sign up here: https://bit.ly/saturn-mlzoomcamp\\nWhen you sign up, write in the chat box that you're an ML Zoomcamp student and you should get extra GPU hours (something like 150)”\\nAdded by Andrii Larkin\", 'section': 'Miscellaneous', 'question': 'Free cloud alternatives', 'course': 'machine-learning-zoomcamp', 'id': 'aa13dd66'}, 'c41e479c': {'text': \"Problem description: I have one column day_of_the_month . It has values 1, 2, 20, 25 etc. and int . I have a second column month_of_the_year. It has values jan, feb, ..dec. and are string. I want to convert these two columns into one column day_of_the_year and I want them to be int. 2 and jan should give me 2, i.e. 2nd day of the year, 1 and feb should give me 32, i.e. 32 nd day of the year. What is the simplest pandas-way to do it?\\nSolution description:\\nconvert dtype in day_of_the_month column from int to str with df['day_of_the_month'] = df['day_of_the_month'].map(str)\\nconvert month_of_the_year column in jan, feb ...,dec into 1,2, ..,12 string using map()\\nconvert day and month into a datetime object with:\\ndf['date_formatted'] = pd.to_datetime(\\ndict(\\nyear='2055',\\nmonth=df['month'],\\nday=df['day']\\n)\\n)\\nget day of year with: df['day_of_year']=df['date_formatted'].dt.dayofyear\\n(Bhaskar Sarma)\", 'section': 'Miscellaneous', 'question': 'Getting day of the year from day and month column', 'course': 'machine-learning-zoomcamp', 'id': 'c41e479c'}, '2f28dcf1': {'text': 'How to visualize the predictions per classes after training a neural net\\nSolution description\\nclasses, predictions = zip(*dict(zip(classes, predictions)).items())\\nplt.figure(figsize=(12, 3))\\nplt.bar(classes, predictions)\\nLuke', 'section': 'Miscellaneous', 'question': 'Chart for classes and predictions', 'course': 'machine-learning-zoomcamp', 'id': '2f28dcf1'}, '7a69cccf': {'text': 'You can convert the prediction output values to a datafarme using \\ndf = pd.DataFrame.from_dict(dict, orient=\\'index\\' , columns=[\"Prediction\"])\\nEdidiong Esu', 'section': 'Miscellaneous', 'question': 'Convert dictionary values to Dataframe table', 'course': 'machine-learning-zoomcamp', 'id': '7a69cccf'}, '20174c95': {'text': 'The image dataset for the competition was in a different layout from what we used in the dino vs dragon lesson. Since that’s what was covered, some folks were more comfortable with that setup, so I wrote a script that would generate it for them\\nIt can be found here: kitchenware-dataset-generator | Kaggle\\nMartin Uribe', 'section': 'Miscellaneous', 'question': 'Kitchenware Classification Competition Dataset Generator', 'course': 'machine-learning-zoomcamp', 'id': '20174c95'}, 'f2cd48b6': {'text': 'Install Nvidia drivers: https://www.nvidia.com/download/index.aspx.\\nWindows:\\nInstall Anaconda prompt https://www.anaconda.com/\\nTwo options:\\nInstall package ‘tensorflow-gpu’ in Anaconda\\nInstall the Tensorflow way https://www.tensorflow.org/install/pip#windows-native\\nWSL/Linux:\\nWSL: Use the Windows Nvida drivers, do not touch that.\\nTwo options:\\nInstall the Tensorflow way https://www.tensorflow.org/install/pip#linux_1\\nMake sure to follow step 4 to install CUDA by environment\\nAlso run:\\necho ‘export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/> $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\\nInstall CUDA toolkit 11.x.x https://developer.nvidia.com/cuda-toolkit-archive\\nInstall https://developer.nvidia.com/rdp/cudnn-download\\nNow you should be able to do training/inference with GPU in Tensorflow\\n(Learning in public links Links to social media posts where you share your progress with others (LinkedIn, Twitter, etc). Use #mlzoomcamp tag. The scores for this part will be capped at 7 points. Please make sure the posts are valid URLs starting with \"https://\" Does it mean that I should provide my linkedin link? or it means that I should write a post that I have completed my first assignement? (\\nANS (by ezehcp7482@gmail.com): Yes, provide the linkedIN link to where you posted.\\nezehcp7482@gmail.com:\\nPROBLEM: Since I had to put up a link to a public repository, I had to use Kaggle and uploading the dataset therein was a bit difficult; but I had to ‘google’ my way out.\\nANS: See this link for a guide (https://www.kaggle.com/code/dansbecker/finding-your-files-in-kaggle-kernels/notebook)', 'section': 'Miscellaneous', 'question': 'CUDA toolkit and cuDNN Install for Tensorflow', 'course': 'machine-learning-zoomcamp', 'id': 'f2cd48b6'}, '59b4324f': {'text': 'When multiplying matrices, the order of multiplication is important.\\nFor example:\\nA (m x n) * B (n x p) = C (m x p)\\nB (n x p) * A (m x n) = D (n x n)\\nC and D are matrices of different sizes and usually have different values. Therefore the order is important in matrix multiplication and changing the order changes the result.\\nBaran Akın', 'section': 'Miscellaneous', 'question': 'About getting the wrong result when multiplying matrices', 'course': 'machine-learning-zoomcamp', 'id': '59b4324f'}, 'e1dc1ed9': {'text': 'Refer to https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/01-intro/06-environment.md\\n(added by Rileen Sinha)', 'section': 'Miscellaneous', 'question': 'None of the videos have how to install the environment in Mac, does someone have instructions for Mac with M1 chip?', 'course': 'machine-learning-zoomcamp', 'id': 'e1dc1ed9'}, 'fc60bf3b': {'text': \"Depends on whether the form will still be open. If you're lucky and it's open, you can submit your homework and it will be evaluated. if closed - it's too late.\\n(Added by Rileen Sinha, based on answer by Alexey on Slack)\", 'section': 'Miscellaneous', 'question': 'I may end up submitting the assignment late. Would it be evaluated?', 'course': 'machine-learning-zoomcamp', 'id': 'fc60bf3b'}, '1e60e888': {'text': 'Yes. Whoever corrects the homework will only be able to access the link if the repository is public.\\n(added by Tano Bugelli)\\nHow to install Conda environment in my local machine?\\nWhich ide is recommended for machine learning?', 'section': 'Miscellaneous', 'question': 'Does the github repository need to be public?', 'course': 'machine-learning-zoomcamp', 'id': '1e60e888'}, '44552c2e': {'text': 'Install w get:\\n!which wget\\nDownload data:\\n!wget -P /content/drive/My\\\\ Drive/Downloads/ URL\\n(added by Paulina Hernandez)', 'section': 'Miscellaneous', 'question': 'How to use wget with Google Colab?', 'course': 'machine-learning-zoomcamp', 'id': '44552c2e'}, '7116b3be': {'text': \"Features (X) must always be formatted as a 2-D array to be accepted by scikit-learn.\\nUse reshape to reshape a 1D array to a 2D.\\n\\t\\t\\t\\t\\t\\t\\t(-Aileah) :>\\n(added by Tano\\nfiltered_df = df[df['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\\n# Select only the desired columns\\nselected_columns = [\\n'latitude',\\n'longitude',\\n'housing_median_age',\\n'total_rooms',\\n'total_bedrooms',\\n'population',\\n'households',\\n'median_income',\\n'median_house_value'\\n]\\nfiltered_df = filtered_df[selected_columns]\\n# Display the first few rows of the filtered DataFrame\\nprint(filtered_df.head())\", 'section': 'Miscellaneous', 'question': 'Features in scikit-learn?', 'course': 'machine-learning-zoomcamp', 'id': '7116b3be'}, '5d4d206e': {'text': 'FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead', 'section': 'Miscellaneous', 'question': 'When I plotted using Matplot lib to check if median has a tail, I got the error below how can one bypass?', 'course': 'machine-learning-zoomcamp', 'id': '5d4d206e'}, '387093cc': {'text': 'When trying to rerun the docker file in Windows, as opposed to developing in WSL/Linux, I got the error of:\\n```\\nWarning: Python 3.11 was not found on your system…\\nNeither ‘pipenv’ nor ‘asdf’ could be found to install Python.\\nYou can specify specific versions of Python with:\\n$ pipenv –python path\\\\to\\\\python\\n```\\nThe solution was to add Python311 installation folder to the PATH and restart the system and run the docker file again. That solved the error.\\n(Added by Abhijit Chakraborty)', 'section': 'Miscellaneous', 'question': 'Reproducibility in different OS', 'course': 'machine-learning-zoomcamp', 'id': '387093cc'}, 'd12a2657': {'text': 'You may quickly deploy your project to DigitalOcean App Cloud. The process is relatively straightforward. The deployment costs about 5 USD/month. The container needs to be up until the end of the project evaluation.\\nSteps:\\nRegister in DigitalOcean\\nGo to Apps -> Create App.\\nYou will need to choose GitHub as a service provider.\\nEdit Source Directory (if your project is not in the repo root)\\nIMPORTANT: Go to settings -> App Spec and edit the Dockerfile path so it looks like ./project/Dockerfile path relative to your repo root\\nRemember to add model files if they are not built automatically during the container build process.\\nBy Dmytro Durach', 'section': 'Miscellaneous', 'question': 'Deploying to Digital Ocean', 'course': 'machine-learning-zoomcamp', 'id': 'd12a2657'}, 'eb7a57a6': {'text': \"I’m just looking back at the lessons in week 3 (churn prediction project), and lesson 3.6 talks about Feature Importance for categorical values. At 8.12, the mutual info scores show that the some features are more important than others, but then in lesson 3.10 the Logistic Regression model is trained on all of the categorical variables (see 1:35). Once we have done feature importance, is it best to train your model only on the most important features?\\nNot necessarily - rather, any feature that can offer additional predictive value should be included (so, e.g. predict with & without including that feature; if excluding it drops performance, keep it, else drop it). A few individually important features might in fact be highly correlated with others, & dropping some might be fine. There are many feature selection algorithms, it might be interesting to read up on them (among the methods we've learned so far in this course, L1 regularization (Lasso) implicitly does feature selection by shrinking some weights all the way to zero).\\nBy Rileen Sinha\", 'section': 'Miscellaneous', 'question': 'Is it best to train your model only on the most important features?', 'course': 'machine-learning-zoomcamp', 'id': 'eb7a57a6'}, 'd6f0c6ea': {'text': 'You can consider several different approaches:\\nSampling: In the exploratory phase, you can use random samples of the data.\\nChunking: When you do need all the data, you can read and process it in chunks that do fit in the memory.\\nOptimizing data types: Pandas’ automatic data type inference (when reading data in) might result in e.g. float64 precision being used to represent integers, which wastes space. You might achieve substantial memory reduction by optimizing the data types.\\nUsing Dask, an open-source python project which parallelizes Numpy and Pandas.\\n(see, e.g. https://www.vantage-ai.com/en/blog/4-strategies-how-to-deal-with-large-datasets-in-pandas)\\nBy Rileen Sinha', 'section': 'Miscellaneous', 'question': 'How can I work with very large datasets, e.g. the New York Yellow Taxi dataset, with over a million rows?', 'course': 'machine-learning-zoomcamp', 'id': 'd6f0c6ea'}, '9f261648': {'text': 'Technically, yes. Advisable? Not really. Reasons:\\nSome homework(s) asks for specific python library versions.\\nAnswers may not match in MCQ options if using different languages other than Python 3.10 (the recommended version for 2023 cohort)\\nAnd as for midterms/capstones, your peer-reviewers may not know these other languages. Do you want to be penalized for others not knowing these other languages?\\nYou can create a separate repo using course’s lessons but written in other languages for your own learnings, but not advisable for submissions.\\ntx[source]', 'section': 'Miscellaneous', 'question': 'Can I do the course in other languages, like R or Scala?', 'course': 'machine-learning-zoomcamp', 'id': '9f261648'}, 'aa7ff0f7': {'text': 'Yes, it’s allowed (as per Alexey).\\nAdded By Rileen Sinha', 'section': 'Miscellaneous', 'question': 'Is use of libraries like fast.ai or huggingface allowed in the capstone and competition, or are they considered to be \"too much help\"?', 'course': 'machine-learning-zoomcamp', 'id': 'aa7ff0f7'}, '387bdc5f': {'text': 'The TF and TF Serving versions have to match (as per solution from the slack channel)\\nAdded by Chiedu Elue', 'section': 'Miscellaneous', 'question': 'Flask image was built and tested successfully, but tensorflow serving image was built and unable to test successfully. What could be the problem?', 'course': 'machine-learning-zoomcamp', 'id': '387bdc5f'}, 'c6a22665': {'text': 'I’ve seen LinkedIn users list DataTalksClub as Experience with titles as:\\nMachine Learning Fellow\\nMachine Learning Student\\nMachine Learning Participant\\nMachine Learning Trainee\\nPlease note it is best advised that you do not list the experience as an official “job” or “internship” experience since DataTalksClub did not hire you, nor financially compensate you.\\nOther ways you can incorporate the experience in the following sections:\\nOrganizations\\nProjects\\nSkills\\nFeatured\\nOriginal posts\\nCertifications\\nCourses\\nBy Annaliese Bronz\\nInteresting question, I put the link of my project into my CV as showcase and make posts to show my progress.\\nBy Ani Mkrtumyan', 'section': 'Miscellaneous', 'question': 'Any advice for adding the Machine Learning Zoomcamp experience to your LinkedIn profile?', 'course': 'machine-learning-zoomcamp', 'id': 'c6a22665'}, '0560e827': {'text': 'MLOps Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course, and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\n[Problem description]\\n[Solution description]\\n(optional) Added by Name', 'section': '+-General course questions', 'question': 'Format for questions: [Problem title]', 'course': 'mlops-zoomcamp', 'id': '0560e827'}, '59812e77': {'text': 'Approximately 3 months. For each module, about 1 week with possible deadline extensions (in total 6~9 weeks), 2 weeks for working on the capstone project and 1 week for peer review.', 'section': '+-General course questions', 'question': 'What is the expected duration of this course or that for each module?', 'course': 'mlops-zoomcamp', 'id': '59812e77'}, 'dce0bb09': {'text': 'The difference is the Orchestration and Monitoring modules. Those videos will be re-recorded. The rest should mostly be the same.\\nAlso all of the homeworks will be changed for the 2023 cohort.', 'section': '+-General course questions', 'question': 'What’s the difference between the 2023 and 2022 course?', 'course': 'mlops-zoomcamp', 'id': 'dce0bb09'}, '4920d4e9': {'text': 'Yes, it will start in May 2024', 'section': '+-General course questions', 'question': 'Will there be a 2024 Cohort? When will the 2024 cohort start?', 'course': 'mlops-zoomcamp', 'id': '4920d4e9'}, '0f1d2765': {'text': 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.', 'section': '+-General course questions', 'question': 'What if my answer is not exactly the same as the choices presented?', 'course': 'mlops-zoomcamp', 'id': '0f1d2765'}, '4eef2f81': {'text': 'Please pick up a problem you want to solve yourself. Potential datasets can be found on either Kaggle, Hugging Face, Google, AWS, or the UCI Machine Learning Datasets Repository.', 'section': '+-General course questions', 'question': 'Are we free to choose our own topics for the final project?', 'course': 'mlops-zoomcamp', 'id': '4eef2f81'}, '7f93c032': {'text': 'In order to obtain the certificate, completion of the final capstone project is mandatory. The completion of weekly homework assignments is optional, but they can contribute to your overall progress and ranking on the top 100 leaderboard.', 'section': '+-General course questions', 'question': 'Can I still graduate when I didn’t complete homework for week x?', 'course': 'mlops-zoomcamp', 'id': '7f93c032'}, 'ee6f7c89': {'text': 'You can get a few cloud points by using kubernetes even if you deploy it only locally. Or you can use local stack too to mimic AWS\\nAdded by Ming Jun, Asked by Ben Pacheco, Answered by Alexey Grigorev', 'section': 'Module 1: Introduction', 'question': 'For the final project, is it required to be put on the cloud?', 'course': 'mlops-zoomcamp', 'id': 'ee6f7c89'}, 'b63b12e0': {'text': 'For those who are not using VSCode (or other similar IDE), you can automate port-forwarding for Jupyter Notebook by adding the following line of code to your\\n~/.ssh/config file (under the mlops-zoomcamp host):\\nLocalForward 127.0.0.1:8899 127.0.0.1:8899\\nThen you can launch Jupyter Notebook using the following command: jupyter notebook --port=8899 --no-browser and copy paste the notebook URL into your browser.\\nAdded by Vishal', 'section': 'Module 1: Introduction', 'question': 'Port-forwarding without Visual Studio', 'course': 'mlops-zoomcamp', 'id': 'b63b12e0'}, '892c22c1': {'text': 'You can install the Jupyter extension to open notebooks in VSCode.\\nAdded by Khubaib', 'section': 'Module 1: Introduction', 'question': 'Opening Jupyter in VSCode', 'course': 'mlops-zoomcamp', 'id': '892c22c1'}, '13d38e8d': {'text': 'In case one would like to set a github repository (e.g. for Homeworks), one can follow 2 great tutorials that helped a lot\\nSetting up github on AWS instance - this\\nSetting up keys on AWS instance - this\\nThen, one should be able to push to its repo\\nAdded by Daniel Hen (daniel8hen@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Configuring Github to work from the remote VM', 'course': 'mlops-zoomcamp', 'id': '13d38e8d'}, '7d64e9e0': {'text': \"Faced issue while setting up JUPYTER NOTEBOOK on AWS. I was unable to access it from my desktop. (I am not using visual studio and hence faced problem)\\nRun\\njupyter notebook --generate-config\\nEdit file /home/ubuntu/.jupyter/jupyter_notebook_config.py to add following line:\\nNotebookApp.ip = '*'\\nAdded by Atul Gupta (samatul@gmail.com)\", 'section': 'Module 1: Introduction', 'question': 'Opening Jupyter in AWS', 'course': 'mlops-zoomcamp', 'id': '7d64e9e0'}, '645f0a55': {'text': 'If you wish to use WSL on your windows machine, here are the setup instructions:\\nCommand: Sudo apt install wget\\nGet Anaconda download address here. wget <download address>\\nTurn on Docker Desktop WFree Download | AnacondaSL2\\nCommand: git clone <github repository address>\\nVSCODE on WSL\\nJupyter: pip3 install jupyter\\nAdded by Gregory Morris (gwm1980@gmail.com)\\nAll in all softwares at one shop:\\nYou can use anaconda which has all built in services like pycharm, jupyter\\nAdded by Khaja Zaffer (khajazaffer@aln.iseg.ulisboa.pt)\\nFor windows “wsl --install” in Powershell\\nAdded by Vadim Surin (vdmsurin@gmai.com)', 'section': 'Module 1: Introduction', 'question': 'WSL instructions', 'course': 'mlops-zoomcamp', 'id': '645f0a55'}, '7297b7fc': {'text': 'If you create a folder data and download datasets or raw files in your local repository. Then to push all your code to remote repository without this files or folder please use gitignore file. The simple way to create it do the following steps\\n1. Create empty .txt file (using text editor or command line)\\n2. Safe as .gitignore (. must use the dot symbol)\\n3. Add rules\\n *.parquet - to ignore all parquet files\\ndata/ - to ignore all files in folder data\\n\\nFor more pattern read GIT documentation\\nhttps://git-scm.com/docs/gitignore\\nAdded by Olga Rudakova (olgakurgan@gmail.com)', 'section': 'Module 1: Introduction', 'question': '.gitignore how-to', 'course': 'mlops-zoomcamp', 'id': '7297b7fc'}, '68154f64': {'text': \"Make sure when you stop an EC2 instance that it actually stops (there's a meme about it somewhere). There are green circles (running), orange (stopping), and red (stopped). Always refresh the page to make sure you see the red circle and status of stopped.\\nEven when an EC2 instance is stopped, there WILL be other charges that are incurred (e.g. if you uploaded data to the EC2 instance, this data has to be stored somewhere, usually an EBS volume and this storage incurs a cost).\\nYou can set up billing alerts. (I've never done this, so no advice on how to do this).\\n(Question by: Akshit Miglani (akshit.miglani09@gmail.com) and Answer by Anna Vasylytsya)\", 'section': 'Module 1: Introduction', 'question': 'AWS suggestions', 'course': 'mlops-zoomcamp', 'id': '68154f64'}, 'dc7b6f51': {'text': 'You can get invitation code by coursera and use it in account to verify it it has different characteristics.\\nI really love it\\nhttps://www.youtube.com/watch?v=h_GdX6KtXjo', 'section': 'Module 1: Introduction', 'question': 'IBM Cloud an alternative for AWS', 'course': 'mlops-zoomcamp', 'id': 'dc7b6f51'}, 'b25c6ca3': {'text': \"I am worried about the cost of keeping an AWS instance running during the course.\\nWith the instance specified during working environment setup, if you remember to Stop Instance once you finished your work for the day.  Using that strategy, in a day with about 5 hours of work you will pay around $0.40 USD which will account for $12 USD per month, which seems to be an affordable amount.\\nYou must remember that you would have a different IP public address every time you Restart your instance, and you would need to edit your ssh Config file.  It's worth the time though.\\nAdditionally, AWS enables you to set up an automatic email alert if a predefined budget is exceeded.\\nHere is a tutorial to set this up.\\nAlso, you can estimate the cost yourself, using AWS pricing calculator (to use it you don’t even need to be logged in).\\nAt the time of writing (20.05.2023) t3a.xlarge instance with 2 hr/day usage (which translates to 10 hr/week that should be enough to complete the course) and 30GB EBS monthly cost is 10.14 USD\\nHere’s a link to the estimate\\nAdded by Alex Litvinov (aaalex.lit@gmail.com)\", 'section': 'Module 1: Introduction', 'question': 'AWS costs', 'course': 'mlops-zoomcamp', 'id': 'b25c6ca3'}, '9f69ca26': {'text': 'For many parts - yes. Some things like kinesis are not in AWS free tier, but you can do it locally with localstack.', 'section': 'Module 1: Introduction', 'question': 'Is the AWS free tier enough for doing this course?', 'course': 'mlops-zoomcamp', 'id': '9f69ca26'}, '0f1ddc9e': {'text': 'When I click an open IP-address in an AWS EC2 instance I get an error: “This site can’t be reached”. What should I do?\\nThis ip-address is not required to be open in a browser. It is needed to connect to the running EC2 instance via terminal from your local machine or via terminal from a remote server with such command, for example if:\\nip-address is 11.111.11.111\\ndownloaded key name is razer.pem (the key should be moved to a hidden folder .ssh)\\nyour user name is user_name\\nssh -i /Users/user_name/.ssh/razer.pem ubuntu@11.111.11.111', 'section': 'Module 1: Introduction', 'question': 'AWS EC2: this site can’t be reached', 'course': 'mlops-zoomcamp', 'id': '0f1ddc9e'}, '01f61154': {'text': 'After this command `ssh -i ~/.ssh/razer.pem ubuntu@XX.XX.XX.XX` I got this error: \"unprotected private key file\". This page (https://99robots.com/how-to-fix-permission-error-ssh-amazon-ec2-instance/) explains how to fix this error. Basically you need to change the file permissions of the key file with this command: chmod 400 ~/.ssh/razer.pem', 'section': 'Module 1: Introduction', 'question': 'Unprotected private key file!', 'course': 'mlops-zoomcamp', 'id': '01f61154'}, 'd43c32ba': {'text': 'My SSH connection to AWS cannot last more than a few minutes, whether via terminal or VS code.\\nMy config:\\n# Copy Configuration in local nano editor, then Save it!\\nHost mlops-zoomcamp                                         # ssh connection calling name\\nUser ubuntu                                             # username AWS EC2\\nHostName <instance-public-IPv4-addr>                    # Public IP, it changes when Source EC2 is turned off.\\nIdentityFile ~/.ssh/name-of-your-private-key-file.pem   # Private SSH key file path\\nLocalForward 8888 localhost:8888                        # Connecting to a service on an internal network from the outside, static forward or set port user forward via on vscode\\nStrictHostKeyChecking no\\nAdded by Muhammed Çelik\\nThe disconnection will occur whether I SSH via WSL2 or via VS Code, and usually occurs after I run some code, i.e. “import mlflow”, so not particularly intense computation.\\nI cannot reconnect to the instance without stopping and restarting with a new IPv4 address.\\nI’ve gone through steps listed on this page: https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-resolve-ssh-connection-errors/\\nInbound rule should allow all incoming IPs for SSH.\\nWhat I expect to happen:\\nSSH connection should remain while I’m actively using the instance, and if it does disconnect, I should be able to reconnect back.\\nSolution: sometimes the hang ups are caused by the instance running out of memory. In one instance, using EC2 feature to view screenshot of the instance as a means to troubleshoot, it was the OS out-of-memory feature which killed off some critical processes. In this case, if we can’t use a higher compute VM with more RAM, try adding a swap file, which uses the disk as RAM substitute and prevents the OOM error. Follow Ubuntu’s documentation here: https://help.ubuntu.com/community/SwapFaq.\\nAlternatively follow AWS’s own doc, which mirrors Ubuntu’s: https://aws.amazon.com/premiumsupport/knowledge-center/ec2-memory-swap-file/', 'section': 'Module 1: Introduction', 'question': 'AWS EC2 instance constantly drops SSH connection', 'course': 'mlops-zoomcamp', 'id': 'd43c32ba'}, 'a044d267': {'text': 'Everytime I restart my EC2 instance I keep getting different IP and need to update the config file manually.\\n\\nSolution: You can create a script like this to automatically update the IP address of your EC2 instance.https://github.com/dimzachar/mlops-zoomcamp/blob/master/notes/Week_1/update_ssh_config.md', 'section': 'Module 1: Introduction', 'question': 'AWS EC2 IP Update', 'course': 'mlops-zoomcamp', 'id': 'a044d267'}, 'abf8ccdc': {'text': 'Make sure to use an instance with enough compute capabilities such as a t2.xlarge. You can check the monitoring tab in the EC2 dashboard to monitor your instance.', 'section': 'Module 1: Introduction', 'question': 'VS Code crashes when connecting to Jupyter', 'course': 'mlops-zoomcamp', 'id': 'abf8ccdc'}, '26918af3': {'text': 'Error “ValueError: X has 526 features, but LinearRegression is expecting 525 features as input.” when running your Linear Regression Model on the validation data set:\\nSolution: The DictVectorizer creates an initial mapping for the features (columns). When calling the DictVecorizer again for the validation dataset transform should be used as it will ignore features that it did not see when fit_transform was last called. E.g.\\nX_train = dv.fit_transform(train_dict)\\nX_test = dv.transform(test_dict)', 'section': 'Module 1: Introduction', 'question': 'X has 526 features, but expecting 525 features', 'course': 'mlops-zoomcamp', 'id': '26918af3'}, 'a5234ac0': {'text': 'If some dependencies are missing\\nInstall following packages\\npandas\\nmatplotlib\\nscikit-learn\\nfastparquet\\npyarrow\\nseaborn\\npip install -r requirements.txt\\nI have seen this error when using pandas.read_parquet(), the solution is to install pyarrow or fastparquet by doing !pip install pyarrow in the notebook\\nNOTE: if you’re using Conda instead of pip, install fastparquet rather than pyarrow, as it is much easier to install and it’s functionally identical to pyarrow for our needs.', 'section': 'Module 1: Introduction', 'question': 'Missing dependencies', 'course': 'mlops-zoomcamp', 'id': 'a5234ac0'}, 'af22c52a': {'text': 'The evaluation RMSE I get doesn’t figure within the options!\\nIf you’re evaluating the model on the entire February data, try to filter outliers using the same technique you used on the train data (0≤duration≤60) and you’ll get a RMSE which is (approximately) in the options. Also don’t forget to convert the columns data types to str before using the DictVectorizer.\\nAnother option: Along with filtering outliers, additionally filter on null values by replacing them with -1.  You will get a RMSE which is (almost same as) in the options. Use ‘.round(2)’ method to round it to 2 decimal points.\\nWarning deprecation\\nThe python interpreter warning of modules that have been deprecated  and will be removed in future releases as well as making suggestion how to go about your code.\\nFor example\\nC:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\seaborn\\\\distributions.py:2619:\\nFutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\\nwarnings.warn(msg, FutureWarning)\\nTo suppress the warnings, you can include this code at the beginning of your notebook\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")', 'section': 'Module 1: Introduction', 'question': 'No RMSE value in the options', 'course': 'mlops-zoomcamp', 'id': 'af22c52a'}, '2aaac94c': {'text': 'sns.distplot(df_train[\"duration\"])\\nCan be replaced with\\nsns.histplot(\\ndf_train[\"duration\"] , kde=True,\\nstat=\"density\", kde_kws=dict(cut=3), bins=50,\\nalpha=.4, edgecolor=(1, 1, 1, 0.4),\\n)\\nTo get almost identical result', 'section': 'Module 1: Introduction', 'question': 'How to replace distplot with histplot', 'course': 'mlops-zoomcamp', 'id': '2aaac94c'}, '9d15c9e9': {'text': 'You need to replace the capital letter “L” with a small one “l”', 'section': 'Module 1: Introduction', 'question': \"KeyError: 'PULocationID'  or  'DOLocationID'\", 'course': 'mlops-zoomcamp', 'id': '9d15c9e9'}, '79b88d0b': {'text': 'I have faced a problem while reading the large parquet file. I tried some workarounds but they were NOT successful with Jupyter.\\nThe error message is:\\nIndexError: index 311297 is out of bounds for axis 0 with size 131743\\nI solved it by performing the homework directly as a python script.\\nAdded by Ibraheem Taha (ibraheemtaha91@gmail.com)\\nYou can try using the Pyspark library\\nAnswered by kamaldeen (kamaldeen32@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Reading large parquet files', 'course': 'mlops-zoomcamp', 'id': '79b88d0b'}, '45485322': {'text': 'First remove the outliers (trips with unusual duration) before plotting\\nAdded by Ibraheem Taha (ibraheemtaha91@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Distplot takes too long', 'course': 'mlops-zoomcamp', 'id': '45485322'}, 'd5eab395': {'text': 'Problem: RMSE on test set was too high when hot encoding the validation set with a previously fitted OneHotEncoder(handle_unknown=’ignore’) on the training set, while DictVectorizer would yield the correct RMSE.\\nIn principle both transformers should behave identically when treating categorical features (at least in this week’s homework where we don’t have sequences of strings in each row):\\nFeatures are put into binary columns encoding their presence (1) or absence (0)\\nUnknown categories are imputed as zeroes in the hot-encoded matrix', 'section': 'Module 1: Introduction', 'question': 'RMSE on test set too high', 'course': 'mlops-zoomcamp', 'id': 'd5eab395'}, '282957fb': {'text': 'A: Alexey’s answer https://www.youtube.com/watch?v=8uJ36ZZr_Is&t=13s\\nIn summary,\\npd.get_dummies or OHE can come up with result in different orders and handle missing data differently, so train and val set would have different columns during train and validation\\nDictVectorizer would ignore missing (in train) and new (in val) datasets\\nOther sources:\\nhttps://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor\\nhttps://scikit-learn.org/stable/modules/feature_extraction.html\\nhttps://innovation.alteryx.com/encode-smarter/\\n~ ellacharmed', 'section': 'Module 1: Introduction', 'question': 'Q: Using of OneHotEncoder instead of DictVectorizer', 'course': 'mlops-zoomcamp', 'id': '282957fb'}, '39ad14fd': {'text': \"Why didn't get_dummies in pandas library or OneHotEncoder in scikit-learn library be used for one-hot encoding? I know OneHotEncoder is the most common and useful. One-hot coding can also be done using the eye or identity components of the NumPy library.\\nM.Sari\\nOneHotEncoder has the option to output a row column tuple matrix. DictVectorizer is a one step method to encode and support row column tuple matrix output.\\nHarinder(sudwalh@gmail.com)\", 'section': 'Module 1: Introduction', 'question': 'Q: Why did we not use OneHotEncoder(sklearn) instead of DictVectorizer ?', 'course': 'mlops-zoomcamp', 'id': '39ad14fd'}, 'e34df2a5': {'text': 'How to check that we removed the outliers?\\nUse the pandas function describe() which can provide a report of the data distribution along with the statistics to describe the data. For example, after clipping the outliers using boolean expression, the min and max can be verified using\\ndf[‘duration’].describe()', 'section': 'Module 1: Introduction', 'question': 'Clipping outliers', 'course': 'mlops-zoomcamp', 'id': 'e34df2a5'}, 'c91b6b57': {'text': 'pd.get_dummies and DictVectorizer both create a one-hot encoding on string values. Therefore you need to convert the values in PUlocationID and DOlocationID to string.\\nIf you convert the values in PUlocationID and DOlocationID from numeric to string, the NaN values get converted to the string \"nan\".  With DictVectorizer the RMSE is the same whether you use \"nan\" or \"-1\" as string representation for the NaN values. Therefore the representation doesn\\'t have to be \"-1\" specifically, it could also be some other string.', 'section': 'Module 1: Introduction', 'question': 'Replacing NaNs for pickup location and drop off location with -1 for One-Hot Encoding', 'course': 'mlops-zoomcamp', 'id': 'c91b6b57'}, '4aa8eafc': {'text': 'Problem: My LinearRegression RSME is very close to the answer but not exactly the same. Is this normal?\\nAnswer: No, LinearRegression is an deterministic model, it should always output the same results when given the same inputs.\\nAnswer:\\nCheck if you have treated the outlier properly for both train and validation sets\\nCheck if the one hot encoding has been done properly by looking at the shape of one hot encoded feature matrix. If it shows 2 features, there is wrong with one hot encoding. Hint: the drop off and pick up codes need to be converted to proper data format and then DictVectorizer is fitted.\\nHarshit Lamba (hlamba19@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Slightly different RSME', 'course': 'mlops-zoomcamp', 'id': '4aa8eafc'}, 'a9daaab0': {'text': 'Problem: I’m facing an extremely low RMSE score (eg: 4.3451e-6) - what shall I do?\\nAnswer: Recheck your code to see if your model is learning the target prior to making the prediction. If the target variable is passed in as a parameter while fitting the model, chances are the model would score extremely low. However, that’s not what you would want and would much like to have your model predict that. A good way to check that is to make sure your X_train doesn’t contain any part of your y_train. The same stands for validation too.\\nSnehangsu De (desnehangsu@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Extremely low RSME', 'course': 'mlops-zoomcamp', 'id': 'a9daaab0'}, '931f9626': {'text': 'Problem: how to enable auto completion in jupyter notebook? Tab doesn’t work for me\\nSolution: !pip install --upgrade jedi==0.17.2\\nChristopher R.J.(romanjaimesc@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Enabling Auto-completion in jupyter notebook', 'course': 'mlops-zoomcamp', 'id': '931f9626'}, '782e1723': {'text': \"Problem: While following the steps in the videos you may have problems trying to download with wget the files. Usually it is a 403 error type (Forbidden access).\\nSolution: The links point to files on cloudfront.net, something like this:\\nhttps://d37ci6vzurychx.cloudfront.net/tOSError: Could not open parquet input source '<Buffer>': Invalid: Parquet OSError: Could not open parquet input source '<Buffer>': Invalid: Parquet rip+data/green_tripdata_2021-01.parquet\\nI’m not download the dataset directly, i use dataset URL and run this in the file.\\nUpdate(27-May-2023): Vikram\\nI am able to download the data from the below link. This is from the official  NYC trip record page (https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). Copy link from page directly as the below url might get changed if the NYC decides to move away from this. Go to the page , right click and use copy link.\\nwget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet\\n(Asif)\\nCopy the link address and replace the cloudfront.net part with s3.amazonaws.com/nyc-tlc/, so it looks like this:\\nhttps://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\\nMario Tormo (mario@tormo-romero.eu)\\nOSError: Could not open parquet input source '<Buffer>': Invalid: Parquet\", 'section': 'Module 1: Introduction', 'question': 'Downloading the data from the NY Taxis datasets gives error : 403 Forbidden', 'course': 'mlops-zoomcamp', 'id': '782e1723'}, '4e08c86a': {'text': 'Problem: PyCharm (remote) doesn’t see conda execution path. So, I cannot use conda env (which is located on a remote server).\\nSolution: In remote server in command line write “conda activate envname”, after write “which python” - it gives you python execution path. After you can use this path when you will add new interpreter in PyCharm: add local interpreter -> system interpreter -> and put the path with python.\\nSalimov Ilnaz (salimovilnaz777@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Using PyCharm & Conda env in remote development', 'course': 'mlops-zoomcamp', 'id': '4e08c86a'}, '34bcad27': {'text': 'Problem: The output of DictVectorizer was taking up too much memory. So much so, that I couldn’t even fit the linear regression model before running out of memory on my 16 GB machine.\\nSolution: In the example for DictVectorizer in the scikit-learn website, they set the parameter “sparse” as False. Although this helps with viewing the results, this results in a lot of memory usage. The solution is to either use “sparse=True” instead, or leave it at the default which is also True.\\nAhmed Fahim (afahim03@yahoo.com)', 'section': 'Module 1: Introduction', 'question': 'Running out of memory', 'course': 'mlops-zoomcamp', 'id': '34bcad27'}, '96144e66': {'text': 'Problem: For me, Installing anaconda didn’t modify the .bashrc profile. That means Anaconda env was not activated even after exiting and relaunching the unix shell.\\nSolution:\\nFor bash : Initiate conda again, which will add entries for anaconda in .bashrc file.\\n$ cd YOUR_PATH_ANACONDA/bin $ ./conda init bash\\nThat will automatically edit your .bashrc.\\nReload:\\n$ source ~/.bashrc\\nAhamed Irshad (daisyfuentesahamed@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Activating Anaconda env in .bashrc', 'course': 'mlops-zoomcamp', 'id': '96144e66'}, '840f739d': {'text': 'While working through the HW1, you will realize that the training and the validation data set feature sizes are different. I was trying to figure out why and went down the entire rabbit hole only to see that I wasn’t doing ```transform``` on the premade dictionary vectorizer instead of ```fit_transform```. You already have the dictionary vectorizer made so no need to execute the fit pipeline on the model.\\nSam Lim(changhyeonlim@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'The feature size is different for training set and validation set', 'course': 'mlops-zoomcamp', 'id': '840f739d'}, 'bf006ff9': {'text': 'I found a good guide how to get acces to your machine again when you removed your public key.\\nUsing the following link you can go to Session Manager and log in to your instance and create public key again. https://repost.aws/knowledge-center/ec2-linux-fix-permission-denied-errors\\nThe main problem for me here was to get my old public key, so for doing this you should run the following command: ssh-keygen -y -f /path_to_key_pair/my-key-pair.pem\\nFor more information: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/describe-keys.html#retrieving-the-public-key\\nHanna Zhukavets (a.zhukovec1901@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Permission denied (publickey) Error (when you remove your public key on the AWS machine)', 'course': 'mlops-zoomcamp', 'id': 'bf006ff9'}, 'f178d4a0': {'text': 'Problem: The February dataset has been used as a validation/test dataset and been stripped of the outliers in a similar manner to the train dataset (taking only the rows for the duration between 1 and 60, inclusive). The RMSE obtained afterward is in the thousands.\\nAnswer: The sparsematrix result from DictVectorizer shouldn’t be turned into an ndarray. After removing that part of the code, I ended up receiving a correct result .\\nTahina Mahatoky (tahinadanny@gmail.com)', 'section': 'Module 1: Introduction', 'question': 'Overfitting: Absurdly high RMSE on the validation dataset', 'course': 'mlops-zoomcamp', 'id': 'f178d4a0'}, 'b80401a2': {'text': 'more specific error line:\\nfrom sklearn.feature_extraction import DictVectorizer\\nI had this issue and to solve it I did\\n!pip install scikit-learn\\nJoel Auccapuclla (auccapuclla 2013@gmail.com)', 'section': 'Module 2: Experiment tracking', 'question': 'Can’t import sklearn', 'course': 'mlops-zoomcamp', 'id': 'b80401a2'}, '88002d35': {'text': 'Problem: Localhost:5000 Unavailable // Access to Localhost Denied // You don’t have authorization to view this page (127.0.0.1:5000)\\n\\nSolution: If you are on an chrome browser you need to head to `chrome://net-internals/#sockets` and press “Flush Socket Pools”', 'section': 'Module 2: Experiment tracking', 'question': 'Access Denied at Localhost:5000 - Authorization Issue', 'course': 'mlops-zoomcamp', 'id': '88002d35'}, 'fe61aa5b': {'text': \"You have something running on the 5000 port. You need to stop it.\\nAnswer: On terminal in mac .\\nRun ps -A | grep gunicorn\\nLook for the number process id which is the 1st number after running the command\\nkill 13580\\nwhere 13580  represents the process number.\\nSource\\nwarrie.warrieus@gmail.com\\nOr by executing the following command it will kill all the processes using port 5000:\\n>> sudo fuser -k 5000/tcp\\nAnswered by Vaibhav Khandelwal\\nJust execute in the command below in he command line to kill the running port\\n->> kill -9 $(ps -A | grep python | awk '{print $1}')\\nAnswered by kamaldeen (kamaldeen32@gmail.com)\\nChange to different port (5001 in this case)\\n>> mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001\\nAnswered by krishna (nellaikrishna@gmail.com)\", 'section': 'Module 2: Experiment tracking', 'question': \"Connection in use: ('127.0.0.1', 5000)\", 'course': 'mlops-zoomcamp', 'id': 'fe61aa5b'}, 'b9adeb39': {'text': 'Running python register_model.py results in the following error:\\nValueError: could not convert string to float: \\'0 int\\\\n1   float\\\\n2     hyperopt_param\\\\n3       Literal{n_estimators}\\\\n4       quniform\\\\n5         Literal{10}\\\\n6         Literal{50}\\\\n7         Literal{1}\\'\\nFull Traceback:\\nTraceback (most recent call last):\\nFile \"/Users/name/Desktop/Programming/DataTalksClub/MLOps-Zoomcamp/2. Experiment tracking and model management/homework/scripts/register_model.py\", line 101, in <module>\\nrun(args.data_path, args.top_n)\\nFile \"/Users/name/Desktop/Programming/DataTalksClub/MLOps-Zoomcamp/2. Experiment tracking and model management/homework/scripts/register_model.py\", line 67, in run\\ntrain_and_log_model(data_path=data_path, params=run.data.params)\\nFile \"/Users/name/Desktop/Programming/DataTalksClub/MLOps-Zoomcamp/2. Experiment tracking and model management/homework/scripts/register_model.py\", line 41, in train_and_log_model\\nparams = space_eval(SPACE, params)\\nFile \"/Users/name/miniconda3/envs/mlops-zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py\", line 618, in space_eval\\nrval = pyll.rec_eval(space, memo=memo)\\nFile \"/Users/name/miniconda3/envs/mlops-zoomcamp/lib/python3.9/site-packages/hyperopt/pyll/base.py\", line 902, in rec_eval\\nrval = scope._impls[node.name](*args, **kwargs)\\nValueError: could not convert string to float: \\'0 int\\\\n1   float\\\\n2     hyperopt_param\\\\n3       Literal{n_estimators}\\\\n4       quniform\\\\n5         Literal{10}\\\\n6         Literal{50}\\\\n7         Literal{1}\\'\\nSolution: There are two plausible errors to this. Both are in the hpo.py file where the hyper-parameter tuning is run. The objective function should look like this.\\n\\n   def objective(params):\\n# It\\'s important to set the \"with\" statement and the \"log_params\" function here\\n# in order to properly log all the runs and parameters.\\nwith mlflow.start_run():\\n# Log the parameters\\nmlflow.log_params(params)\\nrf = RandomForestRegressor(**params)\\nrf.fit(X_train, y_train)\\ny_pred = rf.predict(X_valid)\\n# Calculate and log rmse\\nrmse = mean_squared_error(y_valid, y_pred, squared=False)\\nmlflow.log_metric(\\'rmse\\', rmse)\\nIf you add the with statement before this function, and just after the following line\\nX_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\\nand you log the parameters just after the search_space dictionary is defined, like this\\nsearch_space = {....}\\n# Log the parameters\\nmlflow.log_params(search_space)\\nThen there is a risk that the parameters will be logged in group. As a result, the\\nparams = space_eval(SPACE, params)\\nregister_model.py file will receive the parameters in group, while in fact it expects to receive them one by one. Thus, make sure that the objective function looks as above.\\nAdded by Jakob Salomonsson', 'section': 'Module 2: Experiment tracking', 'question': 'Could not convert string to float - ValueError', 'course': 'mlops-zoomcamp', 'id': 'b9adeb39'}, 'ebc13686': {'text': 'Make sure you launch the mlflow UI from the same directory as thec that is running the experiments (same directory that has the mlflow directory and the database that stores the experiments).\\nOr navigate to the correct directory when specifying the tracking_uri.\\nFor example:\\nIf the mlflow.db is in a subdirectory called database, the tracking uri would be ‘sqllite:///database/mlflow.db’\\nIf the mlflow.db is a directory above your current directory: the tracking uri would be ‘sqlite:///../mlflow.db’\\nAnswered by Anna Vasylytsya\\nAnother alternative is to use an absolute path to mlflow.db rather than relative path\\nAnd yet another alternative is to launch the UI from the same notebook by executing the following code cell\\nimport subprocess\\nMLFLOW_TRACKING_URI = \"sqlite:///data/mlflow.db\"\\nsubprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI])\\nAnd then using the same MLFLOW_TRACKING_URI when initializing mlflow or the client\\nclient = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)', 'section': 'Module 2: Experiment tracking', 'question': 'Experiment not visible in MLflow UI', 'course': 'mlops-zoomcamp', 'id': 'ebc13686'}, '939f9c33': {'text': \"Problem:\\nGetting\\nERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE\\nduring MLFlow's installation process, particularly while installing the Numpy package using pip\\nWhen I installed mlflow using ‘pip install mlflow’ on 27th May 2022, I got the following error while numpy was getting installed through mlflow:\\n\\nCollecting numpy\\nDownloading numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\\n|██████████████              \\t| 6.3 MB 107 kB/s eta 0:01:19\\nERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE.\\nIf you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\\nnumpy from https://files.pythonhosted.org/packages/b5/50/d7978137464251c393df28fe0592fbb968110f752d66f60c7a53f7158076/numpy-1.22.4-cp310-cp310-win_amd64.whl#sha256=3e1ffa4748168e1cc8d3cde93f006fe92b5421396221a02f2274aab6ac83b077 (from mlflow):\\nExpected sha256 3e1ffa4748168e1cc8d3cde93f006fe92b5421396221a02f2274aab6ac83b077\\nGot    \\t15e691797dba353af05cf51233aefc4c654ea7ff194b3e7435e6eec321807e90\\nSolution:\\nThen when I install numpy separately (and not as part of mlflow), numpy gets installed (same version), and then when I do 'pip install mlflow', it also goes through.\\nPlease note that the above may not be consistently simulatable, but please be aware of this issue that could occur during pip install of mlflow.\\nAdded by Venkat Ramakrishnan\", 'section': 'Module 2: Experiment tracking', 'question': 'Hash Mismatch Error with Package Installation', 'course': 'mlops-zoomcamp', 'id': '939f9c33'}, 'b5c3e6af': {'text': 'After deleting an experiment from UI, the deleted experiment still persists in the database.\\nSolution: To delete this experiment permanently, follow these steps.\\nAssuming you are using sqlite database;\\nInstall ipython sql using the following command: pip install ipython-sql\\nIn your jupyter notebook, load the SQL magic scripts with this: %load_ext sql\\nLoad the database with this: %sql sqlite:///nameofdatabase.db\\nRun the following SQL script to delete the experiment permanently: check link', 'section': 'Module 2: Experiment tracking', 'question': 'How to Delete an Experiment Permanently from MLFlow UI', 'course': 'mlops-zoomcamp', 'id': 'b5c3e6af'}, '80554fc2': {'text': 'Problem: I cloned the public repo, made edits, committed and pushed them to my own repo. Now I want to get the recent commits from the public repo without overwriting my own changes to my own repo. Which command(s) should I use?\\nThis is what my config looks like (in case this might be useful):\\n[core]\\nrepositoryformatversion = 0\\nfilemode = true\\nbare = false\\nlogallrefupdates = true\\nignorecase = true\\nprecomposeunicode = true\\n[remote \"origin\"]\\nurl = git@github.com:my_username/mlops-zoomcamp.git\\nfetch = +refs/heads/*:refs/remotes/origin/*\\n[branch \"main\"]\\nremote = origin\\nmerge = refs/heads/main\\nSolution: You should fork DataClubsTak’s repo instead of cloning it. On GitHub, click “Fetch and Merge” under the menu “Fetch upstream” at the main page of your own', 'section': 'Module 2: Experiment tracking', 'question': 'How to Update Git Public Repo Without Overwriting Changes', 'course': 'mlops-zoomcamp', 'id': '80554fc2'}, '943df153': {'text': 'This is caused by ```mlflow.xgboost.autolog()``` when version 1.6.1 of xgboost\\nDowngrade to 1.6.0\\n```pip install xgboost==1.6.0``` or update requirements file with xgboost==1.6.0 instead of xgboost\\nAdded by Nakul Bajaj', 'section': 'Module 2: Experiment tracking', 'question': 'Image size of 460x93139 pixels is too large. It must be less than 2^16 in each direction.', 'course': 'mlops-zoomcamp', 'id': '943df153'}, 'b8d3c55e': {'text': 'Since the version 1.29 the list_experiments method was deprecated and then removed in the later version\\nYou should use search_experiments instead\\nAdded by Alex Litvinov', 'section': 'Module 2: Experiment tracking', 'question': \"MlflowClient object has no attribute 'list_experiments'\", 'course': 'mlops-zoomcamp', 'id': 'b8d3c55e'}, '67bf60c6': {'text': 'Make sure `mlflow.autolog()` ( or framework-specific autolog ) written BEFORE `with mlflow.start_run()` not after.\\nAlso make sure that all dependencies for the autologger are installed, including matplotlib. A warning about uninstalled dependencies will be raised.\\nMohammed Ayoub Chettouh', 'section': 'Module 2: Experiment tracking', 'question': 'MLflow Autolog not working', 'course': 'mlops-zoomcamp', 'id': '67bf60c6'}, '336f5e36': {'text': 'If you’re running MLflow on a remote VM, you need to forward the port too like we did in Module 1 for Jupyter notebook port 8888. Simply connect your server to VS Code, as we did, and add 5000 to the PORT like in the screenshot:\\nAdded by Sharon Ibejih\\nIf you are running MLflow locally and 127.0.0.1:5000 shows a blank page navigate to localhost:5000 instead.', 'section': 'Module 2: Experiment tracking', 'question': 'MLflow URL (http://127.0.0.1:5000), doesn’t open.', 'course': 'mlops-zoomcamp', 'id': '336f5e36'}, 'fd2b9972': {'text': 'Got the same warning message as Warrie Warrie when using “mlflow.xgboost.autolog()”\\nIt turned out that this was just a warning message and upon checking MLflow UI (making sure that no “tag” filters were included), the model was actually automatically tracked in the MLflow.\\nAdded by Bengsoon Chuah, Asked by Warrie Warrie, Answered by Anna Vasylytsya & Ivan Starovit', 'section': 'Module 2: Experiment tracking', 'question': 'MLflow.xgboost Autolog Model Signature Failure', 'course': 'mlops-zoomcamp', 'id': 'fd2b9972'}, '75cd9b7a': {'text': \"mlflow.exceptions.MlflowException: Cannot set a deleted experiment 'cross-sell' as the active experiment. You can restore the experiment, or permanently delete the  experiment to create a new one.\\nThere are many options to solve in this link: https://stackoverflow.com/questions/60088889/how-do-you-permanently-delete-an-experiment-in-mlflow\", 'section': 'Module 2: Experiment tracking', 'question': 'MlflowException: Unable to Set a Deleted Experiment', 'course': 'mlops-zoomcamp', 'id': '75cd9b7a'}, '51c99586': {'text': 'You do not have enough disk space to install the requirements. You can either increase the base EBS volume by following this link or add an external disk to your instance and configure conda installation to happen on the external disk.\\nAbinaya Mahendiran\\nOn GCP: I added another disk to my vm and followed this guide to mount the disk. Confirm the mount by running df -H (disk free) command in bash shell. I also deleted Anaconda and instead used miniconda. I downloaded miniconda in the additional disk that I mounted and when installing miniconda, enter the path to the extra disk instead of the default disk, this way conda is installed on the extra disk.\\nYang Cao', 'section': 'Module 2: Experiment tracking', 'question': 'No Space Left on Device - OSError[Errno 28]', 'course': 'mlops-zoomcamp', 'id': '51c99586'}, '089c8c18': {'text': 'I was using an old version of sklearn due to which I got the wrong number of parameters because in the latest version min_impurity_split for randomforrestRegressor was deprecated. Had to upgrade to the latest version to get the correct number of params.', 'section': 'Module 2: Experiment tracking', 'question': 'Parameters Mismatch in Homework Q3', 'course': 'mlops-zoomcamp', 'id': '089c8c18'}, 'f4b82056': {'text': \"Error: I installed all the libraries from the requirements.txt document in a new environment as follows:\\npip install -r requirementes.txt\\nThen when I run mlflow from my terminal like this:\\nmlflow\\nI get this error:\\nSOLUTION: You need to downgrade the version of 'protobuf' module to 3.20.x or lower. Initially, it was version=4.21, I installed protobuf==3.20\\npip install protobuf==3.20\\nAfter which I was able to run mlflow from my terminal.\\n-Submitted by Aashnna Soni\", 'section': 'Module 2: Experiment tracking', 'question': 'Protobuf error when installing MLflow', 'course': 'mlops-zoomcamp', 'id': 'f4b82056'}, 'dd2e7dc9': {'text': 'Please check your current directory while running the mlflow ui command. You need to run mlflow ui or mlflow server command in the right directory.', 'section': 'Module 2: Experiment tracking', 'question': 'Setting up Artifacts folders', 'course': 'mlops-zoomcamp', 'id': 'dd2e7dc9'}, '3fcbd80e': {'text': 'If you have problem with setting up MLflow for experiment tracking on GCP, you can check these two links:\\nhttps://kargarisaac.github.io/blog/mlops/data%20engineering/2022/06/15/MLFlow-on-GCP.html\\nhttps://kargarisaac.github.io/blog/mlops/2022/08/26/machine-learning-workflow-orchestration-zenml.html', 'section': 'Module 2: Experiment tracking', 'question': 'Setting up MLflow experiment tracker on GCP', 'course': 'mlops-zoomcamp', 'id': '3fcbd80e'}, '924fcf47': {'text': 'Solution: Downgrade setuptools (I downgraded 62.3.2 -> 49.1.0)', 'section': 'Module 2: Experiment tracking', 'question': 'Setuptools Replacing Distutils - MLflow Autolog Warning', 'course': 'mlops-zoomcamp', 'id': '924fcf47'}, '58240887': {'text': 'I can’t sort runs in MLFlow\\nMake sure you are in table view (not list view) in the MLflow UI.\\nAdded and Answered by Anna Vasylytsya', 'section': 'Module 2: Experiment tracking', 'question': 'Sorting runs in MLflow UI', 'course': 'mlops-zoomcamp', 'id': '58240887'}, '67d343f2': {'text': 'Problem: When I ran `$ mlflow ui` on a remote server and try to open it in my local browser I got an exception  and the page with mlflow ui wasn’t loaded.\\nSolution: You should `pip uninstall flask` on your remote server on conda env and after it install Flask `pip install Flask`. It is because the base conda env has ~flask<1.2, and when you clone it to your new work env, you are stuck with this old version.\\nAdded by Salimov Ilnaz', 'section': 'Module 2: Experiment tracking', 'question': \"TypeError: send_file() unexpected keyword 'max_age' during MLflow UI Launch\", 'course': 'mlops-zoomcamp', 'id': '67d343f2'}, '6de95c2a': {'text': 'Problem: After successfully installing mlflow using pip install mlflow on my Windows system, I am trying to run the mlflow ui command but it throws the following error:\\nFileNotFoundError: [WinError 2] The system cannot find the file specified\\nSolution: Add C:\\\\Users\\\\{User_Name}\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts to the PATH\\nAdded by Alex Litvinov', 'section': 'Module 2: Experiment tracking', 'question': 'mlflow ui on Windows FileNotFoundError: [WinError 2] The system cannot find the file specified', 'course': 'mlops-zoomcamp', 'id': '6de95c2a'}, '2ff28e5b': {'text': 'Running “python hpo.py --data_path=./your-path --max_evals=50” for the homework leads to the following error: TypeError: unsupported operand type(s) for -: \\'str\\' and \\'int\\'\\nFull Traceback:\\nFile \"~/repos/mlops/02-experiment-tracking/homework/hpo.py\", line 73, in <module>\\nrun(args.data_path, args.max_evals)\\nFile \"~/repos/mlops/02-experiment-tracking/homework/hpo.py\", line 47, in run\\nfmin(\\nFile \"~/Library/Caches/pypoetry/virtualenvs/mlflow-intro-SyTqwt0D-py3.9/lib/python3.9/site-packages/hyperopt/fmin.py\", line 540, in fmin\\nreturn trials.fmin(\\nFile \"~/Library/Caches/pypoetry/virtualenvs/mlflow-intro-SyTqwt0D-py3.9/lib/python3.9/site-packages/hyperopt/base.py\", line 671, in fmin\\nreturn fmin(\\nFile \"~/Library/Caches/pypoetry/virtualenvs/mlflow-intro-SyTqwt0D-py3.9/lib/python3.9/site-packages/hyperopt/fmin.py\", line 586, in fmin\\nrval.exhaust()\\nFile \"~/Library/Caches/pypoetry/virtualenvs/mlflow-intro-SyTqwt0D-py3.9/lib/python3.9/site-packages/hyperopt/fmin.py\", line 364, in exhaust\\nself.run(self.max_evals - n_done, block_until_done=self.asynchronous)\\nTypeError: unsupported operand type(s) for -: \\'str\\' and \\'int\\'\\nSolution:\\nThe --max_evals argument in hpo.py has no defined datatype and will therefore implicitly be treated as string. It should be an integer, so that the script can work correctly. Add type=int to the argument definition:\\nparser.add_argument(\\n\"--max_evals\",\\ntype=int,\\ndefault=50,\\nhelp=\"the number of parameter evaluations for the optimizer to explore.\"\\n)', 'section': 'Module 2: Experiment tracking', 'question': 'Unsupported Operand Type Error in hpo.py', 'course': 'mlops-zoomcamp', 'id': '2ff28e5b'}, '29c6bbf1': {'text': 'Getting the following warning when running mlflow.sklearn:\\n\\n2022/05/28 04:36:36 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow. […]\\nSolution: use 0.22.1 <= scikit-learn <= 1.1.0\\nReference: https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html', 'section': 'Module 2: Experiment tracking', 'question': 'Unsupported Scikit-Learn version', 'course': 'mlops-zoomcamp', 'id': '29c6bbf1'}, 'bd09df94': {'text': 'Problem: CLI commands (mlflow experiments list) do not return experiments\\nSolution description: need to set environment variable for the Tracking URI:\\n$ export MLFLOW_TRACKING_URI=http://127.0.0.1:5000\\nAdded and Answered by Dino Vitale', 'section': 'Module 2: Experiment tracking', 'question': 'Mlflow CLI does not return experiments', 'course': 'mlops-zoomcamp', 'id': 'bd09df94'}, 'af887c59': {'text': 'Problem: After starting the tracking server, when we try to use the mlflow cli commands as listed here, most of them can’t seem to find the experiments that have been run with the tracking server\\nSolution: We need to set the environment variable MLFLOW_TRACKING_URI to the URI of the sqlite database. This is something like “export MLFLOW_TRACKING_URI=sqlite:///{path to sqlite database}” . After this, we can view the experiments from the command line using commands like “mlflow experiments search”\\nEven after this commands like “mlflow gc” doesn’t seem to get the tracking uri, and they have to be passed explicitly as an argument every time the command is run.\\nAhmed Fahim (afahim03@yahoo.com)', 'section': 'Module 2: Experiment tracking', 'question': 'Viewing MLflow Experiments using MLflow CLI', 'course': 'mlops-zoomcamp', 'id': 'af887c59'}, 'ee7c59ea': {'text': 'All the experiment and other tracking information in mlflow are stored in sqllite database provided while initiating the mlflow ui command. This database can be inspected using Pycharm’s Database tab by using the SQLLite database type. Once the connection is created as below, the tables can be queried and inspected using regular SQL. The same applies for any SQL backed database such as postgres as well.\\nThis is very useful to understand the entity structure of the data being stored within mlflow and useful for any kind of systematic archiving of model tracking for longer periods.\\nAdded by Senthilkumar Gopal', 'section': 'Module 2: Experiment tracking', 'question': 'Viewing SQLlite Data Raw & Deleting Experiments Manually', 'course': 'mlops-zoomcamp', 'id': 'ee7c59ea'}, 'a2531c75': {'text': 'Solution : It is another way to start it for remote hosting a mlflow server. For example, if you are multiple colleagues working together on something you most likely would not run mlflow on one laptop but rather everyone would connect to the same server running mlflow\\nAnswer by Christoffer Added by Akshit Miglani (akshit.miglani09@gmail.com)', 'section': 'Module 2: Experiment tracking', 'question': 'What does launching the tracking server locally mean?', 'course': 'mlops-zoomcamp', 'id': 'a2531c75'}, 'bc4b2320': {'text': 'Problem: parameter was not recognized during the model registry\\nSolution: parameters should be added in previous to the model registry. The parameters can be added by mlflow.log_params(params) so that the dictionary can be directly appended to the data.run.params.\\nAdded and Answered by Sam Lim', 'section': 'Module 2: Experiment tracking', 'question': 'Parameter adding in case of max_depth not recognized', 'course': 'mlops-zoomcamp', 'id': 'bc4b2320'}, 'f69fb077': {'text': 'Problem: Max_depth is not recognize even when I add the mlflow.log_params\\nSolution: the mlflow.log_params(params) should be added to the hpo.py script, but if you run it it will append the new model to the previous run that doesn’t contain the parameters, you should either remove the previous experiment or change it\\nPastor Soto', 'section': 'Module 2: Experiment tracking', 'question': 'Max_depth is not recognize even when I add the mlflow.log_params', 'course': 'mlops-zoomcamp', 'id': 'f69fb077'}, 'e223524c': {'text': \"Problem: About week_2 homework: The register_model.py  script, when I copy it into a jupyter notebook fails and spits out the following error. AttributeError: 'tuple' object has no attribute 'tb_frame'\\nSolution: remove click decorators\", 'section': 'Module 2: Experiment tracking', 'question': \"AttributeError: 'tuple' object has no attribute 'tb_frame'\", 'course': 'mlops-zoomcamp', 'id': 'e223524c'}, '0f08bec7': {'text': 'Problem: when running the preprocess_data.py file you get the following error:\\n\\nwandb: ERROR api_key not configured (no-tty). call wandb.login(key=[your_api_key])\\nSolution: Go to your WandB profile (top RHS) → user settings → scroll down to “Danger Zone” and copy your API key. \\n\\nThen before running preprocess_data.py, add and run the following cell in your notebook:\\n\\n%%bash\\n\\nWandb login <YOUR_API_KEY_HERE>.\\nAdded and Answered by James Gammerman (jgammerman@gmail.com)', 'section': 'Module 2: Experiment tracking', 'question': 'WandB API error', 'course': 'mlops-zoomcamp', 'id': '0f08bec7'}, '8b4b1685': {'text': 'Please make sure you following the order below nd enabling the autologging before constructing the dataset. If you still have this issue check that your data is in format compatible with XGBoost.\\n# Enable MLflow autologging for XGBoost\\nmlflow.xgboost.autolog()\\n# Construct your dataset\\nX_train, y_train = ...\\n# Train your XGBoost model\\nmodel = xgb.XGBRegressor(...)\\nmodel.fit(X_train, y_train)\\nAdded by Olga Rudakova', 'section': 'Module 2: Experiment tracking', 'question': 'WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.', 'course': 'mlops-zoomcamp', 'id': '8b4b1685'}, 'ecfc5c07': {'text': 'Problem\\nUsing wget command to download either data or python scripts on Windows, I am using the notebook provided by Visual Studio and despite having a python virtual env, it did not recognize the pip command.\\nSolution: Use python -m pip, this same for any other command. Ie. python -m wget\\nAdded by Erick Calderin', 'section': 'Module 2: Experiment tracking', 'question': 'wget not working', 'course': 'mlops-zoomcamp', 'id': 'ecfc5c07'}, 'a1b68c52': {'text': \"Problem: Open/run github notebook(.ipynb) directly in Google Colab\\nSolution: Change the domain from 'github.com' to 'githubtocolab.com'. The notebook will open in Google Colab.\\nOnly works with Public repo.\\nAdded by Ming Jun\\nNavigating in Wandb UI became difficult to me, I had to intuit some options until I found the correct one.\\nSolution: Go to the official doc.\\nAdded by Erick Calderin\", 'section': 'Module 2: Experiment tracking', 'question': 'Open/run github notebook(.ipynb) directly in Google Colab', 'course': 'mlops-zoomcamp', 'id': 'a1b68c52'}, '483e7d61': {'text': 'Problem: Someone asked why we are using this type of split approach instead of just a random split.\\nSolution: For example, I have some models at work that train on Jan 1 2020 — Aug 1 2021 time period, and then test on Aug 1 - Dec 31 2021, and finally validate on Jan - March or something\\nWe do these “out of time”  validations to do a few things:\\nCheck for seasonality of our data\\nWe know if the RMSE for Test is 5 say, and then RMSE for validation is 20, then there’s serious seasonality to the data we are looking at, and now we might change to Time Series approaches\\nIf I’m predicting on Mar 30 2023 the outcomes for the next 3 months, the “random sample” in our train/test would have caused data leakage, overfitting, and poor model performance in production. We mustn’t take information about the future and apply it to the present when we are predicting in a model context.\\nThese are two of, I think, the biggest points for why we are doing jan/feb/march. I wouldn’t do it any other way.\\nTrain: Jan\\nTest: Feb\\nValidate: March\\nThe point of validation is to report out model metrics to leadership, regulators, auditors, and record the models performance to then later analyze target drift\\nAdded by Sam LaFell\\nProblem: If you get an error while trying to run the mlflow server on AWS CLI with S3 bucket and POSTGRES database:\\nReproducible Command:\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri postgresql://<DB_USERNAME>:<DB_PASSWORD>@<DB_ENDPOINT>:<DB_PORT>/<DB_NAME> --default-artifact-root s3://<BUCKET_NAME>\\nError:\\n\"urllib3 v2.0 only supports OpenSSL 1.1.1+, currently \"\\nImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the \\'ssl\\' module is compiled with \\'OpenSSL 1.0.2k-fips  26 Jan 2017\\'. See: https://github.com/urllib3/urllib3/issues/2168\\nSolution: Upgrade mlflow using\\nCode: pip3 install --upgrade mlflow\\nResolution: It downgrades urllib3 2.0.3 to 1.26.16 which is compatible with mlflow and ssl 1.0.2\\nInstalling collected packages: urllib3\\nAttempting uninstall: urllib3\\nFound existing installation: urllib3 2.0.3\\nUninstalling urllib3-2.0.3:\\nSuccessfully uninstalled urllib3-2.0.3\\nSuccessfully installed urllib3-1.26.16\\nAdded by Sarvesh Thakur', 'section': 'Module 3: Orchestration', 'question': 'Why do we use Jan/Feb/March for Train/Test/Validation Purposes?', 'course': 'mlops-zoomcamp', 'id': '483e7d61'}, 'e5c33f50': {'text': 'Problem description\\nSolution description\\n(optional) Added by Name', 'section': 'Module 3: Orchestration', 'question': 'Problem title', 'course': 'mlops-zoomcamp', 'id': 'e5c33f50'}, 'cbf13b19': {'text': 'Here', 'section': 'Module 4: Deployment', 'question': 'Where is the FAQ for Prefect questions?', 'course': 'mlops-zoomcamp', 'id': 'cbf13b19'}, '39861d6e': {'text': 'Windows with AWS CLI already installed\\nAWS CLI version:\\naws-cli/2.4.24 Python/3.8.8 Windows/10 exe/AMD64 prompt/off\\nExecuting\\n$(aws ecr get-login --no-include-email)\\nshows error\\naws.exe: error: argument operation: Invalid choice, valid choices are…\\nUse this command instead. More info here:\\nhttps://docs.aws.amazon.com/cli/latest/reference/ecr/get-login-password.html\\naws ecr get-login-password \\\\\\n--region <region> \\\\\\n| docker login \\\\\\n--username AWS \\\\\\n--password-stdin <aws_account_id>.dkr.ecr.<region>.amazonaws.com\\nAdded by MarcosMJD', 'section': 'Module 4: Deployment', 'question': 'aws.exe: error: argument operation: Invalid choice — Docker can not login to ECR.', 'course': 'mlops-zoomcamp', 'id': '39861d6e'}, '3dac15ff': {'text': 'Use ` at the end of each line except the last. Note that multiline string does not need `.\\nEscape “ to “\\\\ .\\nUse $env: to create env vars (non-persistent). E.g.:\\n$env:KINESIS_STREAM_INPUT=\"ride_events\"\\naws kinesis put-record --cli-binary-format raw-in-base64-out `\\n--stream-name $env:KINESIS_STREAM_INPUT `\\n--partition-key 1 `\\n--data \\'{\\n\\\\\"ride\\\\\": {\\n\\\\\"PULocationID\\\\\": 130,\\n\\\\\"DOLocationID\\\\\": 205,\\n\\\\\"trip_distance\\\\\": 3.66\\n},\\n\\\\\"ride_id\\\\\": 156\\n}\\'\\nAdded by MarcosMJD', 'section': 'Module 4: Deployment', 'question': 'Multiline commands in Windows Powershell', 'course': 'mlops-zoomcamp', 'id': '3dac15ff'}, '32686722': {'text': \"If one gets pipenv failures for pipenv install command -\\nAttributeError: module 'collections' has no attribute 'MutableMapping'\\nIt happens because you use the system Python (3.10) for pipenv.\\nIf you previously installed pipenv with apt-get, remove it - sudo-apt remove pipenv\\nMake sure you have a non-system Python installed in your environment. The easiest way to do it is to install anaconda or miniconda\\nNext, install pipenv to your non-system Python. If you use the setup from the lectures, it’s just this: pip install pipenv\\nNow re-run pipenv install XXXX (relevant dependencies) - should work\\nTested and worked on AWS instance, similar to the config Alexey presented in class.\\nAdded by Daniel HenSSL\", 'section': 'Module 4: Deployment', 'question': \"Pipenv installation not working (AttributeError: module 'collections' has no attribute 'MutableMapping')\", 'course': 'mlops-zoomcamp', 'id': '32686722'}, '22521751': {'text': 'First check if SSL module configured with following command:\\nPython -m ssl\\n\\nIf the output of this is empty there is no problem with SSL configuration.\\n\\nThen you should upgrade your pipenv package in your current environment to resolve the problem.\\nAdded by Kenan Arslanbay', 'section': 'Module 4: Deployment', 'question': \"module is not available (Can't connect to HTTPS URL)\", 'course': 'mlops-zoomcamp', 'id': '22521751'}, '81ad4784': {'text': \"During scikit-learn installation via the command:\\npipenv install scikit-learn==1.0.2\\nThe following error is raised:\\nModuleNotFoundError: No module named 'pip._vendor.six'\\nThen, one should:\\nsudo apt install python-six\\npipenv --rm\\npipenv install scikit-learn==1.0.2\\nAdded by Giovanni Pecoraro\", 'section': 'Module 4: Deployment', 'question': \"No module named 'pip._vendor.six'\", 'course': 'mlops-zoomcamp', 'id': '81ad4784'}, '29b5651e': {'text': 'Problem description. How can we use Jupyter notebooks with the Pipenv environment?\\nSolution: Refer to this stackoverflow question. Basically install jupyter and ipykernel using pipenv. And then register the kernel with `python -m ipykernel install --user --name=my-virtualenv-name` inside the Pipenv shell. If you are using Jupyter notebooks in VS Code, doing this will also add the virtual environment in the list of kernels.\\nAdded by Ron Medina', 'section': 'Module 4: Deployment', 'question': 'Pipenv with Jupyter', 'course': 'mlops-zoomcamp', 'id': '29b5651e'}, 'ca79bbe8': {'text': \"Problem: I tried to run starter notebook on pipenv environment but had issues with no output on prints. \\nI used scikit-learn==1.2.2 and python==3.10\\nTornado version was 6.3.2\\n\\nSolution: The error you're encountering seems to be a bug related to Tornado, which is a Python web server and networking library. It's used by Jupyter under the hood to handle networking tasks.\\nDowngrading to tornado==6.1 fixed the issue\\nhttps://stackoverflow.com/questions/54971836/no-output-jupyter-notebook\", 'section': 'Module 4: Deployment', 'question': 'Pipenv with Jupyter no output', 'course': 'mlops-zoomcamp', 'id': 'ca79bbe8'}, '668f1ad9': {'text': 'Problem description:  You might get an error ‘Invalid base64’ after running the ‘aws kinesis put-record’ command on your local machine. This might be the case if you are using the AWS CLI version 2 (note that in the video 4.4, around 57:42, you can see a warning since the instructor is using v1 of the CLI.\\nSolution description: To get around this, pass the argument ‘--cli-binary-format raw-in-base64-out’. This will encode your data string into base64 before passing it to kinesis\\nAdded by M', 'section': 'Module 4: Deployment', 'question': '‘Invalid base64’ error after running `aws kinesis put-record`', 'course': 'mlops-zoomcamp', 'id': '668f1ad9'}, '7a6f23eb': {'text': 'Problem description:   Running starter.ipynb in homework’s Q1 will show up this error.\\nSolution description: Update pandas (actually pandas version was the latest, but several dependencies are updated).\\nAdded by Marcos Jimenez', 'section': 'Module 4: Deployment', 'question': 'Error index 311297 is out of bounds for axis 0 with size 131483 when loading parquet file.', 'course': 'mlops-zoomcamp', 'id': '7a6f23eb'}, '232e5557': {'text': 'Use command $pipenv lock to force the creation of Pipfile.lock\\nAdded by Bijay P.', 'section': 'Module 4: Deployment', 'question': 'Pipfile.lock was not created along with Pipfile', 'course': 'mlops-zoomcamp', 'id': '232e5557'}, 'e44ec04a': {'text': 'This issue is usually due to the pythonfinder module in pipenv.\\nThe solution to this involves manually changing the scripts as describe here python_finder_fix\\nAdded by Ridwan Amure', 'section': 'Module 4: Deployment', 'question': 'Permission Denied using Pipenv', 'course': 'mlops-zoomcamp', 'id': 'e44ec04a'}, '55fdb8b9': {'text': 'When passing arguments to a script via command line and converting it to a 4 digit number using f’{year:04d}’, this error showed up.\\nThis happens because all inputs from the command line are read as string by the script. They need to be converted to numeric/integer before transformation in fstring.\\nyear = int(sys.argv[1])\\nf’{year:04d}’\\nIf you use click library just edit a decorator\\n@click.command()\\n@click.option( \"--year\",  help=\"Year for evaluation\",   type=int)\\ndef  your_function(year):\\n<<Your code>>\\nAdded by Taras Sh', 'section': 'Module 4: Deployment', 'question': \"Error while parsing arguments via CLI  [ValueError: Unknown format code 'd' for object of type 'str']\", 'course': 'mlops-zoomcamp', 'id': '55fdb8b9'}, 'bf9082a2': {'text': 'Ensure the correct image is being used to derive from.\\nCopy the data from local to the docker image using the COPY command to a relative path. Using absolute paths within the image might be troublesome.\\nUse paths starting from /app and don’t forget to do WORKDIR /app before actually performing the code execution.\\nMost common commands\\nBuild container using docker build -t mlops-learn .\\nExecute the script using docker run -it --rm mlops-learn\\n<mlops-learn> is just a name used for the image and does not have any significance.', 'section': 'Module 4: Deployment', 'question': 'Dockerizing tips', 'course': 'mlops-zoomcamp', 'id': 'bf9082a2'}, 'e7906e44': {'text': 'If you are trying to run Flask gunicorn & MLFlow server from the same container, defining both in Dockerfile with CMD will only run MLFlow & not Flask.\\nSolution: Create separate shell script with server run commands, for eg:\\n> \\tscript1.sh\\n#!/bin/bash\\ngunicorn --bind=0.0.0.0:9696 predict:app\\nAnother script with e.g. MLFlow server:\\n>\\tscript2.sh\\n#!/bin/bash\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri=sqlite:///mlflow.db --default-artifact-root=g3://zc-bucket/mlruns/\\nCreate a wrapper script to run above 2 scripts:\\n>\\twrapper_script.sh\\n#!/bin/bash\\n# Start the first process\\n./script1.sh &\\n# Start the second process\\n./script2.sh &\\n# Wait for any process to exit\\nwait -n\\n# Exit with status of process that exited first\\nexit $?\\nGive executable permissions to all scripts:\\nchmod +x *.sh\\nNow we can define last line of Dockerfile as:\\n> \\tDockerfile\\nCMD ./wrapper_script.sh\\nDont forget to expose all ports defined by services!', 'section': 'Module 4: Deployment', 'question': 'Running multiple services in a Docker container', 'course': 'mlops-zoomcamp', 'id': 'e7906e44'}, '76d8892e': {'text': 'Problem description cannot generate pipfile.lock raise InstallationError( pip9.exceptions.InstallationError: Command \"python setup.py egg_info\" failed with error code 1\\nSolution: you need to force and upgrade wheel and pipenv\\nJust run the command line :\\npip install --user --upgrade --upgrade-strategy eager pipenv wheel', 'section': 'Module 4: Deployment', 'question': 'Cannot generate pipfile.lock raise InstallationError( pip9.exceptions.InstallationError)', 'course': 'mlops-zoomcamp', 'id': '76d8892e'}, 'c5c2c82a': {'text': \"Problem description. How can we connect s3 bucket to MLFLOW?\\nSolution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\\nRead more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\\nAdded by Akshit Miglani\", 'section': 'Module 4: Deployment', 'question': 'Connecting s3 bucket to MLFLOW', 'course': 'mlops-zoomcamp', 'id': 'c5c2c82a'}, '82b6c143': {'text': 'Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)', 'section': 'Module 4: Deployment', 'question': 'Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\"', 'course': 'mlops-zoomcamp', 'id': '82b6c143'}, '77d9a742': {'text': 'Problem description: lib_lightgbm.so Reason: image not found\\nSolution description: Add “RUN apt-get install libgomp1” to your docker. (change installer command based on OS)\\nAdded by Kazeem Hakeem', 'section': 'Module 4: Deployment', 'question': 'Dockerizing lightgbm', 'course': 'mlops-zoomcamp', 'id': '77d9a742'}, '1667e95d': {'text': 'When the request is processed in lambda function, mlflow library raises:\\n2022/09/19 21:18:47 WARNING mlflow.pyfunc: Encountered an unexpected error (AttributeError(\"module \\'dataclasses\\' has no attribute \\'__version__\\'\")) while detecting model dependency mismatches. Set logging level to DEBUG to see the full traceback.\\nSolution: Increase the memory of the lambda function.\\nAdded by MarcosMJD', 'section': 'Module 4: Deployment', 'question': 'Error raised when executing mlflow’s pyfunc.load_model in lambda function.', 'course': 'mlops-zoomcamp', 'id': '1667e95d'}, '624a3525': {'text': 'Just a note if you are following the video but also using the repo’s notebook The notebook is the end state of the video which eventually uses mlflow pipelines.\\nJust watch the video and be patient. Everything will work :)\\nAdded by Quinn Avila', 'section': 'Module 4: Deployment', 'question': '4.3 FYI Notebook is end state of Video -', 'course': 'mlops-zoomcamp', 'id': '624a3525'}, '1db86601': {'text': 'Problem description: I was having issues because my python script was not reading AWS credentials from env vars, after building the image I was running it like this:\\ndocker run -it homework-04 -e AWS_ACCESS_KEY_ID=xxxxxxxx -e AWS_SECRET_ACCESS_KEY=xxxxxx\\nSolution 1:\\n\\nEnvironment Variables: \\nYou can set the AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN (if you are using AWS STS) environment variables. You can set these in your shell, or you can include them in your Docker run command like this:\\nI found out by myself that those variables must be passed before specifying the name of the image, as follow:\\ndocker run -e AWS_ACCESS_KEY_ID=xxxxxxxx -e AWS_SECRET_ACCESS_KEY=xxxxxx -it homework-04\\nAdded by Erick Cal\\nSolution 2 (if AWS credentials were not found):\\nAWS Configuration Files: \\nThe AWS SDKs and CLI will check the ~/.aws/credentials and ~/.aws/config files for credentials if they exist. You can map these files into your Docker container using volumes:\\n\\ndocker run -it --rm -v ~/.aws:/root/.aws homework:v1', 'section': 'Module 4: Deployment', 'question': 'Passing envs to my docker image', 'course': 'mlops-zoomcamp', 'id': '1db86601'}, '047baefe': {'text': 'If anyone is troubleshooting or just interested in seeing the model listed on the image svizor/zoomcamp-model:mlops-3.10.0-slim.\\nCreate a dockerfile. (yep thats all) and build “docker build -t zoomcamp_test .”\\nFROM svizor/zoomcamp-model:mlops-3.10.0-slim\\nRun “docker run -it zoomcamp_test ls /app” output -> model.bin\\nThis will list the contents of the app directory and “model.bin” should output. With this you could just copy your files, for example “copy myfile .” maybe a requirements file and this can be run for example “docker run -it myimage myscript arg1 arg2 ”. Of course keep in mind a build is needed everytime you change the Dockerfile.\\nAnother variation is to have it run when you run the docker file.\\n“””\\nFROM svizor/zoomcamp-model:mlops-3.10.0-slim\\nWORKDIR /app\\nCMD ls\\n“””\\nJust keep in mind CMD is needed because the RUN commands are used for building the image and the CMD is used at container runtime. And in your example you probably want to run a script or should we say CMD a script.\\nQuinn Avila', 'section': 'Module 4: Deployment', 'question': 'How to see the model in the docker container in app/?', 'course': 'mlops-zoomcamp', 'id': '047baefe'}, '4f240372': {'text': 'To resolve this make sure to build the docker image with the platform tag, like this:\\n“docker build -t homework:v1 --platform=linux/arm64 .”', 'section': 'Module 4: Deployment', 'question': \"WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\", 'course': 'mlops-zoomcamp', 'id': '4f240372'}, '7aef625b': {'text': \"Solution: instead of input_file = f'https://s3.amazonaws.com/nyc-tlc/trip+data/{taxi_type}_tripdata_{year:04d}-{month:02d}.parquet'  use input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/{taxi_type}_tripdata_{year:04d}-{month:02d}.parquet'\\nIlnaz Salimov\\nsalimovilnaz777@gmail.com\", 'section': 'Module 4: Deployment', 'question': 'HTTPError: HTTP Error 403: Forbidden when call apply_model() in score.ipynb', 'course': 'mlops-zoomcamp', 'id': '7aef625b'}, 'a3aa3a7d': {'text': 'i\\'m getting this error ModuleNotFoundError: No module named \\'pipenv.patched.pip._vendor.urllib3.response\\'\\nand Resolved from this command pip install pipenv --force-reinstall\\ngetting this errror site-packages\\\\pipenv\\\\patched\\\\pip\\\\_vendor\\\\urllib3\\\\connectionpool.py\"\\nResolved from this command pip install -U pip and pip install requests\\nAsif', 'section': 'Module 5: Monitoring', 'question': \"ModuleNotFoundError: No module named 'pipenv.patched.pip._vendor.urllib3.response'\", 'course': 'mlops-zoomcamp', 'id': 'a3aa3a7d'}, 'd2719204': {'text': 'Problem description: When running docker-compose up as shown in the video 5.2 if you go to http://localhost:3000/ you get asked for a username and a password.\\nSolution: for both of them the default is “admin”. Then you can enter your new password. \\nSee also here\\nAdded by JaimeRV', 'section': 'Module 5: Monitoring', 'question': 'Login window in Grafana', 'course': 'mlops-zoomcamp', 'id': 'd2719204'}, '30b8e8e6': {'text': 'Problem Description : In Linux, when starting services using docker compose up --build  as shown in video 5.2, the services won’t start and instead we get message unknown flag: --build in command prompt.\\nSolution : Since we install docker-compose separately in Linux, we have to run docker-compose up --build instead of docker compose up --build\\nAdded by Ashish Lalchandani', 'section': 'Module 5: Monitoring', 'question': 'Error in starting monitoring services in Linux', 'course': 'mlops-zoomcamp', 'id': '30b8e8e6'}, 'f33fc6e9': {'text': 'Problem: When running prepare.py getting KeyError: ‘content-length’\\nSolution: From Emeli Dral:\\nIt seems to me that the link we used in prepare.py to download taxi data does not work anymore. I substituted the instruction:\\nurl = f\"https://nyc-tlc.s3.amazonaws.com/trip+data/{file}\\nby the\\nurl = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file}\"\\nin the prepare.py and it worked for me. Hopefully, if you do the same you will be able to get those data.', 'section': 'Module 5: Monitoring', 'question': 'KeyError ‘content-length’ when running prepare.py', 'course': 'mlops-zoomcamp', 'id': 'f33fc6e9'}, 'd828de2a': {'text': 'Problem description\\nWhen I run the command “docker-compose up –build” and send the data to the real-time prediction service. The service will return “Max retries exceeded with url: /api”.\\nIn my case it because of my evidently service exit with code 2 due to the “app.py” in evidently service cannot import “from pyarrow import parquet as pq”.\\nSolution description\\nThe first solution is just install the pyarrow module “pip install pyarrow”\\nThe second solution is restart your machine.\\nThe third solution is if the first and second one didn’t work with your machine. I found that “app.py” of evidently service didn’t use that module. So comment the pyarrow module out and the problem was solved for me.\\nAdded by Surawut Jirasaktavee', 'section': 'Module 5: Monitoring', 'question': 'Evidently service exit with code 2', 'course': 'mlops-zoomcamp', 'id': 'd828de2a'}, '03f20ec1': {'text': 'When using evidently if you get this error.\\nYou probably forgot to and parentheses () just and opening and closing and you are good to go.\\nQuinn Avila', 'section': 'Module 5: Monitoring', 'question': 'ValueError: Incorrect item instead of a metric or metric preset was passed to Report', 'course': 'mlops-zoomcamp', 'id': '03f20ec1'}, '249726fe': {'text': 'You will get an error if you didn’t add a target=’duration_min’\\nIf you want to use RegressionQualityMetric() you need a target=’duration_min and you need this added to you current_data[‘duration_min’]\\nQuinn Avila', 'section': 'Module 5: Monitoring', 'question': 'For the report RegressionQualityMetric()', 'course': 'mlops-zoomcamp', 'id': '249726fe'}, '4e492af0': {'text': 'Problem description\\nValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required by LinearRegression.\\nSolution description\\nThis happens because the generated data is based on an early date therefore the training dataset would be empty.\\nAdjust the following\\nbegin = datetime.datetime(202X, X, X, 0, 0)\\nAdded by Luke', 'section': 'Module 5: Monitoring', 'question': 'Found array with 0 sample(s)', 'course': 'mlops-zoomcamp', 'id': '4e492af0'}, '10011dc1': {'text': 'Problem description\\nGetting “target columns” “prediction columns” not present errors after adding a metric\\nSolution description\\nMake sure to read through the documentation on what is required or optional when adding the metric. I added DatasetCorrelationsMetric which doesn’t require any parameters because the metric evaluates for correlations among the features.\\nSam Lim', 'section': 'Module 5: Monitoring', 'question': 'Adding additional metric', 'course': 'mlops-zoomcamp', 'id': '10011dc1'}, '92fb909a': {'text': 'When you try to login in Grafana with standard requisites (admin/admin) it throw up an error.\\nAfter run grafana-cli admin reset-admin-password admin in Grafana container the problem will be fixed\\nAdded by Artem Glazkov', 'section': 'Module 5: Monitoring', 'question': 'Standard login in Grafana does not work', 'course': 'mlops-zoomcamp', 'id': '92fb909a'}, '2b8cb640': {'text': 'Problem description. While my metric generation script was still running, I noticed that the charts in Grafana don’t get updated.\\nSolution description. There are two things to pay attention to:\\nRefresh interval: set it to a small value: 5-10-30 seconds\\nUse your local timezone in a call to `pytz.timezone` – I couldn’t get updates before changing this from the original value “Europe/London” to my own zone', 'section': 'Module 5: Monitoring', 'question': 'The chart in Grafana doesn’t get updates', 'course': 'mlops-zoomcamp', 'id': '2b8cb640'}, 'd4ceab0b': {'text': 'Problem description. Prefect server was not running locally, I ran `prefect server start` command but it stopped immediately..\\nSolution description. I used Prefect cloud to run the script, however I created an issue on the Prefect github.\\nBy Erick Calderin', 'section': 'Module 5: Monitoring', 'question': 'Prefect server was not running locally', 'course': 'mlops-zoomcamp', 'id': 'd4ceab0b'}, '482e575f': {'text': 'Solution. Using docker CLI run docker system prune to remove unused things (build cache, containers, images etc)\\nAlso, to see what’s taking space before pruning you can run docker system df\\nBy Alex Litvinov', 'section': 'Module 5: Monitoring', 'question': 'no disk space left error when doing docker compose up', 'course': 'mlops-zoomcamp', 'id': '482e575f'}, '33e775eb': {'text': 'Problem: when run docker-compose up –build, you may see this error. To solve, add `command: php -S 0.0.0.0:8080 -t /var/www/html` in adminer block in yml file like:\\nadminer:\\ncommand: php -S 0.0.0.0:8080 -t /var/www/html\\nimage: adminer\\n…\\nIlnaz Salimov\\nsalimovilnaz777@gmail.com', 'section': 'Module 5: Monitoring', 'question': 'Failed to listen on :::8080 (reason: php_network_getaddresses: getaddrinfo failed: Address family for hostname not supported)', 'course': 'mlops-zoomcamp', 'id': '33e775eb'}, '19a3d34a': {'text': 'Problem: Can we generate charts like Evidently inside Grafana?\\nSolution: In Grafana that would be a stat panel (just a number) and scatter plot panel (I believe it requires a plug-in). However, there is no native way to quickly recreate this exact Evidently dashboard. You\\'d need to make sure you have all the relevant information logged to your Grafana data source, and then design your own plots in Grafana.\\nIf you want to recreate the Evidently visualizations externally, you can export the Evidently output in JSON with include_render=True\\n(more details here https://docs.evidentlyai.com/user-guide/customization/json-dict-output) and then parse information from it for your external visualization layer. To include everything you need for non-aggregated visuals, you should also add \"raw_data\": True  option (more details here https://docs.evidentlyai.com/user-guide/customization/report-data-aggregation).\\nOverall, this specific plot with under- and over-performance segments is more useful during debugging, so might be easier to access it ad hoc using Evidently.\\nAdded by Ming Jun, Asked by Luke, Answered by Elena Samuylova', 'section': 'Module 6: Best practices', 'question': 'Generate Evidently Chart in Grafana', 'course': 'mlops-zoomcamp', 'id': '19a3d34a'}, '55c68f23': {'text': \"You may get an error ‘{'errorMessage': 'Unable to locate credentials', …’ from the print statement in test_docker.py after running localstack with kinesis.\\nTo fix this, in the docker-compose.yaml file, in addition to the environment variables like AWS_DEFAULT_REGION, add two other variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY. Their value is not important; anything like abc will suffice\\nAdded by M\\nOther possibility is just to run\\naws --endpoint-url http://localhost:4566 configure\\nAnd providing random values for AWS Access Key ID , AWS Secret Access Key, Default region name, and Default output format.\\nAdded by M.A. Monjas\", 'section': 'Module 6: Best practices', 'question': 'Get an error ‘Unable to locate credentials’ after running localstack with kinesis', 'course': 'mlops-zoomcamp', 'id': '55c68f23'}, '54020f0a': {'text': \"You may get an error while creating a bucket with localstack and the boto3 client:\\nbotocore.exceptions.ClientError: An error occurred (IllegalLocationConstraintException) when calling the CreateBucket operation: The unspecified location constraint is incompatible for the region specific endpoint this request was sent to.\\nTo fix this, instead of creating a bucket via\\ns3_client.create_bucket(Bucket='nyc-duration')\\nCreate it with\\ns3_client.create_bucket(Bucket='nyc-duration', CreateBucketConfiguration={\\n'LocationConstraint': AWS_DEFAULT_REGION})\\nyam\\nAdded by M\", 'section': 'Module 6: Best practices', 'question': 'Get an error ‘ unspecified location constraint is incompatible ’', 'course': 'mlops-zoomcamp', 'id': '54020f0a'}, 'b6249d2c': {'text': 'When executing an AWS CLI command (e.g., aws s3 ls), you can get the error <botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>.\\nTo fix it, simply set the AWS CLI environment variables:\\nexport AWS_DEFAULT_REGION=eu-west-1\\nexport AWS_ACCESS_KEY_ID=foobar\\nexport AWS_SECRET_ACCESS_KEY=foobar\\nTheir value is not important; anything would be ok.\\nAdded by Giovanni Pecoraro', 'section': 'Module 6: Best practices', 'question': 'Get an error “<botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>” after running an AWS CLI command', 'course': 'mlops-zoomcamp', 'id': 'b6249d2c'}, '31543d95': {'text': 'At every commit the above error is thrown and no pre-commit hooks are ran.\\nMake sure the indentation in .pre-commit-config.yaml is correct. Especially the 4 spaces ahead of every `repo` statement\\nAdded by M. Ayoub C.', 'section': 'Module 6: Best practices', 'question': 'Pre-commit triggers an error at every commit: “mapping values are not allowed in this context”', 'course': 'mlops-zoomcamp', 'id': '31543d95'}, 'e147bbb6': {'text': 'No option to remove pytest test\\nRemove .vscode folder located on the folder you previously used for testing, e.g. folder code (from week6-best-practices) was chosen to test, so you may remove .vscode inside the folder.\\nAdded by Rizdi Aprilian', 'section': 'Module 6: Best practices', 'question': 'Could not reconfigure pytest from zero after getting done with previous folder', 'course': 'mlops-zoomcamp', 'id': 'e147bbb6'}, 'dc55657f': {'text': 'Problem description\\nFollowing video 6.3, at minute 11:23, get records command returns empty Records.\\nSolution description\\nAdd --no-sign-request to Kinesis get records call:\\n aws --endpoint-url=http://localhost:4566 kinesis get-records --shard-iterator […] --no-sign-request', 'section': 'Module 6: Best practices', 'question': 'Empty Records in Kinesis Get Records with LocalStack', 'course': 'mlops-zoomcamp', 'id': 'dc55657f'}, 'f6979915': {'text': \"Problem description\\ngit commit -m 'Updated xxxxxx'\\nAn error has occurred: InvalidConfigError:\\n==> File .pre-commit-config.yaml\\n=====> 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\\nSolution description\\nSet uft-8 encoding when creating the pre-commit yaml file:\\npre-commit sample-config | out-file .pre-commit-config.yaml -encoding utf8\\nAdded by MarcosMJD\", 'section': 'Module 6: Best practices', 'question': 'In Powershell, Git commit raises utf-8 encoding error after creating pre-commit yaml file', 'course': 'mlops-zoomcamp', 'id': 'f6979915'}, '1076a121': {'text': \"Problem description\\ngit commit -m 'Updated xxxxxx'\\n[INFO] Initializing environment for https://github.com/pre-commit/pre-commit-hooks.\\n[INFO] Installing environment for https://github.com/pre-commit/pre-commit-hooks.\\n[INFO] Once installed this environment will be reused.\\nAn unexpected error has occurred: CalledProcessError: command:\\n…\\nreturn code: 1\\nexpected return code: 0\\nstdout:\\nAttributeError: 'PythonInfo' object has no attribute 'version_nodot'\\nSolution description\\nClear app-data of the virtualenv\\npython -m virtualenv api -vvv --reset-app-data\\nAdded by MarcosMJD\", 'section': 'Module 6: Best practices', 'question': \"Git commit with pre-commit hook raises error ‘'PythonInfo' object has no attribute 'version_nodot'\", 'course': 'mlops-zoomcamp', 'id': '1076a121'}, 'aa203ca7': {'text': 'Problem description\\nProject structure:\\n/sources/production/model_service.py\\n/sources/tests/unit_tests/test_model_service.py (“from production.model_service import ModelService)\\nWhen running python test_model_service.py from the sources directory, it works.\\nWhen running pytest ./test/unit_tests fails. ‘No module named ‘production’’\\nSolution description\\nUse python -m pytest ./test/unit_tests\\nExplanation: pytest does not add to the sys.path the path where pytest is run.\\nYou can run python -m pytest, or alternatively export PYTHONPATH=. Before executing pytest\\nAdded by MarcosMJD', 'section': 'Module 6: Best practices', 'question': 'Pytest error ‘module not found’ when if using custom packages in the source code', 'course': 'mlops-zoomcamp', 'id': 'aa203ca7'}, '8b04605d': {'text': 'Problem description\\nProject structure:\\n/sources/production/model_service.py\\n/sources/tests/unit_tests/test_model_service.py (“from production.model_service import ModelService)\\ngit commit -t ‘test’ raises ‘No module named ‘production’’ when calling pytest hook\\n- repo: local\\nhooks:\\n- id: pytest-check\\nname: pytest-check\\nentry: pytest\\nlanguage: system\\npass_filenames: false\\nalways_run: true\\nargs: [\\n\"tests/\"\\n]\\nSolution description\\nUse this hook instead:\\n- repo: local\\nhooks:\\n- id: pytest-check\\nname: pytest-check\\nentry: \"./sources/tests/unit_tests/run.sh\"\\nlanguage: system\\ntypes: [python]\\npass_filenames: false\\nalways_run: true\\nAnd make sure that run.sh sets the right directory and run pytest:\\ncd \"$(dirname \"$0\")\"\\ncd ../..\\nexport PYTHONPATH=.\\npipenv run pytest ./tests/unit_tests\\nAdded by MarcosMJD', 'section': 'Module 6: Best practices', 'question': 'Pytest error ‘module not found’ when using pre-commit hooks if using custom packages in the source code', 'course': 'mlops-zoomcamp', 'id': '8b04605d'}, 'a3b9af04': {'text': 'Problem description\\nThis is the step in the ci yml file definition:\\n- name: Run Unit Tests\\nworking-directory: \"sources\"\\nrun: ./tests/unit_tests/run.sh\\nWhen executing github ci action, error raises:\\n…/tests/unit_test/run.sh Permission error\\nError: Process completed with error code 126\\nSolution description\\nAdd execution  permission to the script and commit+push:\\ngit update-index --chmod=+x .\\\\sources\\\\tests\\\\unit_tests\\\\run.sh\\nAdded by MarcosMJD', 'section': 'Module 6: Best practices', 'question': 'Github actions: Permission denied error when executing script file', 'course': 'mlops-zoomcamp', 'id': 'a3b9af04'}, 'b16aae74': {'text': 'Problem description\\nWhen a docker-compose file contains a lot of containers, running the containers may take too much resource. There is a need to easily select only a group of containers while ignoring irrelevant containers during testing.\\nSolution description\\nAdd profiles: [“profile_name”] in the service definition.\\nWhen starting up the service, add `--profile profile_name` in the command.\\nAdded by Ammar Chalifah', 'section': 'Module 6: Best practices', 'question': 'Managing Multiple Docker Containers with docker-compose profile', 'course': 'mlops-zoomcamp', 'id': 'b16aae74'}, '66326a87': {'text': 'Problem description\\nIf you are having problems with the integration tests and kinesis double check that your aws regions match on the docker-compose and local config. Otherwise you will be creating a stream in the wrong region\\nSolution description\\nFor example set ~/.aws/config region = us-east-1 and the docker-compose.yaml - AWS_DEFAULT_REGION=us-east-1\\nAdded by Quinn Avila', 'section': 'Module 6: Best practices', 'question': 'AWS regions need to match docker-compose', 'course': 'mlops-zoomcamp', 'id': '66326a87'}, 'fb3c4150': {'text': 'Problem description\\nPre-commit command was failing with isort repo.\\nSolution description\\nSet version to 5.12.0\\nAdded by Erick Calderin', 'section': 'Module 6: Best practices', 'question': 'Isort Pre-commit', 'course': 'mlops-zoomcamp', 'id': 'fb3c4150'}, '886d1617': {'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin', 'section': 'Module 6: Best practices', 'question': 'How to destroy infrastructure created via GitHub Actions', 'course': 'mlops-zoomcamp', 'id': '886d1617'}}\n"
     ]
    }
   ],
   "source": [
    "print(doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "55d87d56-23f2-4df2-bdfc-174bc7add340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-engineering-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "course = doc_index['c02e79ef']['course']\n",
    "print(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b16cfc9f-2b8f-46b7-b147-d2c440fae36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in parsed_results.items():\n",
    "    course = doc_index[doc_id]['course']\n",
    "    for q in questions:\n",
    "        final_results.append((q, course, doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6e3262a3-b311-41dc-945f-9a3d66fd99b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the specific date and time when the course is set to begin?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c02e79ef'),\n",
       " ('How can I stay updated with course announcements and important dates?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c02e79ef'),\n",
       " ('Is there a registration process required before the course starts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c02e79ef'),\n",
       " (\"What platform should I use to access the course's public calendar?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c02e79ef'),\n",
       " ('Where can I find the link to register for the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c02e79ef'),\n",
       " ('What specific skills or knowledge do I need before enrolling in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1f6520ca'),\n",
       " ('Can you point me to where I can find the requirements for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1f6520ca'),\n",
       " ('Are there any prior courses or experiences necessary for joining this program?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1f6520ca'),\n",
       " ('Is there a resource that outlines the prerequisites for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1f6520ca'),\n",
       " ('What should I have completed before I start this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1f6520ca'),\n",
       " ('Is it possible to enroll in the course after it has begun?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7842b56a'),\n",
       " ('If I miss the registration, can I still participate in homework assignments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7842b56a'),\n",
       " ('Are there any specific deadlines I should know about for the final project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7842b56a'),\n",
       " ('What happens if I complete my final project after the deadline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7842b56a'),\n",
       " ('Should I manage my time carefully to avoid last-minute submissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7842b56a'),\n",
       " ('When will I get a confirmation email after registering for the bootcamp?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0bbf41ec'),\n",
       " ('Is it necessary to wait for a confirmation email to start the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0bbf41ec'),\n",
       " ('Can I begin submitting my assignments without formal registration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0bbf41ec'),\n",
       " ('What is the purpose of the registration for the Data Engineering Bootcamp?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0bbf41ec'),\n",
       " ('How does the registration process work for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0bbf41ec'),\n",
       " ('What steps should I take to prepare for the course prior to its start?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63394d91'),\n",
       " ('Are there any specific software or accounts I need to set up before the course begins?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63394d91'),\n",
       " (\"What prerequisites should I review to ensure I'm ready for the course?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63394d91'),\n",
       " ('Is there a particular programming language I need to have installed before the course starts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63394d91'),\n",
       " ('What tools and technologies should I familiarize myself with ahead of the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63394d91'),\n",
       " ('How many Zoom Camps are offered annually for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2ed9b986'),\n",
       " ('What are the specific time frames for each Zoom Camp throughout the year?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2ed9b986'),\n",
       " ('Is there only one live cohort available for the Data-Engineering Zoom Camp each year?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2ed9b986'),\n",
       " (\"Can I participate in any Zoom Camp at my own pace if I don't want a certificate?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2ed9b986'),\n",
       " ('Are the schedules for each cohort consistent across different Zoom Camps?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2ed9b986'),\n",
       " ('Will the 2024 cohort have different tools compared to the previous one?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '93e2c8ed'),\n",
       " ('What AI tool will be used in the 2024 edition of the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '93e2c8ed'),\n",
       " ('Are there any updated videos for the 2024 course cohort?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '93e2c8ed'),\n",
       " ('What was used in the course for the 2023 edition instead of Airflow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '93e2c8ed'),\n",
       " ('How does the 2024 course differ from the one in 2023?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '93e2c8ed'),\n",
       " ('Is it possible to access course materials after the course ends?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a482086d'),\n",
       " ('Can I work on assignments after completion of the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a482086d'),\n",
       " ('Will I be able to prepare for the next cohort after the course finishes?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a482086d'),\n",
       " ('Can I start my capstone project after the course is over?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a482086d'),\n",
       " ('How can I continue my learning journey after the course concludes?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a482086d'),\n",
       " ('Is there any support available for students in the self-paced course format?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb56ae98'),\n",
       " ('Where can I find answers to my questions about the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb56ae98'),\n",
       " ('How should I approach getting help if I encounter an issue while studying?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb56ae98'),\n",
       " ('Can I use the Slack channel for support while taking the course at my own pace?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb56ae98'),\n",
       " ('What should I do before asking a question in the Slack channel?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb56ae98'),\n",
       " ('Where can I find the main videos for our course on YouTube?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4292531b'),\n",
       " ('Is there a specific GitHub repository that lists the video thumbnails linking to the playlist?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4292531b'),\n",
       " ('Are there any additional playlists for this year available in the course materials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4292531b'),\n",
       " ('How do I access the year-specific playlist for office hours videos?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4292531b'),\n",
       " ('Where is the main playlist for the DATA ENGINEERING course pinned in our communication tools?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4292531b'),\n",
       " ('What is the weekly time commitment for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ea739c65'),\n",
       " ('How should I determine my expected hours per week?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ea739c65'),\n",
       " ('Is the required study time the same for everyone?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ea739c65'),\n",
       " ('Can I assess my own time investment for the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ea739c65'),\n",
       " ('What factors influence the number of hours needed weekly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ea739c65'),\n",
       " ('Is it possible to earn a certificate while taking the course at my own pace?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cb257ee5'),\n",
       " ('What are the requirements for obtaining a certificate in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cb257ee5'),\n",
       " (\"Why can't I receive a certificate if I choose the self-paced option?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cb257ee5'),\n",
       " ('Are peer-reviews necessary for earning the course certificate?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cb257ee5'),\n",
       " ('When can I peer-review projects during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cb257ee5'),\n",
       " ('Where can I find the video link for the Office Hour sessions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '04aa4897'),\n",
       " ('How do students submit questions during the workshop sessions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '04aa4897'),\n",
       " ('Is the Zoom link available to students for the Office Hours?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '04aa4897'),\n",
       " ('When will the video URL for the sessions be announced?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '04aa4897'),\n",
       " ('What platform should I use to watch the Office Hour sessions live?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '04aa4897'),\n",
       " ('Will the Office Hours be recorded if I cannot make it to the live session?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9681be3b'),\n",
       " ('How soon after the Office Hours ends will the recording be available?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9681be3b'),\n",
       " ('Can I watch the recorded Office Hours at my convenience?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9681be3b'),\n",
       " ('Is there a way to access past Office Hours recordings?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9681be3b'),\n",
       " ('What happens if I miss the live workshop during Office Hours?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9681be3b'),\n",
       " ('What is the best way to keep track of my homework and project deadlines for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1daf537'),\n",
       " ('Where can I find the most current deadlines for assignments and projects?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1daf537'),\n",
       " ('How should I stay updated on possible extensions or changes to deadlines?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1daf537'),\n",
       " ('Is there a specific link to check for deadlines and updates throughout the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1daf537'),\n",
       " ('What should I do if I believe a deadline has been changed or extended?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1daf537'),\n",
       " ('Is it permitted to submit homework after the due date?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'be5bfee4'),\n",
       " ('What happens if I miss the deadline for homework submissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'be5bfee4'),\n",
       " ('Can I turn in my homework if the submission process is still open?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'be5bfee4'),\n",
       " (\"How can I confirm my homework submission after it's due?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'be5bfee4'),\n",
       " ('Are there any exceptions to the late submission policy for homework?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'be5bfee4'),\n",
       " ('What specific URL do I need to provide for homework submissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0e424a44'),\n",
       " ('Where should I store my code for the homework assignments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0e424a44'),\n",
       " ('Is it acceptable to use platforms other than GitHub for my homework?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0e424a44'),\n",
       " ('What criteria should my homework repository meet?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0e424a44'),\n",
       " ('How should I ensure my code is accessible for review?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0e424a44'),\n",
       " ('How is homework graded and how can I check my points for it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29865466'),\n",
       " ('What does the leaderboard display in terms of my total points?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29865466'),\n",
       " ('Can you explain how points are earned from FAQ submissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29865466'),\n",
       " ('How many points can I earn from sharing my learning publicly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29865466'),\n",
       " (\"Where can I find the points I've accumulated for each homework task?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29865466'),\n",
       " ('How was my display name determined when I created my account for the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '016d46a1'),\n",
       " ('Where can I find my current display name to check my leaderboard status?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '016d46a1'),\n",
       " ('Is it possible to change my display name once I see it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '016d46a1'),\n",
       " ('What steps should I follow to view my display name in the course profile?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '016d46a1'),\n",
       " ('Why am I not appearing on the leaderboard and how can I confirm my display name?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '016d46a1'),\n",
       " ('Is Python 3.9 the preferred version for this course in 2024?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '47972cb1'),\n",
       " ('Will using Python 3.10 or 3.11 cause issues with the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '47972cb1'),\n",
       " ('Why is Python 3.9 recommended over other versions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '47972cb1'),\n",
       " ('Are there any advantages to using Python 3.9 in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '47972cb1'),\n",
       " ('What should I do if I have Python 3.10 or 3.11 installed?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '47972cb1'),\n",
       " ('What are the options for setting up my environment for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ddf6c1b3'),\n",
       " ('Are there any specific challenges for Windows users when working locally?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ddf6c1b3'),\n",
       " ('What should I do if I want to start with Docker for my local setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ddf6c1b3'),\n",
       " ('How can I use GitHub Codespaces for my virtual machine environment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ddf6c1b3'),\n",
       " ('Is it possible to work from different devices during the boot camp?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ddf6c1b3'),\n",
       " ('Can I use GitHub Codespaces instead of CLI or Git Bash for data ingestion?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ac25d3af'),\n",
       " ('What resources does GitHub Codespaces provide for my project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ac25d3af'),\n",
       " ('Does GitHub Codespaces come with pre-installed tools I might need?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ac25d3af'),\n",
       " ('Is it possible to access GitHub repositories directly from a Codespace?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ac25d3af'),\n",
       " ('How can GitHub Codespaces assist in creating a Docker file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ac25d3af'),\n",
       " ('Is GitHub Codespaces mandatory for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '251218fc'),\n",
       " ('Can I use my own installed PostgreSQL and Docker for the assignments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '251218fc'),\n",
       " ('Are there alternative environments besides GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '251218fc'),\n",
       " ('Is it acceptable to complete the course using my personal laptop?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '251218fc'),\n",
       " ('Do I have to use the recommended platforms for the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '251218fc'),\n",
       " ('Do I have to use both GitHub Codespaces and GCP for the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3c0114ce'),\n",
       " ('Which option should I choose for my final project development?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3c0114ce'),\n",
       " ('Is it necessary to learn BigQuery during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3c0114ce'),\n",
       " ('Can I create a local environment instead of using the cloud platforms?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3c0114ce'),\n",
       " ('What environment suits my project idea best?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3c0114ce'),\n",
       " ('What steps should I follow to open the Run command window on my Windows machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f43f5fe7'),\n",
       " ('How can I access the Registry Editor to change registry values?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f43f5fe7'),\n",
       " ('What specific registry value do I need to modify to resolve the GCP VM connection issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f43f5fe7'),\n",
       " ('Is there an alternative way to address connection problems with a GCP VM besides changing registry values?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f43f5fe7'),\n",
       " ('Where can I find the known_hosts file on my Windows machine to delete the saved fingerprint?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f43f5fe7'),\n",
       " ('What are the main reasons for choosing GCP as the primary cloud provider for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd061525d'),\n",
       " ('Am I allowed to use other cloud platforms like AWS instead of GCP during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd061525d'),\n",
       " ('Is there any cost involved when signing up for a free GCP account?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd061525d'),\n",
       " ('What benefits do new users receive when they start using GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd061525d'),\n",
       " ('Can you explain the relationship between BigQuery and GCP in the context of this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd061525d'),\n",
       " ('Is it necessary to pay for cloud services during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd01b2c'),\n",
       " ('What are the cloud service options available to us?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd01b2c'),\n",
       " ('How can I utilize GCP for free?', 'data-engineering-zoomcamp', '1cd01b2c'),\n",
       " ('Are there any costs associated with using cloud platforms in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd01b2c'),\n",
       " ('Will using cloud services incur any fees while enrolled?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd01b2c'),\n",
       " ('Is it feasible to complete the course without using cloud platforms like GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e4a7c3b0'),\n",
       " ('Are there local alternatives available for all the tools covered in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e4a7c3b0'),\n",
       " ('Can the course be entirely done using a home setup instead of cloud services?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e4a7c3b0'),\n",
       " ('Will there be any materials provided for running elements of the course locally?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e4a7c3b0'),\n",
       " ('Is BigQuery the only component of the course that requires cloud access?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e4a7c3b0'),\n",
       " ('Is it allowed to utilize AWS for the course assignments, and what should I keep in mind while doing so?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7cd1912e'),\n",
       " ('What are the main tasks I need to focus on for the final capstone project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7cd1912e'),\n",
       " ('Will there be enough peers available for assistance if I choose AWS over GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7cd1912e'),\n",
       " ('How does my choice of AWS impact my collaboration with other students in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7cd1912e'),\n",
       " ('Are there any specific guidelines I need to follow when adapting the course content for AWS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7cd1912e'),\n",
       " ('What additional live Zoom sessions might occur apart from the Office Hour?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '52393fb3'),\n",
       " ('Will there be scheduled calls during the Capstone phase to address any inquiries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '52393fb3'),\n",
       " ('How will we be notified if there are extra Zoom calls during Capstone?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '52393fb3'),\n",
       " ('Are live calls planned to assist with questions throughout the Capstone period?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '52393fb3'),\n",
       " ('When can I expect announcements regarding potential Capstone Zoom sessions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '52393fb3'),\n",
       " ('Will we continue to use the NYC Trip data from January 2021 for our project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10515af5'),\n",
       " (\"Is the project for this year the same as last year's?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10515af5'),\n",
       " ('Are we switching to the 2022 NYC Trip data for our assignments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10515af5'),\n",
       " ('Where can I access the NYC Trip data for January 2021?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10515af5'),\n",
       " ('Is there a significant change in the project compared to last year?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10515af5'),\n",
       " ('Is the repository from 2022 still available?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cdb86a97'),\n",
       " ('Where can I find the materials from 2022?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cdb86a97'),\n",
       " ('Has the 2022 content been removed?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cdb86a97'),\n",
       " ('What happened to the 2022 resources?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cdb86a97'),\n",
       " ('Can I access the 2022 information somewhere?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cdb86a97'),\n",
       " ('Is Airflow an acceptable tool for my final project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e0114ad'),\n",
       " ('Am I allowed to choose any tool for my project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e0114ad'),\n",
       " ('Can I select a different software for my final assignment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e0114ad'),\n",
       " ('Are there restrictions on the tools I can use for my project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e0114ad'),\n",
       " ('Is it mandatory to use a specific tool for the final project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e0114ad'),\n",
       " ('Can I utilize tools like Airflow or Prefect in place of the designated tool in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b2799574'),\n",
       " ('Is it acceptable to choose AWS or Snowflake instead of the prescribed GCP products for my projects?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b2799574'),\n",
       " ('Am I permitted to use Tableau instead of Metabase or Google Data Studio in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b2799574'),\n",
       " ('What are the implications of selecting an alternative tool or stack for my capstone project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b2799574'),\n",
       " (\"Will there be support available if I decide to go with a different data stack than what's provided?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b2799574'),\n",
       " ('What are some ways I can add value to this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f19301f'),\n",
       " ('Is there a specific way to share the course with others?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f19301f'),\n",
       " ('How can I suggest improvements or changes to the course materials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f19301f'),\n",
       " ('What should I do if I find something in the repository that needs better organization?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f19301f'),\n",
       " ('Can you explain how to create a PR for the repository?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f19301f'),\n",
       " ('Is there a preferred operating system for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c700adb'),\n",
       " ('Can I use Windows for the course assignments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c700adb'),\n",
       " ('Are students in the course using different operating systems?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c700adb'),\n",
       " ('Which operating system works best with the course material?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c700adb'),\n",
       " ('Is Linux necessary for successful course completion?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c700adb'),\n",
       " ('What issues might Windows users experience in the course when dealing with shell scripts in *.sh files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '44b14808'),\n",
       " ('Why is it important to use WSL for the course modules involving shell scripts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '44b14808'),\n",
       " ('How did past cohorts manage to overcome the challenges with shell scripts on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '44b14808'),\n",
       " ('Are there any alternatives for Windows users who do not want to use WSL when running the course materials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '44b14808'),\n",
       " ('What specific modules will require the use of shell scripts that might pose problems for non-WSL Windows users?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '44b14808'),\n",
       " ('Are there any recommended books for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '76e4baf6'),\n",
       " ('What additional resources should I check out?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '76e4baf6'),\n",
       " ('Is there a document that lists useful materials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '76e4baf6'),\n",
       " ('Can you provide a link to the resources for data engineering?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '76e4baf6'),\n",
       " ('Do you suggest any particular readings for this curriculum?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '76e4baf6'),\n",
       " ('Can you explain what Project Attempt #1 and Project Attempt #2 are in detail?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '48b533a8'),\n",
       " (\"What happens if I'm late for the first project deadline?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '48b533a8'),\n",
       " ('Is there a possibility to resubmit the project after a failed first attempt?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '48b533a8'),\n",
       " ('How does the second attempt for the project work?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '48b533a8'),\n",
       " ('What are the consequences of missing the first project submission?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '48b533a8'),\n",
       " ('What are some effective strategies for troubleshooting technical issues on my own before seeking help?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '954044d1'),\n",
       " ('How can I find solutions to common errors I encounter while coding?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '954044d1'),\n",
       " ('What should I include in my question when seeking assistance from others on platforms like Stackoverflow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '954044d1'),\n",
       " ('What is the recommended approach for using Slack to resolve technical problems with my peers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '954044d1'),\n",
       " ('How can taking a break help me with solving coding issues, and what activities do you suggest for a mental reset?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '954044d1'),\n",
       " ('What should I include when I ask a question for help?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a820b9b3'),\n",
       " ('When is it appropriate to seek assistance rather than relying on the troubleshooting guide?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a820b9b3'),\n",
       " ('What specific details about my coding environment should I mention when asking for help?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a820b9b3'),\n",
       " ('Why is it important to describe what I have already attempted when asking a question?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a820b9b3'),\n",
       " ('What types of errors should I report, and how should I present them?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a820b9b3'),\n",
       " ('What steps should I follow after creating a GitHub account for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f2945cd2'),\n",
       " ('How can I ensure that my local Git repository is properly set up for accessing course materials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f2945cd2'),\n",
       " ('What should I do if I want to make modifications to the content of the course using Git?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f2945cd2'),\n",
       " ('Are there any specific types of files that I need to ignore when creating my repositories?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f2945cd2'),\n",
       " ('Where can I find helpful resources for learning how to manage my Git repositories effectively?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f2945cd2'),\n",
       " ('What error message might I encounter if I use spaces instead of tabs in my Makefile?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb9d376f'),\n",
       " ('How can I resolve the issue of missing separators in a document?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb9d376f'),\n",
       " ('What should I replace spaces with in my Makefile to avoid errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb9d376f'),\n",
       " ('Is there a specific solution or guide I should follow for fixing tab issues in VS Code?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb9d376f'),\n",
       " (\"What steps do I need to take if I see a 'missing separator' error in my Makefile?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb9d376f'),\n",
       " ('How can I open an HTML file using a Windows browser while working on Linux in WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72f25f6d'),\n",
       " ('What command do I need to use to view an HTML file from WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72f25f6d'),\n",
       " ('Is it possible to choose a specific browser for viewing HTML files in WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72f25f6d'),\n",
       " ('What should I do if I want to use Firefox to open an HTML file from Linux?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72f25f6d'),\n",
       " ('Do I need to install any additional tools to open HTML files in a Windows browser from WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72f25f6d'),\n",
       " ('How do I set up Chrome Remote Desktop on a Debian Linux virtual machine in Compute Engine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1e59afc'),\n",
       " ('What should I do if I encounter an ERROR 403: Forbidden when trying to download the 2021 Yellow Taxi Trip Records?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1e59afc'),\n",
       " ('Where can I find a backup of the 2021 Yellow Taxi Trip Records data if the original link fails?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1e59afc'),\n",
       " ('What command should I use to properly unzip a gzipped file that I downloaded?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1e59afc'),\n",
       " (\"Can I use the standard 'unzip' command to extract contents from a .gz file?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1e59afc'),\n",
       " ('What is the correct naming convention for taxi data files when handling them in our project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '71c10610'),\n",
       " ('What alternative approach can I take to name the data file if it is downloaded with a csv.gz extension?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '71c10610'),\n",
       " ('How can I extract the file name from the URL provided for the yellow taxi data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '71c10610'),\n",
       " ('Can you explain how to adjust the csv_name variable in the context of the video?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '71c10610'),\n",
       " ('What function can I use to read taxi data files that have the csv.gz extension in Python?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '71c10610'),\n",
       " ('What is the data dictionary for Yellow Taxi trips in New York?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '17a5aea1'),\n",
       " ('Can you provide the link for the Green Taxi data dictionary?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '17a5aea1'),\n",
       " ('Where can I find the Yellow Trips data dictionary for NYC?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '17a5aea1'),\n",
       " ('Is there an online resource for Green Taxi trip records?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '17a5aea1'),\n",
       " ('How do I access the data dictionary for Yellow and Green Taxi trips?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '17a5aea1'),\n",
       " ('How can I unzip a downloaded parquet file using the command line?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a275db7'),\n",
       " ('What command should I use to extract the parquet file into a CSV format?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a275db7'),\n",
       " ('Can you explain how to read a parquet file directly in a Python script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a275db7'),\n",
       " ('What do I need to include in the main function to handle parquet files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a275db7'),\n",
       " ('How can I convert a parquet file to CSV after downloading it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a275db7'),\n",
       " (\"What are the steps to install wget on an Ubuntu system if I encounter the error 'wget is not recognized as an internal or external command'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7ec0f9b0'),\n",
       " ('Can you explain how to install wget on MacOS using Brew if the command is not recognized?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7ec0f9b0'),\n",
       " ('What options do I have for installing wget on a Windows machine when the command is unrecognized?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7ec0f9b0'),\n",
       " ('If I prefer using Python to download files, how can I utilize the wget library instead of the command line tool?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7ec0f9b0'),\n",
       " ('Is there a way to bypass using wget entirely when attempting to download a file, and if so, what is the method?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7ec0f9b0'),\n",
       " ('What should I do if I encounter a certificate verification error while using wget on MacOS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bb1ba786'),\n",
       " (\"Can you explain the importance of adding '!' before wget when using it in a Jupyter Notebook?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bb1ba786'),\n",
       " ('What are the two methods I can use to bypass the certificate verification for wget?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bb1ba786'),\n",
       " ('How do I utilize the Python library wget as a potential solution for my issue on MacOS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bb1ba786'),\n",
       " ('What is the correct command format to run wget while ignoring certificate verification?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bb1ba786'),\n",
       " ('How can I set the backslash as an escape character in Git Bash for Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f83dbe7'),\n",
       " ('What command do I need to use in the terminal for setting the escape character?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f83dbe7'),\n",
       " ('Do I need to include the escape character setting in my .bashrc file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f83dbe7'),\n",
       " ('Is the escape character setting in Git Bash specific to any user or can anyone use it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f83dbe7'),\n",
       " ('What specific environment is mentioned for using the backslash as an escape character?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2f83dbe7'),\n",
       " ('What steps do I need to follow to securely store secrets in GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '543ff080'),\n",
       " ('Is there a guide for managing account-specific secrets in GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '543ff080'),\n",
       " ('Where can I find instructions for storing secrets in GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '543ff080'),\n",
       " ('Can you explain how to handle my secrets while using GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '543ff080'),\n",
       " ('What documentation is available for secret management in GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '543ff080'),\n",
       " ('What should I do if I encounter an error about not being able to connect to the Docker daemon?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd407d65b'),\n",
       " ('How can I verify if the Docker daemon is running properly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd407d65b'),\n",
       " ('Is there a specific command to update WSL in PowerShell?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd407d65b'),\n",
       " ('What steps should I follow to troubleshoot Docker connection issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd407d65b'),\n",
       " (\"Can you explain how to start the Docker daemon if it's not running?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd407d65b'),\n",
       " ('What are the requirements for running Docker on Windows Pro versions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c9375c56'),\n",
       " ('How can Windows Home users run Docker if Hyper-V is not available?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c9375c56'),\n",
       " ('What should I do if I encounter an error related to WSL2 installation?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c9375c56'),\n",
       " ('Is it necessary to enable Hyper-V before using Docker on Windows 10 Pro?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c9375c56'),\n",
       " ('Where can I find instructions to install WSL2 on Windows 11?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c9375c56'),\n",
       " ('What steps should I take to download an image from a public repository using Docker, and do I need to log in?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e866156b'),\n",
       " (\"If I get an error saying 'access denied' when pulling an image, what could be causing this issue?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e866156b'),\n",
       " ('What should I do if I face a permission denied error while creating a PostgreSQL container on macOS M1?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e866156b'),\n",
       " ('Why is it necessary to install Docker Desktop instead of using Rancher Desktop for running PostgreSQL containers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e866156b'),\n",
       " (\"Can you explain the potential reasons for a 'repository does not exist' error when pulling a Docker image?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e866156b'),\n",
       " ('Why is it impossible for me to delete a local folder that is mounted to a Docker volume?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '16370470'),\n",
       " ('What ownership and permissions might prevent me from deleting a folder created by a Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '16370470'),\n",
       " ('How do I resolve access errors in Obsidian that result from Docker volume permissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '16370470'),\n",
       " ('What command should I use to forcefully delete a folder created during a Docker process?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '16370470'),\n",
       " ('Can you explain the meaning of the options used in the command to remove the Docker test folder?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '16370470'),\n",
       " ('What should I do if Docker on my Windows 10/11 is not starting or appears to be stuck in the settings?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '316df755'),\n",
       " ('How can I check if I am using the latest version of Docker for Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '316df755'),\n",
       " ('Is there a way to switch between containers if Docker is stuck on starting?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '316df755'),\n",
       " ('Do I need to enable Hyper-V on Windows 10/11 to run Docker smoothly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '316df755'),\n",
       " ('What are the steps to enable WSL2 for Docker on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '316df755'),\n",
       " ('Is it better to execute Docker commands from the Windows file system or a Linux distribution file system in WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3aa9252'),\n",
       " ('What should I do if Docker does not work even after setting up WSL2 or Hyper-V correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3aa9252'),\n",
       " ('Can I use Docker on Windows 10 Home Edition with the help of WSL2, and how?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3aa9252'),\n",
       " ('What steps should I take if my Docker installation remains stuck after setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3aa9252'),\n",
       " ('Is there a way to reset Docker to resolve issues after installation on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3aa9252'),\n",
       " ('What is the recommended way to store code for optimal file system performance in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a4abe7a5'),\n",
       " ('Where can I find more information about Docker best practices?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a4abe7a5'),\n",
       " ('Which backend does Docker run on by default for Windows 10 Home users?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a4abe7a5'),\n",
       " ('What does the default setup for Windows 11 Home users imply for Docker usage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a4abe7a5'),\n",
       " ('How does WSL2 affect Docker performance on my machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a4abe7a5'),\n",
       " ('What error might I encounter when running a Docker command in Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fb930700'),\n",
       " (\"How can I resolve the 'input device is not a TTY' error when using Docker?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fb930700'),\n",
       " ('Is there a command I should use before my Docker command if I am using mintty?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fb930700'),\n",
       " (\"Can I create an alias to avoid typing 'winpty' before Docker commands every time?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fb930700'),\n",
       " ('Where should I add the alias command to make it permanent for Docker on my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fb930700'),\n",
       " ('What could be causing the error when I try to pip install in a Docker container on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa187680'),\n",
       " ('Is there a specific error message I should look for when having issues with pip install on Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa187680'),\n",
       " (\"What DNS settings should I try if I'm experiencing temporary name resolution failures in Docker?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa187680'),\n",
       " ('Can you provide a command that might resolve issues with pip install in a Windows Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa187680'),\n",
       " ('Which version of Python is suggested for use in the Docker command to troubleshoot pip install issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa187680'),\n",
       " ('What should I do if the ny_taxi_postgres_data folder remains empty after running the Docker script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b000e899'),\n",
       " ('Can you provide the specific command to run for populating the ny_taxi_postgres_data on a Windows machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b000e899'),\n",
       " ('What are the environment variable settings needed for the Docker command to work correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b000e899'),\n",
       " ('Why is it important to specify the absolute path in the -v parameter of the Docker command?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b000e899'),\n",
       " ('How can I verify that all the files are present in the ny_taxi folder within VS Code after running the command?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b000e899'),\n",
       " ('What should I refer to for guidance on installing Docker on a Mac?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9c66759f'),\n",
       " ('Are there any known issues with the previous method for setting up Docker on macOS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9c66759f'),\n",
       " ('What alternative method did you find effective for installing Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9c66759f'),\n",
       " (\"Has Docker's licensing model impacted installation procedures on macOS?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9c66759f'),\n",
       " ('Where can I find the latest instructions for downloading Docker on a Mac?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9c66759f'),\n",
       " (\"What is the solution if I encounter a permission error when trying to change the directory permissions for '/var/lib/postgresql/data' in Docker?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e3106e07'),\n",
       " ('How can I create a local Docker volume and utilize it for the PostgreSQL data directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e3106e07'),\n",
       " ('What are the necessary environment variables to set when running the PostgreSQL container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e3106e07'),\n",
       " (\"What should I do if I see an error stating that the directory '/var/lib/postgresql/data' exists but is not empty?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e3106e07'),\n",
       " ('How can I verify that my Docker volume has been created and is listed in Docker Desktop?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e3106e07'),\n",
       " ('What should I do if my Docker volume mapping is not working on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72229da5'),\n",
       " ('Can you suggest some folder names that are compatible for data mapping in Docker on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72229da5'),\n",
       " ('What options are available for specifying volume paths in Docker commands on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72229da5'),\n",
       " ('How can I check and correct volume mapping issues if Docker creates an unexpected folder on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72229da5'),\n",
       " ('Is it possible to use a volume name instead of a path for Docker on Windows, and how would I do that?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '72229da5'),\n",
       " ('What should I do if I get an error related to the daemon when using Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '58c9f99f'),\n",
       " ('How can I resolve the invalid mode error when working with PostgreSQL in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '58c9f99f'),\n",
       " ('Is there a specific format for mounting paths in Docker that I need to follow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '58c9f99f'),\n",
       " ('Are there alternative mounting paths I can use instead of the one provided?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '58c9f99f'),\n",
       " (\"What does adding a leading slash before 'c:' achieve in the mounting path for Docker?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '58c9f99f'),\n",
       " ('What causes the specific Docker error related to creating a build mount source path?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc42139a'),\n",
       " ('Is there a way to fix the error when running the Docker command a second time?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc42139a'),\n",
       " ('What command can I use on subsequent runs of the Docker container to avoid the error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc42139a'),\n",
       " ('Which environment variables do I need to set for the PostgreSQL Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc42139a'),\n",
       " ('What port should I use for PostgreSQL when running it in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc42139a'),\n",
       " ('What error occurs when running the command docker build -t taxi_ingest:v001?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a146e3ee'),\n",
       " ('Why did the user encounter a permission issue with the ny_taxi_postgres_data directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a146e3ee'),\n",
       " ('What files do I need present to avoid the build error when using Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a146e3ee'),\n",
       " ('How can I resolve the permission issue on an Ubuntu system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a146e3ee'),\n",
       " ('Where can I find more details about the Docker build error related to checking context?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a146e3ee'),\n",
       " ('What should I do if I encounter an error waiting for a container in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '593a85ba'),\n",
       " ('How can I check the status of my Docker installation if I used snap to install it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '593a85ba'),\n",
       " ('What steps should I take if I receive an unknown command error while checking Docker with snap?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '593a85ba'),\n",
       " ('What might cause a failure when binding to the port 5432 in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '593a85ba'),\n",
       " ('Is there a recommended method for installing Docker if I need to uninstall it first?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '593a85ba'),\n",
       " ('What could be the reason for the build error in Docker related to my project folder?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '50bd1a71'),\n",
       " ('How can I resolve the issue of not having the proper authorization rights to my host folder in PopOS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '50bd1a71'),\n",
       " ('Why does the folder appear empty when I encounter the Docker build error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '50bd1a71'),\n",
       " ('What command should I use to change permissions for the folder causing the build error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '50bd1a71'),\n",
       " ('Can you provide an example of how to set folder permissions for Docker in my case?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '50bd1a71'),\n",
       " ('What causes the permission denied error when trying to build a Docker container on Ubuntu/Linux?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f409f751'),\n",
       " ('What command can I use to build the Docker container for the taxi ingest project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f409f751'),\n",
       " ('What folder is created when I run the Docker build command for this project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f409f751'),\n",
       " ('How can I resolve the permission issues when rebuilding the pipeline or creating a new one?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f409f751'),\n",
       " ('What does the chmod command do when applied to the ny_taxi_postgres_data folder?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f409f751'),\n",
       " ('How can I find the name of the Docker network?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d217da3'),\n",
       " ('What command should I use to list Docker networks?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d217da3'),\n",
       " ('Is there a specific way to retrieve the network name in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d217da3'),\n",
       " ('What steps do I follow to obtain the Docker network name?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d217da3'),\n",
       " ('Can you tell me how to view the available Docker networks?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d217da3'),\n",
       " (\"What should I do if I encounter a conflict error stating that the container name 'pg-database' is already in use?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '09081824'),\n",
       " (\"Can you explain how to resolve the issue when I'm trying to restart a Docker image and face a container name conflict?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '09081824'),\n",
       " ('What command do I need to run to stop a running container before I can remove it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '09081824'),\n",
       " ('How can I restart a Docker image without removing the container that has the same name?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '09081824'),\n",
       " (\"Is there an alternative command to using 'docker run' if I want to restart the Docker image safely?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '09081824'),\n",
       " ('What could be the cause of receiving a name translation error when using docker-compose for ingestion?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4df80c55'),\n",
       " ('How can I determine the correct network to use in my ingestion script when running docker-compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4df80c55'),\n",
       " ('What is the significance of the error message from SQLAlchemy regarding operational issues with the database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4df80c55'),\n",
       " ('Can you explain how to identify the correct database name when encountering host name translation issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4df80c55'),\n",
       " ('What are the specific naming conventions for networks and databases I should be aware of when using Docker and Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4df80c55'),\n",
       " ('What should I do if I cannot install Docker on my MacOS or Windows 11 VM running on Linux?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3aee7261'),\n",
       " ('Is there a command I need to run to enable nested virtualization for Docker installation?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3aee7261'),\n",
       " ('What are the specific commands to run on an Intel CPU before starting my VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3aee7261'),\n",
       " ('Are there any different commands for enabling nested virtualization on an AMD CPU?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3aee7261'),\n",
       " ('What happens if nested virtualization is not enabled when using Docker in this environment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3aee7261'),\n",
       " ('How can I manage Docker containers and images using VS Code?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6497b659'),\n",
       " ('What do I need to do to connect VS Code with my Docker setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6497b659'),\n",
       " ('Is it possible to use VS Code with Docker running on WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6497b659'),\n",
       " ('What command should I use to stop a Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6497b659'),\n",
       " ('Where can I find the official VS Code extension for Docker management?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6497b659'),\n",
       " ('What does it mean when the logs indicate that the PostgreSQL database directory contains a database but the system is shut down?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a02f2039'),\n",
       " ('Why is my PostgreSQL container not accepting requests?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a02f2039'),\n",
       " ('What error am I likely to encounter if my PostgreSQL server terminates abnormally?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a02f2039'),\n",
       " ('What should I do if I see a connection failure from my PostgreSQL container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a02f2039'),\n",
       " ('How can I resolve the issue with the PostgreSQL database shutting down unexpectedly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a02f2039'),\n",
       " (\"How can I install Docker if I'm using an unsupported version of Ubuntu?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c6db65aa'),\n",
       " ('What is the command to install Docker using snap on Ubuntu?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c6db65aa'),\n",
       " ('Is there a specific command I need to use for Docker installation on Ubuntu?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c6db65aa'),\n",
       " ('Can I use snap to install Docker on my Ubuntu version?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c6db65aa'),\n",
       " (\"Are there alternatives to install Docker if snap isn't available on my Ubuntu?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c6db65aa'),\n",
       " ('What should I do if I encounter a mounting error related to directory permissions when using Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f476a606'),\n",
       " (\"How can I specify a named volume in my Docker-Compose file if I've set up a local Docker volume earlier?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f476a606'),\n",
       " ('What command can I use to inspect the location of my named volume in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f476a606'),\n",
       " ('Why did my composed service create a mounting directory with a different name than the one I expected?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f476a606'),\n",
       " ('What steps did the author take to resolve the naming issue with the Docker volume in their setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f476a606'),\n",
       " ('What steps should I follow if I encounter an error related to translating a host name to an address while working with Docker Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e41b100c'),\n",
       " ('How can I ensure that my PostgreSQL database is running when using Docker Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e41b100c'),\n",
       " ('What command do I need to use to start my Docker containers in detached mode?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e41b100c'),\n",
       " (\"What should I do if the output of 'docker ps' does not show my PostgreSQL database container as running?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e41b100c'),\n",
       " ('How can I check the logs of a specific Docker container to troubleshoot issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e41b100c'),\n",
       " (\"What should I do if I encounter an error indicating that Docker can't translate the host name 'pg-database' after running 'docker-compose up'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cd0f9300'),\n",
       " ('How can I retrieve the default network name created by Docker Compose to update my Ingestion script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cd0f9300'),\n",
       " (\"What actions should I take if I lose database data after executing 'docker-compose up'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cd0f9300'),\n",
       " ('In case of persistent issues with pgcli, what alternative tools can I use to connect to my database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cd0f9300'),\n",
       " ('Where can I find the logs for Docker Compose execution to check the network name?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cd0f9300'),\n",
       " ('What error do I get if the hostname does not resolve in Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7f845a1c'),\n",
       " ('What command can I use to view all stopped and running containers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7f845a1c'),\n",
       " ('How can I resolve an issue where the server cannot connect on localhost:8080?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7f845a1c'),\n",
       " ('What is a recommended format for a hostname to avoid resolution issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7f845a1c'),\n",
       " ('In the docker-compose.yml file, how should I configure networks for multiple containers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7f845a1c'),\n",
       " ('What is the common issue when running docker-compose on Google Cloud Platform regarding Postgres data persistence?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '36e54439'),\n",
       " ('How can I ensure that PGAdmin data persists when using Docker on GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '36e54439'),\n",
       " ('What is the recommended way to modify the volume configuration for PGAdmin in a docker-compose file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '36e54439'),\n",
       " ('What should I change in the docker-compose file to make PGAdmin use Docker Volume for data persistence?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '36e54439'),\n",
       " (\"Can you explain the difference between using a local path and Docker Volume for PGAdmin's data storage?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '36e54439'),\n",
       " ('What should I do if my Docker engine keeps crashing?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '32e8450c'),\n",
       " ('How can I check if I have the latest version of Docker installed?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '32e8450c'),\n",
       " ('What steps should I take if updating Docker does not resolve my issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '32e8450c'),\n",
       " ('Is it necessary to reinstall Docker if the problem continues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '32e8450c'),\n",
       " ('Will I lose any important data if I need to fetch images again after reinstalling Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '32e8450c'),\n",
       " ('How can I ensure that my pgAdmin configuration is saved across container restarts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '96606db2'),\n",
       " ('What specific YAML configuration should I use to set up pgAdmin with persistent storage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '96606db2'),\n",
       " ('Before executing the docker-compose command, what permission changes must I make to the pgAdmin_data folder?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '96606db2'),\n",
       " ('What are the default environment variables required for setting up pgAdmin in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '96606db2'),\n",
       " ('Which user and group does the pgAdmin container run as, and how does that relate to folder permissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '96606db2'),\n",
       " ('What should I do if I encounter a permission denied error when using Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0882bfac'),\n",
       " ('How can I ensure my user has the necessary permissions for Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0882bfac'),\n",
       " ('What steps should I follow to create a volume for pgAdmin to retain previous connections?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0882bfac'),\n",
       " ('Can you explain how to modify the docker-compose.yaml file for pgAdmin?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0882bfac'),\n",
       " ('What do I need to do after adding my user to the docker group?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0882bfac'),\n",
       " ('What should I do if docker-compose does not seem to work after I modified my .bashrc file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d067f5c'),\n",
       " ('Why did my docker-compose file from GitHub get named docker-compose-linux-x86_64 instead of docker-compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d067f5c'),\n",
       " ('Is there a specific reason why using the command docker-compose is more convenient than the file I downloaded?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d067f5c'),\n",
       " ('What steps should I take to rename the downloaded docker-compose file for it to function correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d067f5c'),\n",
       " ('Can you explain why the naming of the docker-compose file might affect its usability in my Google Cloud VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7d067f5c'),\n",
       " ('What should I do if I encounter an error related to credentials when using docker-compose up?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ff352621'),\n",
       " ('How can I resolve the issue of getting credentials errors in Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ff352621'),\n",
       " ('Is there a specific solution for the Docker-Compose credentials error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ff352621'),\n",
       " ('Where can I find more information regarding the credentials error in Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ff352621'),\n",
       " ('What command is recommended to fix the Docker-Compose error related to getting credentials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ff352621'),\n",
       " ('What steps should I follow if I encounter errors with the docker-compose.yml file and pgadmin setup while using Docker-Compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2d653208'),\n",
       " ('What adjustments do I need to make to my docker-compose.yml file to resolve issues with PostgreSQL data retrieval?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2d653208'),\n",
       " ('How should I handle low_memory settings when importing a CSV file during the data ingestion process?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2d653208'),\n",
       " ('What is the correct order of operations to ensure successful execution of my Docker setup for PostgreSQL and pgAdmin?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2d653208'),\n",
       " ('How can I ensure that my pgAdmin server configuration matches the settings in my docker-compose.yml file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2d653208'),\n",
       " ('How can I resolve the Docker Compose up -d error related to credentials in my environment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f09ea61e'),\n",
       " ('What should I do if I encounter an executable file not found error with docker-credential-desktop?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f09ea61e'),\n",
       " ('Where can I find the config.json file for Docker on my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f09ea61e'),\n",
       " ('What changes do I need to make to the credsStore in the config.json file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f09ea61e'),\n",
       " ('What steps should I follow after modifying the config.json file to address the error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f09ea61e'),\n",
       " ('What steps should I follow to determine the correct docker-compose binary for my WSL setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fbd3d2bb'),\n",
       " ('Where can I find the docker-compose releases for download?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fbd3d2bb'),\n",
       " ('What commands can I use to check my system prior to downloading docker-compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fbd3d2bb'),\n",
       " ('Is there a specific command I can run to download the appropriate version of docker-compose directly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fbd3d2bb'),\n",
       " ('What will the commands uname -s and uname -m return when executed?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fbd3d2bb'),\n",
       " ('What should I do if I see an error about an undefined volume in my Docker-Compose setup on Windows/WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0b014d0c'),\n",
       " ('Can you explain how to resolve the issue of a service referring to an undefined volume in my docker-compose.yaml file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0b014d0c'),\n",
       " ('What specific changes do I need to make in my docker-compose.yaml file to fix volume errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0b014d0c'),\n",
       " ('How should I structure the volumes section in my docker-compose file to avoid errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0b014d0c'),\n",
       " ('Is there a specific format I need to follow when adding volumes to the docker-compose file for my project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0b014d0c'),\n",
       " ('What causes the permission errors when using Docker with WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd21bff1d'),\n",
       " ('How can I resolve permission conflicts between WSL and Windows when using Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd21bff1d'),\n",
       " ('Why should I prefer using Docker volumes instead of local drives?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd21bff1d'),\n",
       " ('What are the benefits of utilizing Docker volumes for data storage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd21bff1d'),\n",
       " (\"Is it necessary to specify the 'user:' option when using Docker volumes?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd21bff1d'),\n",
       " ('What should I do if pgadmin is malfunctioning when querying in Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6afb7b55'),\n",
       " ('Why does pgadmin have issues when run on Git Bash or a VM in Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6afb7b55'),\n",
       " ('What are the required libraries for pgadmin to work correctly with Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6afb7b55'),\n",
       " ('Can you suggest an alternative to pgadmin for executing queries in Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6afb7b55'),\n",
       " ('How do I install the necessary libraries for using Postgres with Python?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6afb7b55'),\n",
       " (\"What might cause the error message stating 'Insufficient system resources exist to complete the requested service' when using WSL?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b51c3b82'),\n",
       " ('How can I check if there are any pending updates for Windows Terminal and WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b51c3b82'),\n",
       " ('What steps should I follow to update the Windows Terminal app on my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b51c3b82'),\n",
       " ('Is there a specific section of Windows updates where I can find pending security updates?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b51c3b82'),\n",
       " ('What should I do after updating my apps and security updates to ensure changes take effect?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b51c3b82'),\n",
       " ('What should I do if my WSL integration with Ubuntu stops unexpectedly with exit code 1?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '326af690'),\n",
       " ('Can you provide a solution for a potential DNS issue related to WSL on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '326af690'),\n",
       " ('What steps can I follow to resolve the Docker icon issue where I need to switch to Linux containers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '326af690'),\n",
       " ('Why am I receiving an error about an uninitialized database and missing superuser password?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '326af690'),\n",
       " ('Is there a specific registry command I need to run to fix the DNS service for WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '326af690'),\n",
       " ('What might be the reason for the error when trying to run the GPC VM through SSH in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c2ec9047'),\n",
       " ('How can I resolve the permission issue with my SSH private key file in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c2ec9047'),\n",
       " ('What command can I use to create a .ssh directory in the home directory of WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c2ec9047'),\n",
       " ('Is there a way to ensure that WSL2 uses the correct .ssh keys for SSH connections?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c2ec9047'),\n",
       " ('What steps should I take to copy my Windows .ssh folder contents to the new .ssh folder in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c2ec9047'),\n",
       " ('What should I do if I encounter a host name resolution issue in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3b711e73'),\n",
       " ('How do I create a .ssh/config file in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3b711e73'),\n",
       " ('What commands do I need to run to set up the .ssh directory in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3b711e73'),\n",
       " ('Where should I place the configuration details for my GPC VM in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3b711e73'),\n",
       " ('What steps should I follow to ensure WSL2 references the correct .ssh/config path?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3b711e73'),\n",
       " ('What should I do if I encounter a PGCLI connection error indicating a failure to receive data from the server?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cfe07c9d'),\n",
       " ('How can I resolve the issue of the connection being refused when trying to connect to port 5432?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cfe07c9d'),\n",
       " ('What command do I need to use to connect to the database if I get an SSL negotiation packet error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cfe07c9d'),\n",
       " ('Is there a specific host that I should use when attempting to connect via PGCLI in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cfe07c9d'),\n",
       " ('Can you provide the correct connection string for accessing the ny_taxi database using PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'cfe07c9d'),\n",
       " ('What should I do if I encounter a PGCLI --help error during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'acf42bb8'),\n",
       " ('Is there a way to resolve a potential installation error related to PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'acf42bb8'),\n",
       " ('How can I troubleshoot the PGCLI --help error we discussed in Module 1?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'acf42bb8'),\n",
       " ('Where can I find additional resources if I experience installation issues with PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'acf42bb8'),\n",
       " ('What steps should I take to verify my installation if PGCLI is not functioning correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'acf42bb8'),\n",
       " ('Is it necessary to run pgcli within a separate Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '176ce516'),\n",
       " ('What port do we need to map for pgsql in this module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '176ce516'),\n",
       " ('Can pgcli be accessed directly from my local computer?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '176ce516'),\n",
       " ('What is the role of port 5432 in this section?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '176ce516'),\n",
       " ('Should pgcli be run locally or within another container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '176ce516'),\n",
       " (\"What should I do if I encounter a fatal password authentication error for user 'root' when using PGCLI?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e5d1e9b'),\n",
       " ('How can I resolve conflicts with my local Postgres installation when running a Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e5d1e9b'),\n",
       " ('What port should I use to connect to my Postgres Docker container to avoid authentication issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e5d1e9b'),\n",
       " ('Is there a specific command I can use to check for applications using a port on my MacOS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e5d1e9b'),\n",
       " ('What steps do I need to take to unload and start the PostgreSQL service on MacOS to free up a port?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3e5d1e9b'),\n",
       " ('What should I do if I encounter a PermissionError when running pgcli?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '78833f32'),\n",
       " ('How can I resolve the error related to creating the config directory for pgcli?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '78833f32'),\n",
       " ('What is the recommended method for installing pgcli without encountering permission issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '78833f32'),\n",
       " (\"What should I do if conda install gets stuck at the 'Solving environment' step?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '78833f32'),\n",
       " ('Can using sudo for installing pgcli lead to permission errors, and what is the alternative?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '78833f32'),\n",
       " ('What specific error does the PGCLI report when there is no valid pq wrapper available?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63823f21'),\n",
       " ('What is the minimum Python version required to properly install psycopg2-binary?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63823f21'),\n",
       " ('What command should I use to create a new conda environment with Python 3.9?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63823f21'),\n",
       " ('What is the recommended method to install pgcli after ensuring the correct Python version?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63823f21'),\n",
       " ('What alternative command can I run to install psycopg with binary and pool options?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '63823f21'),\n",
       " ('What should I do if my Bash terminal is stuck at the password prompt for pgcli when trying to connect to PostgreSQL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b36ea564'),\n",
       " ('Can you suggest any alternative terminals to use if I encounter issues with pgcli on my current setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b36ea564'),\n",
       " ('What steps should I take if I receive the error message stating \\'password authentication failed for user \"root\"\\' despite entering the correct password?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b36ea564'),\n",
       " ('What are the potential solutions if the PostgreSQL service is causing connection issues on my Windows machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b36ea564'),\n",
       " ('Why do I need to keep my database connection active while following the tutorial, especially after running a PostgreSQL container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b36ea564'),\n",
       " (\"What should I do if my system shows the 'command not found' error for pgcli after installation?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2a46ce5'),\n",
       " ('How can I confirm the installation location of pgcli on my Windows system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2a46ce5'),\n",
       " ('What steps do I need to take to add Python Scripts to my Windows PATH variable?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2a46ce5'),\n",
       " ('Is there a possibility that my Python installation might be under a different directory than the one provided?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2a46ce5'),\n",
       " ('Where can I find more information or a reference regarding the pgcli command error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2a46ce5'),\n",
       " ('Is there a way to use pgcli without installing it on my local machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '27bdbc3f'),\n",
       " ('What Docker command should I run to execute pgcli in a container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '27bdbc3f'),\n",
       " ('Can you tell me the Docker network name used in the course videos for pgcli?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '27bdbc3f'),\n",
       " ('What are the PostgreSQL connection details necessary to use pgcli in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '27bdbc3f'),\n",
       " (\"What is the version of pgcli being used in this course's Docker example?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '27bdbc3f'),\n",
       " ('Why is PULocationID not recognized in queries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f7c5d8da'),\n",
       " ('How should I format column names with capital letters in PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f7c5d8da'),\n",
       " ('What happens if I do not use quotations around capitalized columns?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f7c5d8da'),\n",
       " ('Can you explain the case sensitivity issue with local identifiers?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f7c5d8da'),\n",
       " ('Where can I find more information about case sensitivity in PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f7c5d8da'),\n",
       " (\"What error might I encounter when executing the command '\\\\d <database name>' in PGCLI?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c91ad8f2'),\n",
       " (\"What steps should I take if I face the error 'column c.relhasoids does not exist'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c91ad8f2'),\n",
       " (\"How can I resolve the issue of the database 'ny_taxi' not being found?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c91ad8f2'),\n",
       " ('What should I do if I experience problems with PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c91ad8f2'),\n",
       " ('Is restarting my computer necessary after reinstalling PGCLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c91ad8f2'),\n",
       " ('What should I do if I encounter an OperationalError related to password authentication while trying to connect to Postgres in Jupyter Notebook?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '88bf31a0'),\n",
       " ('Why am I experiencing a connection issue with my Postgres database on localhost when using Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '88bf31a0'),\n",
       " ('What steps can I take to resolve the problem if I get a connection error at port 5432 while working with my database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '88bf31a0'),\n",
       " ('Is there a specific port I need to use when accessing my Postgres database through Docker, and how can I find that?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '88bf31a0'),\n",
       " ('How can I check if there is another Postgres service running on my Windows machine that might be causing connection issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '88bf31a0'),\n",
       " (\"What could be the reason for receiving an OperationalError related to the role 'root' when connecting to Postgres?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '23524e6d'),\n",
       " (\"How can I check if a 'root' user exists with login capabilities in my Postgres setup?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '23524e6d'),\n",
       " ('What steps should I take to change the default port if it conflicts with an existing Postgres installation?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '23524e6d'),\n",
       " ('What alternative user settings can be applied in the Docker setup to resolve connection issues with Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '23524e6d'),\n",
       " ('What actions should I perform to reset my Docker Postgres setup if I experience persistent connection errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '23524e6d'),\n",
       " ('What does the OperationalError related to psycopg2 indicate about the database connection to localhost?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9211bbd6'),\n",
       " ('How can I verify if the Postgres server is running on my machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9211bbd6'),\n",
       " (\"What should I do if I encounter a connection error stating that the database 'ny_taxi' does not exist?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9211bbd6'),\n",
       " ('Is there a recommended port to use for Postgres if port 5432 is unavailable on my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9211bbd6'),\n",
       " ('Where can I find the psycopg2 code referenced in the error message regarding the database connection?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9211bbd6'),\n",
       " ('What should I do if I encounter a ModuleNotFoundError related to psycopg2 when working with Postgres in Module 1?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5db86809'),\n",
       " ('Can you explain the steps I should take if the initial installation of psycopg2-binary does not resolve the error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5db86809'),\n",
       " ('Is there a specific command I should use to update conda or pip before reinstalling psycopg2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5db86809'),\n",
       " ('What actions should I take if I still have issues with psycopg2 indicating that pg_config is not found?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5db86809'),\n",
       " ('How do I install PostgreSQL on a Mac if required for resolving psycopg2 installation problems?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5db86809'),\n",
       " (\"What might cause a 'column does not exist' error when using Postgres on a MacBook Pro M2?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20c604dd'),\n",
       " ('How should I properly reference column names in join queries to avoid SQL errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20c604dd'),\n",
       " ('What specific quoting method should I use for column names to prevent errors in Pyscopg2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20c604dd'),\n",
       " ('Is there a difference between using single quotes and double quotes for column names in PostgreSQL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20c604dd'),\n",
       " ('What error message indicates an issue with column names when executing queries in Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20c604dd'),\n",
       " (\"Why doesn't the Create server dialog appear in pgAdmin?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b11b8c15'),\n",
       " (\"What should I do if pgAdmin's Create server dialog is missing?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b11b8c15'),\n",
       " ('Is there a reason the Create server dialog is not showing in the latest version of pgAdmin?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b11b8c15'),\n",
       " (\"How can I create a server in pgAdmin if the dialog doesn't show?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b11b8c15'),\n",
       " ('What alternative action can I take to create a server in pgAdmin?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b11b8c15'),\n",
       " ('What could cause a blank or white screen when logging into pgAdmin in a browser?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a6475348'),\n",
       " ('What error message was displayed in the terminal of the pgAdmin container when I encountered the login issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a6475348'),\n",
       " ('What environment variable needs to be set to avoid the CSRF error when running pgAdmin in Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a6475348'),\n",
       " (\"What modifications are needed in the 'docker run' command to resolve the issue with pgAdmin?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a6475348'),\n",
       " ('How can using VSCode locally help prevent the blank screen issue when working with GitHub Codespaces?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a6475348'),\n",
       " ('What should I do if I cannot access the pgAdmin interface through my web browser after starting the container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1ea7680e'),\n",
       " (\"How did you modify the 'docker run' command to successfully access pgAdmin?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1ea7680e'),\n",
       " ('What changes did you make to the docker-compose.yaml to allow pgAdmin access?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1ea7680e'),\n",
       " (\"I encountered a ModuleNotFoundError for 'pysqlite2'; how did you resolve this issue?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1ea7680e'),\n",
       " ('Where can I find the missing sqlite3.dll file to fix the DLL load error I am experiencing?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1ea7680e'),\n",
       " ('What should I do if I am missing 100000 records while ingesting data using the Jupyter notebook?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10acd478'),\n",
       " ('Can you explain why I only see about 1.2 million rows instead of the expected 1.3 million when running the script again?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10acd478'),\n",
       " ('Is there a recommended video that I should watch to understand how to properly ingest the NY Taxi Data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10acd478'),\n",
       " ('Why does running the entire script in the Jupyter notebook result in skipping the first chunk of records?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10acd478'),\n",
       " ('What specific change do I need to make in the notebook to ensure I ingest all the records correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10acd478'),\n",
       " ('How can I read a CSV file properly in Python without encountering errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '752e8452'),\n",
       " ('What is the advantage of using a compressed CSV file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '752e8452'),\n",
       " ('What command do I need to run to install gunzip on an Ubuntu machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '752e8452'),\n",
       " ('Is there a way to preview uncompressed CSV files easily?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '752e8452'),\n",
       " ('What specific warning should I be aware of when executing my Python script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '752e8452'),\n",
       " ('How can I configure Pandas to automatically handle date conversion when reading a CSV file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa6f52b8'),\n",
       " ('What parameter do I need to use with pd.read_csv to specify which columns should be parsed as dates?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa6f52b8'),\n",
       " ('Can you provide an example of using parse_dates with the pd.read_csv function?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa6f52b8'),\n",
       " ('What will be the data types of the columns after using parse_dates with my CSV data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa6f52b8'),\n",
       " ('Is it necessary to convert date strings to datetime types after importing data with Pandas if I use the appropriate parameter?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa6f52b8'),\n",
       " ('How can I download data using curl in my Python script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3dacbb98'),\n",
       " ('What command should I use to retrieve a CSV file from a GitHub link?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3dacbb98'),\n",
       " ('Is there a specific format for the curl command in Python?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3dacbb98'),\n",
       " ('What function allows me to execute system commands like curl?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3dacbb98'),\n",
       " ('Can you provide a Python example for using curl to get data from a URL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3dacbb98'),\n",
       " ('How can I read a Gzip compressed CSV file in Pandas?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8b71a398'),\n",
       " ('What file extension is used for a Gzip compressed CSV file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8b71a398'),\n",
       " ('Which function in Pandas do I use to read CSV files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8b71a398'),\n",
       " ('What parameters can the read_csv() function accept?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8b71a398'),\n",
       " ('Can you give an example of reading a Gzip compressed CSV file with Pandas?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8b71a398'),\n",
       " ('What is the recommended method for processing parquet files in Python?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa244fa0'),\n",
       " (\"How does the process of ingesting parquet files differ from using pandas' read_csv method?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa244fa0'),\n",
       " ('Can you provide an example of how to clear an existing SQL table before ingesting new data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa244fa0'),\n",
       " ('What library do we need to use to handle parquet files effectively in Python?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa244fa0'),\n",
       " ('What steps are involved in iterating through a parquet file and inserting its data into a PostgreSQL database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'aa244fa0'),\n",
       " ('What error might occur when executing a Jupyter notebook cell that imports SQLAlchemy?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eac816d7'),\n",
       " (\"How can I resolve an ImportError related to 'TypeAliasType' in Python?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eac816d7'),\n",
       " (\"Is there a specific version requirement for the 'typing_extensions' module to avoid the error?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eac816d7'),\n",
       " (\"What are the methods I can use to update the 'typing_extensions' module in my environment?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eac816d7'),\n",
       " ('What is the import statement that triggers the error in the SQLAlchemy library?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eac816d7'),\n",
       " (\"What connection string should I use to avoid the 'TypeError: module object is not callable' when working with SQLAlchemy?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd44d1c77'),\n",
       " ('How can I correctly create an engine for a PostgreSQL database using SQLAlchemy?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd44d1c77'),\n",
       " ('What is the appropriate format for the connection string for connecting to a local PostgreSQL database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd44d1c77'),\n",
       " ('Why do I receive a TypeError when attempting to use create_engine with my original connection string?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd44d1c77'),\n",
       " ('Can you provide a corrected example for creating a connection with SQLAlchemy and PostgreSQL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'd44d1c77'),\n",
       " ('What error might occur when executing a cell in Jupyter Notebook related to SQLAlchemy?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ed34766a'),\n",
       " (\"How can I resolve the ModuleNotFoundError for 'psycopg2'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ed34766a'),\n",
       " ('Which Python module needs to be installed for PostgreSQL connectivity?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ed34766a'),\n",
       " (\"What commands can I use to install the missing 'psycopg2' module?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ed34766a'),\n",
       " ('Under what circumstances would I see the error related to the PostgreSQL engine connection?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'ed34766a'),\n",
       " ('What should I do if I receive an error about adding Google Cloud SDK to the PATH on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fd714677'),\n",
       " ('Are there steps I need to follow to set up Git Bash correctly on my Windows system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fd714677'),\n",
       " ('How can I ensure that Conda is added to the PATH when installing Anaconda Navigator?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fd714677'),\n",
       " ('What options should I select during the Git Bash installation process?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fd714677'),\n",
       " ('Is there a way to make Git Bash my default terminal in Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'fd714677'),\n",
       " ('What should I do if I encounter a project creation failure due to the error message stating that the requested entity already exists?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9de2c3e9'),\n",
       " ('Why does the FAQ suggest that I might not need this information regarding project creation failures?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9de2c3e9'),\n",
       " ('Where should I go to create a project instead of relying on command-line instructions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9de2c3e9'),\n",
       " (\"What are the implications of using a common project ID like 'testproject' when creating a new project in GCP?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9de2c3e9'),\n",
       " ('Can you explain what the status code 409 signifies in the response I receive during project creation attempts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9de2c3e9'),\n",
       " (\"What should I do if I encounter a '403: absent billing account' error on GCP?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '827dd4af'),\n",
       " ('How can I find my unique project ID on the GCP Dashboard?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '827dd4af'),\n",
       " ('What might prevent my billing account from linking to my current project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '827dd4af'),\n",
       " ('Where can I locate the project ID that I need to enter?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '827dd4af'),\n",
       " ('Why is it important to enter my specific project ID in the GCP setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '827dd4af'),\n",
       " ('What should I do if my credit card is not accepted by Google for my GCP account?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a42a7e8c'),\n",
       " ('Is there a particular bank that has been successful for making payments in GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a42a7e8c'),\n",
       " ('What other payment options do you recommend if my card is refused?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a42a7e8c'),\n",
       " ('How likely is it that Google support will assist with account issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a42a7e8c'),\n",
       " ('Are there any alternative payment methods that are known to work with Google Cloud?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a42a7e8c'),\n",
       " ('Could you please explain how I can locate the ny-rides.json file in Google Cloud Platform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4eefdd01'),\n",
       " ('What are the specific steps I need to follow to access my private file in GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4eefdd01'),\n",
       " ('In GCP, how do I navigate to the Service Accounts Keys tab to find the ny-rides.json file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4eefdd01'),\n",
       " ('Can you clarify where I should click in GCP after selecting my project to create a JSON key?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4eefdd01'),\n",
       " (\"What should I do after clicking the email in the Service Accounts Keys tab to find the 'KEYS' option?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4eefdd01'),\n",
       " ('Is it necessary to remove my instance in Google Cloud after watching the lecture?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0282578d'),\n",
       " ('What happens if I delete my instance in Google Cloud?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0282578d'),\n",
       " (\"Will I need to delete instances more than once if I don't follow instructions?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0282578d'),\n",
       " ('Could you clarify if deleting the instance is required in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0282578d'),\n",
       " ('What advice do you have regarding instances on Google Cloud during this module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0282578d'),\n",
       " ('What commands can I use to monitor the system resources on my virtual machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bd3e60fd'),\n",
       " ('Which command will show me the disk usage of a specific directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bd3e60fd'),\n",
       " ('How can I check the currently active network connections on my virtual machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bd3e60fd'),\n",
       " ('What command should I use to view the hardware configuration of my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bd3e60fd'),\n",
       " ('How can I find out who is currently logged into my system along with their activities?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bd3e60fd'),\n",
       " ('What should I do if I receive an error message stating that billing has not been enabled for my project, even though I believe I have already set it up?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c4e9bc60'),\n",
       " (\"Can you give me a solution if I've confirmed my billing account is enabled but still see the billing error?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c4e9bc60'),\n",
       " ('What is the specific error message I might encounter related to billing when working on my dataset?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c4e9bc60'),\n",
       " (\"Is there a recommended action to take if I'm facing a billing-related error with my project on Google Cloud?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c4e9bc60'),\n",
       " (\"How can I resolve the issue if I get a 403 error indicating that billing is not enabled for my project's dataset?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c4e9bc60'),\n",
       " ('What should I do if I encounter an error related to Application Default Credentials when installing the Google Cloud SDK on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f10b49be'),\n",
       " ('How can I resolve the issue of not being able to find a quota project while using the Google Cloud SDK?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f10b49be'),\n",
       " ('What steps did you take after reinstalling the Google Cloud SDK to ensure it was functioning correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f10b49be'),\n",
       " ('How do I create a new Virtual Machine instance from an image if my original VM cannot start due to resource issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f10b49be'),\n",
       " ('What adjustments do I need to make on the settings page when creating a new VM instance from an image in GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f10b49be'),\n",
       " ('Is it really necessary to use a GCP VM for this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3184bd8b'),\n",
       " ('What issues did students face that led to the creation of the GCP VM video?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3184bd8b'),\n",
       " ('Can I work with my own environment instead of using the GCP VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3184bd8b'),\n",
       " ('What are the benefits of using my own environment while working on the course material?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3184bd8b'),\n",
       " (\"Why can't I commit changes directly from the repo cloned in the GCP VM?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3184bd8b'),\n",
       " (\"What should I do if I encounter a 'Permission denied' error while trying to create the '.ssh' directory?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8bea4d53'),\n",
       " ('Where is the correct location to create the directory for SSH?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8bea4d53'),\n",
       " ('Why does the command fail when executed in the root folder instead of my home directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8bea4d53'),\n",
       " ('Is there a tutorial or resource that can help me understand this issue better?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8bea4d53'),\n",
       " (\"Can I create the '.ssh' directory in any other location besides my home directory?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8bea4d53'),\n",
       " ('What should I do if I encounter a permissions error when saving files in a GCP VM using VS Code?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '86d11cc0'),\n",
       " ('How can I change the ownership of files that I need to edit in my GCP VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '86d11cc0'),\n",
       " (\"What command do I use to fix the 'permission denied' error when attempting to save files in my VM?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '86d11cc0'),\n",
       " ('Is there a specific command I can run to resolve saving issues in VS Code related to file permissions?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '86d11cc0'),\n",
       " ('What steps should I take to ensure I have access to edit files located in my GCP VM directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '86d11cc0'),\n",
       " ('How can I troubleshoot a timeout issue when connecting to my GCP VM via SSH?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2cb48591'),\n",
       " ('What steps should I take if my VM was accessible last week but is timing out this week?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2cb48591'),\n",
       " ('What should I do to ensure my VM is running before trying to connect?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2cb48591'),\n",
       " ('How do I locate and edit the config file within my ~/.ssh folder?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2cb48591'),\n",
       " ('What is the process for retrieving the External IP of my VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2cb48591'),\n",
       " ('How can I fix the issue of not being able to connect to my GCP VM on port 22?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9523c813'),\n",
       " ('What steps do I need to take to edit my VM settings in GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9523c813'),\n",
       " ('Where do I find the Automation section to add a startup script in my VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9523c813'),\n",
       " ('What specific command should I include in the startup script to allow SSH connections?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9523c813'),\n",
       " ('Do I need to stop and restart my VM after adding the startup script?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '9523c813'),\n",
       " ('How can I forward the ports for pgAdmin, postgres, and Jupyter Notebook from GCP without relying on VS Code?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4f8d9174'),\n",
       " ('What command do I need to execute on my local machine to establish the SSH connection for port forwarding?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4f8d9174'),\n",
       " ('After running the Jupyter Notebook command, where can I find the access token if I encounter credential issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4f8d9174'),\n",
       " ('What specific ports do I need to use for accessing pgAdmin and Jupyter Notebook from my local browser?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4f8d9174'),\n",
       " ('Is there a combined SSH command for forwarding both pgAdmin and postgres at the same time, and if so, what is it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4f8d9174'),\n",
       " ('What should I do if gcloud authentication hangs while using MS VS Code in WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29f84a82'),\n",
       " ('Why do I see an error message when attempting to login to GCP via the gcloud CLI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29f84a82'),\n",
       " ('How can I successfully open the login page after clicking the prompt in gcloud auth?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29f84a82'),\n",
       " ('What steps should I follow to configure Trusted Domains for gcloud auth?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29f84a82'),\n",
       " ('How can I ensure that gcloud auth works seamlessly next time I try to log in?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29f84a82'),\n",
       " ('What could cause the error when Terraform fails to query available provider packages?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20a01fd0'),\n",
       " ('How can I resolve the issue of Terraform not accessing the online registry?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20a01fd0'),\n",
       " ('What steps should I take if I encounter a request failure for the provider hashicorp/google?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20a01fd0'),\n",
       " (\"Could my VPN or Firewall settings be affecting Terraform's ability to connect to the registry?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20a01fd0'),\n",
       " ('What actions might I take to fix the error after checking my network settings?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '20a01fd0'),\n",
       " (\"What might cause the network error related to Terraform when trying to access Google's storage service?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a712a20'),\n",
       " ('How does using a VPN affect the connectivity issues I may face with Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a712a20'),\n",
       " ('What steps did you take to resolve the Terraform error you encountered?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a712a20'),\n",
       " ('Why does the terminal program not automatically use the system proxy when running Terraform commands?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a712a20'),\n",
       " ('What should I do if I continue to have connectivity issues while using Terraform and a VPN?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a712a20'),\n",
       " ('How can I install Terraform specifically for WSL on my system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06021091'),\n",
       " (\"Is there a guide available for configuring Terraform on Windows 10's Linux Subsystem?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06021091'),\n",
       " ('Where can I find detailed instructions for setting up Terraform in a WSL environment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06021091'),\n",
       " ('Are there any steps outlined for installing Terraform on Windows 10 with WSL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06021091'),\n",
       " ('Can you recommend a resource for configuring Terraform using the Windows 10 Linux Subsystem?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06021091'),\n",
       " ('What should I do if I encounter a state lock error while using Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'df8ea7e8'),\n",
       " ('Is there a specific GitHub issue I can refer to regarding state lock errors in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'df8ea7e8'),\n",
       " ('Where can I find more information on resolving state lock issues in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'df8ea7e8'),\n",
       " ('Can you guide me on troubleshooting the state lock error in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'df8ea7e8'),\n",
       " (\"Where is the link to the GitHub discussion about Terraform's state lock error?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'df8ea7e8'),\n",
       " ('What error message might I encounter when executing terraform apply on WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1093daf5'),\n",
       " ('What causes the invalid JWT token error when using Terraform on WSL2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1093daf5'),\n",
       " ('How can I resolve the 400 Bad Request error related to OAuth2 when running Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1093daf5'),\n",
       " ('What command can I use to synchronize my system time and potentially fix the JWT issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1093daf5'),\n",
       " ('What should I check in the JWT claim if I receive an invalid grant error during Terraform operations?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1093daf5'),\n",
       " ('What does the Error 403 message indicate when using Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '947213b1'),\n",
       " ('How can I resolve the Access Denied issue with Google Cloud?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '947213b1'),\n",
       " ('Where should the GOOGLE_APPLICATION_CREDENTIALS point to?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '947213b1'),\n",
       " ('What command should I run to activate the service account?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '947213b1'),\n",
       " ('What is the format of the file referenced in GOOGLE_APPLICATION_CREDENTIALS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '947213b1'),\n",
       " ('Is it necessary to create a separate service account for Terraform during the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '002d4943'),\n",
       " ('How many service accounts do I need for the services in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '002d4943'),\n",
       " ('What should I do after obtaining the JSON file with my credentials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '002d4943'),\n",
       " ('Will one service account cover all resources I use in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '002d4943'),\n",
       " ('What is the importance of setting my environment variable after getting my credentials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '002d4943'),\n",
       " ('Where is the download link for Terraform 1.1.3 for Linux AMD 64?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8dc77677'),\n",
       " ('Can you provide me with the location of Terraform version 1.1.3 for Linux using AMD 64 architecture?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8dc77677'),\n",
       " ('Where can I access the download for Terraform 1.1.3 specifically for Linux AMD 64?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8dc77677'),\n",
       " ('Is there a direct link available for downloading Terraform 1.1.3 for Linux with AMD 64?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8dc77677'),\n",
       " ('What is the URL for obtaining Terraform version 1.1.3 for Linux AMD 64?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8dc77677'),\n",
       " ('What does the error message regarding Terraform initialization mean?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29d3d343'),\n",
       " ('How should I properly set up my working directory for Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29d3d343'),\n",
       " ('What command do I need to run after navigating to my working directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29d3d343'),\n",
       " ('Why is it incorrect to run terraform init outside the working directory?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29d3d343'),\n",
       " ('What files do I need to create before starting to work with Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '29d3d343'),\n",
       " ('What does the error message regarding insufficient authentication scopes indicate?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2095203'),\n",
       " ('How can I solve the error related to creating a dataset in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2095203'),\n",
       " ('What command should I run to check the status of GOOGLE_APPLICATION_CREDENTIALS?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2095203'),\n",
       " ('What does the command echo $? do in the context of this error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2095203'),\n",
       " ('Where can I find instructions on setting GOOGLE_APPLICATION_CREDENTIALS correctly?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'e2095203'),\n",
       " (\"What does the error message 'Error: googleapi: Error 403' indicate when using Terraform?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '22a2b9f2'),\n",
       " ('How can I resolve the issue of being denied permission to create a bucket in Google Cloud?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '22a2b9f2'),\n",
       " (\"What specific permission is lacking if I encounter 'storage.buckets.create access' error in Terraform?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '22a2b9f2'),\n",
       " ('Is it necessary to use the Project ID instead of the Project name to avoid this error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '22a2b9f2'),\n",
       " ('Where can I find the correct Project ID for my Google Cloud project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '22a2b9f2'),\n",
       " ('How do I manage the GCP credentials securely within my Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5d7588f0'),\n",
       " ('What is the format for specifying the Google provider in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5d7588f0'),\n",
       " ('Can I avoid hardcoding the credentials directly into my Terraform files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5d7588f0'),\n",
       " ('Which variables are necessary for configuring the Google provider in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5d7588f0'),\n",
       " ('Is there a specific method to input sensitive information like credentials in Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5d7588f0'),\n",
       " ('What is the correct SQL query to retrieve data from the zones_taxi table for the Astoria Zone?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5276a695'),\n",
       " (\"Why does the error indicate that the column 'Zone' doesn't exist in the database?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5276a695'),\n",
       " ('How do I properly reference columns that start with uppercase letters in SQL queries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5276a695'),\n",
       " (\"Can you clarify if 'Astoria Zone' actually exists in the dataset or if it's listed as 'Astoria'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5276a695'),\n",
       " ('What steps can I take to avoid similar issues with column names in my future SQL queries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5276a695'),\n",
       " (\"What should I do if I get an error stating that the Zone column doesn't exist when running SQL on taxi zones?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70c159df'),\n",
       " ('How can I avoid using quotation marks repeatedly in my SQL queries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70c159df'),\n",
       " ('Is there a preferred format for the data when putting it into the database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70c159df'),\n",
       " ('What steps should I take after loading the CSV file in Pandas to align column names?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70c159df'),\n",
       " ('How can I ensure that my column names are consistently formatted in lowercase?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70c159df'),\n",
       " ('What steps should I follow to resolve the host issue when using CURL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f55efcf0'),\n",
       " ('Can you provide a solution for the CURL error related to output.csv?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f55efcf0'),\n",
       " ('What command should Mac users use to solve the CURL error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f55efcf0'),\n",
       " ('How can I download a file using CURL if I encounter a host resolution problem?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f55efcf0'),\n",
       " ('Is there a specific command format for CURL that Mac users need to follow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f55efcf0'),\n",
       " ('What should I check if I encounter an SSH error related to hostname resolution?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2b7a8512'),\n",
       " ('Where should I verify the location of my SSH config file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2b7a8512'),\n",
       " (\"What steps can I take to fix the error indicating 'Name or service not known'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2b7a8512'),\n",
       " ('In case of SSH issues, how can I ensure proper configuration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2b7a8512'),\n",
       " ('What is the correct directory path for the SSH config file on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '2b7a8512'),\n",
       " (\"What steps do I need to follow to add Anaconda's Python to the PATH on a Linux or MacOS system?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd746c4'),\n",
       " ('How can I check if Python and pip are installed in the correct locations when using Git Bash on Windows?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd746c4'),\n",
       " ('What command should I use to permanently add Anaconda to my PATH on a Linux system?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd746c4'),\n",
       " (\"What should I do if I'm using Windows without Git Bash to add Anaconda to the PATH?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd746c4'),\n",
       " ('How can I refresh my environment after making changes to the PATH variable?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '1cd746c4'),\n",
       " ('What should I do if I encounter the error stating that the address is already in use when starting the userland proxy?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d367222'),\n",
       " ('How can I resolve the permission denied error when attempting to stop a Docker container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d367222'),\n",
       " ('What command do I need to run in Linux to fix the issue of not being able to import the psycopg2 module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d367222'),\n",
       " ('What could be causing the Docker build error related to file context, and how can I resolve it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d367222'),\n",
       " ('If Docker requires permission to access a file during a build, what steps can I take to address this issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d367222'),\n",
       " ('How can I create a requirements.txt file that is compatible with pip from Anaconda?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '84e601e1'),\n",
       " ('What command should I run to install pip using Anaconda?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '84e601e1'),\n",
       " (\"Why doesn't conda list -d > requirements.txt work for creating a requirements file?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '84e601e1'),\n",
       " ('What is the correct way to export a pip-friendly requirements.txt file from Anaconda?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '84e601e1'),\n",
       " ('Will using pip freeze > requirements.txt provide accurate paths for my dependencies?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '84e601e1'),\n",
       " ('Can you provide the links to the FAQ documents for Prefect and Airflow from previous cohorts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4cf83cc2'),\n",
       " ('Where can I find the FAQ questions pertaining to the orchestration module for past classes?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4cf83cc2'),\n",
       " ('Is there a specific document that contains the previous cohort questions for the orchestration module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4cf83cc2'),\n",
       " ('Are there separate documents for Prefect and Airflow containing FAQ questions from earlier cohorts?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4cf83cc2'),\n",
       " ('What URLs should I visit to access the FAQ records related to the orchestration module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4cf83cc2'),\n",
       " ('What should I do if my Docker containers exit with code 132 when I run docker compose up?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5adc5188'),\n",
       " (\"Is the issue with Docker containers due to my computer's architecture or hardware?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5adc5188'),\n",
       " ('What alternative solution can I try if purchasing a new computer is not an option?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5adc5188'),\n",
       " ('What version of Ubuntu and Docker is mentioned in the issue recorded about Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5adc5188'),\n",
       " ('Why is it inconclusive to determine the cause of the Docker containers exiting without knowing the VirtualBox configuration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5adc5188'),\n",
       " ('What is the primary reason behind unexpected kernel restarts in WSL 2 when using Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3ef0bb96'),\n",
       " ('How can I check if my .wslconfig file exists in my Bash environment?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3ef0bb96'),\n",
       " ('What should I do if I notice WSL 2 not allocating enough CPU cores to Docker?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3ef0bb96'),\n",
       " ('How can I modify my .wslconfig file to improve Docker performance in WSL 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3ef0bb96'),\n",
       " ('What steps should I take after editing my .wslconfig file to ensure changes are applied?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '3ef0bb96'),\n",
       " ('What is the link to find the issue and solution for configuring Postgres in Module 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a41ce360'),\n",
       " ('Where can I access the discussion about Postgres configuration problems?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a41ce360'),\n",
       " ('Is there a specific Slack channel for questions related to Postgres setup?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a41ce360'),\n",
       " ('Can you share the resource for troubleshooting Postgres mentioned in the course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a41ce360'),\n",
       " ('What do I do if I encounter issues while configuring Postgres?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a41ce360'),\n",
       " ('What should I do if I encounter an OperationalError while trying to connect to my PostgreSQL database?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b1cf59e5'),\n",
       " ('How can I resolve the issue if the connection to the server at localhost fails?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b1cf59e5'),\n",
       " ('What is the correct port to set for the POSTGRES_PORT variable in the io_config.yml file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b1cf59e5'),\n",
       " ('Is it necessary to change the POSTGRES_PORT to match a conflicting PostgreSQL installation on my host machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b1cf59e5'),\n",
       " ('Where can I find the POSTGRES_PORT variable that needs to be configured for the mage container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b1cf59e5'),\n",
       " ('What could cause a KeyError when executing SELECT 1 in module 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f9d6f8bd'),\n",
       " ('How do I avoid the KeyError when using PostgreSQL in MAGE?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f9d6f8bd'),\n",
       " ('What should I check if I encounter a KeyError while working on workflow orchestration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f9d6f8bd'),\n",
       " ('Which profile do I need to select to successfully execute queries?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f9d6f8bd'),\n",
       " (\"Where can I find the dropdown menu to select the 'dev' profile?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f9d6f8bd'),\n",
       " ('What steps should I take if I encounter the ConnectionError with a timeout during my workflow orchestration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3adb937'),\n",
       " ('How can I resolve the 404 Not Found error when testing the BigQuery connection for my dataset?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3adb937'),\n",
       " ('What specific timeout value should I set in the mage io_config.yaml file to fix the connection issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3adb937'),\n",
       " ('Is there a specific setting I need to check if my service account has all the necessary roles but still returns a Not Found error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3adb937'),\n",
       " ('What should I do after I update the timeout value in my configuration file to ensure the changes take effect?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f3adb937'),\n",
       " ('What should I do if I encounter a RefreshError related to invalid JWT while working with workflow orchestration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb3d6d36'),\n",
       " ('Can you guide me on how to resolve a problem where the error states my JWT must be short-lived?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb3d6d36'),\n",
       " ('Where can I find more information on fixing the invalid grant issue related to JWT tokens?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb3d6d36'),\n",
       " (\"What does the error message about checking 'iat' and 'exp' values in the JWT claim mean?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb3d6d36'),\n",
       " ('Is there a reliable source or link for troubleshooting the invalid JWT token issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eb3d6d36'),\n",
       " ('What causes the IndexError: list index out of range in the Mage workflow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a76e1f4d'),\n",
       " ('How can I find the original solution for the IndexError in Mage version 0.9.61?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a76e1f4d'),\n",
       " ('What steps should I take to resolve the error that arises after addressing the issue in 2.2.4?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a76e1f4d'),\n",
       " ('Is there a newer version of Mage that I should consider using to avoid this error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a76e1f4d'),\n",
       " ('What changes need to be made in the docker-compose.yaml file to fix this problem?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a76e1f4d'),\n",
       " ('What should I do if I encounter an OSError indicating that I cannot save a file into a non-existent directory in Module 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '934facf8'),\n",
       " ('How can I ensure that the directory for saving a file exists before attempting to save it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '934facf8'),\n",
       " ('What specific code should I add to handle the situation where the directory does not exist?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '934facf8'),\n",
       " ('Is there a way to convert a file path to a posix format in this module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '934facf8'),\n",
       " ('Where can I find more information or discussion related to saving files and handling directories in this course?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '934facf8'),\n",
       " ('What specific steps do I need to follow for deploying Mage to GCP using Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a2c7b59f'),\n",
       " ('Is there any information available about enabling the Cloud Filestore API in Google Cloud?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a2c7b59f'),\n",
       " ('During the deployment process, what does Terraform prompt me to enter?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a2c7b59f'),\n",
       " (\"Can you explain what I need to do after the 'terraform apply' command is executed?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a2c7b59f'),\n",
       " ('Where can I find the video that has the details about deploying Mage to GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a2c7b59f'),\n",
       " ('What steps should I follow to run multiple Docker containers from different directories without issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '997d4aaa'),\n",
       " ('How can I customize the host port in my Docker setup for Mage on my local machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '997d4aaa'),\n",
       " ('What should I do if I encounter an insufficient authentication scopes error while terraforming resources in a GCP VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '997d4aaa'),\n",
       " ('What specific permission changes are necessary in the GCP console to resolve the insufficient permission error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '997d4aaa'),\n",
       " ('How can I ensure that my GCP virtual machine has the correct access scopes for Google APIs?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '997d4aaa'),\n",
       " ('What issues might I encounter when deploying infrastructures using Terraform on a free trial account in GCP?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc269b95'),\n",
       " (\"Is the Load Balancer service available for users on GCP's free trial?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc269b95'),\n",
       " ('What steps should I take if I face a Security Policies quota problem while using Terraform?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc269b95'),\n",
       " ('Can you explain how to modify the main.tf file to resolve the load balancer issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc269b95'),\n",
       " ('What command should I run after deleting the load_balancer.tf file to clean up the created infrastructure?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'bc269b95'),\n",
       " ('What should I do if I encounter an error when executing terraform apply for the GCP module?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10ea342e'),\n",
       " ('How can I ensure that my project-id, region, and zones are set correctly in the GCP workflow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10ea342e'),\n",
       " ('What steps should I take if the MAGE Terraform files are taking longer than expected to deploy?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10ea342e'),\n",
       " ('Why might some GCP resources not be destroyed after running terraform destroy, and how can I find them?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10ea342e'),\n",
       " ('How can I check my GCP billing account to monitor charges related to the MAGE Terraform IaC?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '10ea342e'),\n",
       " (\"What does the error message indicate regarding the permission 'vpcaccess.connectors.create'?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4bd23594'),\n",
       " (\"How can I resolve the 'Permission denied' error when creating a Connector?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4bd23594'),\n",
       " ('What role should I assign to the Service Account to fix the error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4bd23594'),\n",
       " ('What is the specific resource mentioned in the error details for the denied permission?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4bd23594'),\n",
       " ('In which part of the Terraform configuration does the error occur related to the Connector?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '4bd23594'),\n",
       " ('Why is it that I cannot save a file in a folder that does not exist within my project?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b0d48cd7'),\n",
       " ('What should I do if Git fails to push my empty directory to GitHub?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b0d48cd7'),\n",
       " ('Can you explain how to create a directory in my code if it is not already present?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b0d48cd7'),\n",
       " ('Why might my local relative path not function properly when using GitHub storage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b0d48cd7'),\n",
       " ('What are the recommended practices for handling file paths when uploading to GCS buckets?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'b0d48cd7'),\n",
       " ('What are the names of the pickup datetime columns in the green and yellow datasets?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70a37f2c'),\n",
       " ('How should I adjust my scripts based on the dataset I am using?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70a37f2c'),\n",
       " ('Is there a difference between lpep_pickup_datetime and tpep_pickup_datetime?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70a37f2c'),\n",
       " ('Can I use the same script for both datasets?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70a37f2c'),\n",
       " ('Which dataset contains lpep_pickup_datetime?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '70a37f2c'),\n",
       " ('What should I use to download the VSC utilizing Pandas?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8ab78bee'),\n",
       " ('How do I handle large datasets in Pandas when reading from a URL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8ab78bee'),\n",
       " ('What method is recommended for appending data to a parquet file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8ab78bee'),\n",
       " ('Which compression technique should I use when saving to parquet format?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8ab78bee'),\n",
       " ('What engine should be specified when appending data to parquet files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '8ab78bee'),\n",
       " ('What does it mean when I encounter a push to Docker image failure?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '54c6db2f'),\n",
       " (\"What should I do if I see a 'requested access to the resource is denied' error?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  '54c6db2f'),\n",
       " ('How can I ensure that I am properly logged into Docker Desktop before pushing an image?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '54c6db2f'),\n",
       " ('Is it important to use the correct username when pushing Docker images, and why?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '54c6db2f'),\n",
       " ('What commands do I need to run for building and pushing a Docker image with my username?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '54c6db2f'),\n",
       " (\"What does it mean when my flow script fails and displays a 'killed' message?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c5b998f3'),\n",
       " ('How can I determine if memory issues are causing my flow script failures?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c5b998f3'),\n",
       " ('What is the recommended RAM for a VM to prevent flow script termination?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c5b998f3'),\n",
       " (\"If my VM has 8GB of RAM, how much should I upgrade it to if I'm experiencing issues?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c5b998f3'),\n",
       " ('Are there any specific indicators that confirm my flow script is failing due to memory shortage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c5b998f3'),\n",
       " ('What should I do if I encounter a situation where my GCP VM disk space is full?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eec29536'),\n",
       " ('How can I check which directories are consuming the most disk space on my VM?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eec29536'),\n",
       " ('Where are cached flows stored that might be taking up too much space?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eec29536'),\n",
       " ('What steps should I take to delete older flows from my VM and prevent errors when running new ones?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eec29536'),\n",
       " ('How can I resolve the SSL certificate verification error I received while trying to run flows on my MAC?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'eec29536'),\n",
       " ('What does it indicate when my Docker container crashes with a status code of 137?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '727e5a69'),\n",
       " ('Why does my container use so much RAM when executing tasks in the homework?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '727e5a69'),\n",
       " ('What steps can I take if restarting my computer does not resolve the issue with the container?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '727e5a69'),\n",
       " ('Can you suggest ways to allocate more resources to Docker on my workstation?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '727e5a69'),\n",
       " ('Is there a free online compute environment I can use if my local machine struggles with container memory requirements?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '727e5a69'),\n",
       " ('What was the issue that caused the timeout during the task running the ETL script in Q3?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'da899638'),\n",
       " ('Can you explain the process involved in uploading data from the web to GCS as described in the record?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'da899638'),\n",
       " ('What kind of errors might occur due to slow internet connections, as mentioned in the FAQ?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'da899638'),\n",
       " ('What is the recommended method for handling large data uploads to GCS when experiencing timeout issues?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'da899638'),\n",
       " ('How should I adjust the timeout setting when uploading parquet files to accommodate larger datasets?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'da899638'),\n",
       " ('What does the UndefinedColumn error mean when exporting green_taxi data to PostgreSQL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'dde58c8f'),\n",
       " ('How can I resolve the issue of missing columns during the export process?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'dde58c8f'),\n",
       " ('What steps should I take if I encounter a re-run problem with the export block?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'dde58c8f'),\n",
       " ('Is there a specific SQL command to drop the table in Mage for the green_taxi data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'dde58c8f'),\n",
       " ('Will re-running the block work after dropping the table in PostgreSQL?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'dde58c8f'),\n",
       " ('What is the cause of the SettingWithCopyWarning error in pandas?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '207be93b'),\n",
       " ('How can I avoid encountering the SettingWithCopyWarning in my homework?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '207be93b'),\n",
       " ('What syntax should I use to set values in a DataFrame without triggering a warning?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '207be93b'),\n",
       " ('Is there a recommended method for assigning new columns in a DataFrame?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '207be93b'),\n",
       " ('What does the error indicate about the DataFrame I am working with?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '207be93b'),\n",
       " ('What are the advantages of using the Pyspark kernel in Mage over the Python kernel when working with large CSV files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f0617e65'),\n",
       " ('Is there any specific documentation available for utilizing the Pyspark kernel in Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f0617e65'),\n",
       " ('How does the performance of Pyspark compare to Pandas when handling large datasets?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f0617e65'),\n",
       " ('Can you provide guidance on switching from the Python kernel to the Pyspark kernel in Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f0617e65'),\n",
       " ('Are there any limitations or challenges I should be aware of when using Pyspark for large CSV files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'f0617e65'),\n",
       " ('What steps should I follow to delete a block from a pipeline without encountering errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6290a1a6'),\n",
       " ('Is it necessary to delete connections before removing a block in a pipeline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6290a1a6'),\n",
       " ('Can you explain the process of removing a connection between blocks in a pipeline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6290a1a6'),\n",
       " ('What should I do if I face an error while trying to delete a block in my pipeline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6290a1a6'),\n",
       " ('Are there any prerequisites to consider before deleting a block in my workflow orchestration?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6290a1a6'),\n",
       " ('What should I do if I encounter a permission denied error while trying to edit the Pipeline name in Mage UI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a06248c'),\n",
       " ('Is there a workaround for editing the Pipeline name if the UI does not allow it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a06248c'),\n",
       " ('Can I save my work and edit the Pipeline name later if I face an error?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a06248c'),\n",
       " ('What steps should I take if I cannot change the Pipeline name in Mage UI?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a06248c'),\n",
       " ('Why does Mage UI throw a permission denied error when I attempt to rename the Pipeline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '5a06248c'),\n",
       " ('What are the steps to load all partitioned files I created into BigQuery using Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c46a2e9e'),\n",
       " ('Can you explain how to load specific date ranges from partitioned files into BigQuery with Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c46a2e9e'),\n",
       " (\"What should I do if I encounter an 'undefined column' error while connecting to the green_taxi table?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c46a2e9e'),\n",
       " ('Is there a way to delete the green_taxi table if it already exists before loading new data?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c46a2e9e'),\n",
       " (\"How can I adjust the Data Extractor's settings for loading data from the dataframe in Mage?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c46a2e9e'),\n",
       " ('Where can I find the necessary mage files for Homework 2 on my local machine?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0513ab8a'),\n",
       " ('What specific folders should I look for in my mage directory to complete the homework submission?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0513ab8a'),\n",
       " ('How do I download the entire pipeline and what additional files will I receive?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0513ab8a'),\n",
       " ('What types of files do I need to download from the mage folders for the blocks in my pipeline?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0513ab8a'),\n",
       " ('Once I have downloaded the required files, what should I do with them before submitting on GitHub?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0513ab8a'),\n",
       " ('What steps do I need to follow to integrate files from the Mage repository into my personal Data Engineering Zoomcamp repository?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a9385356'),\n",
       " ('Why do I need to move the contents of the .gitignore file to include the Mage repo files in my Zoomcamp repo?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a9385356'),\n",
       " ('What commands should I run in the terminal after accessing the Mage folder to prepare it for inclusion in my main repo?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a9385356'),\n",
       " ('How does GitHub treat the Mage repo and my Data Engineering Zoomcamp repo when I try to include their files?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a9385356'),\n",
       " (\"What does the command 'git remote remove origin' accomplish when working with the Mage repository?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a9385356'),\n",
       " ('What error did I encounter when adding multiple assertions in Module 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c30468c0'),\n",
       " ('What should I do if I receive a ValueError about the truth value of a Series?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c30468c0'),\n",
       " ('How can I correctly filter data based on multiple conditions in my code?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c30468c0'),\n",
       " (\"Which operator should I use instead of 'and' for combining conditions in a DataFrame?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c30468c0'),\n",
       " ('Where can I find more discussions or solutions related to this ValueError issue?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'c30468c0'),\n",
       " ('What should I do if I notice that my Mage AI files are missing after starting my PC and running docker compose up?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '305aead7'),\n",
       " ('Is there a specific command I need to use to properly shut down the Mage Docker before restarting it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '305aead7'),\n",
       " ('How can I ensure that I am in the correct directory before executing the docker compose up command?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '305aead7'),\n",
       " ('What steps should I take if I continue encountering issues with disappearing files while using Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '305aead7'),\n",
       " ('Where can I find additional discussions or solutions regarding issues with Mage AI files in the course community?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '305aead7'),\n",
       " ('What kind of errors can occur in the io.config.yaml file in relation to the Mage section?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '77410975'),\n",
       " ('How should I fix errors that are caused by incorrect quotes in the io.config.yaml file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '77410975'),\n",
       " ('What specific modifications are necessary for fixing trailing side errors in the io.config.yaml file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '77410975'),\n",
       " ('Who can I refer to for help with issues related to the io.config.yaml file in Module 2?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '77410975'),\n",
       " ('Are there particular characters that should be avoided in the io.config.yaml file to prevent errors?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '77410975'),\n",
       " ('What error occurs when exporting data from Mage to a GCS bucket using pyarrow?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0952abde'),\n",
       " ('What does the ArrowException indicate about permissions when accessing the GCP credentials file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0952abde'),\n",
       " ('How do I resolve the issue of Mage being unable to open the credentials file?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0952abde'),\n",
       " ('What steps should I follow to create the necessary credentials folder for Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0952abde'),\n",
       " ('Where do I update the code to specify the path to my GCP service account credentials?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '0952abde'),\n",
       " ('What does the OSError related to Google Cloud indicate when working with Mage?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c4326eb'),\n",
       " ('Why might I encounter a retry policy exhaustion error while trying to get bucket metadata?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c4326eb'),\n",
       " ('What is required to successfully complete a request for Google Cloud resources?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c4326eb'),\n",
       " ('Where can I find more information about Google Cloud authentication?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c4326eb'),\n",
       " ('What does the underlying error message suggest about the issue with performing the work?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '7c4326eb'),\n",
       " ('What issue arises when I try to export data from Mage to a Google Cloud Storage bucket?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1fc1a14'),\n",
       " (\"What does the error message indicate regarding the service account's permissions?\",\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1fc1a14'),\n",
       " ('How can I resolve the PermissionError related to Google Cloud Storage access?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1fc1a14'),\n",
       " ('What steps do I need to follow to add the necessary role to my service account?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1fc1a14'),\n",
       " ('What role should I assign to the service account for it to gain access to the storage bucket?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  'a1fc1a14'),\n",
       " ('What preparations do I need to make for my pyspark script before sending it to the Dataproc cluster?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d67fba9'),\n",
       " ('How do I create a Dataproc Cluster in the GCP Console?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d67fba9'),\n",
       " ('What changes must be made to the service account in order to add the Dataproc Editor role?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d67fba9'),\n",
       " ('Where should I place my python script in the GCS bucket and how do I access it?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d67fba9'),\n",
       " ('Is there a specific requirement for installing the gcloud CLI to allow Mage to access Dataproc?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '6d67fba9'),\n",
       " ('What is a potential solution for the long installation time of zip and unzip packages in Docker-compose?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06876291'),\n",
       " ('How can I automate the installation of additional packages when using apt-get?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06876291'),\n",
       " ('Is there an alternative method for unpacking datasets besides using zip and unzip?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06876291'),\n",
       " ('Why might Docker-compose take a long time to install required packages for datasets on Linux?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06876291'),\n",
       " ('Is the Python ZipFile package available in all current Python environments?',\n",
       "  'data-engineering-zoomcamp',\n",
       "  '06876291'),\n",
       " ...]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6c0b63a-ba8d-4b2f-802c-ea3944cecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "00be3bf4-809f-41a0-9fde-fb390737aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_results, columns=['questions', 'course', 'document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b51a4c57-0bd2-4ce2-af38-c6924f9e7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ground-truth-data.csv', index =  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "47ff1bae-ce95-4892-8809-8dd3a9c78992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions,course,document\n",
      "What is the specific date and time when the course is set to begin?,data-engineering-zoomcamp,c02e79ef\n",
      "How can I stay updated with course announcements and important dates?,data-engineering-zoomcamp,c02e79ef\n",
      "Is there a registration process required before the course starts?,data-engineering-zoomcamp,c02e79ef\n",
      "What platform should I use to access the course's public calendar?,data-engineering-zoomcamp,c02e79ef\n",
      "Where can I find the link to register for the course?,data-engineering-zoomcamp,c02e79ef\n",
      "What specific skills or knowledge do I need before enrolling in this course?,data-engineering-zoomcamp,1f6520ca\n",
      "Can you point me to where I can find the requirements for this course?,data-engineering-zoomcamp,1f6520ca\n",
      "Are there any prior courses or experiences necessary for joining this program?,data-engineering-zoomcamp,1f6520ca\n",
      "Is there a resource that outlines the prerequisites for this course?,data-engineering-zoomcamp,1f6520ca\n"
     ]
    }
   ],
   "source": [
    "!head ground-truth-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3924f05-d332-40b9-9e10-aa6924f32705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/project_llm1/03_evaluation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "748f200f-9559-47f5-89d7-d76bddb474fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-rw- 1 codespace codespace 542K Oct 11 19:07 ground-truth-data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ground-truth-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d80310b-1895-4c0a-a0af-de4819d95316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='ground-truth-data.csv' target='_blank'>ground-truth-data.csv</a><br>"
      ],
      "text/plain": [
       "/workspaces/project_llm1/03_evaluation/ground-truth-data.csv"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('ground-truth-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e038a2-1f34-4abd-b9ce-f8ba17d65c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
