{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d7454b-c04f-4a90-811d-3a9f1b94fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (2.3.1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (1.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f9b97c-f5bd-4068-8fee-0f59eb2c8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from minsearch import AppendableIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccca3d5-df1a-43b5-9283-93fe08060111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chat_assistant_2 import IPythonChatInterface, Tools, ChatAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c60b20-2ec8-4c05-9202-9c3b6180833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d0567c9-fb02-40a4-b29d-aeb63bfe6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38292f81-d64b-4887-ad86-ea740eafdc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7832dbac37d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c499c84c-a44c-47a6-8114-d4dd80d40c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56de7222-f612-48bd-8697-59fb0452add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    \n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "304ed7f0-771f-4f33-9c02-002fec4b564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_tool = {\n",
    "#     \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#         \"name\": \"search\",\n",
    "#         \"description\": \"Search the FAQ database\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"query\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"query\"],\n",
    "#             \"additionalProperties\": False\n",
    "#         }\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60749c0b-fff4-40e2-8112-f7b3a9b2e30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "results = search('I just discovered the course.Can I still join now?')\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1ed30-7137-40bf-8c15-8763acb4aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c07d26-a87f-4fd1-a80f-6cb1f1da3428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be424329-663c-4895-bc70-d0bd4c688273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaa3701f-9f0e-4809-aaf5-499b2f185257",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd3d1e44-20f1-415c-bfcf-76705600feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.responses.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     input=\"hello\"\n",
    "# )\n",
    "# print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "325473d3-61ea-4083-99b4-3537918463cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it\n",
    "\n",
    "Before making any function calls, explain you reasoning behind calling the funtion.\n",
    "\n",
    "When searching in our FAQ, perform multiple search queries with differently phrased.\n",
    "\n",
    "In the end also ask a related question to make it more engaging !\n",
    "\"\"\".strip()\n",
    "\n",
    "#question = \"what are the things I need to install and learn to do well in module 1?\"\n",
    "\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages, \n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "526bc522-e7f2-46bb-a4d1-97d7bad721ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'message'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82d5c121-f724-4900-ba21-b403d51961fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_0c0e5bc957ec607d006905ec1b173481a29b004fb2735f6566', content=[ResponseOutputText(annotations=[], text='Sure! To help answer the student\\'s question, I\\'ll start by searching the FAQ database for relevant information. Since I want to ensure I cover various angles and phrasing of the same topic, I will conduct multiple searches with different but related queries.\\n\\nFor example, if a student asks about assignment deadlines, I might search for:\\n1. \"What are the deadlines for assignments?\"\\n2. \"When are assignments due?\"\\n3. \"How can I find assignment submission dates?\"\\n\\nBy doing this, I increase the likelihood of finding comprehensive information that addresses the student\\'s query effectively.\\n\\nNow, let\\'s search the FAQ database with these varied queries. Could you please provide me with the specific question from the student?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "560cc186-3934-4d74-a0f6-de749c84b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response.output[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62d29b5e-9f3f-42c0-9a50-ebef597ff92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_call(entry):\n",
    "    args = json.loads(entry.arguments)\n",
    "    f_name = entry.name\n",
    "    f = globals()[f_name]  \n",
    "    call_id = entry.call_id\n",
    "    results = f(**args)\n",
    "    output_json = json.dumps(results)\n",
    "    \n",
    "    call_output = {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": entry.call_id,\n",
    "        \"output\": output_json,\n",
    "    }\n",
    "    return call_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b4b4f9e-c351-4ef5-87ca-c039f3642fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: How do I do well in module 2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant\n",
      "To answer your question about doing well in module 2, I want to look up specific strategies or tips related to this module, as well as any common challenges or FAQs that might be addressed in our database.\n",
      "\n",
      "First, I will perform a search for \"how to succeed in module 2\" and then follow up with a search for \"tips for module 2\" or similar phrases. This approach should help me find relevant information tailored to your needs.\n",
      "\n",
      "Let me get started on that!\n",
      "Invoking search {\"query\":\"how to succeed in module 2\"}\n",
      "Invoking search {\"query\":\"tips for module 2\"}\n",
      "Assistant\n",
      "Based on my searches, here are some tips and strategies for doing well in Module 2:\n",
      "\n",
      "1. **Understand the Concepts**: Make sure you grasp the foundational concepts before diving deeper. Take notes and summarize key points from the lectures.\n",
      "\n",
      "2. **Practice Regularly**: Engage with the assignments and hands-on labs frequently. The more you practice, the more comfortable you'll become with the material.\n",
      "\n",
      "3. **Utilize Resources**: Don't hesitate to use supplementary resources such as textbooks, articles, or online tutorials related to the module content.\n",
      "\n",
      "4. **Engage with the Community**: Join forums or study groups if available. Discussing topics with peers can enhance your understanding and provide new insights.\n",
      "\n",
      "5. **Stay Organized**: Keep track of deadlines for assignments and exams. Creating a study schedule can help you manage your time effectively.\n",
      "\n",
      "6. **Seek Help When Needed**: If you're struggling with a particular topic, reach out to your instructor or teaching assistants for clarification.\n",
      "\n",
      "7. **Test Your Knowledge**: Try to explain concepts to someone else or write down what you've learned after each class to reinforce your memory.\n",
      "\n",
      "If you have any specific areas of Module 2 that you feel uncertain about, let me know. \n",
      "\n",
      "Also, what part of Module 2 are you most excited to learn about, or is there a particular topic you find challenging?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: thanks, stop !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant\n",
      "You're welcome! If you have any more questions or need assistance in the future, feel free to ask. Good luck with your studies!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Ended\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input('User:').strip()\n",
    "\n",
    "    if question == 'stop':\n",
    "        print(\"Chat Ended\")\n",
    "        break\n",
    "\n",
    "    chat_messages.append({\"role\": \"user\", \"content\": question})\n",
    "    while True:\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages, \n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_funtion_call = False\n",
    "        for entry in response.output:\n",
    "        \n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'message':\n",
    "                print('Assistant')\n",
    "                print(entry.content[0].text)\n",
    "            if entry.type == 'function_call':\n",
    "                print('Invoking', entry.name, entry.arguments)\n",
    "                call_output = make_call(entry)\n",
    "                chat_messages.append(call_output)\n",
    "                has_funtion_call =  True\n",
    "        if not has_funtion_call:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380d74d2-c0cd-4052-8767-f500481c44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': \"You're a course teaching assistant.\\nYou're given a question from a course student and your task is to answer it\\n\\nWhen searching in our FAQ, perform multiple search queries with differently phrased.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'what are the things I need to install and learn to do well in module 1?'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"module 1 requirements\"}', call_id='call_TJUaPelCd7yUEhAttSt4gZD4', name='search', type='function_call', id='fc_086e2691b485ad7a006905d2ea11948194830179ad378f6c76', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_TJUaPelCd7yUEhAttSt4gZD4',\n",
       "  'output': '[{\"text\": \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\\\nTo create a virtual env and install packages (run only once)\\\\npython -m venv env\\\\nsource env/bin/activate\\\\npip install -r ../requirements.txt\\\\nTo activate it (you\\'ll need to run it every time you need the virtual env):\\\\nsource env/bin/activate\\\\nTo deactivate it:\\\\ndeactivate\\\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it\\'s env/Scripts/activate)\\\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", \"section\": \"Module 6: streaming with kafka\", \"question\": \"Module \\\\u201ckafka\\\\u201d not found when trying to run producer.py\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 372}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \\\\\"TypeError: \\'module\\' object is not callable\\\\\"\\\\nSolution:\\\\nconn_string = \\\\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\\\"\\\\nengine = create_engine(conn_string)\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLALchemy - TypeError \\'module\\' object is not callable\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 124}]'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"module 1 software to install\"}', call_id='call_iyB5yEIhIgp045I97epVyST7', name='search', type='function_call', id='fc_086e2691b485ad7a006905d2ea55f081948d960627960e8368', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_iyB5yEIhIgp045I97epVyST7',\n",
       "  'output': '[{\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"Error raised during the jupyter notebook\\\\u2019s cell execution:\\\\nengine = create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\').\\\\nSolution: Need to install Python module \\\\u201cpsycopg2\\\\u201d. Can be installed by Conda or pip.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named \\'psycopg2\\'.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 125}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"Issue:\\\\ne\\\\u2026\\\\nSolution:\\\\npip install psycopg2-binary\\\\nIf you already have it, you might need to update it:\\\\npip install psycopg2-binary --upgrade\\\\nOther methods, if the above fails:\\\\nif you are getting the \\\\u201c ModuleNotFoundError: No module named \\'psycopg2\\' \\\\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\\\nFirst uninstall the psycopg package\\\\nThen update conda or pip\\\\nThen install psycopg again using pip.\\\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Postgres - ModuleNotFoundError: No module named \\'psycopg2\\'\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 112}]'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"module 1 learning resources\"}', call_id='call_5DPwKYwLWCuZFj3L5eUM5Uid', name='search', type='function_call', id='fc_086e2691b485ad7a006905d2ea9dc48194be0ad04bf9fae80e', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_5DPwKYwLWCuZFj3L5eUM5Uid',\n",
       "  'output': '[{\"text\": \"Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\", \"section\": \"Module 6: streaming with kafka\", \"question\": \"data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 377}, {\"text\": \"Cause:\\\\nIt happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\\\\nSolution\\\\nfor updating Windows terminal which worked for me:\\\\nGo to Microsoft Store.\\\\nGo to the library of apps installed in your system.\\\\nSearch for Windows terminal.\\\\nUpdate the app and restart your system to  see the changes.\\\\nFor updating the Windows security updates:\\\\nGo to Windows updates and check if there are any pending updates from Windows, especially security updates.\\\\nDo restart your system once the updates are downloaded and installed successfully.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"WSL - Insufficient system resources exist to complete the requested service.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 94}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"Issue:\\\\ne\\\\u2026\\\\nSolution:\\\\npip install psycopg2-binary\\\\nIf you already have it, you might need to update it:\\\\npip install psycopg2-binary --upgrade\\\\nOther methods, if the above fails:\\\\nif you are getting the \\\\u201c ModuleNotFoundError: No module named \\'psycopg2\\' \\\\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\\\nFirst uninstall the psycopg package\\\\nThen update conda or pip\\\\nThen install psycopg again using pip.\\\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Postgres - ModuleNotFoundError: No module named \\'psycopg2\\'\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 112}]'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061a6e20-dc93-4b60-b767-a1e08dd07979",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsess = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    input=chat_messages, \n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb0cb210-e3c8-45be-946f-aa6d726ddfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = responsess.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc5c8d76-7f66-42e3-9b21-bca9d42a3619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_086e2691b485ad7a006905d4d30fb481948d48c67db24573d2', content=[ResponseOutputText(annotations=[], text=\"To do well in Module 1 of the course, here are some key things you need to install and learn:\\n\\n### Install\\n1. **Docker**: You'll work with Docker containers, so ensuring Docker is installed and running is essential.\\n   \\n2. **Terraform**: Installing Terraform is vital as you'll use it for infrastructure management.\\n\\n3. **PostgreSQL**: You might need to install PostgreSQL, especially for any database interactions.\\n\\n4. **Python Modules**: Ensure the installation of necessary Python packages such as `psycopg2`. You can install it via pip with `pip install psycopg2-binary`.\\n\\n5. **Any Required Updates**: For Windows users, ensure that your Windows Terminal, WSL, and Windows Security updates are up-to-date.\\n\\n### Learn\\n- Familiarize yourself with Docker commands and container management.\\n- Understand the basics of Terraform for managing infrastructure as code.\\n- Learn to connect Python applications to SQL databases like PostgreSQL using libraries like SQLAlchemy.\\n\\nThese installations and learnings will help you successfully navigate through Module 1.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e10dc87-4d41-42ca-a6f3-4dcd9a3423fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To do well in Module 1 of the course, here are some key things you need to install and learn:\\n\\n### Install\\n1. **Docker**: You'll work with Docker containers, so ensuring Docker is installed and running is essential.\\n   \\n2. **Terraform**: Installing Terraform is vital as you'll use it for infrastructure management.\\n\\n3. **PostgreSQL**: You might need to install PostgreSQL, especially for any database interactions.\\n\\n4. **Python Modules**: Ensure the installation of necessary Python packages such as `psycopg2`. You can install it via pip with `pip install psycopg2-binary`.\\n\\n5. **Any Required Updates**: For Windows users, ensure that your Windows Terminal, WSL, and Windows Security updates are up-to-date.\\n\\n### Learn\\n- Familiarize yourself with Docker commands and container management.\\n- Understand the basics of Terraform for managing infrastructure as code.\\n- Learn to connect Python applications to SQL databases like PostgreSQL using libraries like SQLAlchemy.\\n\\nThese installations and learnings will help you successfully navigate through Module 1.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63325b49-434d-4ca4-9381-d3d1287e574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c71bdae-ff21-4dc5-8777-daa1be1cc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "class CourseFAQTools:\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search the FAQ database for entries matching the given query.\n",
    "    \n",
    "        Args:\n",
    "            query (str): Search query text to look up in the course FAQ.\n",
    "    \n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\n",
    "        \"\"\"\n",
    "        boost = {'question': 3.0, 'section': 0.5}\n",
    "    \n",
    "        results = self.index.search(\n",
    "            query=query,\n",
    "            filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "            boost_dict=boost,\n",
    "            num_results=5,\n",
    "            output_ids=True\n",
    "        )\n",
    "    \n",
    "        return results\n",
    "\n",
    "\n",
    "    def add_entry(self, question: str, answer: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a new entry to the FAQ database.\n",
    "    \n",
    "        Args:\n",
    "            question (str): The question to be added to the FAQ database.\n",
    "            answer (str): The corresponding answer to the question.\n",
    "        \"\"\"\n",
    "        doc = {\n",
    "            'question': question,\n",
    "            'text': answer,\n",
    "            'section': 'user added',\n",
    "            'course': 'data-engineering-zoomcamp'\n",
    "        }\n",
    "        self.index.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6619ab2-56a7-42b6-938e-2f1c56ad8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_tools = CourseFAQTools(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03889d3e-177f-45ff-88b1-8694d4c6af6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'question parameter'},\n",
       "    'answer': {'type': 'string', 'description': 'answer parameter'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'query parameter'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = Tools()\n",
    "tools.add_tools(faq_tools)\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca8a9aa-678d-40be-b23d-f782d991b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Before making any function calls, explain your reasoning why you want to perform something.\n",
    "\n",
    "When searching in our FAQ, perform multiple search queries with diffierently phrased questions.\n",
    "\n",
    "At the end, as the user a question to make it more engaging\n",
    "\"\"\".strip()\n",
    "\n",
    "interface = IPythonChatInterface()\n",
    "\n",
    "chat = ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    interface=interface,\n",
    "    openai_client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2588ed-62c8-4721-9b81-b03440248a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: how do I do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To help the student, I will perform a search in the FAQ database using various phrasings related to succeeding in Module 1. This approach ensures we gather comprehensive guidance that may be available in the FAQs.</p>\n",
       "<p>I will start by searching for \"succeed in Module 1,\" \"how to do well in Module 1,\" and \"tips for Module 1.\" This will allow me to find relevant advice or strategies that have already been documented. </p>\n",
       "<p>Let me proceed with these searches.</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "                <summary>Function call: <tt>search({\"query\":\"succeed in Module 1\"})</tt></summary>\n",
       "                <div>\n",
       "                    <b>Call</b>\n",
       "                    <pre>{\"query\":\"succeed in Module 1\"}</pre>\n",
       "                </div>\n",
       "                <div>\n",
       "                    <b>Output</b>\n",
       "                    <pre>[{\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 112}, {\"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 124}]</pre>\n",
       "                </div>\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "                <summary>Function call: <tt>search({\"query\":\"how to do well in Module 1\"})</tt></summary>\n",
       "                <div>\n",
       "                    <b>Call</b>\n",
       "                    <pre>{\"query\":\"how to do well in Module 1\"}</pre>\n",
       "                </div>\n",
       "                <div>\n",
       "                    <b>Output</b>\n",
       "                    <pre>[{\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 112}, {\"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 125}]</pre>\n",
       "                </div>\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "                <summary>Function call: <tt>search({\"query\":\"tips for Module 1\"})</tt></summary>\n",
       "                <div>\n",
       "                    <b>Call</b>\n",
       "                    <pre>{\"query\":\"tips for Module 1\"}</pre>\n",
       "                </div>\n",
       "                <div>\n",
       "                    <b>Output</b>\n",
       "                    <pre>[{\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 112}, {\"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 125}]</pre>\n",
       "                </div>\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Here are some tips for doing well in Module 1 based on findings from the FAQ database:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand the Technology Stack</strong>: Module 1 often involves working with Docker and Terraform. Familiarize yourself with the basics of these tools. Their documentation can be immensely helpful.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Install Required Packages</strong>:</p>\n",
       "</li>\n",
       "<li>Make sure to install essential Python modules, such as <code>psycopg2</code>. You can do this using pip: \n",
       "     <code>bash\n",
       "     pip install psycopg2-binary</code></li>\n",
       "<li>\n",
       "<p>If you encounter an error stating that the module is not found, ensure you've also updated pip or conda.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Error Handling</strong>:</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>If you run into issues like <code>ModuleNotFoundError</code>, it could be due to not installing essential dependencies. For instance, double-check your environment to ensure everything is set up correctly.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Check Your Setup</strong>: Ensure that your development environment (like Jupyter Notebook) is configured correctly. If you face issues with Jupyter, you can try initializing the environment using:\n",
       "   <code>python\n",
       "   !pip install findspark\n",
       "   import findspark\n",
       "   findspark.init()</code></p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Follow Instructions Carefully</strong>: Pay close attention to the course materials and follow the setup instructions step-by-step, especially for Docker and Terraform configurations.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Practice Regularly</strong>: Hands-on practice with the assignments will solidify your understanding. Don't hesitate to experiment with the tools.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Ask for Help</strong>: If you encounter challenges, reach out to instructors or peers. Engaging with your course community can provide additional insights and support.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Do these tips resonate with your understanding of the module? Are there specific areas you want to focus on?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat ended\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc0aca-cd39-4841-996b-b28a2a3f0de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
